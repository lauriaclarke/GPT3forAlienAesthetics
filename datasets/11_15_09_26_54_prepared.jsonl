{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  4  Sensibility The philosophy of organism is the inversion of Kant’s philosophy.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  The Critique of Pure Reason describes the process by which subjective data pass into the appearance of an objective world. The philosophy of organism seeks to describe how objective data provides intensity in the subjective satisfaction. For Kant, the world emerges from the subject; for the philosophy of organism, the subject emerges from the world— a “superject” rather than a “subject.” The philosophy of organism aspires to construct a critique of pure feeling, in the philosophical position in which Kant put his Critique of Pure Reason . . . . Thus in the organic philosophy Kant’s “Transcendental Aesthetic” becomes a distorted fragment of what should have been his main topic. The datum includes its own interconnections, and the first stage of the process of feeling is the reception into the responsive conformity of feeling whereby the datum, which is mere potentiality, becomes the individualized basis for a complex unity of realization. Feelings are the “real” components of actual entities. Alfred North Whitehead, Process and Reality  The Precognitive Vocation of Twenty-First-Century Media “With ever-expanding volumes of stored data to draw upon, and new ways of connecting people, machines and forces— distributing and sharing their functions in a larger field of human and machinic agency— relationships are uncovered among widely disparate kinds of information. Through a technologically enhanced perception, a mathematical seeing,  the naked eye, in ways that augment, or occlude, traditional observational expertise and human intuition.”1 With this account of the contemporary technical distribution of precognitive sensibility, media artist and theorist Jordan Crandall perfectly captures both the vastly expanded sensory field within which contemporary events occur and the fine-tuning of our access to the separate, most often microtemporal performances, both machinic and human, that contribute to their occurrence.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  What is distinctive about Crandall’s account, and what motivates my invocation of it here, is his readiness to associate the technical transformations that lie at the heart of twenty-first-century media— and that witness a full-scale installation of a calculative ontology of prediction— with distinct modifications in the structure of experience. He rightly discerns that technological media are in no sense simply and solely technical, but are indelibly and inseparably technical, performative, affective, experiential, and sensory. Among Crandall’s various characterizations of the broad correlations between media technicity and experience, most fundamental for my purposes is his keen insight into the decoupling of effect and awareness— of causal efficacy and presentational immediacy— that characterizes the operationality of contemporary media. What accounts for the singularity of contemporary media is not simply that their data-driven operations bypass the scope of consciousness, but that they impact experience on a much broader basis than through consciousness. They literally seep into the texture of experience, forming a background, a peripheral “calculative ambience,” that indirectly flavors any and all resulting events or phenomena: As tracking becomes elevated into a condition, dissolving into behavior, sensation and all manner of embodied social practices in the data-intensive, analytics-driven spaces of megacities, the “sense of continual access to information” that arises out of the connectivity and interoperability among all kinds of data-enhanced actors (Thrift 2008: 92– 9) is not necessarily grounded in a direct access. It is not simply a matter of whether one has a direct connection to this data-intensive surround, since it increasingly constitutes a defining horizon against which the phenomena of the megacity are understood— a calculative ambience that imposes its distinction, categories and ways of being onto all facets of urban life— as it acts as a cognitive, ontological, and experiential supplement for the simplest forms of ordinary routine.2  With his appreciation for the supplementarity of twenty-first-century me-  plementary becomes more fundamental than what is supplements (in this case, consciousness), Crandall’s analysis directly addresses the experiential paradigm at issue here. In particular, it helps us to appreciate how the dataintensive, analytics-driven media surround operative in the contemporary urban environment operates not by affording direct, cognitive access to information, but rather by creating a tacit atmosphere of sensibility for action and capacities for data-gathering and analysis that open possibilities for precognitive shaping of— and capture of information about— our actions or likely tendencies for action. Crandall’s analysis underscores the close ties linking the experiential paradigm of twenty-first-century media to an increasingly sophisticated and ubiquitous technical capacity for gathering data concerning aspects of experience that are not directly accessible to us qua individual agents, that we simply cannot experience through consciousness and perceptual awareness.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In this sense, twenty-first-century media are characterized first and foremost by the capacity for capturing information that directly concerns our behavior and tendencies but to which we ourselves lack any direct access. This fundamental separation of data-gathering from experience forms the basis for what I shall theorize, with Crandall and others, as the precognitive vocation of twenty-first-century media. This vocation, in turn, stems from the tendency of twenty-first-century media to target the infrastructural or causally efficacious elements informing future behavior with the aim of reliably predicting such behavior before it actually happens. The precognitive vocation of twenty-first-century media is deeply imbricated within the operation of global capital. With the advent of network capitalism, the extraction of surplus value that is a generic feature of capitalism has increasingly come to focus on the value of data, as it were, “automatically” gathered from traces left by our living activity. A broad range of theorists, including Maurizio Lazzarato, Tiziana Terranova, and Franco “Bifo” Berardi, have reflected on how forms of immaterial labor have, with the acceleration of Internet culture, transformed into free labor: the production of content that, in a closed yet infinitely expanding spiral, serves as lure for further Internet traffic, and with it the production of more value. Post-Autonomist philosopher Matteo Pasquinelli, writing about Google’s PageRank algorithm, invokes the term “network surplus value” to distinguish this shift in value production: If the biopolitical dimension of Google is widely debated . . . , what is missing is a bioeconomic analysis to explain how Google extracts value from our life and transforms the common intellect into net-  Foucauldian paradigm that highlights only one side of the problem, as Google’s power is not given as a metaphysical being but it is originated from its technological platform and business model. . . .\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  The metaphor of the Panopticon must be reversed: Google is not simply an apparatus of dataveillance from above but an apparatus of value production from below. Specifically, Google produces and accumulates value through the PageRank algorithm and by rendering the collective knowledge into a proprietary scale of values— this is the core question. The political economy of Google starts from the political economy of PageRank.3  The crucial aspect of this example of network value is its automaticity: precisely because they contribute, because they cannot but contribute to the system of knowledge owned by Google, Internet queries using the search engine automatically produce surplus value. Itself an operation of twentyfirst-century media, network surplus value transforms data about human behavior that is not accessible to human awareness into surplus value, which is expropriated from human users by the data industries like Google that, in the form of PageRank, have implemented technical circuits for automatizing the generation of surplus value. The subterranean operation of such surplus value extraction explains why geographer Nigel Thrift can claim that contemporary capitalism operates first and foremost by exploiting its marginal advantage in manipulating this sub-perceptual data: What is new about the current conjuncture is the way in which capitalism is attempting to use the huge reservoir of non-cognitive processes, of forethought, for its own industrial ends in a much more open-ended way. . . . More recently, much thought has been given to understanding forethought as not just a substrate but as a vital performative element of situations, one which cannot only produce its own intelligibilities but which can be trained to produce ideas. . . . Now the intention is to read and exploit signs of invention by regarding the body as a mine of potentiality and to generate and harness unpredictable interactions as a source of value.4  Thrift’s account of contemporary data capitalism foregrounds the temporal dimension of its operation: if capitalist institutions have succeeded in exploiting the precognitive processes of bodily life that generate “forethought,” they have done so precisely because they have found ways to ac-  industries can tap the bodily processes leading to “foresight”— the domain of Whitehead’s causal efficacy— because they are able, with the help of microcomputational sensors, to access the sensory output of these processes independently of the normal embodied circuits that, via some kind of emergence, yield forethought as a bodily feeling, as affective anticipation. It is as if microcomputational sensors literally wrested these processes from their natural embodied context and made them independently operable and accessible. What independent access in this case affords is a capacity to manipulate “forethought” as a technical variable, and crucially, to exploit its value in time frames that are far closer to the operational time frame of the precognitive embodied processes than to the operational time frame of whatever cognitive output— “forethought” in its proper sense— emerges when they are processed by the body. To the extent that the time frames at issue here are smaller than those of bodily emergence, and are smaller— by an order of magnitude— than the time frames of time-consciousness, this operation is one that simply bypasses consciousness altogether, and that is literally premised upon such bypassing of consciousness.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  We must, accordingly, ask what becomes of consciousness and of perceptual awareness in the wake of the industrial conquest of forethought. Is consciousness simply left in the dust by the technical developments facilitating such an industrial conquest? Or must we rather find ways to redescribe the basic operation and function of consciousness for a new technicoexperiential reality? And can we ultimately move beyond the task of tracking the temporal disjunction between data operationality and consciousness that empowers contemporary capitalist institutions in order to gain access to and deploy the troves of sub-perceptual data made available by twentyfirst-century media for the end of our own experiential intensification? Because it grasps the correlation between data-intensive media and experience in its full potentiality, a theorization of twenty-first-century media like the one I have been developing here rounds out the picture that capitalist institutions would like to truncate. Theorization of twenty-first-century media shows that the sway exercised by contemporary capitalist institutions is a function of their capacity to control the time of experience to exploit this time as a source for surplus value. This fact makes twenty-first-century media a crucial site for political struggle over control of time itself in our world today. To challenge the contemporary exploitation of the time of attention by capital, we will need to contest the temporal problematic at its core.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  For this reason, it is crucial to point out that contemporary capitalist industries are able to bypass consciousness— and thus to control indi-  the massive acceleration in the operationality of culture caused by massivescale data-gathering and predictive analysis. These industries benefit from the maintenance of the crucial temporal gap at the heart of experience: the gap between the operationality of media and the subsequent advent of consciousness. We can get a sense for the temporal structure at issue here by comparing it with the microtemporal gap separating neuronal events from consciousness as neuroscientists like Benjamin Libet and Antonio Damasio understand it. In both cases, consciousness arises with a constitutive delay in relation to its causal efficacy. In the case of the brain, this delay is materialized in Libet’s famous “missing half-second,” the temporal gap between brain activation and awareness. In the case of twenty-first-century media, and its operation to supplement human experience, the delay is materialized outside the brain, in the temporal gap between data-gathering of the operational present of sensibility and the subsequent experience of this data by consciousness. Thus, where neuroscience questions the agency of consciousness, asking ultimately whether we have free will at all if consciousness is limited to the function of ratifying what has already been decided, twenty-first-century media effectively repress consciousness by rendering it an emergence generated through the feeding-forward of technically gathered data concerning antecedent microtemporal events. Despite their rough functional parallelism, a crucial factor differentiates the latter, technical delay from the former, neuronal delay— namely, its radical exteriority.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  The information captured by microsensors is accessed and fed-forward into consciousness not as the material basis for an emergent mental state but, quite literally, as an intrusion from the outside. As such, it does far more than simply support emergent mental contents; indeed, it captures a far larger swathe of the causal efficacy supporting the behavior that underpins such emergent states, including much that simply cannot find its way into consciousness via any organization or assembly of neurons. In this way, the data gathered by technical inscription makes available to consciousness aspects of its own causal background that it literally has no capacity to grasp directly, via embodied pathways, including neural ones. And it does this by way of a temporal dynamics that is characterized by a fundamental futural orientation: rather than marking the essential correlation of our present experience with what is now past—or, more precisely, just-past— as it does for the orthodox phenomenology of time-consciousness as well as for Whitehead’s concept of “nonsensuous perception,” this technically constituted delay reorients everything to an almost present future moment in which present, “operational” experience becomes— or more precisely,  will have become— available to consciousness and to further operations, including conscious reflection and deliberation and, importantly, targeted modification of embodied behavior. This is the “feed-forward” structure of twenty-first-century consciousness. Once again, Crandall seems to grasp the technico-experiential specificity of this temporal predicament: “As performatively constituted actiondensities, inferred through calculative, predictive or pro-active operations, an actor integrates and internalizes, consolidates and extends within the organizational and ontological horizon of tracking— a field that harbors a fundamentally anticipatory orientation. Actors are characterized by what they do— instantiation is action— and what they do is inflected by what they will do. Actuality is conditioned by tendency.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Embroiled in a calculative, mobilizing externality, agency pushes and is pulled outward, as if seeking to become the predisposition that it courts.” By grasping how behavior resonates with its own futurity, Crandall foregrounds one essential element of the experiential paradigm introduced by twenty-first-century media: the displacement of consciousness’s function from direct awareness of experience as it is happening to a supervisory role that can be exerted only indirectly over future experience to come. Within the complex and heterogeneous fields of contemporary sensibility, consciousness undergoes a fundamental retooling: as its direct perception of its own causal efficacy gives way to a much expanded and radically exterior technical inscription of this same causal efficacy that can only be fed-forward into, and thus indirectly experienced by, a future moment of consciousness, consciousness comes to learn that it lags behind its own efficacy. What consciousness experiences as its present— the present of sense perception— is, with respect to its efficacy, always already past. That, indeed, is precisely why Whitehead calls causal efficacy “nonsensuous perception”: by the time consciousness has sense perception of its sensory experience or experience of sensibility, the causal basis for that perception will have become past, will be no longer sensuously present. Yet, as I suggested above in chapter 3, perception of causal efficacy can be considered to be nonsensuous only because and only so long as it is forced to be experienced exclusively through and from the standpoint of consciousness, only because and only so long as it cannot be experienced more directly and more diffusely, through alternate, technical channels. Everything changes, however, when we factor in the capacity of technical microsensors to capture data concerning causal efficacy. For if I am right that today’s microcomputational sensors operate as sensing agents, then the data they generate about our behavior constitutes a form of worldly sensibility that marks a sensory present— the operational present of sensibility—  which, we can now see, is categorically distinct from the present of consciousness. In light of the newfound capacity to directly register the present of sensory efficacy, and to feed this forward into conscious experience to come, the necessity to channel causal efficacy through the presentational immediacy of consciousness— the very necessity informing Whitehead’s account of symbolic reference— would seem to dissolve.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  And what such a dissolution makes possible, we can now fully appreciate, is nothing short of a fundamental shift in the frame of reference that determines what counts as the sensory present: by directly capturing the sensory immediacy of causal efficacy in a form that is directly presentational (and that can be fed-forward into future consciousness as an alternate, artifactual source of presentified data concerning causal efficacy), today’s computational microsensors inaugurate the operation of a new level of presencing— the direct presencing of causal efficacy itself (the operational present of sensibility)— that both supplements and, in a sense, takes over the long-standing role and privilege consciousness has historically exercised as agent of presencing. While consciousness continues to experience its own narrow bandwidth reality through sense perception, this experience is disjoined, both temporally and operationally, from the distinct presencing of causal efficacy— from operational presencing— where, increasingly, behavior gets operated on and controlled, independently of any conscious access or input. To the extent that contemporary technologies for data-gathering and analytics allow for predictive precognition of what is to come, they manage to define a microtemporal, sub-perceptual— yet still sensory— present that impacts the future independently of any input from consciousness. As a consequence of this refining of the operationality of the present, consciousness must trade in its former monopoly over presentation for a supervisory role: since its presentational immediacy always comes too late in relation to the operational present, consciousness must give up its dream of coinciding with its own production and must redirect itself to predictively shaping its future behavior in light of the insight produced by the technical registration of the causal efficacy informing it. Rather than living the operational present of sensibility as presentational immediacy (i.e., through sense perception), consciousness can only live it as a deferred or after-the-fact experience of technically gathered sensory data concerning its own efficacy: consciousness literally encounters its own operationality only once this operationality has been fed-forward, as artifactual presentification or “machinic reference,” into a new present of that consciousness, a “future present” when it can be known before its belated effects come to impact consciousness directly, as an embodied causal source for symbolic reference. Reading Organs Directly This experiential paradigm, with its feed-forward structure, doesn’t simply impact the scope and operation of consciousness, but has significant effects on the way the body can be said to “mediate” worldly sensibility. In the place of Whitehead’s concept of the body as a ground where causal efficacy can be “perceived” and correlated with sense perception proper, we need to introduce a more porous and less self-referential conception of embodiment, a conception that understands the body to be a society of microsensibilities themselves directly and atomically susceptible to technical capture. In Society of Anticipation, French cultural critic and science fiction writer Eric Sadin correlates such a fluid, multi-scalar embodiment with the operation of automatization; for Sadin, the key point is that technical capture of embodied microsensibilities no longer serves to facilitate action or interactivity— no longer extends the body as an integral agency— but rather seeks to “read organs” themselves, with the aim of inducing compliance and reducing uncertainty: Our present moment bears witness to an integral automatization that excludes all subjective appreciation or process of dialogue in favor of a mute relationship determined by the prior recording of data and their verification via “anatomo-numerical” testing.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  At the heart of this automatization is a “reading” of organs no longer carried out with the goal of offering a more fluid relation to data, but in order to guarantee an optimization of social regulation . . . within a milieu technically capable of carrying out a roboticized indexing of people and of storing in the same movement the historical background of numerous actions and antecedents.5  Just as it did in the case of consciousness, this direct targeting of the organs chips away at the body’s privilege: no longer positioned as default mediator and integrator of worldly microsensibilities, the body has itself become increasingly dependent on technical supplements for its capacity to sense, or, more precisely, for its capacity to encounter— to em-body— worldly sensibility in its operational present. Again, the crux of this transformation concerns its temporal dimension; like conscious perception, bodily perception always comes too late, for by the time the body can integrate sensibility into a coherent perceptual organization, the force and living presence of sensibility will have already faded into the past. This temporal gap is precisely what gets artifactualized through the “reading of organs” performed  by today’s microcomputational sensors: the capacity to gather microtemporal data concerning worldly sensibility— the capacity to record “at the level of the organ”— exposes the lag of the body in relation to sensibility and positions computational sensing in the place formerly occupied by the integrated body. It is crucial that we pinpoint the source for this transformation. For it is not so much sensibility itself but rather our capacity to operate within the domain of sensibility that has changed. Indeed, experience has always included microsensibilities of all kinds, even if, up to now, these have been largely opaque in their operation, beyond our capacities for accessing them. What computational sensing and recording introduce is the capacity— indeed the power— to engage microsensibility directly, at a more granular level than what “resolves” upward on the matrix of the integrated body and ultimately that of conscious sense perception.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  If we understand this power to involve a technical contamination of bodily sensing and of worldly sensibility, as I think we must, we cannot fail to appreciate the political and ethical stakes of the transformation at issue here: by opening our embodiment to recording at the level of the organ and by making embodiment susceptible to direct microtemporal manipulation of worldly sensibility, this technical contamination risks bypassing entirely any agency we might (still) have over how sensibility gets shaped into experience. For if our bodily tendencies and susceptibilities are read independently of bodily integration, and if they become manipulable separately from and prior to such integration, then any emergent bodily integration runs the risk of being thoroughly epiphenomenal, a purely passive expression of infraempirical manipulation that will have already taken place at a level of experience to which it lacks all access. It is this risk that critics like Sadin and Thrift grasp so clearly. The capitalizing of precognition that they invoke constitutes a short-circuiting of bodily integration in precisely this sense: today’s data industries and experience engineers target the operational present of sensibility in order to manipulate— and thus to predetermine— the future emergence of bodily and conscious experience. Their strategy is to drive a wedge between the event of sensibility and any later event of bodily or of conscious experience such that the latter, despite being a direct or “natural” emergence from the former, no longer has any power to shape or to constrain how sensibility is experienced and the ends to which it is deployed. What is thereby effectuated is a decoupling of sensibility from perception that— precisely because it opens sensibility to manipulation independently of bodily integration— fundamentally interrupts their “natural” continuity. With this development,  what Libet postulates: for with technical access to the operational present of sensibility, experience can be manipulated prior to its resolution into bodily and perceptual effect, prior to its being felt through embodied affectivity and consciousness. Once again, the singularity of this threat, and particularly of its political dimension, can be discerned by way of contrast to the neuroscientific paradox of the missing half second.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  If this paradox can be solved, as certain philosophers have argued it can, by insisting that the mental is the relevant level of selection for neuronal events,6 no such solution is available where technical targeting of sensibility is concerned. In this case, sensibility is captured and manipulated by a technical agency that simply has no common ground with and that operates at a more primordial level than any perceptual or mental integrations that might subsequently emerge from it. Accordingly, if technical accessibility to sensibility poses a threat to free will, it is not due to some temporal gap within our “natural” cognitiveperceptual system, but rather to a gap between this system and a sensible field that is radically exterior to it. With their capacity to operate directly on that exterior sensible field before it affects our cognitive-perceptual system, today’s data industries are able to predetermine our responses in ways that simply bypass our agency. By exploiting the temporal specificity of twentyfirst-century media— the fact that technical access takes place faster than “natural” emergence— today’s capitalist institutions are able to capture sensibility, including the sensibility most intimately bound to our behavior, at a far more granular level than, and long before, we can. As a result, we are effectively deprived of the ability to shape and constrain how our sensibility becomes our experience. This situation exposes the technicity of the operational present of sensibility, the way in which the scope of the present depends on the degree of precision of technical access. From the perspective of today’s extremely fine-grained parsing of sensibility, we can appreciate just how much the “thickness” of the operational present is a fundamentally technico-historical artifact.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  That is why, prior to the moment when it became possible to access microsensibility in its operational present, the living (or sensory) present effectively encompassed a much thicker section of time than it does today: simply put, it was a function of a much cruder temporalizer, human time-consciousness. In this respect, Husserl’s descriptions of the present of time-consciousness furnish proof of sorts for this historically changing artifactuality: for Husserl, the time frame of the retentional-impressionalprotentional complex— the time frame of the qualitative experience of presence by consciousness— simply was the most minimal time frame for sensi-  the experiments of nineteenth-century psychophysicists, which certainly did give access to time frames beneath the thick now of Husserlian timeconsciousness, could not grasp microtemporal processes in their operational present, but only in retrospect. And the historical fact that the philosophical legacy of these experiments was largely derailed by twentieth-century phenomenology, beginning with Husserl’s epochē of sensation, only serves to lend support to the point being made here: for if the higher-order syntheses promoted by the phenomenologists held sway, it was on account of the need for a notion of living presence, a determination of the scope of the present as a function of human phenomenological experience.8 This situation also makes clear just how much the isolation of the operational present of worldly sensibility is a political issue calling for specific tactics on the part of critics who would seek to contest the alleged irrelevance of properly human modes of experience. First among such tactics is the exposure of the artifactuality of the operational present: far from correlating with anything “natural,” “essential,” or “necessary” about human experience (and indeed, about experience as such) in the world today, the narrowing of the operational present must be shown to be nothing more than the purely contingent result of a convergence of technical capacity, economic interest, and collective or social desire. In contrast to the missing half second of the neuroscientists, which in some sense does mark a delay in the “natural” relay from sensibility to perception (though see below), the disjunction of sensibility from perception that is targeted for exploitation by today’s data industries is thoroughly artifactual. Not only does this mean that it can be contested, it also means that it fits seamlessly within the pharmacological history of technics that I have introduced above and that concretizes why technological change is always a political issue: in the very gesture of rendering embodied humans susceptible to “integral automatization” (Sadin), today’s computational datagathering capacities open up newfound possibilities for reconstituting viable forms— or consistencies— of embodied life that are more open to and inclusive of worldly sensibility. Expressed more affirmatively, there is nothing about the data-fication of sensibility that requires it to be separated from and used against the higher-order agencies of perception. Indeed, because the separation is contingent, we can imagine— and can create— circuits that make use of the specific affordances of technical data-gathering and analysis, not solely to anticipate our tendencies and susceptibilities for purposes of manipulation and exploitation, but also to inform us about these tendencies and susceptibilities and let us act on and in virtue of them.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  By re-embedding the operationality of worldly sensibility within a thicker sphere of presence,  such larger circuits would bring the affordances of technical data-gathering to bear on phenomenal experience in ways that could enhance our capacities to shape our future experience. Let me now try to correlate my above account of the specificity of twentyfirst-century media with the isolation of the operational present of sensibility. Extending my earlier claim (in chapter 2) that media mediate nothing other than sensation, let me now suggest that media directly modulate worldly sensibility itself, and by so doing shape sensation before the emergence of bodily self-perception and consciousness. By operating on worldly sensibility prior to any impact they may subsequently have on human sense perception, media engage directly with the causal efficacy of the world’s selfperpetuation in a way that shifts the locus of presencing from perception to sensibility: on such an understanding, causal efficacy would no longer be the just-past of a present of consciousness— whether this be understood via Whitehead or via Husserl— but would assume its proper role as itself the relevant operational present in relation to which bodily perception and consciousness are still-to-come, futural emergences. In light of this situation— a situation that, to emphasize it yet again, is only made possible by our technical access to the operational present of sensibility— it should be clear that media theory must change its “object,” or rather, must trade in its focus on technical objects for a concern with the sensory processes to which technics gives access. Media theory, that is, must find ways to address the operational present of sensibility, for it is directly in the space of this microtemporal present— and not in the form of subsequently emergent bodily sensations or consciousness— that media primordially shape sensibility. What this situation requires is a politics of sensibility that, in contrast to the politics of memory articulated by Bernard Stiegler, focuses on the power of the microtemporal present of sensibility to shape future experience.9 As Sadin, Thrift, and others perfectly well understand, the contemporary capitalist targeting and isolation of the operational present of sensibility exposes the powerlessness of any media theory premised on the projection of a future through past achievements of perception and consciousness. For as soon as it becomes correlated with bodily self-perception and consciousness, media can only be about the past: from the standpoint of their respective presents, bodily self-perception and consciousness will have missed any opportunity whatsoever to intervene in the operational present of sensibility.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  For media to address the future— and for us to have any chance of “portending” a viable future— media must be engaged at the level of its modulating of sensibility, as causal efficacy, where it has the power to shape emergent experience to come, including the perceptual experience characteristic of the human. Developing the precognitive paradigm of twenty-first-century media sketched here thus requires two distinct, yet ultimately co-implicated, tasks. First, we must recognize and seek to understand the primordial role of media in shaping worldly sensibility, and we must differentiate this role categorically from its (still prevalent) role in recording and storing human experience as the contents of bodily and conscious life; far from a mere instrument that makes the content of bodily and conscious experience accessible to perception, media impact sensibility directly, prior to, yet in anticipation of, the emergence of such experience. And, second, we must struggle against the capitalist capture of causal efficacy by foregrounding the artifactuality of the separation of the operational present of sensibility from higher-order experience; such struggle will serve to remind us that the problem is not so much the technical accessibility to data of causal efficacy but rather the way that such accessibility can be used— and currently is being used— in total isolation from, and in order to bypass entirely, any and all subsequent integrations at the level of bodily perception and consciousness. That is why we must ultimately oppose the impoverished model of today’s data industries not by rejecting the basis for its operation (direct technical accessibility to data of causal efficacy), but by grasping and exploiting the pharmacological complexity of this operation: as a crucial new source of information about worldly sensibility, including information about our own behavior, the directly accessible data of causal efficacy can be integrated into larger behavioral assemblages that will help us form our higher-order behavior by modulating how media shape the sensibility from which such behavior emerges. The pattern for such integration— which stands starkly opposed to the instrumental targeting of sensibility— is precisely the operation of feed-forward where data about our behavior is “artifactually” made available to a just-to-come, future moment of consciousness before it will have bubbled up, as it were “naturally,” into consciousness. In this way, we acquire the capacity to access sensibility literally before we can perceive it. A double pharmacological imperative arises from this precognitive paradigm.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  First, we must struggle against the narrowly instrumental capture of sensibility that puts our power to shape our own experience at risk. And second, we must do this not by turning our backs on the technologies permitting such capture but precisely by using them in the name of a resolutely technical, yet in no way instrumental, experiential integration. We must, that is, embrace the technically accessible precognitive dimension of sensibility as the very ground on which to politicize media, to modulate our own becoming by intervening in how media shape sensibility, and to grasp the techno-sensible complexity involved in whatever agency we do in fact wield  Beyond “Reactive Corporeity” In his characterization of what he calls the “body interface,” Eric Sadin emphasizes how our contemporary moment introduces an “anthropological turning point” in our species-constitutive relation with technology: Historically, the relation to the technical object has been instituted and developed on the inside of a distance that aims to make good— “from the outside”— deficiencies of the body and to amplify its physical capacities; our period marks the end of this distance, to the benefit of a ever more closed-in proximity. A deplacement of the conception relative to technē is de facto called for, the latter no longer being envisaged, following the Western philosophical tradition, as a palliative and “prosthetic” production, or again, in the more informed manner described and analyzed by Leroi-Gourhan, as a relation of dynamic intermixture between instruments and corporeality. Technē must from now on be understood as an enveloping of virtualities offered to the body, which constitutes the fundamental anchor point for present and future technological evolutions, and which induces an automatized and fluid relation to the milieu.10  Sadin goes on to characterize this automatized and fluid relation as one that gives rise to an “unheard of reactive corporeality” rooted in the sensory fluidity between body and milieu: “The contemporary anthropotechnic condition no longer refers to a common ensemble that is nevertheless deployed in a gap (un écart), but to a principle of fusion witnessing a recent sympathy that ‘mutually makes body’ and that henceforth jettisons all distance for a sensory and automatized interaction operating on just in time fluxes, on the interior of a new bioelectronic unity.”11 With this characterization, Sadin foregrounds the necessity for reconceptualizing the model of technics that has been so forcefully advanced by Bernard Stiegler, in the wake of the paleontologist André Leroi-Gourhan. What Sadin makes clear is that we no longer confront the technical object as an exterior surrogate for consciousness or some other human faculty, but rather as part of a process that is far less differentiated and in which technics (data-gathering and analysis) operates directly on the sensibility underlying— and preceding— our corporeal reactivity and, ultimately, our conscious experience. To be even more precise: the “reactive corporeity” that Sadin theorizes engages contemporary technics— data-gathering, microcomputational sensing, predictive analytics— as a “radical exteriority”  tive corporeity differs from the temporal gap involved in emergent mental experience because it marks a radical divide between a cognitive-perceptual system and an exterior sensible field that is nonetheless part of what informs experience. Whereas the missing half second marks a constitutive delay within a homogenous process that occurs entirely in the brain, reactive corporeity entails a far more radical technical distribution of experience that moves outside the brain.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  This shift has important consequences for our understanding of how technics “contaminates” experience: for if technical processes impact sensibility before any higher-order emergence— and long before any differentiation of consciousness and technical object— we simply cannot treat technics exclusively or primarily as an exterior surrogate for consciousness, or, more generally, as an exteriorization of life by means other than life.12 Yet while Sadin clearly understands how this situation gives rise to a “precognitive orientation” rooted in our direct technical accessibility to data of causal efficacy, his impoverished conception of what this access affords (the reduction of the threat of chance) not only makes common cause with the imperative driving today’s data industries (the imperative to create closed data loops) but also fails to recognize any potential for our compensatory contact with worldly sensibility to yield new experiences and intensities. This situation exposes the tension between the radicality of Sadin’s analysis of the precognitive orientation and his limited resources for exploring its potential. For Sadin’s decision to focus on acts rather than tendencies ultimately causes him to miss the truly radical promise of a pre-agential experience of worldly sensibility. As our discussion of Judith Jones’s Intensity has made clear, this is precisely what Whitehead’s notion of the superject affords, once it is radicalized to overcome his bias toward concrescence. For if the causal efficacy of worldly sensibility obtains before there is a sensing agent— if the genesis of intensity from contrasts is, as Jones argues, subjectivity without a perduring subject— then any approach that exclusively tracks acts rather than tendencies engages at a level that is already too organized and that consequentially risks missing the promise of sensibility’s power. That is why Sadin, at the very moment when he contrasts today’s datacentric model of anticipatory evolution with natural selection, simply overlooks what is most promising about today’s “anthropological turn”: namely, how it puts us into recursive yet open-ended contact with a vastly expanded domain of microsensation. In this sense, the precognitive orientation facilitated by our direct technical access to worldly sensibility does not so much provide an alternate model for how humans evolve as it does a much  involves a complex overlay of multiple levels, an “operational overlap” that we could liken to William James’s notion of a “consciousness of still wider scope” where human, animal, and vegetable consciousnesses come together without losing their operational specificity.13 In this respect, if Sadin accurately grasps the link between the “continuous quantification of gestures” and a “precognitive orientation,” his continued talk about “our autonomy” (even if some of it is “delegated to our processors”) and his appeal to deterministic causality make clear that his interest centers on the tracking of acts and the capacity of such tracking to predict the future rather than the, to my mind, far more important opportunities thereby opened up to tap the more open-ended and more radical potentiality of tendencies. That is why Sadin’s analysis compromises its own promise: it sacrifices whatever benefit might accrue from exposing our human condition to “other modalities of existence” in favor of predetermination, of “a ‘possible avoidance or bypassing of chance’” rooted in “an anticipative and roboticized evaluation of acts .\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  . . that will determine the course of our individual and collective destinies.”14 The distinction between tracking acts and tracking tendencies foregrounds the crucial issue introduced by our direct technical access to worldly sensibility: the issue of how we should understand the “precognitive” dimension. Regarding this issue, our response is clear: we must resist the strict identification of the precognitive with the predictive capacity obtained through reduction of a worldly process to a closed circuit and, instead, affirm the de jure openness of worldly sensibility. Only in this way will we be able to conceptualize the precognitive in a fully general manner: as the partial inherence of the future in the present. Because it is Whitehead’s philosophy that furnishes the resources for such a conceptualization, making good on this imperative will require us to understand his account of real potentiality as nothing less than an ontology of the probabilistic potentiality informing contemporary operations of data-mining and predictive analytics. Specifically, with his account of the inherence of the future in the present, Whitehead furnishes an understanding of data as dynamically oriented toward the future. In this way, Whitehead is able to explain the power of prediction as a general power, one that lies at the heart of today’s predictive industries but that also informs the pharmacological flip side of the instrumental capitalization of real potentiality. With such an account, Whitehead helps us appreciate how human agents and collectivities can use prediction as a means to benefit from technically facilitated access to data of causal efficacy that cannot be accessed through conscious awareness and sense perception. Whitehead’s perspective reminds us that prediction is much more than a means of control wielded by to-  resource that could potentially allow human individuals and collectivities to feed data concerning the operational present of sensibility forward into future consciousness, and thereby, to make it relevant for future-oriented modulation of experience.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In characterizing this alternate deployment of prediction as the pharmacological flip side of instrumental capitalization of real potentiality, I aim to position it as a recompense for the enhanced control over behavior afforded by today’s microcomputational sensing capabilities. But I also aim to recognize its dependence on the very same technical capacities that make such recompense desirable, if not indeed necessary. In this respect, we could say that prediction focalizes the challenges faced by contemporary media theory. For with the ubiquitous dissemination of probabilistic predictive technologies in our world comes a fundamental shift in the status of sensibility: rather than being directly experienced by embodied, sensing human beings, sensibility has increasingly come to require— and indeed, to be experienced on the basis of— mediation via microsensors and predictive analysis. If I am right that contemporary data industries seek to target the operational present of sensibility independently of its inclusion within larger sensory-perceptual processes, we can readily discern the threat this shift poses to the power of sensibility. For what would happen if the exploitation of the operational present of sensibility began to occur in total independence from any return to the “slower” sensory-perceptual processes characteristic of human experience? Stripped of any and all means to experience sensibility— of any and all opportunity to feed data of sensibility forward into future consciousness— we would simply lose whatever pharmacological recompense twenty-first-century media could offer by way of increased contact with worldly sensibility. Far from functioning as a scare tactic or a flight into science fiction, this scenario— whose ultimate end point positions us as simple puppets of a predictive analytical system operating in complete autonomy from the domain of our sensory and conscious experience— should serve to catalyze consciousness-raising concerning the contemporary imperative to contest corporate control over the data of sensibility made accessible by twenty-first-century media.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Indeed, to combat the hyperbolically dystopian scenario just sketched, we must develop alternate ways of accessing and utilizing the data of operational sensibility such that it can be reintegrated into larger processes of sensory-perceptual life. The point, to say it yet again, is not to refuse the technification of sensibility nor to bemoan our dependence on computational microsensors for access to it, but rather to embrace both in the service of a different outcome: the broadening of human experience to encompass a greater share of the microsensible domain. his account of the future’s immanence in the present, Whitehead’s general ontology of potentiality shows that there is a surplus of sensibility underlying any and every prediction and that, to purchase reliability, predictions cannot avoid closing off such potential sensibility. What this means, to put it another way, is that contemporary computational capacities to “read organs directly” generate far more data (data of sensibility) than can be used by— and contained within— any system of predictive analytics. It is precisely on the basis of this surplus of sensibility that we can benefit from the predictive technologies driving the twenty-first-century media revolution. Reclaiming this surplus of sensibility from today’s data industries can and must constitute the main “positive” task of contemporary media theory: how, we must ask, can we access this data and deploy it for open-ended experimentation with the modulation of future experience? Exploring this possibility will require us to develop an explicitly nonanthropomorphic, nonrepresentational, and non-prosthetic account of media that situates their operation at the infra-experiential level of worldly sensibility itself. Thus situated, media become a technique for the modulation of sensibility that can be used to engineer experience in the just-to-come future.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Like prediction, media modulation operates on the operational present of sensibility, but there the similarities end: for whereas prediction narrows the scope of sensibility in order to assure maximum reliability, media modulation submits future experience to the potentialities— or propensities— of worldly sensibility in a radically open-ended manner. Because of its embrace of indeterminacy, this engineering in the operational present for the just-to-come future resonates with Nigel Thrift’s conception of worlding as the process of modulating experience by shaping “active spaces.” Thrift specifically contrasts active spaces to bounded spaces of technological spectacle and to the technical objects inhabiting them; unlike the latter, active spaces provide “a means of harnessing and working with process in order to produce particular propensities: this continuous activity of strategic intervention might be called worlding, with the emphasis on the ‘ing.’. . . The intention is not . . . to create fully-formed spaces. . . . Rather it is to add mediological detail which makes these spaces resonate in ways which would not have otherwise occurred so that they grow in desired directions. Not the creation of discrete worlds into which participants enter, then, but a continuous process of worlding.”15 In a similar way, any media modulation rooted in technically facilitated access to sensibility would attempt to influence the future on the basis of the full sensibility of the operational present— on the basis of the entirety of its “real potentiality,” and not solely through a narrow, instrumental selection of that potentiality. of media, let us dwell a bit longer on Whitehead’s crucial contribution to the effort to think through the complex pharmacological recompense that emerges on the basis of technical access to the operational present of sensibility. By way of what I have been calling his general ontology of potentiality, Whitehead is able to ground the inherence of the future in the present, to clarify how the anticipated future is felt in the present.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  It is crucial that we fully appreciate just how fundamentally this grounding and clarification differ from the method of predictive analytics: rather than forecasting the likelihood of future events on the basis of present and past data, Whitehead’s account foregrounds both the relative stability of the universe from moment to moment and the emergence of the future— and specifically of novelty in the future— on the basis of the real potentiality of the settled world at each moment of its becoming. If the future is felt in the present, that is precisely because the future literally is (or will be) produced from out of the real potentiality— which is equally to say, on the basis of the superjectal intensity— of the present settled world. The key point is that the connection between future and present proceeds by way of efficacy—or, better, propensity—and not of prediction. The connection is real, or, more precisely, it is actual without being actualized, which means, as we shall see, that Whitehead’s philosophy accords a certain priority to potentiality over actuality. With this perhaps surprising claim (given Whitehead’s repeated affirmation of the priority of the actual), we come back to the operation of superjective intensity that has proved so important for our understanding of Whitehead’s philosophy, and that is clearly manifest in the description of the Eighth Category in Process and Reality: (viii) The Category of Subjective Intensity. The subjective aim, whereby there is origination of conceptual feeling, is at intensity of feeling (∂) in the immediate subject, and (ß) in the relevant future. This double aim— at the immediate present and the relevant future— is less divided than appears on the surface. For the determination of the relevant future, and the anticipatory feeling respecting provision for its grade of intensity, are elements affecting the immediate complex of feeling.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  The greater part of morality hinges on the determination of relevance in the future. The relevant future consists of those elements in the anticipated future which are felt with effective intensity by the present subject by reason of the real potentiality for them to be derived from itself.16  To understand the full force of this claim, and specifically its promise to  Judith Jones radicalizes Whitehead’s description of intensity with her claim that the subject referenced in its final line, and the subjective aim animating it, simply is the agency of the contrast yielding intensity. As Jones puts it: “The agency of contrast is the subject, the subject is the agency of contrast. To be a subject is to be a provoked instance of the agency of contrast, and that is all it is.”17 We can now appreciate this claim in its full significance. For what Jones’s interpretation underscores is how the real potentiality of the future is already felt as intensity in the present— is felt, that is, prior to its actualization and in its full force of potentiality: this feeling of potentiality for the future generates— indeed, simply is— the subject. For Jones, this conclusion is the strict entailment of Whitehead’s concept of the vibratory character of actuality: The pattern involved in an intensive contrast is . . . the feeling of the dynamic presence of the (other) individuals felt into the unity of a subject’s intensity. This is the only way to understand Whitehead’s repeated assertion of the vibratory character of actuality.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  No vibratory character has only one cycle qua that vibratory character— to be a vibratory character is to be an intensive imposition on all subsequent process, and, on the other end, to have emerged from the enduring vibrations of other insistent agencies of contrast. I see no other way of understanding why provision for future intensity is included in the category respecting “subjective” concrescence.18  Jones’s point here is absolutely crucial: subjectivity, insofar as it is the intensity produced by contrasts of settled data, simply is a distillation of real potentiality for the future that is felt in the present, and whose feeling in the present impacts the emergence of the future, and specifically of the genesis of novelty in the future from intensity experienced in the present. As such, subjectivity cannot be restrictively located in the present, but spans the transition from present to future: it places the future— as real potentiality, as the force of historically achieved potentiality— in the present. Superjective subjectivity quite literally is the power of potentiality acting in the present on behalf of the future. For Whitehead (and for Jones), the future is already in the present, not simply as a statistical likelihood, however reliable, but because each new concrescence is catalyzed into becoming by the superjectal intensity or real potentiality— the future agency— of the universe that will be prehended in its entirety and that it will unify during its concrescence. And, if we accept Nobo’s understanding of the fundamental role played by the dative phase  powerful; indeed, what Nobo shows is that each new concrescence actually comes into being as a passive reaction to the data of the settled world, replete with its real potentiality for the future, real potentiality emanating from the future. How does this ontological model of potentiality bear on our efforts to adapt media theory to the situation of twenty-first-century media or, perhaps more pointedly, to the mediation of the total situation? And specifically, what significance does it have for the pharmacological reclaiming of contemporary media’s ever more impressive capacities to channel and to control the inherence of the future in the present?\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Recorded Future Consider the example of Recorded Future. Recorded Future is a small, Swedish intelligence company that sells a data-analytics service for predicting future events. Initially financed by small venture capital grants from the CIA and from Google, Recorded Future has developed algorithms that make predictions about future events entirely based on publicly available information, including news articles, financial reports, blogs, RSS feeds, Facebook posts, and tweets. Recorded Future has a client base that includes banks, government agencies, and hedge funds. What it offers is a technical platform designed to monitor the likelihood of future events or, as the company’s press puts it, a “new tool that allows you to visualize the future.” Two particular features of Recorded Future deserve our attention. First is its status as a “third-generation” search engine. Rather than looking at individual pages in isolation, as did first-generation engines like Lycos and AltaVista, and rather than analyzing the explicit links between web pages with the aim of promoting those with the most links, as Google has done since the introduction of its PageRank algorithm in 1998, Recorded Future examines implicit links. Implicit links, or what it calls “invisible links” between documents, are links that obtain not because of any direct connection between them but because they refer to the same entities or event.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  To examine implicit links, Recorded Future does not simply use metadata embedded into documents, but actually separates the content contained in documents from what they are about; Recorded Future’s algorithms are able to identify in the documents themselves references to events and entities that exist outside of them, and on the basis of such identification, to create an entirely new network of affiliations that establish relations of meaning and knowledge between documents, rather than mere associations. Journalist Tom Cheshire pinpoints the significance of this capacity for external reference  who Nicolas Sarkozy is, say: that he’s the president of France, he’s the husband of Carla Bruni, he’s 1.65m tall in his socks, he travelled to Deauville for the G8 summit in May. If you Google ‘president of France,’ you’ll get two Wikipedia pages on ‘president of France’ then ‘Nicolas Sarkozy.’ Useful, but Google doesn’t know how the two, Sarkozy and the presidency, are actually related; it’s just searching for pages linking the terms.”19 What is most crucial here is what Recorded Future does with the references it identifies, how it manages to construct those shadow references into a meaningful knowledge network with predictive power. To do this, Recorded Future ranks the entities and events identified by its algorithms. It ranks all of these entities and events based a myriad of factors, the most important of which include: the number of references to them, the credibility of the documents referring to them, and the occurrence of different entities and events within the same document. The result of this analysis is a “momentum score” that, combined with a “sentiment valuation,” indexes the power of the event or entity with respect to its potential future impact. For example, as Cheshire notes, “searching big pharma in general will tell you that over the next five years, nine of the world’s 15 best-selling medicines will lose patent protection”; the basis for this knowledge, which of course is only a heavily weighted prediction, is the high momentum score of the event, a score due to its being supported by thirteen news stories from twelve different sources. To fully appreciate the substantial predictive power of Recorded Future, we must introduce a second key feature: temporal dynamics.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Recorded Future includes a time and space dimension of documents in its evaluation, which allows it to score events and entities that are yet to happen on the basis of present knowledge about them— what, in Whitehead’s terms, we would call data of the settled universe. “References to when and where an event . . . will take place” are crucial, observes Staffan Truvé, one of Recorded Future’s cofounders, “since many documents actually refer to events expected to take place in the future.” By using RSS feeds, Recorded Future is able to integrate publishing time as an index for this temporal analysis. Such temporal analysis affords Recorded Future the capacity to weight opinions about the likely happening and timing of future events using algorithmically processed crowdsourcing and statistical analysis of historical records of related series of such events. The result: differentially weighted predictions about the future. At first glance, this procedure may appear to dovetail with Bernard Stiegler’s account of how today’s media industries support— or obstruct— “protention,” a term introduced by Edmund Husserl to designate the man-  Stiegler, the problem of culture today is its failure to facilitate any sense for a viable future— hence his appropriation of the punk slogan “No Future”; Stiegler’s wager is that this failure can be understood analytically through a transformative updating of Husserl’s model of time-consciousness. According to this updating, contemporary cultural industrial products— movies, television, advertising, marketing, video games, and so on— now monopolize the production of “collective secondary memories” which, following Stiegler, provide the source for anticipations of and expectations for the future. For Stiegler, there can be no viable future because this industrially manufactured source has literally taken the place of “natural” or “lived” secondary memories, and thus of collective cultural traditions that could furnish a living source for the invention of viable futures: as a consequence, whatever we today can imagine, anticipate, or expect are mere projections of possible futures that are rooted in and emerge as permutations of past manufactured or “tertiary” memories.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  How would this situation change if we were to develop a theory of protention on the basis of a media platform like Recorded Future? Whatever affinity there may be between Stiegler’s conception of protention as projection on the basis of manufactured collective secondary memories and Recorded Future’s weighted probabilities concerning future events, their methods are fundamentally dissimilar: for whereas Stiegler’s model operates in relation to a static source of fixed possibilities, a situation reinforced by his discretization of memory and the past as tertiary— that is, recorded and inert— contents of experience, Recorded Future operates in terms of probabilities that are generated not primarily through a processing of the repository of past, inert data of experience, but— crucially— through the power of present data to lay claim on the future, or, more precisely, through the power of the future to act in the present. By reorienting the directionality of media from past to future, Recorded Future— despite its own instrumental framework— performs an important service for the media theorist: specifically, it focuses questions concerning media’s impact around their capacity to predict— and potentially, to modulate— future experience. Not only must we take advantage of this technical development in our efforts to bring media theory up-to-date with media’s contemporary evolution, we must do so precisely by embracing the affordances of computational access to the domain of microsensibility, and not simply by adopting the rhetoric of futurity. Before pursuing this crucial opportunity— which means returning to Whitehead’s conception of “real potentiality”— let me explore another key point of difference between Stiegler’s protention and Recorded Future’s pre-  any role whatsoever for mental content. Whereas protention via projection relies on mental content— it is literally the carrying over of past memories to the future in the form of expectations— protention via weighted prediction eschews all dependence on mental content, and with it, any narrowing of the vehicle for protention to higher-order, exclusively human operations like memory. Accordingly, in contrast to Stiegler’s conception of protention as a continuity between present and just-to-come that takes place through mental processing (albeit collective and technically supplemented mental processing), protention as it might be modeled on the basis of Recorded Future is a function of the material, causal insistence of the future in the present of worldly sensibility and not, in any way, a mental projection or continuity from present to just-to-come. It is not enough to say that such “worldly” protention or protention in this more general scope— protention rooted in the power of the total present world to impact the future— doesn’t depend on any mediation via mental content.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  For what is truly distinctive about protention is its fundamental inaccessibility to and by the mental. Accordingly, the power informing it— the power of the settled world in its totality— can only be fed-forward into a future moment of the mental life of consciousness that, by definition, must be discontinuous with it. Let me note in passing that this “nonmental,” datacentric model of protention goes quite a way toward resolving the impasse of phenomenological accounts of protention which founder on the vexing question of how present consciousness can portend a future content that has not yet been lived— indeed, that has not yet even been constituted— as a content of consciousness. The material model of protention resolves this impasse by shifting the terrain for continuity with the future from mental content to data, the vast majority of which cannot be filtered through minds or time-consciousness. If material, nonmental protention actively and repeatedly reconstitutes the continuity of present with future, it does so by wielding the power of present data to partially determine the future, and thus to include (a part of) the future within it. To fully appreciate this power, let us put it into dialogue with Whitehead’s claim that every actuality prehends the entirety of the universe as it exists at the moment of its becoming. Because it furnishes an ontological basis for conceptualizing the relation between present and future, this forceful speculative claim provides a grounding for the process of prediction at the same time as it provides a critical check on the scope of any and all claims to predict the future. Remember that what Whitehead means by prehension (as explored above in chapter 3) is something like grasping, and prehension can be positive, where some element of the settled world is included in an  a mode of exclusion that still constitutes a relation.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  By saying that every actuality prehends the entirety of the universe as it exists at the moment of its becoming, Whitehead thus means something fairly straightforward: that every actuality, every new element in the universe, arises on the basis of all of what has come before. Though on the surface reminiscent of Bergson’s conception of perception as selection of images by a center of indetermination within a universe of images, Whitehead’s account actively eschews the operation of selection— an operation which gives pride of place to actualization of the virtual and to some privileged form of self-reference— in favor of an embrace of the total situation, and the ensuing access to the real potentiality of the total situation as it exists in itself, that is, prior to the selective genesis that occurs in relation to, and that ultimately yields, a new actuality. Whereas for Bergson, what is perceived is a certain actualization of the virtual universe of images, for Whitehead, what is prehended is potentiality, the superjective subjectivity that attaches to every element of the entire settled world and that, following the Category of Subjective Intensity from Process and Reality, “aims at intensity of feeling . . . in the relevant future.”21 In saying that every actuality prehends the entirety of the universe, Whitehead is in effect arguing not just that every actuality includes in its present feeling its potential to impact future actualities but also— and to my mind more importantly— that it feels the potentiality for the future in its present, and indeed, as part of what constitutes the causal force of the present. Its intensity simply is the index of the power of this potentiality. It is the solidarity attributed by Whitehead to the extensive continuum that explains how potentiality implicates the future in the present: “the extensive continuum is ‘real,’” he writes, “because it expresses a fact derived from the actual world and concerning the contemporary actual world. All actual entities are related according to the determinations of this continuum; and all possible actual entities in the future must exemplify these determinations in their relations with the already actual world. The reality of the future is bound up with the reality of this continuum.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  It is the reality of what is potential, in its character of a real component of what is actual.”22 On this account, what implicates the future in the present is ultimately nothing other than the total ensemble of causal nexuses operative at any moment in the ongoing process of the universe, or, more concretely, in any given settled state of the superjectal world: this total causal ensemble just is the “real potentiality” of that settled state. Whitehead’s speculative account of the solidarity of the universe, and the crucial role it accords potentiality both of and for the future, addresses the total causal reality of a situation that is, by definition, beyond empiri-  analytics, including Recorded Future, that, no matter how sophisticated their algorithms become and how much data they will be able to process, by necessity operate on delimited, closed sets of data. That is why, as I have already suggested, Whitehead’s process philosophy furnishes a general ontology of probabilistic potentiality capable of grasping how our datacentric world works. Even though it exceeds— or rather, precisely because it exceeds— the grasp of any particular predictive system or empirical perspective, Whitehead’s ontology of the “total situation” and his account of the future’s inherence in the present explains what gives prediction its particular (necessarily limited) power: the implication of future potentiality as a real power in the present. With this conclusion, we can pinpoint the accomplishment of Recorded Future and begin to explore how it might contribute to the pharmacological recompense of twenty-first-century media. For with a third-generation search engine like Recorded Future, the mining and analysis of data takes a “Whiteheadian turn” in the sense that it ceases to ground the power of prediction in a recursive analysis of past behavior,23 and instead— taking full advantage of recently acquired technical capacities for text analysis— channels predictive power through the reference of present data to future entities and events. In this sense, we might say that Recorded Future concretizes Whitehead’s understanding of how the future is felt by the present: “Actual fact,” writes Whitehead, “includes in its own constitution real potentiality which is referent beyond itself.”24 A Whiteheadian explanation of Recorded Future thus reveals a “positive” dimension of prediction: more than a mere extrapolation of the causal force of the present and the past to future possibility, prediction concerns the potentiality contained in the transition from present to future. The key point is that this potentiality, despite being imperfectly reliable as a ground for prediction, has indisputable ontological power: the very power that is at issue when Whitehead characterizes potentiality as the mode through which the future is felt in the present.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Of course, the scope and power of the reference involved in Recorded Future’s predictive analytics and in Whitehead’s ontology of potentiality are of entirely different orders of magnitude: the former is an empirical instantiation of the insistence of the future in the present; the latter, a general speculative “explanation” for the power exercised by the future in the present. This contrast in the scope and power of reference brings us back to the question of the pharmacological promise of data-mining and predictive analytics. How, we must now ask, does Whitehead’s philosophy contribute to the pharmacological recompense we have sought to discover in the operation of twenty-first-century media? Or, more specifically, how does  to reveal a compensatory dimension of a transformation of contemporary capitalism that seems hell-bent on simply bypassing consciousness and human agency as such? The answer to this question has two parts. First, by furnishing a speculative account of the “total situation” informing the genesis of every new actuality, Whitehead’s account of potentiality in effect foregrounds the impossibility for any empirical analytic system— no matter how computationally sophisticated and how much data it can process— to grapple with the entirety of real potentiality, or anything close to it. Rather, driven by a grandiose— and, in the end, fundamentally incoherent— desire “to organize the world . . . for analysis,” systems like Recorded Future can— and no doubt will— get more reliable by including more data, but their reliability will always be purchased at the cost of inclusiveness: reliability, that is, is a function of the capacity to close off some data from the larger universe of data surrounding— and complicating— it.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In this sense, Whitehead’s speculative account serves as a critical check on totalizing impulses of today’s data industries, a guarantee of sorts that the future, even though it can be (partially) felt in the present, can never be known or actually experienced in advance. In this way, Whitehead’s ontology of potentiality exposes the surplus of sensibility that must be closed off for potentiality to become reliably predictive. Second, by facilitating a model of technical distribution of sensibility rooted in an expansion of perception beyond consciousness and bodily self-perception, Whitehead’s philosophy helps us understand how a thirdgeneration technical platform like Recorded Future can impact human experience in potentially positive ways— ways that go beyond the narrow and largely instrumental purposes that inform governmental and corporate deployments of it. The capacity to predict future events through present reference refines a technical platform for accessing a larger quantity of data of sensibility that is relevant to human behavior but that remains inaccessible through human modes of perception; as such, it increases the amount of data that is available for the shaping of human behavior in the future. Isn’t this twofold investment in the power of potentiality the source for the appeal of the recent television drama Person of Interest, in the sense that it features superhero-like characters who have imperfect knowledge of the predictions of an all-knowing but fully mysterious “machine” and who must act— and must embrace the uncertainties of acting— if they are to prevent predicted future murders? What Person of Interest dramatizes is a technical distribution of agency in which a highly sophisticated computational machine accesses data of worldly sensibility and feeds it forward into  film Minority Report (and even more so Philip K. Dick’s 1956 short story “The Minority Report” on which it is based), Person of Interest contains no possibility for an existential moment of self-recognition where one can modify one’s “precognized” fate; rather, the characters “blindly” follow the clue furnished by the machine until they can, by acting in the near futureoriented present, figure out how the person identified by that clue is involved in a future murder and act to prevent its occurrence. Gone here is any hope for a reconciliation of the knowledge afforded by data (the precog’s visions of the near future) and the knowledge afforded by experience: the “numbers” generated by the machine, which correspond to unique identities of persons (i.e., their social security numbers), brook no interpretation. They function simply to trigger an action-based process of search that never fails to yield the desired goal of preventing murder.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  What makes Person of Interest so resonant with my general claim concerning twenty-first-century media is its taken-for-granted embrace of the “machine,” or rather The Machine, as a sophisticated cognitive agent whose workings remain absolutely inscrutable to humans— indeed, unquestionably beyond human exploration as such. From what little we are told about the machine, we know that it processes massive amounts of video surveillance and cell phone data— the passive data that lies at the heart of twenty-firstcentury media— in order to make incomplete but fundamentally reliable predictions concerning the future. By depicting a co-functioning between the machine and the characters acting on its predictions, Person of Interest allegorizes the very condition I am seeking to theorize: the imperative for us to embrace the qualified marginalization of consciousness that goes together with— that is, as it were, the price to be paid for— any opportunity we might have to benefit from the technical access to the operational present of sensibility. Indeed, with its various compensatory narratives— one episode, for example, involves the salvation of a post-9\/11 war veteran whose guilt over the death of a fellow soldier and desire to support his family has led him to commit multiple armed robberies— Person of Interest could well be read as an allegory of the pharmacological recompense of twenty-first-century media: by depicting the use of data extracted from human activity, not as a new source of economic value, but as the instigator of superhero-like doinggood, the show capitalizes on the potential, and the popular desire, for cold, quantitative— dare I say “inhuman”— data to benefit human life. Media Modulation What kind of media theory does the politics of sensibility I have been de-  specificity of my interest in Recorded Future. I am interested in how it exemplifies what I take to be a new technical paradigm of media that is both future-directed and committed to the extraction and analysis of data of microsensibility. In this respect, Recorded Future is important less as a concrete technical platform that media theorists might literally or practically deploy than as a demonstration of the new potentials for media to open up the domain of sensibility not simply for prediction of future events but also for modulation and intensification of future behavior. What remains to be worked out is what role media might play in such modulation of sensibility.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Nigel Thrift, whom I have discussed above, furnishes one account that, due to its complexity, broad scope, and explanatory power, can serve to jump-start a discussion of the contemporary vocation of media theory. As we have seen, Thrift attempts to think media modulation in terms of propensity, where the function of media would be less that of providing stable objects for consciousness, or even stable sedimentations of memory, than that of continuously tweaking ongoing, largely precognitive tendencies in light of desired experiential outcomes. As Thrift sees it, and I would wholeheartedly concur, media modulation occurs at the level of “premediation,” prior to the emergence of perceptual experience. It should come as no surprise, then, that media modulation has served the interest of those contemporary institutions of capitalism— most prominently, neuromarketing, experience design, and predictive analytics— that focus on excavating and exploiting the precognitive domain. The key question for us is how— and indeed whether— media modulation can also be enlisted in the service of experiential amelioration, of making our lived experience more intense, more interesting, more rich, and more enjoyable. Like Sadin and Crandall, Thrift seizes on the incursions that capitalist institutions have made into the body and the precognitive dimensions of experience: thus, neuroscientific models support capital’s “emphasis on more effective everyday creativity” by attempting “to mobilize the momentary processes that go to make up much of what counts as human. Persons are to be trained to ‘unthinkingly’ conjure up more and better things both at work and as consumers, by drawing on a certain kind of neuro-aesthetics which works on the myriad small periods of time that are relevant to the structures of forethought and the ways that human bodies routinely mobilize them to obtain results.”25 Thrift leaves little doubt as to who is in control of this excavation: as exemplified in strategies for design composition that mobilize “thing power” and create environments “rich enough in calculative processes to allow the neuro-aesthetic to function more forcefully,” the aim of this excavation is “to produce a certain anticipatory readiness about  changeable opportunities, thus adding to the sum total of intellect that can be drawn on. This is a style which is congenial to capitalism.”26 The question this rather bleak picture raises is how any account of media that would deploy the resources of premediation for the purposes of experience modulation can manage to evade the grip of capital, of what philosopher Catherine Malabou diagnoses as the reduction of neuronal and experiential plasticity to the flexibility central to regimes of post-Fordist capitalism.27 This issue arises forcefully in Thrift’s 2008 account of how contemporary capitalism uses media to influence “hormonal swashes”: The intent is clear— to identify susceptible populations and to render them open to suggestion.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  That involves a series of techniques which allow the susceptibility of populations to be described and worked upon. To begin with, contemporary information technology allows populations to be gathered up and monitored in ways heretofore impossible, for example, through emotional stance, with the result that it increasingly becomes possible to track mimetic rays. The rise of analytics premised on the mining of very large and continuously updated data sets allows “prediction competition” to become general. Then, through the internet and various mobile technologies, it becomes possible to rapidly feed information and recommendations to these populations, producing a means of trading on those susceptibilities that have been identified. Finally, it also becomes possible to enter into something like an individualized dialogue with members of these populations, so that they feedback their reactions, both producing more information on their susceptibilities, and new triggers. In extremis, they may well produce their own new and innovative variants which can themselves become the basis of new business. In other words, an era of permanent survey of populations replaces the fractured surveys of “samples.”28  Despite its neutral tone, Thrift’s diagnosis of the closed circuits of contemporary data capitalism would appear to leave little room for any more hopeful modulation: with their capacity to ensnare populations in data loops that they alone can process, today’s data industries manage to hijack and to control the operation of the “precognitive,” thereby wresting it from its “natural” function of priming human perceptual activity and targeting it in a hyperaccelerated time frame that simply bypasses human involvement altogether. What this diagnosis brings to the fore is the question of the technic-  but precisely because of its bleakness: for if humans find themselves wholly foreclosed from this scene of precognitive sampling, the reason is— let me repeat— that they have absolutely no “natural” capacity to act within, or even to access, the microtemporal time frames involved.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  As diagnosed by Thrift, the operation of contemporary data capitalism unequivocally establishes that access to the precognitive requires technical mediation— and indeed, a form of technical mediation that is radically out of sync with the rhythms of human experience, including the affectivity associated with the neural processes that prime perception. With this diagnosis, Thrift pinpoints precisely what media theory needs to theorize in order to understand how media operates in a world where even primordial sensibility is co-opted by industry. The broadly pharmacological perspective I have been developing here helps us appreciate the significance of Thrift’s embrace of media’s radical exteriority, of its operation outside of any “space of subjectivity,” including the space of the brain-mind that neural imaging technologies, following in the wake of the braintime experiment, have opened up for analysis and exploitation. Specifically, it can help us see why, for Thrift, the potentiality for media to modulate sensibility must stem directly from the “extra-subjective” nature of its operationality. Exploring the evolution of Thrift’s account over the past decade will help us to get a better understanding both of the imperative for and the resistance against the feed-forward structure that I have argued characterizes human experience of twenty-first-century media. Specifically, the position at which Thrift arrives in his 2008 article on propensity perfectly illustrates the ambivalence that, I would suggest, cannot but attend any effort to embrace the pharmacological structure of twenty-first-century media. It is precisely because of such ambivalence that we find Thrift, on one hand, ready to embrace the radical demotion of human phenomenological agency made necessary by twenty-first-century media, and on the other, reticent to give up the last vestiges of this agency. As I see it, Thrift’s position, notwithstanding its embrace of some of the most radical implications of contemporary technical incursions into the body, retains a misguided— because unsustainable— “faith” in phenomenological agency as well as a certain technophobia, both of which lead him in turn to adopt a misguided conceptualization of what the pharmacological recompense of twenty-first-century media precisely is or can be.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Within the terms of the 2008 article, Thrift’s ambivalence centers around the possibility for “reengineering presence”: “What if,” he asks, “presence can be reengineered” on the basis of “an alternative realism appealing directly to sensation and perception? . . . Certainly, that is what is being at-  struction of a giant temporal shortcut. For all their comparative speed, neural and genetic changes still take time to impact the body but now, courtesy of new technical practices which are driven by the logic of propensity and make appeals directly to particular biological territories, simulations of their work can come into existence all but immediately as sensations and perceptions.”29 With their capacity to operate directly on the present of sensibility, today’s media industries are able to create simulations of sensations and perceptions that simply take the place of “naturally-occurring” sensations and perceptions. By effectively co-opting our role in generating our own experiences, this substitution manages to preserve the phenomenological appearance of experience even as it severs all ties between that appearance and its underlying causal basis in embodiment. The key question thus raised— a question that Thrift would seem to skirt more than to answer— is whether such simulated experience is indeed capable of reengineering presence, and if so, whether this would be a presence that can be experienced by human bodyminds. Everything in Thrift’s 2008 diagnosis of the industrial co-optation of sensibility suggests a negative answer to this question: what he has shown is that the simulated sensations and perceptions central to the operation of contemporary data capitalism, like our above account of the data of sensibility, take place at time frames that are faster than neural time, and that, for this very reason, simply cannot be directly lived by embodied humans. If Thrift seems reticent to accept this reality, it is, I suggest, due to a misplaced hope in “neurophenomenology” and, more precisely, to his mistaken conviction that braintime can furnish a “space of action” for embodied humans.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Although it is developed most fully in Thrift’s earlier work on premediation and the space of the missing half second, traces of this hope linger in Thrift’s 2008 account of the “creation of neurophenomenological worlds” and the “science of ‘placing’” that affords the possibility to “create something like the all-at-onceness of phenomenological worlds on a temporary basis.”30 In accord with this lingering hope, Thrift invests the changes wrought by technical incursions into neurophenomenology— changes to “the very sensory and perceptual pathways” on which people rely to experience the world— with the power to mobilize and to strengthen phenomenological experience of the world.31 In this way, he is able to position these technical incursions as antidotes to the “the brutally instrumentalist view that underlies developments like neuromarketing.”32 What is missing from Thrift’s account is any explanation of how expanded technical agency over the operational present of sensibility can in fact benefit phenomenological modes of experience. This is just what my  by embracing our non-phenomenologizable dependence on technics and the resulting temporal indirection or scrambling— the requisite projection into a just-to-come future— by which we are able to experience the artifactual “presentifications” afforded by technical access to data of sensibility. The contrast with feed-forward thus helps pinpoint exactly what is missing from Thrift’s account: namely, an appreciation that whatever access we do have to the operational present of sensibility is mediated by— and thus dependent on— a non-phenomenologizable, thoroughly technical, and artifactual process. More than a simple theoretical oversight, Thrift’s failure to appreciate this situation is rooted, as I have already suggested, in his earlier investment in the neural space-time of the half-second delay. As he explains in an essay reprised in his 2007 collection, Non-Representational Theory, this neural space-time furnishes the site for the construction of a “new structure of attention.” What was formerly invisible or imperceptible becomes constituted as visible and perceptible through a new structure of attention which is more and more likely to pay more than lip-service to those actions which go on in small spaces and times, actions which involve qualities like anticipation, improvisation and intuition, all those things which by drawing on the second-to-second resourcefulness of the body make for artful conduct. Thus, perception can no longer “be thought of in terms of immediacy, presence, punctuality” (citing Jonathan Crary) as it is both stretched and intensified, widened and condensed. . . . The result is that we now have a small space of time which is increasingly able to be sensed, the space of time which shapes the moment. Of course, once such a space is opened up it can also be operated on. . . . What is being ushered in now is a microbiopolitics, a new domain carved out of the half-second delay which has become visible and so available to be worked upon through a whole series of new entities and institutions.33  Thrift’s investment in the missing half second as a space of agency— as, precisely, “a small space of time that is .\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  . . able to be sensed”— is premised on the notion that technicity can operate within phenomenological experience as a mechanism to expand its temporal scope and sensitivity.34 In concert with Libet and the contemporary cultural theorists who radicalize his work, but also with the Whitehead, who restricts causal efficacy to “nonsensuous perception” (as explored in chapter 2), the 2007 Thrift depicts the technical  also as the revelation of a new “space of action” for embodied human beings. For this Thrift, it is as if the discovery of the neural timespace of the half-second delay opened up a space of action that is available equally to corporations and to individuals— available equally for the exploitation of attention and for the refining of sensory and perceptual capacities. The governing assumption here— that technicity and phenomenality somehow operate at the same level— is precisely what must be given up if we are to understand the full consequences of twenty-first-century media’s incursions into the operational present of sensibility. As I have been arguing throughout, sensibility implicates human experience from the outside: it constitutes a source for that experience that simply cannot be presentified within it and that must be introduced into it, through technical mediation, as a radically exterior power. In this context, we can see that Thrift’s earlier position doesn’t just ignore the massive imbalance in resources that allows today’s data industries to atomize and hijack the operational present of sensibility (effectively wresting it from the larger circuits of embodied becoming within which it itself becomes). It also fundamentally misunderstands the meaning of the missing half second. Contra Thrift, but also contra Massumi and others who have invoked it as an affective anticipation of perception, the missing half second simply cannot constitute a space of action in which more fine-grained sensations and perceptions can arise. This is because, not unlike the technical circuits afforded by twenty-first-century media, it is a thoroughly technical artifact that, as historian of science Henning Schmidgen has compellingly argued, results from and cannot exist or operate independently of the construction of a “cyborg assemblage” in the laboratory.35 Far from being a faculty of (human) experience, which is how Thrift, Massumi, and others effectively treat it, the missing half second is an artifactual construction that has no agency independently of its technical setup— that, in short, has no “natural” agency whatsoever.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Not only does this mean that the missing half second cannot exist as a self-standing agency, independently of the technical apparatus facilitating its presentification, but it also means that it cannot directly function to intensify or granulate sensing and perceiving. There simply is no direct phenomenological interface onto the operation of braintime. The picture the 2007 Thrift paints is thus wrong, both in its thematization of the missing half second as a “space of action” and in its assessment of the neutrality of the technicity involved in its presentification. Far from first “opening up” the “small space of time . . . which shapes the moment” for apprehension in sense perception, the technical presentification of the missing half second is from its very onset an originarily technical  by the “fastest bidder,” by whatever institution can access it most quickly. Although capacities for manipulating the space of the missing half second have multiplied exponentially in the wake of digital computation, the structure of its operation has remained constant since the mid-nineteenth century when the protocol of what Schmidgen calls the “braintime experiment” was initially configured. This protocol involves using technical acceleration to access psychophysiological processes imperceptible to “natural” perception in order to slow them down for subsequent perceptual apprehension.36 What is true for these psychophysiological processes— namely, that they cannot constitute agencies independently from the technical setup that makes them accessible— is all the more true for the domain of sensibility opened up by twenty-first-century media. That is why what we learn from the longer history of the braintime experiment can help us to appreciate what is involved in the industrial co-optation of sensibility: rather than operating on the basis of a gap within our “natural” perceptual faculty, a gap between neural processing and subsequently emergent mental phenomena, this cooptation, as the protocol of the braintime experiment shows, operates on a gap between our “natural” perceptual faculty and the radically exterior domain of sensibility.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  And it is also why Helmholtz’s psychophysical research paradigm, insofar as it develops an experimental practice on the basis of the braintime experiment, constitutes a particularly crucial forerunner of the account of feed-forward I develop here. What Helmholtz puts into place as a methodology for a scientific research program premised on the dethroning of consciousness has now become an everyday reality: living with twenty-firstcentury media calls for a constant give and take with media flows that evade conscious presentification and that require data supplementation and an abandonment of the long-standing privilege of conscious attention and perception as the privileged or sole arbiters of experience. In short, the everyday reality I am seeking to describe in my account of twenty-first-century media is the same reality embraced by the Helmholtzian natural scientist faced with a world operating according to its own protocols: despite differences of scale, what is at stake in both cases is an embrace of a technically distributed cognitive system in which consciousness takes a backseat to the power of data and its capacity to access the microtemporal structure of worldly sensibility.37 We can get a clear sense for the stakes involved in the historical lineage of the braintime experiment— and in the radicalization it undergoes in its repositioning as the infrastructural pattern of experience in twenty-firstcentury media environments— by recalling what I have suggested above in  imperative of technics. When our behavior becomes accessible as technically generated data that we ourselves cannot experience directly (which is to say, phenomenologically), the long-standing prosthetic pharmacology that characterizes media history undergoes a fundamental transformation. Put schematically, we could say that it loses its prosthetic basis since the loss of our agency over our own behavioral data is recompensed by something that has no direct correlation with it, namely, the affordances of social media and the Internet. By splitting the pharmacological structure of media, this transformation introduces an experiential level— the world of social media and the Internet— as a false recompense for what is really going on, namely the extraction of “data-value” in the form of user profiles. What is particularly interesting about this splitting, and what merits the characterization of a “perversion,” is the way it overlays a traditional pharmacological narrative (we give up our data and are given in return the affordances of social media) on a quite different story (we give up our data and are thereby transformed into commodities, data profiles, to be sold to the highest bidder). We can get a clearer understanding for the nuances of this transformation by comparing social media with writing.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Writing, as both Derrida and Paul de Man established in their work on figures like Plato and Hegel, involves the replacement of one form of memory (interior memory, or Erinnerung) with another (artifactual memory, or Gedächtnis).38 And despite the success of their deconstructive readings in revealing the dependence of interior memory on technical memory— which is also to say, the “originary technicity” of memory— there is a sense in which writing qua technical memory serves, or, more exactly, has always served, as a recompense, and indeed as a phenomenological recompense, for the weaknesses of natural memory. Despite its superficial similarity to the pairing of interior and exterior memory, the pharmacological relationship at work in contemporary techniques for gathering data about what happens in the missing half second— and in the braintime experiment more generally— involves the deployment of technics to access and presentify data that is radically disjunctive with phenomenological modes of experience. For, whereas artificial memory aids as theorized by philosophers from Plato via Hegel to Stiegler technically exteriorize memory without changing the form of its content, technical access to data of sensibility and to the neural processes constituting braintime operate in lieu of any possible phenomenological mode of experience. Twenty-firstcentury media operate on and with data that cannot take the form of contents of consciousness, that simply cannot be lived by consciousness. Like Etienne-Jules Marey’s graphic and chronophotographic machines which must be understood to be autonomous sensing agents that possess their own  the heart of Helmholtz’s psychophysical research paradigm, today’s cyborg assemblages that access and capture the data of sensibility do so in radical disjunction from any possible (future) presentification to perceptual consciousness. Accordingly, when this data is fed-forward into our embodied experience, as I have argued it must be if it is to be experienced by us at all, it marks and cannot but mark the intrusion of a radical exteriority into consciousness, an exteriority that cannot so much be interiorized as introjected. This is why any attempt to grasp the technicity introduced by twentyfirst-century media by way of affectivity— understood as a sub-perceptual but nonetheless still direct connection to sensibility— remains insufficiently radical. It remains insufficiently radical because the technical capture and feed-forward of data of sensibility simply has and can have no direct experiential interface.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Even those affective dimensions of experience that serve to prime ensuing perceptions can neither be directly experienced, nor be made to capture the broader and more primordial interface with worldly sensibility that, as I have sought to demonstrate, comes before the consolidation of any subjective unity capable of hosting such affectivity. In full resonance with Whitehead’s description of the dative phase, this interface generates a primordial feeling, a primal impressionality, that is preaffective— a feeling without a feeler. With this clarification of the preaffective impact of technics on sensibility, we are in a position to pinpoint the significance of Thrift’s 2008 account of media modulation and to gain a better understanding for why he remains unable to fully appreciate its radical consequences. First, its significance: the 2008 Thrift rightly abandons the model of an affective intensification of experience and the concomitant notion of a space of action within the missing half second in favor of a more radical localization of technicity beneath embodiment, including neural embodiment. It is precisely because this Thrift refrains from embedding perception in the continuity from the neuronal to consciousness and situates the industrial intervention into experiential time “beneath” even the half-second interval that he is able to capture what is essential about our contemporary predicament: namely, that the industrial reengineering of the present is equivalent to an industrial co-optation of sensibility. On the basis of the “giant temporal shortcut” informing the operation of today’s data industries, Thrift can conclude that the reengineered present evades not just the time frame of consciousness but also the time frame of affect and of the preperceptual affective domain. Yet, as I announced above, Thrift cannot bring himself to embrace the radical consequences of this conclusion: he can neither accept that technicity is required to access primordial sensibility nor recognize that twenty-  first-century media provide the means, indeed the only means, for securing such access. Thrift’s lingering hope for a phenomenological interface with the reengineered present thus betrays an underlying technophobia.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  For if Thrift is right that the industrial co-optation of sensibility operates through a “giant temporal shortcut” that literally bypasses human processing as such, the only consequential conclusion that he could come to would be to embrace the displacement of phenomenological agency in favor of technical processing. What Thrift should have concluded is that the preaffective present or operational present of sensibility, because it can only be accessed as a space of action in the present through technical means, requires the (co)operation of today’s data industries, or, at least, of the technical interfaces they have developed. That Thrift cannot draw such a conclusion attests in equal measure to his lingering hope in phenomenology and to his repressed, covert technophobia. The very same logic informs Thrift’s failure to embrace the underlying pharmacology of this situation: he simply cannot recognize that whatever recompense might come to us from the technical access to sensibility must come through the very operations that lie at the heart of today’s data capitalism. To do so would require Thrift to give up what he seems most unwilling, and indeed, unable to give up: the hope for a direct phenomenological interface with the reengineered, preaffective present. It is thus perfectly understandable that Thrift doesn’t envisage the possibility for an alternate, “phenomenology-implicating” engagement with the operational present of sensibility: the operation of feed-forward. Rather than seeking to restore human sensory and perceptual agency within the present of sensibility, as Thrift’s various recipes for the creation of “neurophenomenological worlds” all do, the operation of feed-forward recognizes the radical opacity of this preconscious and preaffective domain and utilizes the technical means developed by today’s data industries to access it precisely in order to feed it forward into just-to-come future experience of embodied consciousness. Whereas Thrift’s recourse to instantaneous simulation mistakenly indulges the vain fantasy of human agency within the domain of braintime, feed-forward perfectly instantiates the “diagram” of the braintime experiment as it has been repeatedly performed in the laboratory since the 1860s: feed-forward brings very fast— and by definition, non-phenomenologizable— processes into the slower space-time interval of durationally embodied human experience.39 In light of the radical short-circuiting of sensory and perceptual experience that, as Thrift’s analysis reveals, occurs with the contemporary industrial reengineering of the present, it is imperative that we expand our account of feed-forward.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  To the account I have developed thus far— an ac-  count which focuses on the feeding-forward of actual data of sub-perceptual, microtemporal levels of experience (data of causal efficacy or of worldly sensibility)— we must add a second, more indirect account: feed-forward as the prospectively oriented modulation of sensibility itself. With the aim of inducing particular kinds of sensory and perceptual experiences, this form of feed-forward shapes propensity in the inaccessible operational present. On this score, there is much we can learn from Thrift. Indeed, we can find a basic blueprint for this second form of feed-forward in Thrift’s understanding of how adding “mediological detail” to existing spaces might enhance their sensory potentiality or resonance. Yet in developing an account of mediological modulation, we must constantly bear in mind that we are not reengineering the present to expand human agency within the space of that present. On the contrary, we are modulating a present we literally cannot live in order to engineer experience to come in the future— a comingpresent that we can live. Accordingly, the impact of mediological modulation cannot be direct— in the sense that media effects would directly impact human sensations and perceptions— but must be indirect and predictively anticipatory: such modulation intervenes at the level of worldly sensibility itself prior to, but not without relation to, whatever affective, sensory, and perceptual experience might arise from and through it. Put another way, such modulation involves designing media environments that channel preaffective sensibility in ways predictably likely to yield certain kinds of affective, sensory, and perceptual experiences.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In sum: because the operational present of sensibility directly targeted by data capitalism lies outside the domain, and beyond the reach, of embodied perceptual and affective experience, the modulation of sensibility at issue here, including the modulation of environments for sensibility, must follow the diagram of feed-forward: such modulation must, that is, develop the potential for a mediological shaping of the domain of sensibility that would be “autonomous” from any direct connection to human affections, sensations, and perceptions, and that would embrace the technicity “essential,” if not to its very mode of being, than certainly to its mode of access. That is why nothing less is at stake here than the very status— indeed the autonomy— of media itself. For what lies at the heart of mediological modulation in the sense sketched above is an operation of media that takes place beneath the phenomenological (including the “neurophenomenological”) and that is disjoined from any immediate or direct human impact. Exploring the potentiality for mediological modulation of sensibility will accordingly require us to develop a non-anthropomorphic, non-phenomenological, and non-prosthetic theory of media. Mediating the Vibratory Continuum The resources for such a non-anthropomorphic, non-phenomenological, non-prosthetic theory of media can be found in Whitehead’s account of the “extensive continuum.” Introduced by Whitehead to furnish a speculative explanation for the solidarity of the universe, the extensive continuum— or, more precisely, the vibratory continuum specific to our universe— provides a conceptual grounding for understanding “real potentiality” as worldly sensibility. For our purposes here, the most fundamental aspect of Whitehead’s account of the extensive continuum is his investment in vibrations as worldly, which is to say, as wholly separate from concrescences. By establishing the independence of vibrations from the activity of concrescence, Whitehead’s development of the vibratory continuum positions vibrations as the core elements of a potentiality (“real potentiality”) that obtains force prior to and separately from the attainment of actualities. For this reason, as I shall now go on to argue, Whitehead’s account of the vibratory continuum provides the capstone for the claim for inversion (CIF) that has structured my understanding of his process philosophy throughout this study.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Indeed, Whitehead’s account of the vibratory continuum furnishes an explanation for the all-important superjective power of worldly sensibility (the settled universe in Whitehead’s language) that, as I have been arguing, exceeds the conceptual category of “transition” and the restricted oscillatory process informing Whitehead’s account of process and creativity. The vibratory continuum gives a concrete expression to the webs of relationality that are left in the wake of objectification (i.e., that are constituted when attained actualities reenter the settled world). Far from ratifying the attributes of inertness and passivity imposed on attained actualities by the Whiteheadian orthodoxy, recontextualizing attained actualities in relation to the vibratory continuum serves to foreground the significant subjective, or, better, superjective agency they possess as fundamental elements of worldly sensibility. Vibrations are the very matter of causal efficacy and, as such, are characterized by three traits— promiscuity, ubiquity, and futurity. As Jones succinctly puts it (and I shall return to this claim below), “to be a vibratory character is to be an intensive imposition on all subsequent process.”40 On this view, the ultimate “purpose” of process is nothing less than the propagation of vibrations (or sensibility), which is why Whitehead’s account of the vibratory continuum marks the final stage in the inversion that reassigns concrescence the humble role of vehicle for process— or, as we can now properly appreciate, vehicle for the propagation of vibrations. Together with this reassignation of the role of concrescence comes a shift  in focus, a shift to the creativity of experiential entities (societies) that are all, ultimately, more or less complex compositions of vibrations. This shift instantiates, in yet another configuration, the claim of access to the data of sensibility (CADS) that has informed my understanding of twenty-firstcentury media throughout this study. Indeed, the proposal to localize media in relation to the vibratory continuum— the proposal I am here introducing as a foundation for a non-anthropomorphic, non-phenomenological, and non-prosthetic account of media— goes hand in hand with an emphasis on the creativity of access.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  This conjunction of localization and creativity, in turn, allows for a certain specification of my argument concerning twentyfirst-century media: rather than itself introducing some new domain of experience, the system of twenty-first-century media marks the revelation of a dimension of sensibility— the operation of worldly sensibility— that has always been there, that has always impacted our experience, but that has remained largely opaque to our understanding because inaccessible to our (human) modes of perceiving, sensing, and experiencing the world. What is “new” about twenty-first-century media, then, is less their technical disjunction from past media than their opening of the operational present of sensibility to various forms of modulation, including most prominently (as we have just seen) capitalist ones. It is, in other words, the very act of opening experience to an expanded domain of sensibility that lends twenty-firstcentury media their power to impact human experience. To put it schematically, twenty-first-century media are characterized by two features, both of which reiterate the emphasis I have been placing on the operation of access: (1) they mark the technical revelation of (and new forms of access to) an expansive domain of worldly sensibility that lies behind and remains in excess of any delimited act of feeling, sensing, perceiving, thinking, or understanding; and (2) they catalyze a gradual shift in the economy of experience, and with it, a shift from human-addressed media to environmental or (we might now say) vibratory media, which shift however is not “determined” by media so much as it is emergent from the power of sensibility that media open up. Still more simply stated, twenty-first-century media present a situation where the very act of accessing worldly sensibility itself constitutes a transformation in the texture of experience. In the present context, the crucial point is the localization of media in relation to the vibratory continuum: twenty-first-century media impact human experience not “in itself ” or directly— as has been the case (at least predominately) with media up to now— but precisely and only insofar as they open up, modulate, and channel the power of worldly sensibility itself. Twenty-first-century media impact human experience, then, because they  sibility, because they provide an opportunity for worldly sensibility to be brought to bear on human experience without requiring that it first be reduced to the modes of experience characteristic of the human. In this sense, twenty-first-century media can be thought of as a “host” for worldly sensibility, and insofar as we can position it as a “surrogate” for the human bodymind (what I have referred to above as “machinic reference”), it potentially brings the bodymind into a far more robust contact with sensibility than it can realize through its own built-in modes of feeling, sensing, perceiving, understanding, and thinking.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  One of the key factors motivating my embrace of this localization of media within the vibratory continuum is a desire to avoid reducing twentyfirst-century media to understandings of media that too readily and too quickly couple them to human modes of experience. Beyond this general injunction, however, my embrace of the vibrational ontology of media concerns the promise of Whitehead’s process philosophy, and of his conception of the vibratory continuum more specifically, to furnish a concrete account of how media can impact human experience by operating directly on or at the level of vibrations. Once again, the crucial element at work here is the independence of vibrations from the activity of concrescence. At the same time as it liberates vibrations to serve as elements of a potentiality that is “prior” to the activity of attainment, this independence renders vibrations addressable for technical modulation separately from their participation in concrescences and in eternal objects that are ingressed into actualities during concrescence. When media modulate sensibility, which happens in large part simply because they open access to sensibility, they grasp and channel the power of worldly vibrations at a level “prior” to their participation in subjective unifications: they address and mediate vibrations as disparate elements of the disjunctive plurality that is worldly sensibility. By similarly localizing media within the vibratory continuum, sound theorist Steve Goodman proffers a “non-anthropocentric ontology of ubiquitous media” that moves beyond the instrumentality of contemporary conceptualizations of media objects in order to underscore the sensory— or vibrational— power at the heart of media effects. Because of its broad convergence with the argument I am developing here— but also because of its divergence from my investment in worldly sensibility— Goodman’s ontology can help us negotiate some of the difficulties involved in localizing media in relation to the vibratory continuum. Specifically, as we shall see, Goodman’s allegiance to the orthodox narrative that enthrones concrescence as the site and source of creativity prevents him from making good on the promise of his localization of media in relation to the vibratory continuum.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In this  For Goodman, what is at stake in this localization of media in relation to the vibratory continuum is the potential for media to become fully expressive: From cymatics [the study of how static objects are affected by vibration] to the vibratory anarchitecture practiced by artists such as Mark Bain . . . , a set of experimental practices to intensify vibration has been developed for unfolding the body onto a vibrational discontinuum that differentially traverses the media of the earth, built environment, analog and digital sound technologies, industrial oscillators, and the human body. Each actual occasion of experience that populates this discontinuum will be termed a vibrational nexus, drawing in an array of elements in its collective shiver. This differential ecology of vibrational effects directs us toward a nonanthropocentric ontology of ubiquitous media, a topology in which every resonant surface is potentially a host for contagious concepts, percepts, and affects. In this speculative conception of ubiquitous media, not just screens (and the networks they mask everywhere) but all matter becomes a reservoir of mediatic contagion. By approaching this topology of vibrational surfaces without constraint to merely semiotic registers that produce the “interminable compulsion” to communicate, media themselves are allowed to become fully expressive. An outline of a vibrational anarchitecture, then, diagrams a topological mediatic space that cuts across the plexus of the analog and digital, the waveform and the numeric sonic grain, implicating the continuity of the wave into the atomism of the granular.41  With its central notion of a vibrational nexus, Goodman’s account takes a cosmological approach to media that breaks definitively with the anthropocentric pact informing (most) contemporary media theory: far from requiring media to be channeled through human faculties in order to have experiential effects, Goodman’s account locates media operations and media effects at an experiential level that is both indifferent to traditional humanist divisions (human-nonhuman, animate-inanimate, etc.) and imperceptible to and through traditional human modes of sense perception and conscious attention.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  At the heart of Goodman’s ontology of vibrational force is a nonanthropocentric, cosmological conception of feeling that he discovers in Whitehead. For Goodman, Whitehead’s philosophy constitutes an aesthet-  Whitehead’s thoughts on rhythm and vibration form an aesthetic ontology of pulses. To say that Whitehead’s ontology is aesthetic means that he posits feeling, or prehension, as a basic condition of experience. . . . His ontology revolves around a nonanthropocentric concept of feeling. This notion of prehension exceeds the phenomenological demarcation of the human body as the center of experience and at the same time adds a new inflection to an understanding of the feelings . . . of such entities. To feel a thing is to be affected by that thing. The mode of affection, or the way the “prehensor” is changed, is the very content of what it feels. Every event in the universe is in this sense an episode of feeling.42  For Goodman, Whitehead’s aesthetic ontology is structured according to a non-anthropocentric “hierarchy of categories of feeling” that encompasses all levels of experience from the fundamental “wavelengths and vibrations” of the subatomic physical universe to the sophisticated contrasts involving merely possible situations characteristic of human consciousness.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  The correlation of feeling with vibration is what facilitates the becomingcosmological of media. At the furthest extreme from the myopic imperialism of human perception, Whitehead’s vibrational ontology postulates vibrations as the very root of all feelings in the universe. On this account, feelings pertain directly to vibrations— or more precisely, to the contrasts among vibrations that generate intensities— before they characterize properly subjective formations. When he emphasizes the excess of vibrations over the entities in which they participate, Goodman perfectly captures this situation: “It is a concern for potential vibration and the abstract rhythmic relation of oscillation, which is key. What is prioritized here is the in-between of oscillation, the vibration of vibration, the virtuality of the tremble. Vibrations always exceed the actual entities that emit them. Vibrating entities are always entities out of phase with themselves. A vibratory nexus exceeds and precedes the distinction between subject and object, constituting a mesh of relation.”43 Beneath their phenomenological solidification into stable, perceptible objects, vibrations create a field of relationality that yields the “real potentiality” for any actualization whatsoever.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Indeed, to say that vibrations necessarily exceed the entities that actualize them is to say that vibrations have the mode of being of potentiality. But it is also, more broadly, to assert that potentiality is ontologically more fundamental than actuality. Precisely because vibrations exceed any given actualization, the vibratory field of relationality they generate furnishes a source of superjectal potentiality within the spatiotemporal continuum. It is crucial that we grasp  or power that lies within the settled world but is not proper to concrescing actualities. This superjectal potentiality simply is the potentiality of the settled world that, as a total situation, goes into the genesis of every new actuality, and that, for this very reason, cannot itself be the product of such genesis. I call this potentiality “superjectal” precisely to indicate the radical exteriority of its operation in relation to concrescing actualities: it designates a power that belongs to vibrations insofar as they exceed the entities that actualize them in their own concrescences. The excess at issue here is an excess over, not an excess of: it does not depend on the concrescences that it catalyzes, does not belong to the entities resulting from such concrescences, and is not relative to their becoming. Far from being the product of particular actualizations, the vibratory continuum stands behind and supports them: it simply is the “real potentiality” that— in our spatiotemporal world— generates the vibratory contrasts that catalyze new concrescences as part of the world’s continuous reproduction.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  This excess proper to vibrations is crucial to what I consider to be Whitehead’s fundamental contribution to a non-anthropocentric conceptualization of media. Though Whitehead himself does not address media directly, his ontology of vibration, and the fundamental correlation of vibration with feeling, allows us to locate media’s operationality at the level of (or at least in relation to) the vibratory continuum itself, without requiring that it be channeled through any delimited subjective process. More simply still, Whitehead’s ontology allows us to conceptualize twenty-first-century media’s impact— their power to modulate the continuum— in terms of potentiality: if media shape the potentiality for the world to impact future experience, they do so from the outside— from the radically environmental perspective of the total situation of the settled world that, as we have seen, precedes the genesis of any agent-centered subjective perspective. In his effort to develop a non-anthropocentric account of media rooted in Whitehead’s vibrational ontology, Goodman would appear to seize the opportunity presented by this radically environmental operation for situating media beyond phenomenology. Nothing less seems to be at stake in his localization of media beyond perception: “If we subtract human perception, everything moves. Anything static is so only at the level of perceptibility. At the molecular or quantum level, everything is in motion, is vibrating. . . . All entities are potential media that can feel or whose vibrations can be felt by other entities.”44 By defining media in this way— in terms of potentiality for feeling or being felt— Goodman would seem to keep them open to the superjective operation of the settled world, and thus to install media directly within— indeed, as the very agency of— worldly sensibility. tion.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  He cannot make good on his own radical position because of a lingering commitment to the privilege of concrescence and to the operation of “eternal objects” as the vehicle for vibrations to mediate relations. This commitment makes up one pole of what we can only describe as a fundamentally contradictory account of media: like Whitehead, Goodman holds up concrescence as the source for all actuality. Yet, directly countering this commitment is Goodman’s engagement with Whitehead’s vibratory ontology: specifically, Goodman invests the extensive (vibratory) continuum as a primordial source of potentiality. The result is that Goodman holds two commitments that stand at loggerheads one to the other: to the extent that the latter commitment to the vibratory continuum as source of potentiality requires an affirmation of the superjectal as the subjective modality of worldly sensibility (as Nobo and Jones both help to demonstrate), it directly impugns the coherence of the former commitment to the priority of concrescence. From my perspective, the only way to overcome this impasse is to aggressively develop the affirmation of the superjectal: we must invest in Goodman’s own investment in the radical environmental agency of the superject. That is why, as I shall go on to argue, it is out of the ashes of this conflict between the two poles of Whitehead’s thinking (instantiated here in Goodman’s dual commitments) that a truly environmental and nonanthropocentric theory can emerge. Signs of Goodman’s ambivalence appear in the very language he uses to define media, and specifically in the phrase, “whose vibrations can be felt by other entities.” For the qualification of “vibrations” with “whose” suggests that the vibrations belong to a “feeler” and are subsequently felt— as vibrations belonging to past “feelers”— by other entities functioning as “feelers” in their turn. In these constructions, all agency lies on the side of “feelers” or “prehenders,” and none pertains to the vibrations themselves.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Yet if the power of vibrations themselves is more primordial than the agency to which they give rise, as Jones has helped us understand, we can hazard the following functional definition of twenty-first-century media: grasped in terms of their superjectal operation, media modulate vibrations whose contrasts in turn produce other entities, and with them, new webs of relationality. This functional definition is equivalent to our earlier characterization of media as vehicles for channeling worldly sensibility toward specific experiential accomplishments. In both instances, the emphasis is on the indirect relationship between the source for creativity (worldly sensibility or vibratory continuum) and the resultant experiential events or processes: media operate as instruments that mediate sensibility for experiential achievement. One key advantage of this definition is its sensitivity to superjective po-  even if vibrations can and do create relations between entities, their impact on the experience of such entities remains indirect. Grasped at the level of the vibratory continuum, media must designate something far more specific than a relation that obtains when one entity shares vibrations in common with another entity: media channel the operation of vibrations, and vibrations, together with media’s modulation of them, are only subsequently felt by entities. Moreover, media channel vibrations for experiential accomplishments that include those experiences we typically associate with humans; in this sense, they play a much broader role than what Goodman imagines, for well beyond supporting the operation of concrescence, they mediate between the domain of sensibility and higher-order regimes of experience. In sum, entities and experiential societies alike do not feel media directly; what they feel are media effects, the way that media channel or modulate the vibratory continuum for specific purposes. Both entities and experiential societies can thus be said to feel media’s modulation of the vibratory continuum, and it is their response to this latter, which catalyzes their feeling, that bootstraps them into becoming.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  By correlating media with the channeling of sensibility, this definition helpfully specifies the scope of media’s operationality: media operate on real potential prior to any actualization, and indeed, as I said above, they potentialize real potentiality in the sense that they bring the latter to bear on specific forms of experiential achievement. This correlation with potentiality underscores the error that is involved when media are identified— as they are on Goodman’s account— with the activity of concrescence. Simply put, media cannot be identified with concrescence because such identification contradicts the vibratory continuum’s status as real potentiality. To the extent that they operate in and through the vibratory continuum, media impact the potentiality of vibrations themselves. They thus modulate a field of potentiality that can only be environmental in relation to any future concrescence, as well as to any experiential society they may inform. That is why Goodman’s effort to place media in the vibratory continuum, and to accord mediatically inflected vibrations a priority over actualities, founders. This effort, despite its general congruence with the account I have sought to develop here, is simply incompatible with Goodman’s overriding insistence that concrescences of actual entities produce the continuum: Whitehead’s notion of the extensive continuum undoes the split between space and time. It expresses a general scheme of relatedness between actual entities in the actual world.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  More than that, Whitehead insists that the extensive continuum is, above all, a po-  the actual is atomic or quantic by nature. The continuum is not pregiven but exists only in the spatiotemporal gaps between actual occasions. Rather than an underlying continual invariant, each actual entity produces the continuum for itself from the angle of its own occurrence. Only in this way is the continuum the means by which occasions are united in one common world.45  Everything comes down to how we understand Goodman’s phrase, “a potential for actual relatedness.” On the one hand, the invocation of potential here would seem to indicate an awareness of— and an effort to capitalize on— the status of the vibratory continuum as the font of real potentiality for the genesis of new actualities. Yet, if that is the case, what can it mean to claim, as Goodman goes on to do, that each actual entity produces the continuum for itself? Let us explore this question— and the problem it poses for Goodman’s argument— by looking to an alternate view of how the vibratory continuum relates to actualities. In his complex and innovative work on extension in Whitehead’s speculative ontology, philosopher Jorge Nobo argues that the extensive continuum weaves together a meshwork of real potentiality— a meshwork rooted in the superjective power of attained actualities— and thereby provides the basis for the thinking of solidarity that anchors Whitehead’s ontology. Nobo’s work will be useful here on account of its radical claim that the real potentiality created by worldly vibrations is more primordial than the production of actualities: understood in relation to our earlier exploration of the key and grounding role played by the dative phase, we can now see that it is the vibrational continuum itself that furnishes the objective datum for concrescences, and hence for the production of new webs of superjectal relationalities that, as I have sought to emphasize (following my claim for inversion), are the true agents of process in our contemporary world.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In this respect, Nobo’s account furnishes a mechanism for appreciating how media impact experience by way of their flavoring of real potentiality for the future: if twenty-first-century media produce data, and if their production of data has become increasingly central to the operation of contemporary society and the worldly sensibility involved therein, we can conclude that media now play a predominant role in supporting the ongoing production of real potentiality itself. Both in the form of actual data objectified and reentered into the settled universe and, equally importantly, in the form of data about this objectified data of sensibility (which in turn becomes objectified data), media have a pervasive, yet diffuse and indirect, impact on the production of actualizations at all scales— from new concrescences to  With this argument concerning media’s flavoring of real potentiality for the future, we are once again returned to the key claim for access to the data of sensibility (CADS) that has structured my argument about twenty-first-century media. The double data-structure just predicated of media should recall my earlier discussion of the second-order oscillation that computation introduces as a third form of process distinct from both microscopic processes of concrescence and transition and higher-order processes of perception and symbolic reference. Where we earlier saw how this third form of process folded the speculative back on itself, in a way that relativized it to relationalities operating within experience, what we learn in the current context is how the double data-structure of media— the fact that the act of accessing worldly sensibility is itself a new sensible instantly and automatically added to worldly sensibility— provides a concrete structure for the data propagation of sensibility as potentiality. As such, this double data-structure helps to clarify the ontological and temporal status of twenty-first-century media, or, more precisely, to flesh out precisely what is at stake in the question of access that, for me, is the crucial operation of twenty-first-century media. In the figure of “data sensing”— the act of accessing sensibility that is itself the production of a new sensible— we encounter the perfect expression of the “indirection” of twenty-first-century media: twenty-first-century media come to bear on human experience as the simple result of the activity of accessing worldly sensibility. And it is, moreover, potential in its mode of being, or, more precisely, in relation to any events that may be constructed out of it: thus, the sheer activity of accessing worldly sensibility doesn’t directly or necessarily wield any impact on any given human experience; it simply furnishes an expanded sensibility, which is to say, a source of potentiality, that could lead to concrete effects at the level of human experience. By forging an indirect link between human modes of experience and the data of sensibility, the very act of accessing this latter can be said to constitute the “content” of twenty-first-century media: rather than introducing new prostheses for human capacities, or registering, storing, and transmitting experience beyond its lived parameters, twenty-first-century media are quite literally composed of the act of mediating the domain of worldly sensibility for human modes of experience.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  And again, let me emphasize the independence of this mediation from those modes: like Étienne-Jules Marey’s graphic and chronophotographic machines, which (as we have seen) enjoy a sensory domain all their own, the processes of twenty-first-century media aim not to translate sensibility into the framework of these human modes of experience, but to introject into human experience data of sensibility that  their radical exteriority. It is for this reason that I have sought to show precisely how twenty-first-century media mark a shift from human-addressed to environmental media: without in any way simply abandoning the operation of media in their more traditional forms (and indeed media continue to function as prostheses or as registration, storage and transmission systems), the system of twenty-first-century media—or, more exactly, the expanded access to sensibility afforded by twenty-first-century media—is currently in the process of gradually excavating the diffuse operation of sensibility and emancipating its power (or causal efficacy) from the sensory, perceptual, and cognitive acts which it has long supported (and through which it has long been channeled, and, in effect, operationally restricted). With twentyfirst-century media, we can address sensibility itself independently of its correlation with human modes of experience, and it is this address itself, or rather the production of new sensibilities it yields, that constitutes the content— and the promise— of twenty-first-century media. Now that we have grasped how data propagates sensibility as potentiality, let us return to Nobo’s claim that the extensive (or vibratory) continuum generates a meshwork of real potentiality that holds a priority over any actualities that will come to be attained on its basis. As Nobo sees it, Whitehead’s account of the extensive continuum— an account Nobo recognizes to be fraught with inconsistencies— forms an absolutely crucial element of his process philosophy. Indeed, as Nobo sees it, Whitehead’s account of extension in terms of a continuum furnishes nothing less than a metaphysical guarantee for the solidarity of actual entities: “The intelligibility and logical consistency of the solidarity thesis,” argues Nobo, “presupposes positing the existence of an eternal continuum of extension whose metaphysical function is to ground the mutual transcendence, and the mutual immanence, of any two actual entities.”46 As we discover from Nobo’s effort to bring coherence to Whitehead’s position on extension, the tricky issue this metaphysical guarantee raises is how to correlate what Whitehead calls the “eternal continuum of extension”— a continuum that abstracts from all “additional conditions proper only to the cosmic epoch of electrons, protons, molecules, and star systems” and that does not even “include the relations of metrical geometry”47— with the “extensive continuum” underpinning our world. How do these two operations of extension relate to one another, and which one can be said to be foundational? In his effort to clarify this situation, Nobo begins by aligning “mere extension” with “pure potentiality,” and “spatio-temporalized extension” with “limited, or conditioned, [i.e., real] potentiality.” In this way, Nobo manages to invert the apparent hierarchy underpinning Whitehead’s ontology of ex-  Nobo insists on the necessity to subordinate this purely metaphysical notion of extension to extension as the basis for experience.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  As Nobo sees it, this inversion is crucial to the coherence of Whitehead’s scheme: because it only comes into effect through being instantiated in some vibratory configuration of our world, the metaphysical guarantee for the solidarity of the universe is not a transcendental condition for the vibratory continuum, but is, on the contrary and paradoxically, itself a part of the extensive continuum. Because of the Whiteheadian principle that each new actuality “has to arise from the actual world as much as from pure potentiality,”48 Nobo feels justified in claiming that “pure potentiality is an abstraction from real potentiality; for the latter is always impure, that is, always conditioned by attained actuality.”49 Nobo’s decision to privilege real potentiality and the extensive continuum helps us cut through the confusion created by the following, often-cited and often-misunderstood passage from Process and Reality where Whitehead seeks to clarify how mere extension (the eternal continuum) correlates with the extensive continuum. Far from clarifying matters, however, Whitehead’s analysis only seems to increase confusion. Specifically, Whitehead appears to identify the extensive continuum both with the purely metaphysical eternal continuum and with the continuum underpinning our world: The real potentialities relative to all standpoints are coordinated as diverse determinations of one extensive continuum. This extensive continuum is one relational complex in which all potential objectifications find their niche. It underlies the whole world, past, present, and future. Considered in its full generality, apart from the additional conditions proper only to the cosmic epoch of electrons, protons, molecules, and star-systems, the properties of this continuum are very few and do not include the relationships of metrical geometry. An extensive continuum is a complex of entities united by the various allied relationships of whole to part, and of overlapping so as to possess common parts, and of contact, and of other relationships derived from these primary relationships. . . .\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  This extensive continuum expresses the solidarity of all possible standpoints throughout the whole process of the world. It is not a fact prior to the world; it is the first determination of order— that is, of real potentiality— arising out of the general character of the world. In its full generality beyond the present epoch, it does not involve shapes, dimensions, or measurability; these are additional determinations of real potentiality arising from our cosmic epoch.50  As I propose to understand it, following Nobo, this difficult passage asserts nothing less than the primacy of the extensive continuum in its fullest sense, namely as the continuum of our spatiotemporal world in all of its richness: only in its constitutive fullness can the extensive continuum fulfill the crucial function of expressing “the solidarity of all possible standpoints throughout the whole process of the world.” From the standpoint of this entailment, the notion of mere extension (the eternal continuum) constitutes what amounts to a metaphysical guarantee of solidarity that, as I suggested above, is derived by abstraction from this full concept of the continuum. In his commentary on this passage, Nobo clarifies the primacy of the extensive continuum by contrasting it both with the eternal continuum and with what he terms “a continuum of actualized extension.” As careful analysis of the above passage shows, “mere extension” (the eternal continuum), far from being a source for the extensive continuum, is rather an abstraction from it and one that is, in some crucial sense, fully included in it. “It should be evident,” states Nobo, “that by ‘extensive continuum’ we are to understand . . . not the Receptacle or mere extension as such, but either the spatio-temporal continuum peculiar to our world or, in general, the standpoint of any actual entity belonging to our cosmic epoch.”51 In both phrasings, the extensive continuum must be categorically differentiated— as the source for real potentiality— from any continuum of actualized extension. Thus Nobo continues: “Many a commentator of Whitehead has cited these or similar passages in support of the contentions that the extensive continuum is manufactured, bit by bit, by actual entities and that, therefore, it has the ontological status of a derivative abstraction from actuality. I have been defending the opposite theses, namely, that the extensive continuum is ontologically prior to the actual entities that come to be in it and that only a continuum of actualized extension can be considered as a derivative abstraction from actuality.”52 Goodman, of course, fits Nobo’s characterization to a tee: not only does he predicate his interpretation on a claim that the extensive continuum is produced incrementally by actual entities, but in so doing he simply levels the crucial distinction on which Nobo here insists, the distinction of the extensive continuum from any continuum of actualized extension.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Once Goodman decides to channel the vibratory continuum through the concrescence of actual entities, he does the opposite to what Nobo urges: he treats the vibratory continuum as a fully actualized one. As I pointed out above, what is most striking about this decision is how it compromises the very power that Goodman seeks to attribute to vibrations: by rendering vibrations nothing more than the derivative product of actuality, of a continuum  of actualized extension, Goodman compromises their real potentiality, the power they wield beyond, in excess over, and in some sense prior to, the becoming of concrescing actualities. With this conclusion, we can see exactly why Goodman’s conflicting commitments render his position incoherent: channeling vibrations through concrescence deprives them— and the extensive, vibratory continuum they would continually produce— of the power to impact experience from the superjectal outside. Nobo’s bold conclusion that “the extensive continuum is ontologically prior to the actual entities that come to be in it” perfectly clarifies how real potentiality informs the genesis of new actualities: as the power of the settled world at a given moment in the ongoing genesis of the universe, the vibratory continuum is precisely what yields, via contrasts that express the real potentiality of the universe, data whose superjective subjectivity catalyzes new actualities as well as experiential entities at all scales. Whatever promise the vibratory continuum holds for rethinking media beyond anthropomorphism must accordingly stem from its capacity to host the heterogeneity of the superjectal outside. Because it accounts for the solidarity of actualities in a way that does not depend on their actualization via concrescence, the vibratory continuum furnishes a “ground” where media can operate “prior” to their capture by narrowly subjective processes, where, in short, media can express their superjectal power, their capacity to channel the force of worldly sensibility. Vibratory Sensibility To grasp how media operate within and through the vibratory continuum, and thus in indirect relation to human experience, we will need to introduce yet another dimension of the argument for the priority of real potentiality over actualities, and for the vibratory continuum as an expression of this priority. This dimension is the role played by eternal objects in Whitehead’s account of concrescence but also in recent efforts, like Goodman’s, to explore the correlation of media and the vibratory continuum on the basis of this account.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  To anticipate our trajectory here, we will counter this orthodox account by demonstrating why we must repudiate eternal objects as eternal. We must repudiate their eternal status for the same reason that we must repudiate the priority accorded actuality on the orthodox picture: both accounts make the error of privileging the actualized continuum over the vibratory or extensive continuum. Indeed, we can go so far as to say that the liberation of the real potentiality of the vibratory continuum depends directly on— and perhaps amounts to— a liberation from its channel-  real potentiality directly in the vibratory continuum accordingly furnishes a model for potentiality that conflicts with— and can take the place of— the orthodox account of real potentiality as a determination of the pure potentiality of eternal objects. Because of its lingering commitment to precisely this element of Whiteheadian orthodoxy, Goodman’s account once again founders precisely where it should triumph. In a word, Goodman finds himself compelled to subordinate vibratory contrast to the ingression of eternal objects: Whitehead’s extensive continuum points to vibratory potentials jelling a multiplicity of space-times: here there is a resonance of actual occasions, which are able to enter into one another by selecting potentials or eternal objects. It is in such a potential coalescence of one region with another that an affective encounter between distinct actual entities occurs. The vibratory resonance between actual occasions in their own regions of space-time occurs through the rhythmic potential of eternal objects, which enables the participation of one entity in another. This rhythmic potential exceeds the actual occasion into which it ingresses.53  Rather than viewing the extensive continuum as generating vibratory contrasts that precede and indeed catalyze actualizations, along with any ingression of eternal objects into them, Goodman renders such contrasts— and whatever excess they may possess— both subordinate and relative to concrescing actualities.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  This interpretation is anathema to the aim of my argument here: to situate media within—or, perhaps more precisely, at the level of—the vibratory continuum. In accord with this aim, we will need to repudiate the entirety of Whitehead’s received account of real potentiality as a determination of the pure potentiality of eternal objects; like the reduction of the vibratory continuum just explored, this account subordinates real potentiality to the production of actuality (the actualization of eternal objects). By repudiating the canonical Whiteheadian account, we clear the ground for the development of a more radical account that situates potentiality wholly within our world and accords it a primacy as the source for actuality. Indeed, drawing on Nobo’s key understanding of the extensive continuum as ontologically prior to the actual entities that come to be in it, we can simply dispense with the category of “pure potentiality” altogether and transform “eternal” objects into temporal, experiential ones that, like actual entities, find their objective source in the domain of vibratory potentiality. actualization of the continuum, real potentiality is nothing other than the potentiality of the vibratory continuum itself. In this sense, the demotion of eternal objects I am here proposing parallels the demotion of concrescence central to Nobo’s, Jones’s, and my own understanding of Whitehead: just as concrescence loses its separateness and its exclusive status and becomes one element in a larger process culminating in repeated additions to the ongoing universe that increase the potentiality of the settled world, so too must eternal objects shed their purity and their status as “eternal” in order to become, as John Dewey thought they must, temporal elements that emerge “within the flux of experience in response to the resourcefulness of experience.”54 On this modified account, which picks up on my earlier criticism of eternal objects in chapter 3, real potentiality turns out to be much more than simply the achievement of the ingression of eternal objects into actual entities (both in itself and as productive of future actualities). Real potentiality becomes the potentiality not of eternal objects exclusively, but of the entirety of the settled world out of which (no longer eternal) “eternal” objects are produced and which includes them. As I suggested above, this means that worldly sensibility, insofar as it constitutes the concrete texture of the settled world, takes the place of the pure potentiality of eternal objects (together with the God necessary to ensure their ingression into experience) as the source for potentiality.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  What remains to be understood, and what I shall focus on here, is precisely how worldly sensibility can support the potentiality of the settled world and how it might matter for our understanding of media. Once again, the crucial point at issue concerns the operation of access, and in particular how access to the domain of sensibility (the vibratory continuum) in itself constitutes the power of twenty-first-century media and accounts for their potential to impact human experience. The power of twenty-first-century media is a power of potentiality, and the potentiality in question is the “real potentiality” of the actual world, the potentiality of worldly sensibility or vibratory intensity. What we can now add to our previous discussions of the claim of access to the data of sensibility (CADS) is a specification concerning the precise role twenty-first-century media play in potentializing worldly sensibility for human experience: as the vehicle of access to the data of sensibility, twenty-first-century media operate as brokers for the potentiality of sensibility. By gathering data from the operational present of sensibility and feeding it forward into a future operation of consciousness, twenty-first-century media make the surplus of sensibility into a potentiality for human experience, a power that can (but that doesn’t have to) modify how we experience. In playing the role of “host” for worldly  makes it the “real potentiality” for experiences of all kinds, not least of which is the belated experience of consciousness I am calling feed-forward. If the crucial point here is that twenty-first-century media operate at the level of the vibratory continuum— of the vibrations whose contrast generates the real potentiality of the settled world— it is important that we emphasize their role as mediator. As I put it above, twenty-first-century media mediate worldly sensibility itself, meaning that they operate to channel the power of sensibility (vibratory intensity) toward experiential creations of all sorts.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In this sense, we can understand twenty-first-century media as an operation for tapping into the power of sensibility (the power of real potentiality) that dispenses with eternal objects entirely in favor of the power of superjective subjectivity. Recalling our earlier discussion of the fold of the speculative, we can appreciate that this operation is resolutely empirical, in the sense that it takes place within the domain of superjective relationalities constituting the settled world, even as it nonetheless remains speculative in relation to specifically human modes of sensing, perceiving, and thinking. With respect to our interpretation of Whitehead, we might say then that mediation simply replaces eternal objects, and in the process displaces the distinction of pure and real potentiality in favor of a doubling of real potentiality that allows us to claim (as I have just claimed) that twenty-firstcentury media potentialize sensibility (which is to say, that they potentialize real potentiality itself). The force of this displacement hinges on the capacity of worldly sensibility to furnish an alternate account of real potentiality that lets us dispense with Whitehead’s eternal objects. Thus, what remains for us to explain is how vibrations directly generate real potentiality without implicating eternal objects and how the superjective existence of attained actualities can be directly “taken into account” (as Nobo puts it) by worldly processes (societies at all scales) without being channeled through concrescences. With his distinction between “position” and “definiteness” of actual entities, Nobo provides just such an account. By reserving “position” to designate the metaphysical essence of actual entities, Nobo discovers a way to divorce the problem of explaining the solidarity of the universe from the doctrine of eternal objects that has traditionally been used to explain it.55 As a result, Nobo is able to give a concrete account of exactly what happens when eternal objects are demoted— stripped of both their purity and their eternal status. More importantly still, he is able to unpack the “categoreal” nature of real potentiality, the way in which the attained world imposes its pervasive forms on the world in attainment, exercising an agency on the latter that can only come from the superjectal outside.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  universe that inheres within the experiential solidarity of the extensive (spatiotemporal) continuum, Nobo identifies “properties” that “must belong to extension prior to actualization.” These properties, crucially, are ontologically more fundamental than eternal objects: Actual entities are related to one another according to the determinations of the extensive continuum; but this is only to say that their becoming atomizes the continuum and thereby makes actual the solidarity that was antecedently merely potential. The extensive continuum, then, is to be understood as imposing on the actualities that atomize it the necessity that they function in, or be components of, one another. The sense in which actual entities are mutually immanent accounts for, indeed is nothing else than, their solidarity or connexity. But we must not forget that, in a different though related sense, actual entities are also mutually transcendent and that without their reciprocal transcendence there is no accounting for their discreteness and their individuality. Consequently, what we are now searching for are those properties of pure extension that will explain not just mere immanence but the mutual immanence of actual entities having non-overlapping extensive standpoints. We are searching, in effect, for those properties of extension that account for mutual transcendence as well as for mutual immanence, that account, in short, for the solidarity of discrete occasions. And these properties must belong to extension prior to actualization because according to Whitehead the discrete actualities that atomize extension are realizing a solidarity of standpoints that was antecedently potential.56  These properties are the unique “position” of every actual entity and its modal presence in all other actual entities. Every actuality is, as Nobo explains, the “coordinate reality of all of its locations,” meaning that it is transcendentally implicated in every other actual entity.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Nobo traces these properties to “the separative, the prehensive, and the modal characters of space-time” that Whitehead develops in Science and the Modern World: “By reason of the separative, modal, and prehensive properties of the extensive continuum, the unique immanent location of a subject-superject and the many transcendent locations of its objectifications are all coordinated into the one manifold reality of a single actuality.”57 This argument has important consequences for the status of eternal objects that resonate with my above, Dewey-inspired criticism. Not only does  ity, but it grounds an account of solidarity in terms of every actuality’s real potential for relationality. As Nobo explains, this account is far more capacious than the orthodox appeal to eternal objects: The whole point of the doctrine of position, then, is that an actual entity “has a status among other actual entities not expressible wholly in terms of contrasts between eternal objects” (citing Process and Reality, 229). The complete contrast of eternal objects ingressed in an actual occasion constitutes the determinate definiteness of that occasion. This definiteness is part of the occasion’s essence, but it cannot be the whole of its essence. Accordingly, the occasion’s definiteness is termed its abstract essence, whereas its complete determinateness is termed its real essence (citing Process and Reality, 60). . . . From this it follows that the uniqueness of an occasion’s real essence— the uniqueness of its determinate constitution— is a function of its position and not of its definiteness.58  Nobo’s point here is that eternal objects cannot explain solidarity precisely because they cannot capture the transcendent operation of every actual entity in all other actual entities: simply put, they fail to grasp the superjectal subjectivity of every actuality qua attained actuality. Moreover, by introducing the crucial distinction between position and definiteness, Nobo’s account paints a very concrete picture of what happens as eternal objects become temporal: effectively stripped of their role as “pure potentials” for all actuality, eternal objects are able to take on a more specific function as determinants of the definiteness (the “how”) of concrescence. By transferring the burden of explaining solidarity from eternal objects as determinants of definiteness to the unique position of actualities, Nobo, like Jones, gives sway to the superjectal operation of actualities within other actualities as the source for creativity: “Considered in themselves,” he writes, “the functionings of eternal objects in an actual entity will only give us the definiteness, or abstract essence, of that actuality.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Therefore, it is the functionings, or objectifications, of all the other actualities in the said actuality which account for the latter’s unique determinateness and selfidentity. Accordingly, an actuality’s position— its unique, nonshareable, determinateness— is a function of the objectifications within itself of the other actualities in its correlative universe.”59 On this account, there is solidarity of the universe and of every actuality with all other actualities precisely and only because of the superjectal operation of attained actualities outside of their own subjective geneses. egoreal” feature of the actualities of our world: by way of the superjectal subjectivity that yields position and solidarity, the attained world imposes its pervasive forms on all future attainment. For this reason, space and time, understood as the basic forms of the vibratory continuum, must be said to characterize the structure of extensiveness prior to any atomization of the continuum: Our world . . . is to be construed as resulting from the incoming of certain forms into the real potentiality provided by the extensive continuum. . . . Physical space and physical time are two such incoming forms. They are eternal objects of the objective species which have become, through social reproduction, pervasive features of the actualities of our world. Furthermore, it is because of their pervasiveness in the relevant supersessional past that their continued reproduction in the relevant supersessional future is, for all practical purposes, guaranteed.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  In other words, the world as attained imposes its own pervasive forms on the world as in attainment. In this manner, spatio-temporality, though not a true metaphysical category, becomes, nonetheless, a “categoreal” feature of the actualities of our world. It thus comes about that the actualities of our cosmic epoch are not merely extended; they are spatio-temporally extended. And this is not to say . . . that they are extended in spacetime; rather, it is to say that their extensiveness is spatio-temporally structured; for, as I have explained, extension is ontologically prior to, as well as a logical presupposition of, the spatio-temporal structure that it gains by reason of the world’s component actualities.60  With this conclusion, we have further proof that the vibratory continuum exercises agency independently of the actualities that come to be in it: the power of the vibratory continuum simply is the source of the data that catalyzes all attainment and, as such, the very basis for the solidarity of the universe. We can now return to our discussion of the vibratory continuum and its promise to facilitate a becoming-cosmological of media. Having introduced the crucial distinction between position and definiteness and the way it deepens the agency of superjectal subjectivity, we are now in a position to appreciate more fully the fundamental limitation of Goodman’s argument: because he retains the canonical account of potentiality in terms of eternal objects, Goodman simply has no way to value the potentiality of the spatiotemporal (vibratory) continuum other than through its atomiza-  to make good on his own move to align media with a vibratory continuum that operates beneath any continuum of actualized extension. This is why, in complete antithesis to Nobo, Goodman must in the end credit the atomization of the continuum as the very source for its potential: “The actual entity breaks up its continuum realizing the eternal object, or particular potential that it selects.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  This breaking up, atomization or quantization, forces the eternal object into the space-time of the actual occasion; in other words, as the pure potential of the eternal object ingresses into actuality, it forces the becoming of actuality, and at the same time, pure potential becomes real potential.”61 We can now fully appreciate that, on Goodman’s reading, real potentiality belongs exclusively— and can only belong— to the space-time that is actualized by actual entities, to an actualized continuum of actuality, rather than to the vibratory continuum itself. And with this conclusion, we can fully grasp the limitation of Goodman’s account: so long as he insists on the primacy of actuality as the source for the atomization of the continuum, Goodman cannot avoid jettisoning the very element— the potentiality of the vibratory continuum— that could in fact support a non-anthropocentric and radically environmental account of media. What we must take away from this critical analysis of Goodman’s position is an appreciation for how much more is and must be at stake in a “nonanthropocentric ontology of ubiquitous media” than just a conversion of pure into real potentiality via a “vibratory tension between contrasting occasions.” What is and must be at stake is the direct operation of intensities that are generated from contrasts within the vibratory continuum itself, or, in other words, from the operation of the superjective subjectivity of attained actualities operating as an environmental force. As we have already had occasion to observe, such intensities need not be channeled through subjective becomings, but operate first and foremost to qualify the extensive continuum as real potentiality: as the concrete potentiality for relationality resulting from the immanence and transcendence of every actuality. We might even say that the intensities generated within the vibratory continuum are what makes the metaphysical continuum (“mere extension”) into an empirical basis for the solidarity of the universe: by defining concrete webs of potential relationality, these intensities literally render the continuum experientiable! The qualification of the extensive continuum by intensity is, in this sense, equivalent to a making-sensible of the continuum: for us and for all the beings in our universe, the extensive continuum is a “real potentiality” within actuality whose power— the power of intensity— is vibrational or sensory in nature.62 The emphasis Nobo places on the superjectal operation of vibrations as  (explored in chapter 3) on the objective datum as the “nonsubjective” agent (the “dative phase”) through which the real potentiality of the settled world can give rise to new actualities. Indeed, as Nobo concludes, the dative phase simply is the real potentiality for the settled world to generate novelty. We can thus begin to see how it is the world itself— the “objective” or “dative” potentiality of the settled world— that exercises itself causally outside of and independently from the subjective operation of concrescence generative of new actualities.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  As Nobo explains, this operation is crucial to understanding the creativity Whitehead attributes to the universe: Attained actualities can function as efficient causes of a new occasion only if their superjective existence is taken into account by the macroscopic process begetting the dative phase of the new occasion . . . . This taking into account of the universe by the transcendent creativity is not to be understood as belonging to, or as being part of, the new occasion’s own subjective experience. For the occasion’s subjective experience presupposes the existence of the occasion’s dative phase, and the dative phase itself presupposes, and results from, the transcendent creativity’s taking into account of a newly completed state of the universe. Therefore, the notion of taking into account must be construed as . . . an essential aspect of the universe’s extenso-creative or existential matrix— the aspect whereby each transcendent, or individualizing, manifestation of the universe’s creativeness is determined, limited, and enabled by the state of the universe relative to that manifestation. . . . The point is that the Receptacle, the Creativity, the Ultimate— or whatever else we may wish to call it— must be able to take into account, or envisage, the existence of every new disjunctive plurality of completely attained creatures before it can create, relative to each new disjunction, the dative phase of a new creature. The dative phase thus created, since it is a finite extensive region containing within itself the objectification of the plurality in question, is the real potentiality for that plurality of attained creatures to be synthesized into the constitution and subjective experience of a novel creature.63  As an account of the environmental agency of the world, Nobo’s characterization of the “taking into account of the universe” helps us situate the worldly or environmental operation of media, their tendency to impact the vibrational continuum directly. The crux of such environmental agency is the fact that worldly vibrations— together with the operation of media  Thus, in stark contrast to Goodman’s definition of media as the feeling of vibrations, by and in concrescing entities, the environmental agency of media guarantees vibrations a certain autonomy: as instruments for channeling the superjective force of the vibrational continuum, media only indirectly impact macrolevel experience, including human experience.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Together with the vibrational power they channel, media can thus be said to take part in an environmental agency that remains autonomous from any subsequent, higher-order experience. As I have been arguing throughout my study, this kind of environmental agency is central to the operation of twenty-first-century media: unlike nineteenth- and twentieth-century forms of recording which offered humans the capacity to experience the same events multiple times (Stiegler) or which formed the basis for complex disjunctions of machine and human (Kittler), twenty-first-century media typically afford no direct correlation to human perceptual experience whatsoever. The operation of computational microsensors, ubiquitous computing environments, and data-gathering and predictive analysis all share a common pattern: they all modulate worldly sensibility directly, prior to any processing by and indeed any correlation to higher-order human modes of experience. And if they do impact human experience, they do so only indirectly, by impacting the vibrational continuum of worldly sensibility in ways that remain imperceptible, and that are only sensed through means other than the macro-senses (sense organs) and at scales beneath what characterizes ordinary human experience as we know it, or have known it, up to now. In her unpacking of what she calls the “intensive achievement” on the part of the settled universe, Judith Jones correlates the vibratory character of the universe with the worldly or environmental power of superjects. As Jones sees it, vibrations are by definition external to the actualities they impact. They are in excess over concrescing actualities and operate prior to their genesis. That is why it makes no sense at all to speak of a vibration that terminates in the concrescence of an actuality: Both individuality of concrescent process and “sameness” of enduring character refer to intensive achievement.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Intensive achievement is the formed agency of contrastive feeling. It is my suspicion that the denial that a subject is “the same” in its objectifications stems from a conception of agency as something that belongs to the unitary subject of concrescence. The agency of contrast is the subject, the subject is the agency of contrast. To be a subject is to be a provoked instance of the agency of contrast, and that is all it is. Thus,  another individual, the original individual is there in the agentive sense. The pattern involved in an intense contrast is more than a mere arrangement of eternal objects. It is the feeling of the dynamic presence of the (other) individuals felt into the unity of a subject’s intensity. This is the only way to understand Whitehead’s repeated assertion of the vibratory character of actuality.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  No vibratory character has only one cycle qua that vibratory character— to be a vibratory character is to be an intensive imposition on all subsequent process, and, on the other end, to have emerged from the enduring vibrations of other insistent agencies of contrast. I see no other way of understanding why provision for future intensity is included in the category respecting “subjective” concrescence.64  Intensity simply is the process through which worldly vibrations generate superjective force by means of contrast. On this understanding, vibrations should be thought of neither as belonging to subjects, nor as being ingressed into subjects in the form of eternal objects. Rather, as Jones puts it, vibrations constitute “an intensive imposition on all subsequent process”: they operate by constraining, but also by enabling, the genesis of contrasts in the future. Only by conceptualizing vibrations in this way can we avoid the error of construing the power involved in the vibratory throbs constitutive of experience as a power pertaining exclusively or primarily to the subjective aim driving concrescence, and properly view its operation— its generation of contrasts— as what gives rise to subjects, understood here (following Jones) as nothing more nor less than the agencies of contrast. Grasped as a supplement to Nobo’s notion of the “taking into account of the universe,” Jones’s development of the environmental agency of superjects locates the source for the creativity of novelty squarely in the experiential domain of the settled world. In this sense, Jones’s conception of intensity expresses the payoff of the claim for inversion (CIF) that has guided my reading of Whitehead: what we learn from her contribution is that concrescences are not simply instruments for the operation of process, but that they are, like everything else in the world, generated on the basis of the power of intensity produced by vibratory contrasts. Indeed, given what Jones has to say about the “vibratory character” of actuality— and specifically, about how it captures the force of the mutual transcendence of attained actualities— we could go so far as to claim creativity to be a function of the vibratory continuum itself, where the continuum is understood, not, with Goodman, as an “achronological nexus outside the split between space and time,” but rather as the most basic, most minimal periodicity of  account, intensities are achievements of the vibratory continuum that, if they express the solidarity of the latter, do so not by instantiating some abstract metaphysical schema, but by way of their concrete, empirical activity: “In a vibratory cosmos,” Jones concludes, “intensities must come to be.”66 To this, we might add that their coming to be simply is the becoming of the vibratory cosmos.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Insofar as it explicates the vibratory continuum as worldly sensibility— as the real potentiality for intensive achievement— Jones’s theorization of intensity furnishes a basis for conceptualizing the agency of the vibratory continuum both as a materialized and causally efficacious real potentiality and as an agency not relative to any particular actuality-in-attainment. In line with Nobo’s understanding of the extensive continuum as ontologically more fundamental than any actual entities that come to be in it— and yet as fully empirical— the vibratory continuum of intensity captures the seething, heterogeneous, and multi-scalar power of a concrete world— the worldly sensibility— always already at play at any particular moment of actualization. The point, as Jones makes clear, is not to ratify “the relentlessness of perishing that marks a boundary between existents,” but rather to affirm “the persistent vibratory achievement of intensive feeling that marks the interpenetration of individuals in a non-idealistic and nonmonistic sense.”67 Insofar as intensity precedes any distinction between subject and superject, it expresses an agency of real potentiality that cannot be relativized to a particular individual perspective; as the power of the vibratory continuum (the agency of vibratory contrasts), intensity explains how— indeed it simply is how— worldly sensibility comes to wield subjective force, or, more precisely, how it comes to exercise its superjective subjectivity. And because it operates at a level that precedes the self-reference, no matter how inchoate, constitutive of subjective concrescence, intensity can help align the vibratory continuum, and can itself be aligned, with a radically environmental perspective. Following such a radicalizing alignment, the vibratory continuum of intensity can be seen to be an “existential matrix,” to borrow Nobo’s term, that is “sensitive . . . to its own successive states of actual and potential determinateness,” but that is not and cannot be “relative to some actual entity” or other.68 It is a generalized field of sensibility without which, to paraphrase Whitehead, there would be nothing, nothing, pure nothing. Let us finally return to the becoming-cosmological of media. As we have anticipated, the above analysis of the vibratory continuum facilitates a localization of media outside of the narrowly subjective processes that emerge, indirectly, from it.\n"}
{"prompt":"Feed-forward : On the future of twenty-first-century media ->","completion":"  Shedding its former role as surrogate for the perceptual flux of experience, media comes to mediate a level of sensibility— what I  more fundamental than the sensory qualities produced by the ingression of eternal objects into concrescing actualities. Because of their capacity to record and process data of sensibility, twenty-first-century media give us access to a domain of experience, and indeed to a domain of our own experience, that has long been inaccessible: through their direct modulation of the vibratory continuum, they mediate the worldly sensibility (potentialize the real potentiality) out of which our experience emerges; and by capturing sensibility as data, they give us a means to feed sensibility forward into our future conscious experience. We can now fully appreciate why Whitehead’s conception of the vibratory continuum is so fruitful for our task of developing a non-anthropocentric account of media. Vibrations are both antecedent and transcendent in relation to the specific concrescences of actual entities that would seek, even if only punctually or atomically, to contain them. Whatever promise vibrations might hold to support a non-anthropocentric, non-prosthetic, and radically environmental theory of media is bound up with their status as independent from concrescence, which is to say, as a more primordial element or unit of process than what comes to the fore in Whitehead’s orthodox account. It is only on account of their radical excess over any concrescing actualities they may inform that vibrations may be said to constitute a field of real potentiality— a texture of worldly sensibility— whose efficacy is more primordial as well as broader in scope than any unitary subjective aim. And it is only on account of this excess that media can assume their own proper primordiality, as instruments to channel the power of worldly sensibility, to potentialize the world’s real potentiality in ways that bring it into nonconscious, environmental contact with human modes of experience.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  A Sea of Data: Pattern Recognition and Corporate Animism (Forked Version) Hito Steyerl  What is recognition?\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Remember the famous primordiai scene of (seif)-recognition described by Louis Aithusser: a policeman hails someone in the street yelling \"Hey you!\" In that moment the person is supposed to recognize himself both as subject (\"you\") and as subjected to the policeman’s authority (\"hey!\"). \"Hey you!\" is the primary formula of social control, the most basic pattern of personal and political recognition. The categories of knowledge, control, and privilege are established with one single gesture (Althusser 1971,163). But today the situation is more complicated. Gone are the days when it was about one person walking down the street. It’s not five, five thousand, or even five million people crossing the street but 414 trillion bits, the approximate amount of data traveling the internet per second, imagine the poiiceman standing there trying to yell: \"hey you!\"\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  at every singie one of them, it must be flabbergasting. On top of that he has to figure out whether they are sent by a spam bot, a trader, a porn website, a solar flare, Daesh, your mum, or what. Imagine Althusser's scenario of recognition  in a sea of data—with data, data everywhere, but not a drop of in­ formation\" (Sontheimer 2015). This quote is part of a series of texts called \"Signal v. Noise\" posted to the NSA's internal website from 2011 to 2012. Its author complains of an overload of intercepted  data: \"Its not about the data or even access to the data. Its about getting information from the truckloads of data ...\" (Sontheimer 201S). In the NSA's description, data are an overwhelming ocean,  more landscape than library, more raw material than focused message, more taken than givens. Secret services randomly siphon off \"truckloads\" of data.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  But the sheer volume of traffic becomes a source of bewildering opacity. This problem is not restricted to secret services however. Even WikiLeak's Julian Assange himself has said, \"We are drowning in material\" (Sontheimer 2015). Pattern Recognition This is where pattern recognition comes into play. The NSA  columns' main question is how to extract a signal from the noise of excessive data. The answer is: by \"discovering patterns in large data sets\" (Wikipedia 2017a). This happens via: \"the analysis of large quantities of data to extract previously unknown, interesting patterns\" (Wikipedia 2017b) like dependencies, clusters, or an­ omalies. Althusser's overwhelmed cop gets thrown a lifeline.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  The people he was supposed to hail are now patterns of life extracted from geolocation data, phone records, social media trawling, and online shop cookies. They are subjected to continuous surveillance by governments, corporations, their own cars, and Barbie dolls. It's now a question of defining flocks, swarms, rhythms, and constel­ lations within the deafening noise of intercepted data. But how exactly to separate signal and noise, or maybe rather how to define them in the first place? Jacques Ranci^re tells a mythical story—or maybe let's call this kind of story a political fable—about how this might have been done  as speech, whereas women, children, slaves, and foreigners were  assumed to produce garbled noise. The distinction between speech and noise served as a kind of political spam filter. Those identi­ fied as speaking were labeled citizens and the rest as irrelevant, irrational, and potentially dangerous nuisances. Similarly, today, the question of separating signal and noise has a fundamental political dimension.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Dividing signal and noise means not only to \"filter\" patterns but also to create them in the first place. What does an \"anomaly\" exactly mean in pattern \"recognition’? As with  the gesture of Althusser's cop, \"recognition\" creates subjects and subjection, knowledge, authority, and as Ranci^re adds, neatly stacked categories of people. Pattern recognition is, besides many other things, also a fundamentally political operation. In 1988 Fredric Jameson declared paranoia to be one of the main cultural patterns of postmodern narrative, pervading the  political unconscious.' According to Jameson, the totality of social relations could not be culturally represented within the Cold War imagination—and the blanks were filled in by delusions, conjecture, and whacky plots featuring Freemason logos Qameson 2009,15). Today, however, apophenia replaces paranoia,^ How is this? After Edward Snowden's leaks, one thing became clear: many conspiracy theories were actually true (cf.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Sprenger 2015). Worse, they were outdone by reality. Post-Snowden, any specula­ tion about hidden plots or guesswork about intrigue and unlawful behind-the-scenes activities became outdated. One didn't have to speculate anymore about conspiracy; there was evidence to prove it. This does not mean there is no more secrecy. There is. But the same structural conditions that allow ubiquitous surveillanceleaky and unevenly regulated information architectures—also continue to benefit bottom-up exposure—which on the other hand could be totally fake. Potentially all information—at least a lot of it—is removed from the control of its authors once digitally transmitted; any piece of information can and likely will become  reality: a scenario deemed vastly unlikely by all but some experts  has become actual.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Additionally Jameson's totality—the sum of social relations—has taken on a different form. It is not absent; on the contrary, it is rampant. Totality has returned with a vengeance in the form of oceanic \"truckloads of data.\" Social relations are distilled as contact metadata, relational graphs, infection-spread maps, or just a heap of fake news. This quantified version of social relations is just as readily deployed for police operations as for targeted advertising, for personalized clickbait, eyeball tracking, and proprietary feed algorithms. It works both as social profiling and commodity form. Kloutscore-based A-list, black ads marketing, and presidential kill list are based on similar proprietary operations. Today totality comes as probabilistic notation that includes your fuckability as well as disposability ratings, not to mention precise estimates of your skin color.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  It catalogues affiliation, association, addiction; it converts patterns of  life into death by Hellfire missile. This type of totality is also the necessary counterpart of messianic expectations of singularity. Singularity—the pet myth of Californian ideology—describes a time when artificial intelligences take over. According to Jameson, singularity is also characteristic of a period in which general rules no longer apply.’ It's case by case instead; or rather, every case for itself. Singularity is a California fantasy of Weltgeist this time riding a Lethal Autonomous Weapons System enabled by spontaneous jurisdiction, a scarce rule of law, and SKYNET metadata. However, the real singularity of our times is most obviously the semi-divine mythical entity called the markets, a set of organizations regarded as both autonomous and superintelligent, of such providence, by the way, beautiful providence, that human reasoning has to bow to its vast superiority. This is the real-existing singularity in our times, an entity allegedly endowed  The corresponding totalities are taken care of by apophenia and pattern recognition. Pattern recognition formulas sift through truckloads of humble and seemingly trivial data sets divined from the entrails of online shopping and massively multiplayer online gaming.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  \"* No interaction is too modest or menial to be scanned, stored, and saved for eternity. A singularity in which every case is unique correlates to a totality governed by probability management. If paranoia was a standard Cold War narrative, apophenia happens when narrative breaks down and causality has to be recognized— or invented—across a cacophony of spam, spin, fake, and gadget chatter. This is also reflected in contemporary paradigms of truthfulness. The five W questions of traditional inquiry—who, what, where, when, and why—have been replaced with the seven V's of Big Data processing: velocity, variety, volume, veracity, variability, visualiza­ tion, and value. Veracity is no longer produced by verifying facts. It's a matter, as one big-data expert put it, to cleanse '\"dirty data'\" from your systems^ (Normandeau 2013). So what are dirty data?\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Here is one example: Sullivan, from Booz Allen, gave the example the time his team was analyzing demographic information about customers for a luxury hotel chain and came across data showing that teens from a wealthy Middle Eastern coun­ try were frequent guests. \"There were a whole group of 17 year-olds staying at the properties worldwide,\" Sullivan said. \"We thought, 'That can't be true.'\" (Kopytoff 2014)  The data was thus dismissed as dirty data, before someone found out that, indeed, it was true. Brown teenagers, in this worldview, are likely to exist. Dead brown teenagers? Also highly probable. ing from this operation to separate noise and signal is not very different from Ranci^re's political noise filter for allocating citi­ zenship, rationality, and privilege.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Affluent brown teenagers seem just as unlikely as speaking slaves and women in the Greek polls. Had the researchers uncovered that seventeen-year-old brown teenagers were likely to be shot dead by police at their properties they wouldn't have flinched but rather worked on a targeted email campaign promising discounts for premium demise. Probability enters truth production on an extensive scale with the unsurprising effect that the patterns supposed to be uncovered in massive data correspond to some degree with the patterns that are already assumed to be found there. On the other hand, though, dirty data are something like a cache of surreptitious subaltern refusal; they express a refusal to be counted and measured:  A study of more than 2,400 UK consumers by research company Verve found that 60% intentionally provided wrong information when submitting personal details online. Almost one quarter (23%) said they sometimes gave out incorrect dates of birth, for example, while 9% said they did this most of the time and 5% always did it. * (Cabrera 2015) Dirty data is where all your and my refusals to fill a constant on­ slaught of online forms accumulate. Everyone is lying all the time, whenever possible, or at least cutting corners. Not surprisingly, the most \"dirty\" area of data collection is consistently pointed out to be the (U.S.) health sector.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Doctors and nurses are singled out for filling out forms incorrectly, sometimes even going as far as to abbreviate \"gpa\" for \"grandpa,\" a move that deeply baffles and confounds data-mining operations. It seems health professionals are just as enthusiastic about filling forms for systems that are supposed to replace them as consumers are to perform clerical work for corporations that will spam them in turn. suffered a stroke he went through the ordeal of having to apply for Medicaid on her behalf. I had to spend over a month not long after dealing with the ramifying consequences of the act of whatever anon­ ymous functionary in the New York Department of Motor Vehicles had inscribed my given name as \"Daid,\" not to mention the Verizon clerk who spelled my surname \"Grueber.\" Bureaucracies public and private appear—for whatever historical reasons—to be organized in such a way as to guarantee that a significant proportion of actors will not be able to perform their tasks as expected. (Grae­ ber 2015,71)  Graeber goes on to call this an example of utopian thinking. Bu­ reaucracy is based on utopian thinking because it assumes people to be perfect from its own point of view. Dirty data are simply real data in the sense of documenting the struggle of real people with a bureaucracy that exploits for its own ends the reality of unevenly implemented digital technology with all its real-life defects.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Graebers mother died before she was accepted into the Medicaid pro­ gram. The endless labor of filling completely meaningless forms is a new form of domestic labor in the sense that it is not considered labor at all and assumed to be provided \"voluntarily\" or performed by underpaid so-called data Janitors. Yet all the seemingly swift and invisible action of algorithms, their elegant optimization of every­ thing, their recognition of patterns and anomalies, are based on the endless and utterly senseless labor of providing the required or even utterly useless data. Dirty data thus become, so to speak, a remainder of reality in systems that are pegged to ideal models, averages, and Platonic assumptions, inspired by an ideal fictional world in which brown teens are poor by default, doctors just love to cooperate with attempts to get rid of them entirely and people trying to claim  [Figure 1.1.] 33rd square. Google’s Deep Dream Generator. [Screenshot 2015, available at http:\/\/www.33rdsquare.com\/2015\/06\/googles-inceptionism-lets-us-look-at.html ,  Accessed March 31,2018,]  benefits are anomalies by definition and get treated (or are left untreated) accordingly. Sometimes \"dirty data\" record the passive resistance against permanent extraction of unacknowledged labor.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  This \"signal\" however is partly already determined by probability and preexisting models. Corporate Animism A brilliant example for apophenic pattern recognition was recently provided by a Google development team.’ The point is that in order to \"recognize\" anything, neural networks need first to be taught what to recognize. Then, in a quite predictable loop they end up \"recognizing\" the things they were taught. In Google's brilliant experiment, image recognition filters were looped on sheer random noise. There was nothing to recognize  and animais the networks had been taught to \"see\" earlier on. They ended up \"over-recognizing\" these shapes, so to speak. This process reveals the presets of computer vision, its hard­ wired ideologies and preferences. The result: a rainbow-colored mess of disembodied fractal eyes, mostly without lids, inces­ santly surveilling their audience in a strident display of pattern over-identification.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Google calls the act of creating pattern or image from noise \"inceptionism.\" It also calls this mode of image production \"deep dreaming.\" But in a very materialist sense, these entities are far from hallucinations. If they are dreams, those dreams can be interpreted as condensations or displacements of the current technological disposition. They reveal how signal and noise are defined by preexisting categories and probability. If you had trained a neural network to \"recognize\" Hegel's master and slaves, you might have ended up with sheer noise miraculously transform­ ing into Instagrams of an Art Basel Miami VIP preview staffed with temp catering workers. In a feat of unexpected genius, inceptionism manages to visualize the unconscious of prosumer networks:’ images surveilling users, constantly registering their eye movements, behavior, and prefer­ ences, in aesthetic terms helplessly adrift between a knockoff of a Hundertwasser coffee mug and an Art Deco frieze gone ballistic. They show not so much the so-called Five Eyes of state surveillance but the Eyes Unlimited of corporate surveillance, state surveillance, deep state surveillance, academic ranking scores, likability metrics, and so on and so on: Walter Benjamin's \"optical unconscious\" updated to the unconscious of computational image production (Benjamin 1974).\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  By \"recognizing\" things that were \"not given,\" inceptionist neural networks eventually end up effectively identifying a new totality  \"appi\/' or not: \"The results are intriguing—even a relatively simple neural network can be used to over-interpret an image, just like as children we enjoyed watching clouds and interpreting the random shapes\" (Mordvintsev, Olah, and Tyka 2015). Inceptionist image production is decisively different from previous chemical or even electronic photographic procedures, posing new questions concerning realism and veracity. If previous techniques relied on myths of mechanical or optical \"objectivity\" and ulti­ mately on optics and geometry, in the case of inceptionist image production vision appears to rely on pattern recognition, based on implanting pseudo-platonic forms into sensing technology and running the lot on petabytes of spam. The verisimilitude of vision is not based on assumptions about objective hardware but on the replication of brain functions (or what are currently believed to be brain functions). But in terms of veracity, this is a terrible choice indeed; no one really thinks that human brains make good witnesses. They project, speculate, invent, embellish, forget, and extrapolate. They also see faces in clouds, sometimes. As a consequence, cameras based on brain functions provide dubious testimony.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Reproduction of reality becomes a matter of likelihood. Likeness collapses into probability. But inceptionism is not just a digital hallucination. It is a document of an era that trains its smart phones to identify kittens, thus hardwiring truly terrifying jargons of cutesy into its means of pro­ sumption. It demonstrates a version of corporate animism in which commodities are not only fetishes but dreamed-up, franchised chimeras. Yet these are deeply realist representations. According to Gybrgi Lukdcs, \"classical realism\" creates \"typical characters\" as they represent the objective social (and in this case technological) forces of our times (Idris 2005). Thus, inceptionism unlocks the black box of image recognition to release an almost medieval zoo of phantasmagoric creatures locked inside.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  [Figure 1.2.] A plate of spaghetti meatballs returning our gaze. [Image: Thorne Brandt,  available at: https:\/\/twltter.com\/thornebrandt\/status\/6171736182383329287langsen. accessed August 1.2018.1  Inceptionism gives those forces a face—or more precisely un­ limited eyes. The creature that stares at you from your plate of meatballs is not an amphibian beagle, though. It is the ubiquitous surveillance of networked image production, a type of memetically modified intelligence that watches you in the form of the lunch that you will Instagram in a second if it doesn't attack you first. Imagine a world of enslaved objects remorsefully scrutinizing you. Your car, your yacht, your art collection is watching you with a gloomy and utterly depressed expression.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  You may own us, they seem to say, but we're going to inform on you. You will start missing Althusser's lonely police officer, because now you are being interpellated 24\/7 by a serving of dog pasta. And then just guess as to what kind of creature we'll re-cognize in you! This question of recognition recalls and reveals the enduring power of the Turing test as a mode of identification and reveals the segregation at the core of assessing machine learning. Turing's  [Figure 1.3.] The shape in this flock of birds over New York appears to be the face of President Vladimir Putin. (Screenshot of video by Sheryl Gilbert, available at; https.\/\/  www.youtube.com\/watch7v-h-7-Ej_Nulg, accessed August 1, 2018,]  game was successful if a machine had the same ability as a human  to confuse an interrogator about its gender. But contemporary computation is not about confusion of identity but multiplication of identities.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Facebook, for example, has modified the imitation game to say: if you don't want to identify as man or as woman that's fine, but please check one of these fifty-plus boxes to state your precisely defined other type of gender, and we'll make sure to send you the appropriate adds. This is not an imitation game but  an identification game. Similarity—or correlation—as mathematical evidence is something  Turing discussed as well. To challenge his own ideas, he cited the objection that machines could never bond over strawberries and cream like humans. But he answered his own challenge with a complex twist; Yes, a machine cannot bond with a man in the same way that a white man will bond with a white man over strawberries with cream and a black man will bond with a black man over straw-  thinking?’ Some people think so. Because the idea of white guys bonding over strawberries and cream has moved to the heart of social-network analysis. This is a pristine example of so-called homophily, a con­  cept further discussed by Wendy Chun (see Chun in this volume). Homophily means that people like to bond with similar people.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  How could this produce mathematical evidence of anything? If white men mostly have strawberries and cream with white men, this means that whoever a white man has strawberries with is most likely a white man. This is what Facebook packages into the idea that you are like what you like, and that you will like the things that people who are like you like. This is how they sell you strawberries with cream. And this is also how Google concludes you are not a robot. You are not a robot because someone who likes similar things checked the box to say he is not a robot and this applies to you by correlation. If you extend this thinking to the imitation game, you can guess not only the gender of all the players but all their friends and their social network. This is how the game starts transgressing its own boundaries and slowly becomes real.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  So there are two completely different games at hand. On the one  hand, the identification game: if something looks like something,  it is the same. All boxes get checked. On the other hand, Turing's imitation game: maybe something that looks similar is the same. It's definitely possible that someone who comes across as a man is a man. Then again maybe not. At this point, a thinking machine will decide that this is not the interrogator's business. The best choice is to politely move on to a protracted and paradoxical discussion of the weather.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Apophenia Inceptionism proves that pattern recognition also exists where there is no pattern but a form Is detected nevertheless. This  of random patterns within random data. As Benjamin Bratton recently argued, apophenia is about \"drawing connections and conclusions from sources with no direct connection other than their indissoluble perceptual simultaneit\/' (Bratton 2013). Are the patterns \"recognized\" in the sea of data today just supersti­ tious mumbo-jumbo? Is apophenia an updated form of divination? Photography was once famously described as soothsaying by Walter Benjamin: \"[IJs not every corner of our cities a scene of action? Is not each passerby an actor? Is it not the task of the photographer—descendant of the augurs and the haruspices to uncover guilt and name the guilty in his pictures?\"\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  (Benjamin  1974,25). Still, there is a crucial distinction between the twentieth-century photographer and the filterers and analysts of the twenty-first. The new pattern extractors are not mainly supposed to recognize the guilty after the fact. They are expected to predict the perpetrator as well as the crime before it has been able to occur. Every spot of our cities is mapped out as a probable crime site, fully decked with gender- and age-based targeted advertising, and surveilled by animated commodities, divinatory cellphone cameras, and aerial  views from tapped drones. The twenty-first-century augur creates the image before the event, anticipating its effect and calling forth reality. The arrow of time has reversed, but the flow of time is unstable and has become essentially unpredictable. However apophenia also has a creative aspect.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Back in the Neolithic, humans imagined star constellations and ob­ served patterns of movement by projecting animal shapes into the skies. Let's say they saw a crab and called this constellation Cancer. Even though there was no actual crab in space, constellations like  One could laugh about the poor naive people of the period who insisted on seeing nonexistent shapes in the skies. But by tena­ ciously sticking to projecting fictional figures into the cosmos, the fundamental movements of the solar system were uncovered. This didn't happen, though, because people believed crabs were walking in the cosmos; this happened because people came eventually to realize that there were (most probably) no crabs in the cosmos. Had they not they \"seen\" them though, they might have missed defining patterns in the movements of planets. But they would have also missed the patterns if they hadn't given upon the literal reality of the crabs. But even more importantly all these activities also completely changed the organization of society.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  The analysis of planetary and star movements enabled the development of the calendar and agriculture. Cue irrigation, storage, breeding, architecture, sed­ entary lifestyles, and so on. Storage created the idea of property. Bands of hunters and gatherers were replaced by proto-states of farmer-kings and slaveholders, by vertical social hierarchies. Apophenia—as a part of magical thinking—contributed to all these transformations. But what are we going to make of contemporary acts of apophe­ nia? Are we to assume that computer vision has entered its own Neolithic phase of magical thinking and pattern projection? But if this is the case, one thing is very different.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  To keep expressing this through the example of crabs in space: computer vision still seems to be in the phase where it thinks that there really are crabs in space and that the patterns emerging from the cosmos of data are actually reality. Software engineers like saying about computers: garbage in, garbage out. In divinationist computer vision let's rephrase this as: crab in, crap out. Let's see faeces in clouds, while we are at iti  the technologies invented during this period. Today a lot of data-related vocabulary refers back to techniques first developed during the Neolithic. Data farming and harvesting, mining, and extraction point back to agricultural and metallurgic procedures. Today, expressions of life as reflected in data trails become a farmable, harvestable, minable resource managed by informational biopolitics. The stones and ores of the Neolithic are replaced by coltane, silicone, and Minecraft Red Stone.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  So what is the function of apophenia now, when new procedures of pattern \"recognition\" threaten to create new types of kings and slaveholders?\" Outside Let's think back to the beginning and Althusser’s policeman yelling, \"Hey youl\" In fact this really did happen to a person called George Michael, when he was apprehended in a Beverly Hills toilet after a plainclothes policeman had encouraged him to commit what U.S. legal jargon calls a \"lewd” act. Michael was hailed, apprehended, and jailed. He had incorrectly recognized the pattern, or rather he had been duped into believing he was being chatted up. As a result LAPD went all \"Hey you!\" on poor George. Arguably Michael has misinterpreted a pattern: he mistook a policeman yelling \"Hey you\" for a lover, an act of apophenia if there ever was one. And predictably, scorn and ridicule poured over him.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  But, instead of apologizing or admitting an error of judgment, Michael brilliantly insisted on his perspective. He released a video called \"Outside\" in which this scene is retold and roles are flipped over; the men's lavatory turns into a dance floor, disco balls pop from the ceiling and squadrons of gay biker cops dance with one another. After all who said one needs to accept the LAPD's idea of a proper subjected subject? Michael insisted on recognizing patterns differently: \"Hey you!\" is not only an act of subjection but perhaps the most basic act of human communication, an act of acknowledg-  defiant apophenia. This type of apophenia can cause serendipitous misreadings or end you up in jail, that is, but at least not as a docile subjected subject. It (mis-)reads the letter of the law for a love letter, it insists on not recognizing the other at all but rather knowing them in the biblical sense, not as sea of data but as flow of energy, not as pattern-oflife but as wave of desire. Who got the point—the tons of morons who laughed about George for not \"getting it right,\" or George, who got it left so to speak and just cruised ahead of the pattern?\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  This is why I suggest we follow him and go outside, right now. Let's go.’^  Coming in But, wait. Where is outside? This question is less simple than it seems. And it may well turn out we don't have to go anywhere at all because we are outside already. At least the NSA thinks so. Didn't their writer complain about the \"sea of data—data, data every­ where, but not one drop of information?' Isn't this \"sea of data\" a big outside, in the most romantic and sublime sense of the word?\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  An \"unknown unknown\" in Donald Rumsfeld's inimitable definition? Doesn't it look like the \"big out­ doors\" heroically tackled by speculative realists? At the very least this wild and life-threatening sea of data is certainly not \"the sofa\" George Michael emphatically declares he's done with. To give a bit less romantic examples: in terms of political geogra­ phy the outside is increasingly difficult to pin down. More and more spaces are converted into extraterritorial enclaves and duty-free gated communities, into para-statelets and anti-\"terrorist\" oper­ ation zones, offshore entities and corporate proxy concessions, a configuration for which Keller Easterling brilliantly coined the term ExtraStateCraft (Easterling 2014). These areas are not—and  this happening when-as in Lebanon or Italy-the idea of garbage in garbage out no longer works. Instead it's garbage in, garbage in-between, garbage all over, and more to come. Its garbage inside out.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  But if many of us are outside in already, either as dirty or clean data, as signal or noise, Graeber or Grueber; isn't a \"coming out' at  the same time a \"coming in\"? Actually this is exactly how George Michael continues his argument. The \"outside\" is not about the romantic great outdoors of icebergs and posthuman reason, not about calculating being nor divining online shopping craves, nor terrorist threats from petabytes of garbage. \"Outside\" means: servicing the community offlesh and bone  (nothing more).”  He sings: And yes, I've been bad Doctor, won't you do with me what you can You see I think about it all the time I'd service the community (but I already have you see!) I never really said it before There's nothing here but flesh and bone There's nothing more, nothing more There's nothing more Let's go outside  Mr. Michael counterinterpellates the policeman by challenging him to service the community. His version of a policeman does exactly that. But this community is no longer the same either. It is not a world where people end up as dirty data and dead brown teenag­ ers, stuck with overflowing garbage in the paradoxical no-man'slands of statistical bureaucracy and overall exception.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Rather this needs to be a world in which everything looks just the same, just seen from a completely different angle. How does  vast data set of the cosmos is actually there. In the Neolithic this was impossible but not now. Let's say the predicted pattern is: alien intelligence exists, it is evil and everywhere, and in order to create patterns to contain it, we need to compute all the data in the universe. The person then ventures out into the vast ocean of spam and penis enlargement ads to look for this mythical creature. But then the person has a brilliant idea. She asks herself: How about accepting that the projection may or may not correspond to reality? Intelligent evil aliens may exist or not, just as crabs, lions, and scorpions too might actually exist somewhere in the depths of the cosmos.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  We cannot exclude it. Maybe we could even calculate it if we just keep crunching numbers. But how about this question: Do intelligent humans exist at all? This person might then discover potential samples of this species inside the spacecraft's own toilet. It turns out that the intelligent person in the toilet is George Michael. And then she realizes that her space travel is not extra­ terrestrial at all but intraterrestrial. The ExtraSpaceCraft she's been flying never left the launchpad as funding for space missions got cut. The cosmos she saw was some sort of projection of U.S. health insurance data.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  Infuriated, she asks George Michael to immediately reform police services. He politely points out that policing can be seen from a different angle as well: as servicing the community of those who keep on being crunched as overpoliced dirty data, or ignored as underpoliced inhabitants of all sort of failed states, platinum card lounges, and other examples of extraterritorial contemporary geographies. Seen from the latter perspective, just condemning policing is not going to make things better. Both blatant over- and underpolicing combine into the destruction of the common. Let's leave the detailed description of the different modes of servicing the community of flesh and bone to Mr. Michael. But from this perspective the sea of data turns out to be the mess of human relations (nothing more). Althusser's model of recognition and policing suggests that you need to sacrifice the common like  new empires ot data barons and stakeholders. Its a bit rough.\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":"  frankly. in contrast one could first of all accept that what is PO^ray^ “ an external and threatening sea of data that needs to be sifted, filtered, cleansed, and purified is basically the mess of human  nature. One might as well have fun with it. This is not to say that this will be any more rational. It will not be more beautiful, noble, or true either. There will be plenty of crabs  and crap to deal with, not to mention evil humans and intelligent aliens. Just ask yourself; do you prefer to dance in an ExtraSpaceCraft toilet? Or would you rather fill out forms all day?\n"}
{"prompt":"A Sea of Data: Pattern Recognition and Corporate Animism Forked Version ->","completion":" \n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  2 The Creative Power of Nonhuman Photography  iEarth This chapter offers a philosophical exposition of the concept of “nonhuman photography” that forms the axis of the book.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  It also explores the photographic medium’s creative, or life-making, power. As I explained in the preface, “nonhuman photography” embraces three different but often entwined ontological categories: photographs that are not of, by, or for the human. Yet the ultimate aim of this chapter, and the book as a whole, is not just to enumerate examples; rather, it is to suggest that there is more to photography than meets the (human) eye and that all photography bears a nonhuman trace. With this perhaps still somewhat cryptic proposition in mind, let us take a short detour from philosophizing to look at a photographic project of mine as a way to provide a bridge from the previous chapter on nonhuman vision—as well as to introduce the key ideas behind the argument that follows. Titled iEarth (figure 2.1), the project offers a vision of natural spaces that are actually (wo)man-made while also bearing an imprint of a technological tool. Manufactured from a children’s diorama kit, these “unnatural landscapes” (in their original online gif version) dazzle with color and lushness, displaying the kind of greenery that is more associated with media representations of nature than with “nature itself.” The bird’s-eye view of the landscapes evokes the perspective of satellite images of different locations, both remote and familiar, which we associate with Google Earth or Microsoft’s Virtual Earth—a viewing position I discussed in the previous chapter under the rubric of “nonhuman vision.” This particular perspective has a  Figure 2.1 Joanna Zylinska, stills from iEarth, 2014. For the gif version, see Joanna Zylinska, “iEarth,” ADA: A Journal of Gender, New Media, and Technology 5 (May 2014), http:\/\/ adanewmedia.org\/2014\/07\/issue5-zylinska\/. number of levels in this project: in the crafting of the diorama, the taking of the image, the pixelation of the photographs, and then, in the last instance, the gif animation.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Pixelation and animation are more than just a visual or conceptual gimmick here: their implementation was intended to destabilize the relationship between “nature” and “artifact,” between “the real” and “the virtual,” in the constitution of the diorama landscapes. Yet instability is, of course, already inherent in the very concept of “landscape”— a concept which is one of the cornerstones of traditional photography. Besides, iEarth is not actually a landscape but rather a photograph (or rather a series of photographs) of an approximation of a landscape, and hence a copy of a copy—without an original. The work suggests that photographic re\/presentation, be it analog or digital, is always already technological, and also  by means of a whole sequence of technological tools such as ploughs, tractors, excavators, secateurs, easels, paintbrushes, and cameras. “The cut,” as previously argued, is therefore essential both to temporarily stabilize the world into entities and to make temporarily stable, light-induced images (aka photographs) out of the flow of duration. This somewhat serious-sounding philosophical agenda is underpinned by a more playful desire on my part to poke fun with this work at the monumentalization of nature in the work of meditative “large-format” landscape photographers, such as Andreas Gursky and Edward Burtynsky—and at the “view from nowhere” perspective they often adopt. The “now you see it, now you don’t” aspect introduced by the pixelation and gif animation, coupled with what may look like excessive acceleration or even computer error, is aimed to push the viewer to engage with these images physically, through squinted eyes. The aesthetics of iEarth thus issues an injunction: the viewer has to become actively involved in the process of seeing by moving her head, blinking, or even looking away from the dizziness caused by this pseudo-sublime, one we can associate with the oft-frustrating and jaggy visuality of the early Internet.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  The homonymy between the “I” and the “eye” in iEarth is a commentary on our practices of looking at the world but also on our narcissism when engaging with it. The brandlike title was chosen to remind us that “nature” has become a commodity, a product we fetishize and yearn for. With this, iEarth perhaps inscribes itself ironically in what Sarah Kember has termed “iMedia,” with the posited presence of the polyvalent “I” appended to a brand being “an illusion that refuses to be revealed.”1 The subject of iMedia is thus “isolated in the production and consumption of their own media”:2 an illusion that extends to the narcissistically endowed humanist vision of the Earth that is often seen as existing for “our” dominion, benefit, and pleasure. Just like Dziga Vertov’s kino-eye, iEarth also foregrounds the technical process of the production of the world through biological and photographic vision. Through this process, it can perhaps help us look at the Earth—which for us humans tends to stand for “the world”—and at ourselves on this Earth, with a different eye. Seeing our planet from afar has by now become a familiar device for creating an illusion of telluric unity (aka “globalization”). We can think here of two iconic images: the 1968 Earthrise and the 1972 Blue Marble (figures 2.2  Figure 2.2 Earthrise (rotated), taken during the Apollo 8 mission, 1968, courtesy of NASA. Public domain.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  by Stewart Brand, publisher of the Whole Earth Catalog—a countercultural magazine-cum-product review manifesting a unique mix of West Coast environmentalism and entrepreneurship—to conjure up a particular image of both present and future. Brand’s incorporation of the two images into his publication was aimed at creating a collective vision of humanity while also allowing this humanity to see “itself from outside”: a vision intended to evoke a sense of responsibility for this “delicate jewel in vast immensities of hard-vacuum space.” “Suddenly humans had a planet to tend to,” declared  Figure 2.3 The Blue Marble, taken during the Apollo 17 mission, 1972, courtesy of NASA. Public domain. narrow history dominated by the episodic adventures of the space exploration paradigm.”4 He goes on to show that this view from above that is supposed to establish a commonality actually ends up being what I termed in the previous chapter, with Haraway’s help, a “view from nowhere.” Indeed, not a single astronaut on Apollo 17, from whom the image originated, actually did see the Earth as depicted in the Blue Marble image, as they were unable to position their bodies close enough to the window to look out: instead, the images captured had been shot “from the hip.”5 More interest-  involved in the production of the two photographs. On receiving the raw data from the space cameras, the image processors at NASA labs adjusted and “reoriented” the copies obtained; they also chose the color scheme “to align with cultural expectations for popular consumption.”6 While the evenly lit Earth in the Blue Marble is the result of the adjustment of lights and shadows as well as tight cropping,7 the image of Earthrise as we know it has been shifted from a portrait to a landscape orientation in order to create an illusion of the Earth “rising” over the moon, with a view to subjugating the nonhuman eye of the space camera to the visual mastery of the human. The rationale behind these manipulations, Russill argues, was to repress “the strangeness and difficulty in seeing the earth,”8 a perceptual shift that was supposed to help promote the environmental agenda. We cannot actually see environmental damage or climate change—to really “see” them, we would need to capture electromagnetic radiation that is illegible to the human, or map the rise in ocean temperatures over a prolonged period of time and then translate the data streams obtained into diagrams, graphs, and other kinds of visualizations9—and yet images like Earthrise and the Blue Marble constitute the Earth as a graspable object while issuing a veiled threat of “it” being taken away from “us.”10 The “pixel image” of the Earth included in Al Gore’s consciousnessraising environmental documentary An Inconvenient Truth (2006) and adopted from astronomer Carl Sagan’s “Pale Blue Dot” visualization of our planet as an insignificant blurry square captured by Voyager 1 from the distance of around 6 billion kilometers is a case in point (figure 2.4), even though, through its nonrepresentational aspect, it seemingly stands in contrast to the two photographs discussed above. As Russill highlights, “The ‘whole earth’ fills most of the frame and suggests the priority of the global in understanding our earthly condition.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Sagan’s dot, on the other hand, hints at a cosmic zoom by adopting a perspective of an interstellar machine probe.”11 Yet the fantasy of the human grasp of “the object” (be it the Earth or climate change) is manifested by both the photos and the pixel, reduced in scale to allow us to see this “it,” and take control. All three images are therefore very much part of the logic of Kember’s iMedia. They adopt nonhuman vision as attempts at visual mastery, thus repressing the strangeness of what is being perceived, while reducing what is being perceived to an  Figure 2.4 The Pale Blue Dot, taken by the Voyager 1 space probe at the request of astronomer Carl Sagan, 1990, courtesy of NASA, annotated by Joanna Zylinska. Public domain. standpoint for this salvation is and how we should go about embarking upon it remain unknown: in images like this, reduced to our human scale and viewpoint, the human ends up enlarging himself as an occupier and owner of the actual, nonironic “iEarth.”12 The proto-Anthropocene sensibility is thus already reduced to a belief that, as Nicholas Mirzoeff suggests, “somehow the war against nature that Western society has been waging for centuries is not only right; it is beautiful and it can be won”13—because, at the end of the day, we can hold the Earth in our hand, or shrink it to a pale blue dot. The somewhat excessive pixelation of my (definitely ironic) iEarth can therefore perhaps be read as an invitation to look otherwise: not from close up or far away but rather (from) askew, and also through, with, and as part of. It can also signal an attempt to recut and reframe Al Gore’s “pixel as family portrait,” to use Russill’s apt term, in nonhumanist terms in order to open up a less masterful and less self-aggrandizing visuality of the Anthropocene, with its unequal distribution of shadows and lights. Photography as philosophy iEarth and its more serious visual predecessors are not meant to serve as direct illustrations of the concept of nonhuman photography this chapter outlines.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  However, they do lead us to a wider problematic of humannonhuman relations, and raise the politico-ethical question of human responsibility in a world in which the agency of the majority of actants— such as wind, meteorites, rain, or earthquakes—goes beyond that of human decision or will, even if it may be influenced by human action. The question of human responsibility in the universe, in which we are quintessentially entangled on both a cellular and a cosmic level (with all of us being “made of starstuff,” as Carl Sagan remarked in his documentary TV series Cosmos), is an important one. Even if, unlike Stewart Brand, we cannot be entirely sure what this fragile human “we” actually stands for, the responsibility to face, and give an account of, the unfoldings of this world—which is made up of human and nonhuman entities and relations—belongs to us humans in a singular way. Philosophy, in particular ethics, has typically been a way of addressing the problem of responsibility.14 But written linear argument is only one mode of enquiry through which this problem can be approached. issues: those enabled by art, and more specifically photography—of which the iEarth project is an example. These experiments have been driven by one overarching question: Is it possible to practice philosophy as a form of art, while also engaging in photography and image making as ways of philosophizing? The reason photography may lend itself to this kind of cross-modal experimentation is because of its ontological, or world-making (rather than just representational), capabilities. We can turn here for support to literary critic Walter Benn Michaels, who, while upholding “the impossibility (and the undesirability) of simply denying the indexicality of the photograph,”15 also argues, “It is precisely because there are ways in which photographs are not just representations that photography and the theory of photography have been so important.”16 My proposition about photography’s ontological capabilities entails a stronger claim than the one made by Michael Fried in the conclusion to his book, Why Photography Matters as Art as Never Before.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  There, photography as practiced by representatives of what Fried calls “the anti-theatrical tradition,” such as Jeff Wall, Thomas Struth, or Berndt and Hilda Becher, is positioned as “an ontological medium” because it “makes a positive contribution” to ontological thought via its engagement with issues such as absorption and worldhood.17 While for Fried photography just makes philosophy better, my claim in this book is that photography makes philosophy, full stop—and also, more importantly, that photography makes worldhood, rather than just commenting on it. It may seem at this point that what was meant to be an account of nonhuman photography is revealing itself to be quite strongly attached to the concept of the human—as philosopher, photographer, or art critic. This is true, because there is nothing more humanist than any unexamined singular gesture of trying to “move beyond the human.” My ambition here, as in my other work,18 is therefore to explore the possibility of continuing to work with the concept of the human in light of the posthumanist critique,19 taking the latter seriously as both an injunction and a set of possibilities. The reasons for this proposed retention of the human have nothing to do with any kind of residual humanism or species nostalgia. Instead, they spring from the recognition of the strategic role of the concept of the human as a temporary stabilization in any kind of artistic, creative, political, or ethical project, while also remembering that in many works of  dependency, both material and conceptual, on other living and nonliving entities and processes. Seen as too Eurocentric and masculinist by postcolonial and feminist theory, the human has also been revealed by various science disciplines to be just an arbitrary cutoff point in the line of species continuity on the basis of characteristics shared across the species barrier: communication, emotions, or tool use. This (non- or posthumanist) human which my book retains as the anchor point of its inquiry is thus premised on the realization that we are in (philosophical) trouble as soon as we start speaking about the human, but it also recognizes the historical entanglement of this concept and the way it has structured our thinking, philosophy, and art for many centuries.20 So, onto a posthumanist theory of nonhuman photography, as articulated by a human, all too human, philosopher-photographer … Toward nonhuman photography (and all the way back) To anchor our discussion of nonhuman photography in scholarly debates, I want to look at two important texts in photography theory in which the relationship between human and nonhuman agents, technologies, and imaging practices has been addressed explicitly: the 2008 essay by John Tagg titled “Mindless Photography” briefly mentioned in the previous chapter, and a 2009 book by Fred Ritchin, After Photography. Tagg’s essay is a commentary on the supposed withering of the critical paradigm in photographic practice and its interpretation, a paradigm articulated by Victor Burgin in his 1984 seminal text Thinking Photography and subsequently adopted by many scholars and students of photography.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  In his article Tagg references two then-recent phenomena which, in his view, had radically altered the relationship between photography and the human: (1) the CCTV system introduced in 2003 to monitor the implementation of a traffic congestion charge in central London, and (2) the visual rendering of data captured by a radio telescope, in June 2005, of solar dust cloud radiation in the Taurus Molecular Cloud, where the data represented an event that “took place in 1585, or thereabouts.”21 While in the 1970s and early 1980s “photography was framed as a site of human meanings that called the human into place,” the more recent developments cited by Tagg  relationship between the embodied human subject and the technical apparatus has been irrevocably broken, with the technological circuit which consists of “cameras, records, files and computers”23 doing away with visual presentation, “communication, psychic investment, a subject, or even a bodily organ”24—until the visual data concerning the car with a given number plate that has missed the congestion charge payment reaches the court. Tagg is similarly troubled by the severance of the relationship between photography and human sensation, between stimulus and response, in space photography. (Unlike Stewart Brand, he does not find it reassuring to be able to hold whole planets, including our own “Blue Marble,” in our gaze.) Instead, Tagg goes so far as to suggest that in those new technological developments, photography loses its function as a representation of the ego and the eye and even as a pleasure machine built to excite the body. In place of those figures, photography is encountered as an utterly dead thing; mindless in a much blunter sense than imagined [by Burgin]. … [It is] driving towards a systemic disembodiment that, accelerating in the technologies of cybernetics and informatics, has sought to prepare what has been hailed as the “postbiological” or “posthuman” body for its insertions into a new machinic enslavement.25  Photography that is unable to provide stimulation and pleasure for the human is then immediately linked by Tagg with mindlessness, emptiness, and ultimately death. With this articulation, Tagg may seem to be engaging in a belated attempt to rescue photography from its long-standing association with mortality, and to retrospectively postulate the possibility that photography can act as a life-giving force. However, this no doubt radical possibility, briefly hinted at in the passage cited above, is immediately withdrawn.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Photography does not deliver life to the human anymore and, for Tagg, it is only the human that can be both life’s subject and its arbiter. This is, of course, a familiar philosophical gesture, first enacted by Aristotle, whereby technology is reduced to a mere tool for human existence, survival, or improvement and is then assessed on the basis of how well it performs this function (rather than being understood as a dynamic network of forces, as Michel Foucault and Bernard Stiegler respectively suggest, or as an “intrinsic correlation of functions”26 between the human and the apparatus, as Vilém Flusser apprehends it). Conceived in these instrumental  as a space occupied by human and nonhuman entities—photography must inevitably fail. It would be unfair not to mention the political motivation that underpins Tagg’s argument. His concern with “machinic enslavement” is driven by what he sees as the deprivation of the human subject of both corporeal integrity and political subjectivity as a result of the encroachment on our lives of those new photo-imaging technologies, in which “there is nothing to be seen.”27 This concern no doubt has become even more pressing in the era of global networked surveillance enacted by the likes of the NSA, GCHQ, Facebook, and Google. Yet to blame photography for the immoral and inhumane actions of its developers or users is to misidentify the enemy, while also weakening the power of a political critique developed in its ambit. In his essay Tagg takes some significant steps toward analyzing the changes occurring in photographic practice at the beginning of the twenty-first century but then recoils in horror from the brink of his own analysis. What could have served as a stepping stone toward developing both a radical posthumanist photography theory and a radical posthumanist political analysis ends up retreating into a place of nostalgia for the human of yesteryear, one who was supposedly in control of both his personal body and the body politic but who can now only tilt at windmills—which are turning into drones in front of his very eyes.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  If only Tagg had allowed himself to hear the exhortation from another photography theory radical, Fred Ritchin! Admittedly, Ritchin’s work is not free from the sense of nostalgia espoused by Tagg: in After Photography Ritchin reveals that he misses the time when people believed in images and when images could be used to solve conflicts and serve justice. Yet, even though his book opens with a rather dispiriting account of the changes occurring to the photographic medium and its representationalist ambitions, it ends with an affirmation of life in photography. Dazzled by the horizon of scale revealed by telescopy and physics, much as Tagg was, Ritchin nevertheless admits that “in the digital-quantum world, it might be just possible … to use an emerging post-photography to delineate, document, and explore the posthuman. To dance with ambiguity. To introduce humility to the observer, as well as a sense of belonging. To say yes, and simulta-  (Always) nonhuman photography It is precisely in this critical-philosophical spirit, of saying yes, and simultaneously, no, that my opening proposition that all photography is to some extent nonhuman should be read. While I am concerned about ways in which the nonhuman aspect of photography can produce inhumane practices, I also want to suggest that it is precisely in its nonhuman aspect that photography’s creative, or world-making, side can be recognized.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Therefore, rather than contribute to recent jeremiads about photography and its supposed loss of authenticity and materiality, or its visual excess and self-involved banality, I argue that it is precisely through focusing on its nonhuman aspect that we can find life in photography. This line of argument is partly indebted to the work of Flusser, who, in Towards a Philosophy of Photography, writes: “The photographic apparatus lies in wait for photography; it sharpens its teeth in readiness. This readiness to spring into action on the part of apparatuses, their similarity to wild animals, is something to grasp hold of in the attempt to define the term etymologically.”29 Flusser builds here on the Latin origins of the term “apparatus,” which derives from apparare, “make ready for” (as a combination of the prefix ad-, “toward,” and parare, “make ready”). This leads him to read photography as facilitated by, or even proto-inscribed in, the nexus of image capture devices, various chemical and electronic components and processes, as well as sight- and technology-equipped humans. Blaise Aguera y Arcas finds it remarkable that Flusser should describe the camera as having a “program” and “software” when he was writing his philosophy of photography in 1983, given that the first digital camera was not available until 1988. “Maybe it took a philosopher’s squint to notice the programming inherent in the grinding and configuration of lenses, the creation of a frame and field of view, the timing of the shutter, the details of chemical emulsions and film processing. Maybe, also, Flusser was writing about programming in a wider, more sociological sense,” offers Aguera y Arcas.30 Flusser’s conceptualization of photography challenges the humanist narrative of invention as an outcome of singular human genius by recognizing the significance of the technological setup in the emergence of various sociocultural practices. This is not to say that these practices function outside the  of specific technological processes at a particular moment in time.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Flusser’s idea seems to be (unwittingly) reflected in Geoffrey Batchen’s proposition outlined in Burning with Desire that photography was invented—seemingly repeatedly, by Nicéphore Niépce, Louis Daguerre, Hippolyte Bayard, and William Henry Fox Talbot, among others—due to the fact that in the early nineteenth century there already existed a desire for it. This desire manifested itself in the proliferation of discourses and ideas about the possibility of capturing images and fixing them, and of the technologies—“the camera obscura and the chemistry necessary to reproduce”31 the images taken with it—that would facilitate such a development. We could therefore perhaps go so far as to say that the photographic apparatus, which for Batchen contains but also exceeds a discrete human component, was awaiting the very invention of photography. The ideas about the photographic apparatus discussed above will eventually point me not just toward rethinking the photographic medium but also toward a possibility (one that has been withheld by Tagg) of a posthumanist political analysis. For now, taking inspiration from Flusser, and building on the point made by Aguera y Arcas, I want to suggest that human-driven photography—where an act of conscious looking through a viewfinder or, more frequently nowadays, at an LCD screen held at arm’s length—is only one small part of what goes on in the field of photography, even though it is often made to stand in for photography as such. The execution of human agency in photographic practice, be it professional or amateur, ostensibly manifests itself in decisions about the subject matter (the “what”) and about ways of capturing this subject matter with a digital or analog apparatus (the “how”). Yet in amateur, snapshot-type photography, these supposed human-centric decisions are often affective reactions to events quickly unfolding in front of the photographer’s eyes. Such reactions happen too quickly, or we could even say automatically, for any conscious processes of decision making to be involved—apart from the original decision to actually have, bring, and use a camera (or a camera phone), rather than not.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  This automatism in photography also manifests itself in the fact that these kinds of “snap” reactions are usually rechanneled through a whole database of standardized, preprogrammed, preexisting image frames, whose significance we are already familiar with and which we are trying to recreate in a  “couple posing in front of the Taj Mahal.” It is in this sense that, as Flusser has it, “weddings conform to a photographic program.”32 Similar representationalist ambitions accompany many professional photographic activities, including those performed by photographic artists or those undertaken by photojournalists who aim to show us, objectively and without judging, what war, poverty, and “the pain of others,” to borrow Susan Sontag’s phrase,33 are “really” like. Even before any moment of making a picture actually occurs, fine art photographers tend to remain invested in the modernist idea of an artist as a human agent with a particular vocation, one whose aesthetic and conceptual gestures are aimed at capturing something unique, or at least capturing it uniquely, with an image-making device. And thus we get works of formal portraiture; images of different types of vegetation or geological formations that are made to constitute “landscapes”; still-life projects of aestheticized domesticity, including close-ups of kitchen utensils, fraying carpets, or light traces on a wall; and, last but not least, all those works that can be gathered into that ragbag called “conceptual photography.”34 In this way, images inscribe themselves in a cybernetic loop of familiarity, with minor variations to style, color, and the (re)presented object made to stand for creativity, originality, or even “genius.” The automated image Through the decisions of artists and amateurs about their practice, photography becomes an act of making something significant, even if not necessarily making it signify something in any straightforward way. Photography is thus a practice of focusing on what is in its very nature multifocal, of literally casting light on what would have otherwise remained obscure, of carving a fragment from the flow of life and turning it into a splinter of what, post-factum, becomes known as “reality.” Traditionally, this moment of selection—referred to as “decisive” by followers of the documentary tradition in photography, such as Henri Cartier-Bresson—was associated with the pressing of the button to open the camera’s shutter. However, with the introduction of the Lytro camera into the market in 2012, the temporality of this seemingly unique and transient photographic moment has  allowing the photographer to change and readjust the focus on a computer in postproduction. Interestingly, Lytro was advertised as “The only camera that captures life in living pictures”—a poetic formulation which was underpinned by the constant industry claim to “absolute novelty,” but which merely exacerbated and visualized the inherent instability of all photographic practice and all photographic objects. Lytro was thus just one more element in the long-term humanist narrative about “man’s dominion over the earth,” a narrative that drives the progressive automatization of many of our everyday devices, including cameras, cars, and refrigerators. In 2015, the company itself shifted focus—from attempting to alter the focus of singular images to the development of Lytro Immerge: an end-toend system for capturing light fields for use in creating virtual reality (VR) content, “providing lifelike presence for live action VR through six degrees of freedom.”35 And thus, giving us an illusion of control over technology by making cameras smaller and more intimate, and domestic equipment more user-friendly, the technoscientific industry actually exacerbates the gap between technology and the human by relieving us from the responsibility of getting to know and engage with the increasingly software-driven “black boxes.” The renewed interest in VR—a multisensory experience which is supposed to envelop us and feel “real” by being played out in front of our eyes on a screen built into a personal headset—shown not only by Lytro, Inc., but also by many other technology companies, such as Facebook (via its Oculus Rift), Google, Samsung, and Sony, provides an apt illustration of this desire to “keep the box black.” In light of the dominance of the humanist paradigm in photography, a paradigm that is premised on the supposed human control of both the practice of image making and its equipment, it is important to ask what gets elided in such conceptualizations.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Of course, I am not the only one who is asking this question: the problem of nonhuman agency in photography has been explored by other theorists, artists, and curators. One photography event that brought many of these ideas to the fore was Drone: The Automated Image, a series of shows taking place under the umbrella of the photography biennale Le Mois de la Photo in Montreal, curated by Paul Wombell, in 2013.36 The uniqueness of this thirteenth edition of the Montreal biennale lay not so much in highlighting the machinic aspect of  Figure 2.5 Véronique Ducharme, Encounters, 2012–2013. Courtesy of the artist. Rodchenko or László Moholy-Nagy. Drone: The Automated Image (which was concerned with much more than just drones) took one step further on this road toward not just nonhuman but also posthumanist photography by actually departing from the human-centric visualization process. In many of the works shown, the very act and process of capture were relegated to a computer, a camera mounted atop a moving vehicle, a robot, or a dog. To mention just one example, Canadian artist Véronique Ducharme presented a photography-based installation called Encounters, consisting of images taken by automatic hunting cameras (figure 2.5). As the artist explained: Over the course of one year, automatic cameras, installed in various parts of the Quebec landscape, recorded images from the forest.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  The images included animals, sunrise, wind and other actants susceptible of triggering the shutter of the cameras. These digital images, including the “mistakes” of the cameras (i.e., blacked-out or overexposed images) were then transferred onto slide film in order to be projected in the gallery space using slide projectors. Accompanied by its rhythmic mechanical click, each machine has been programmed to sporadically and unpredictably project  Figure 2.6 Juliet Ferguson, Stolen Images, 2011. Courtesy of the artist. Ducharme’s project offers a thought-provoking intervention into the debate about (human) intentionality in photography theory, whereby intentionality is seen as both a condition and a guarantee of the medium being considered a form of art.38 Photographic agency is distributed here among a network of participants, which includes not just nonhuman but also inanimate actors—even if “the beholder” of the installation is still envisaged to be a human gallery-goer. Ducharme’s work has similarities with another project which foregrounds and remediates nonhuman photographic agency without reneging on its human dimension: Stolen Images by British photographer Juliet Ferguson (figure 2.6), published in the London independent photography magazine Flip in 2012 and online in Photomediations Machine in 2013. Accessing CCTV cameras using appropriate search terms via Google as part of her journalism job, Ferguson was able “to see through the all-seeing eyes of the CCTV camera places” what she would not have had access to in the real world—without leaving her sofa.39 The process led her to reflect “on what it means to take a photograph” and to pose the following questions: “The majority of the cameras I used I could pan, zoom and focus. Is this  photography demand a presence or are photographs taken using appropriated cameras controlled from another country in another time zone just as valid as ‘created’ images?”40 Ferguson reveals that, in the process, she began “to see a certain beauty in the images as they became removed from their original intention of surveillance.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Instead, they offered a unique perspective on the ebb and flow of a day, from a vantage point and rigidity that ordinary photography doesn’t offer.”41 The photographic condition Ducharme’s Encounters and Ferguson’s Stolen Images demonstrate that art practice is merely part of a wider photographic condition, with things photographing themselves, without always being brought back to the human spectrum of vision as the ultimate channel of perception and of things perceived. Naturally, humans form part of this photographic continuum—as artists, photojournalists, festival organizers, computer programmers, engineers, printers, Instagram users, and, last but not least, spectators. However, what these two projects make explicit is that we are all part of that photographic flow of things being incessantly photographed, and of trying to make interventions from within the midst of it. In this way, Ducharme’s and Ferguson’s projects fall into a category that we might term insignificant photography—not in the sense that they are mindless (as Tagg would perhaps have it), irrelevant, and of no consequence, but rather in the sense of allowing us to see things that have been captured almost incidentally and in passing, with the thematic “what” not being the key impulse behind the execution of the images. It is worth emphasizing that this idea of insignificant photography has not just come to the fore with the development of networked digital technologies but was actually present in the early discourse of photography, even if that early discourse tended to confine photography’s nonhuman aspect to the fairly conservative idea of “objective observation.” Steve Edwards explains: Throughout its history, the camera has repeatedly been seen as an objective machine that captures information without any interference from the artist. … In the early years of photography this was an often repeated theme: it was assumed that the sun made the picture, or the camera did, or even that the object in question depicted  The separation between the mechanism of photography as “objective observation” and the human-centric notion of the “intentionality” of the photographer has been used as a disciplinary device in art history: as signaled before, the elevation of photography to the status of art has been premised upon it.43 It is this separation that the work of many contemporary photographers such as Ducharme and Ferguson troubles to a significant extent. So what is meant by this notion of the photographic condition, and does the postulation of its existence stand up to philosophical and experiential scrutiny? To explore these questions, let us start from a very simple proposition: there is life in photography.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  If living in the so-called media age has become tantamount to being photographed on a permanent basis, with our identity constituted and verified by the ongoing development of our photo galleries and photo streams on mobile phones, tablets, and social media platforms such as Facebook, Instagram, Tumblr, and Pinterest, not to mention the thousands of security cameras quietly and often invisibly registering our image when we pass through city centers, shopping malls, and airports, then, contrary to its more typical Barthesian association with the passage of time and death, photography can be understood more productively as a life-making process. Photography lends itself to being understood in a critical vitalist framework due to its positioning in a network of dynamic relations between present and past, movement and stasis, flow and cut. In making cuts into duration, in stabilizing the temporal flow into entities, photography is inherently involved with time. Significantly, for vitalist philosophers such as Henri Bergson and Gilles Deleuze, time, duration, and movement stand precisely for life itself. As Bergson provocatively asks, “But is it not obvious that the photograph, if photograph there be, is already taken, already developed in the very heart of things and at all the points of space?”44 Photography’s proximity to life is therefore revealed in its temporal aspect, which is enacted in photography’s dual ontology, whereby it can be seen as both object and practice, as both snapshot and all the other virtual snapshots that could potentially have been there, and, last but not least, as both being something here and now, and being something always unfolding into something else. It is also in this dual ontology that the nonhuman side of photography comes to the fore, performed as it  equipment, and webcams, as well as camera- and mobile-phone-sporting humans. My notion of the photographic condition has affinities with the Deleuzeinspired concept of “camera consciousness” developed by Anthony McCos­ ker with regard to drones. McCosker proposes we move beyond seeing drones primarily as “unruly aerial objects with the capacity for privacyinvasive imaging” and approach them instead “as experience and as provocation to reconsider wireless networks, visuality and camera-conscious sociality.”45 This more relational mode of approaching human-machinic entanglements, beyond the moral panic about technology’s threat to “us”—even if not beyond the political concern about drones’ role in redefining relations of sociality, intimacy, and control—paves the way for a new understanding of visuality prompted by the machinic vision of the disembodied eye.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  In this reconceptualization, “camera consciousness” begins to stand for “a broader cultural condition and logic bound up in the dual sense of visual augmentation and anxiety over altered modes of visibility and mediated perception.”46 Yet anxiety does not mean a priori repudiation: indeed, McCosker is clear that a new consciousness to emerge from a different—intensified, distributed, and networked—relation with technical objects is needed if we are to truly grasp the singularity of the visual experience today, in both its constraining and enabling guises: “Hence with drones we can also ask: what are the new kinds of perception and action or control made possible by our human-technical assemblages?”47 Summing up, we should reiterate that to acknowledge the life-making aspect of photography is not necessarily to condone the politically suspicious yet increasingly widespread technologies of ubiquitous surveillance, control, and loss of privacy enabled by various kinds of cameras. Much has already been written about the latter, with little acknowledgment so far of the vital potentiality of photography—which, in an ontological sense, does not have to be an agent of control, even if it at times plays this role. There is, therefore, a danger of moralizing photography in academic and public discourses before its potential has been truly explored. The foregrounding of the inherently creative power of photography as a practice, and of the camera consciousness as a distributed and networked experience facilitated by the new visual setup, is therefore part of the philosophical argument of this  Photography and life The on-off activity of the photographic process, which carves life into fragments while simultaneously reconnecting them to the imagistic flow, may allow us to conclude not only that there is life in photography, but also that life itself is photographic. Interestingly, Claire Colebrook explains this process of creative becoming in and of life by drawing on the very concept of image production, or “imaging.” She writes: “All life, according to Bergson and to Deleuze after him, can be considered as a form of perception or ‘imaging’ where there is not one being that apprehends or represents another being, but two vectors of creativity where one potential for differentiation encounters another and from that potential forms a relatively stable tendency or manner.”48 This idea has its root in Bergson’s Matter and Memory, where our experience of the world, which is always a way of sensing the world, comes in the form of images. We should mention here that, on the whole, Bergson is somewhat hesitant about the role played by images in cognition: in Creative Evolution, he dismisses them as mere “snapshots” of perception, post-factum reductions of duration and time to a sequence of the latter’s frozen slices.49 It may therefore seem strange that my attempt to say something new about photography revisits the work of a philosopher who only used the concept of photography negatively, to outline a “better”—i.e., more intuitive and more fluid—mode of perception and cognition. However, my argument here, as in my previous work,50 is that Bergson’s error is first and foremost media-specific and not philosophical per se: namely, he misunderstands photography’s inherently creative and dynamic power by reducing it to a sequence of already fossilized artifacts, with the mind fragmenting the world into a sequence of “snapshots.” For this reason, I want to suggest that, putting their mystical underpinnings aside, we can mobilize Bergson’s philosophical writings on duration understood as a manifestation of élan vital to rethink photography as a quintessential practice of life. Indeed, photography is one possible (and historically specific) enactment of the creative practice of imaging, with the cuts into duration it makes always remaining connected to the flow of time.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  If we accept the fact that cutting—whether with our visual or conceptual apparatus—is inevitable to the processes of making sense of the world, then  of the flow of duration that still bear a trace of life—rather than as frozen and ultimately deadly mementoes of the past. It is important to point out that, in order to recognize any kind of process as a process, we need to see it against the concept of a temporary stabilization, interruption, or cut into this process. A photograph is one possible form such stabilizations take, and a rather ubiquitous one at that. It is precisely because of its ubiquity and its increasingly intuitive technological apparatus that it serves as a perfect illustration of Bergson’s ideas—or rather, of my own “differentiated reading” of Bergson. Bergson himself foregrounds this mutually constitutive relationship between process and stoppage when he says, “Things are constituted by the instantaneous cut which the understanding practices, at a given moment, on a flux of this kind, and what is mysterious when we compare the cuts together becomes clear when we relate them to the flux.”51 This supposition allows us to see photography as an ultimately salutary and creative force in managing the duration of the world by the human as a species with limited cognitive and sensory capacity. Bergson aside, there are also more “vernacular” reasons for describing photography as a quintessential practice of life. Over the last few decades, the photographic medium has become so ubiquitous that our very sense of existence is shaped by it. We regularly see ourselves and others represented by the photographic medium, in both its formal and informal guises—from the documentation of our life in its fetal stage via medical imaging, through to the regular recording of our growth and maturation in family, school, and passport photographs; the incessant capture of the fleeting moments of our life with phone cameras; and the subsequent construction of our life’s “timeline” on social media.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  We also make sense of the world around us through seeing it imaged. While photography used to be something that others did—professionals equipped with large machines that allowed them to capture a better image of the world out there, advertisers trying to sell us chunks of that world, photojournalists dispatched to the world’s remote corners that few of us could regularly access—we can safely say that, in the age of the camera phone and wireless communication, we are all photographers now, with our consciousness becoming that of the camera in a more literal sense as well. Yet we are all not just photographers today: we have also become distribu-  in the recent history of photography is not the arrival of digital cameras as such, but rather the broadband connection of these cameras to the Internet—in effect turning every photograph on the Web into a potential frame in a boundless film.”52 One could perhaps go so far as to say that the availability of relatively low-cost storage and networked distribution of digital data has changed the very ontology of the photographic medium. Photographs function less as individual objects or as media content to be looked at and more as data flows to be dipped or cut into occasionally. The intensity and volume of photographic activity today, and the very fact that it is difficult to do anything—order food, go on holiday, learn about the Moon, have sex—without having it visualized in one way or another, before, during, or as part of the experience, gives credence to Sontag’s formulation that “the photographs are us.” Even though this photographic condition does have a very particular, culturally specific enactment in the age of the digital camera and “the networked image,” could we return to our original point to suggest that there is a deeper logic, or tendency, in photography that takes the medium beyond its specific cultural incarnations, be it digital or analog? Chapter 4 will trace this relationship back to deep time, through a parallel reading of photographs and fossils. For now, I would like to highlight that the notion of the creative role of the imaging process in life has also been manifested in the work of radical biologists, such as Lynn Margulis. As she put it in a book coauthored with her son Dorian Sagan, “All living beings, not just animals, but plants and microorganisms, perceive.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  To survive, an organic being must perceive—it must seek, or at least recognize, food and avoid environmental danger.”53 This act of perception, which involves the seeking out and recognition of something else, involves the making of an image of that something else (food, predator, sexual partner), one that needs to be at least temporarily fixed in order for the required proximity—for consumption or sex—to be accomplished. We could perhaps therefore suggest that imaging is a form of proto-photography, planting the seed of the combined humanmachinic “desire” explored by Batchen that came into its own in the early nineteenth century. It is precisely through images that novelty comes into the world, which is why images should not be reduced to mere representations, Colebrook argues, but should rather be understood as creations,  as a form of picturing what already exists: instead, life is a creation of images in the most radical sense, a way of temporarily stabilizing matter into forms. Photographic practice as we conventionally know it, with all the automatism it entails, is just one instantiation of this creative process of life. If all life is indeed photographic, the notion of the photographic apparatus that embraces, yet also goes beyond, the human becomes fundamental to our understanding of what we have called the “photographic condition.” To speak of the photographic apparatus is, of course, not just to argue for a straightforward replacement of the human vision with a machinic one, but rather to recognize the mutual intertwining and coconstitution of the organic and the machinic, the technical and the discursive, in the production of vision, and hence of the world. In her work on the use of apparatuses in physics experiments, philosopher and quantum physicist Karen Barad argues that such devices are not just “passive observing instruments; on the contrary, they are productive of (and part of) phenomena.”55 We could easily apply this argument to photography, where the camera as a viewing device, the photographic frame both in the viewfinder and as the circumference of a photographic print, the enlarger, the computer, the printer, the photographer (who, in many instances, such as surveillance or speed cameras, is replaced by the camera-eye), and, last but not least, the discourses about photography and vision that produce them as objects for us humans are all active agents in the constitution of a photograph. In other words, they are all part of what we understand by photography. Becoming a camera As signaled earlier, it is not just philosophy that help us envisage this nonhuman, machinic dimension of photography: photographic, and, more broadly, artistic practice is even better predisposed to enact it (rather than just provide an argument about it).\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  A series of works by British artist Lindsay Seers is a case in point. Exhibited, among other places, at Matt’s Gallery in London as It Has to Be This Way in 2009, and accompanied by an aptly titled book, Human Camera, Seers’s ongoing project consists of a number of seemingly autobiographic films. These are full of bizarre yet just-about-  Figure 2.7 Lindsay Seers, Optogram (mouth camera), 2010. Courtesy of the artist. appear in the films but also leave behind “evidence” in the form of numerous written accounts, photographs, and documentary records. In one of the films, a young girl, positioned as “Lindsay Seers,” is living her life unable to make a distinction between herself and the world, or between the world and its representations. The girl is gifted with exceptional memory so, like a camera that is permanently switched on, she records and remembers practically everything. “It is as if I was in a kaleidoscope, a bead in the mesmerising and constantly shifting pattern.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Everything was in flux, every single moment and every single object rewritten at every turn,” as “Lindsay Seers” recalls in a short piece called “Becoming Something” included in Human Camera.56 This terrifyingly magnificent gift is lost once the girl sees a photograph of herself. She then spends her adult life clothed in a black sack, photographing things obsessively. In this way, she is literally trying to “become a camera” by making photographs on light-sensitive paper inserted into her mouth, with the images produced “bathed in the red light” of her body (figure 2.7). This ambition is later replaced by an attempt to “become a projector” by creating things ex nihilo through the emanation of light. Some of Seers’s films presented in the show are screened in a black hut modeled on Thomas Edison’s Black Maria, his New Jersey film studio that was used  ourselves, to literally step into the world of imaging, to reconnect us to the technicity of our own being. Although Bergson’s argument about life as a form of imaging is posited as transhistorical, we can add a specific inflection to it by returning to Flusser, and, in particular, his study of the relation between the human and the technical apparatus. For Flusser, that relation changed significantly in the years after the Industrial Revolution, when “photographers [were] inside their apparatus and bound up with it. … It is a new kind of function in which human beings and apparatus merge into a unity.”57 Consequently, human beings now “function as a function of apparatuses,”58 limited as they are to the execution of the camera’s program from the range of seemingly infinite possibilities which are nevertheless determined by the machine’s algorithm.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  Arguably, humans themselves are enactors of such a program, a sequence of possibilities enabled by various couplings of adenine, cytosine, guanine, and thymine, arranged into a double helix of life. To state this is not to postulate some kind of uncritical technological or biological determinism that would remove from “us” any possibility of action—as artists, photographers, critics, or spectators—and any responsibility for the actions we take. It is merely to acknowledge our kinship with other living beings across the evolutionary spectrum, with our lives remaining subject to biochemical reactions that we cannot always understand, control, or overcome (from blushing through to aging and dying). Just as “the imagination of the camera is greater than that of every single photographer and that of all photographers put together,”59 the imagination of “the program called life” in which we all participate (and which is an outcome of multiple processes running across various scales of our planet) far exceeds our human imagination. Such a recognition of our entanglement as sentient and discursive beings in complex biological and technical networks is necessary if we are to become involved, seriously and responsibly, in any kind of photography, philosophy, or other critical or everyday activity in which we aim to exercise “free will.” Re-forming the world By reconnecting us to the technical apparatus, by letting us explore our  are not always up-front about it or perhaps even entirely aware of it) in exploring the fundamental problem that many philosophers of technology who take science seriously have been grappling with: Given that “there is no place for human freedom within the area of automated, programmed and programming apparatuses,” how can we “show a way in which it is nevertheless possible to open up a space for freedom”?60 Such an undertaking is very much needed, according to Flusser, “because it is the only form of revolution open to us.”61 As discussed in the previous chapter, Flusser points to “envisioners”—that is, “people who try to turn an automatic apparatus against its own condition of being automatic”62—as those who will be able to undertake the task of standing “against the world,” by pointing “at it with their fingertips to inform it.”63 In this perspective, codification and visualization are seen as radical interventions into the world, and ways of re-forming it, rather than as ways of dehumanizing it, as Tagg seemed to suggest. Any prudent and effective way of envisaging and picturing a transformation of our relation to the universe must thus be conducted not in terms of a human struggle against the machine but rather in terms of our mutual co-constitution, as a recognition of our shared kinship. This recognition of the photographic condition that encompasses yet goes beyond the human, and of the photographic apparatus that extends well beyond our eyes and beyond the devices supposedly under our control, should prompt us human philosophers, photographers, and spectators to mobilize the ongoing creative impulse of life, in which the whole world is a camera, and put it to creative rather than conservative uses. The conceptual expansion of processes of image making beyond the human can also allow us to work toward escaping what Colebrook calls the “privatization of the eye in late capitalism,”64 where what starts out as a defense of our right to look often ends up as a defense of our right to look at the small screen.\n"}
{"prompt":"The Creative Power of Nonhuman Photography ->","completion":"  In challenging the selfpossessive individualism of the human eye, photography that seriously and consciously engages with its own expansive ontological condition and its nonhuman genealogy may therefore be seen as a truly revolutionary practice. Indeed, the concept and practice of nonhuman photography reconnects us to other beings and processes across the universe, including those of the Taurus Molecular Cloud. Photography in its nonhuman guise serves  view,”65 and that has allowed it to become “seduced, spellbound, distracted and captivated by inanity,”66 should not obscure the wider horizon of our openness to the world, our relationality with it through originary perception. The concept of nonhuman photography can therefore serve as both a response to “man’s tendency to reify himself”67 and an opening toward a radical posthumanist political analysis. It can serve in both ways by highlighting that there is more than just one point of view and that, by tearing the myopic eye from the perspective-driven bipedal body and embracing the distributed machinic-corporeal vision, it may be possible to see the drone as more than just a killing machine—although, of course, there are no guarantees.68\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Beyond Human: Deep Learning, Explainability and Representation  Theory, Culture & Society 2021, Vol.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  38(7-8) 55­–77 © The Author(s) 2020 Article reuse guidelines: https:\/\/doi.org\/10.1177\/0263276420966386 sagepub.com\/journals-permissions DOI: 10.1177\/0263276420966386 journals.sagepub.com\/home\/tcs  M. Beatrice Fazi University of Sussex  Abstract This article addresses computational procedures that are no longer constrained by human modes of representation and considers how these procedures could be philosophically understood in terms of ‘algorithmic thought’. Research in deep learning is its case study. This artificial intelligence (AI) technique operates in computational ways that are often opaque. Such a black-box character demands rethinking the abstractive operations of deep learning. The article does so by entering debates about explainability in AI and assessing how technoscience and technoculture tackle the possibility to ‘re-present’ the algorithmic procedures of feature extraction and feature learning to the human mind. The article thus mobilises the notion of incommensurability (originally developed in the philosophy of science) to address explainability as a communicational and representational issue, which challenges phenomenological and existential modes of comparison between human and algorithmic ‘thinking’ operations. Keywords algorithmic thought, deep neural networks, explanation, incommensurability, interpretability, philosophy, XAI  Beyond Human Representation The success of the Google-owned artiﬁcial intelligence (AI) company DeepMind and its computer program AlphaGo is well known. In March 2016, AlphaGo defeated the 18-time world champion Lee Sedol at Go, an ancient, complex game that involves moving black and white stones on a board to control territory.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  The victory was widely reported by news outlets, with commentators drawing parallels with the famous 1997 chess match between the grandmaster Garry Kasparov and the  predecessor, as the board game Go involves many more possible moves than chess. Go also requires strategic skills that are more intuitive than those useful in a chess game, and which are therefore less mechanisable.1 In this respect, AlphaGo’s victory also made headlines because it demonstrated the potential of the type of AI technology that DeepMind champions: machine learning. This expression denotes computing techniques that provide computer programs with the ability to improve over time with minimal human intervention when exposed to large amounts of data. The same programs subsequently apply this ‘learning’ to make data-driven decisions. While AlphaGo’s success is well known, the story of DeepMind’s 2017 cognate program AlphaGo Zero is less familiar to the general public. AlphaGo learned to play Go by being exposed to training data derived from millions of moves of past players. AlphaGo Zero, in contrast, was not given data from games played by humans or machines but was trained by playing against itself, starting from random moves and knowing nothing about the game of Go. This feat of solid and stable reinforcement learning amazed the AI community, which welcomed AlphaGo Zero as a signiﬁcant achievement.2 DeepMind proposed a self-taught AI program that can train itself from scratch, being de facto ‘no longer constrained by the limits of human knowledge’, as DeepMind put it (see Hassabis and Silver, 2017).\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Whereas AlphaGo took months to learn how to play, AlphaGo Zero took just a few days, less computing power and a streamlined architecture to master the game, quickly reaching levels of ‘superhuman performance’ (Silver et al., 2017: 354). The ability of a program to self-train without the input of human data is a key step towards achieving the holy grail of AI research: artiﬁcial general intelligence. This is the capacity of a machine to perform a breadth of cognitive tasks like that of a person. Recognising this, DeepMind is keen ‘to make some real progress on some real problems’ (Hassabis, quoted in Gibney, 2017) and extend its success to areas with practical applications (e.g. material design, genomics and drug discovery). Central to this possibility is acknowledging that being ‘no longer constrained by the limits of human knowledge’ means that AlphaGo Zero won not by out-reading humans but ‘by seeing patterns and shapes more deeply’, as Andy Okun – the president of the American Go Association – observed (quoted in Sample, 2017). In other words, AlphaGo Zero succeeded not because it behaved like a human player but because it played diﬀerently from a human. This condition is particularly interesting from both philosophical and sociocultural perspectives: in my view, cases such as AlphaGo Zero allow us to say that contemporary  In that work, I claimed that we should conceive of ‘automated modes of thought in such a way as to supersede the hope that machines might replicate human cognitive faculties, and to thereby acknowledge a form of onto-epistemological autonomy in automated ‘‘thinking’’ processes’ (Fazi, 2019a: 813).\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  I thus argued for the possibility of considering the algorithmic modes of thought of computing machines as ‘dramatically alien to human thought’ (Fazi, 2019a: 813). This article continues developing that line of argumentation and focuses on algorithmic modes of cognition, thus maintaining a philosophical commitment to ontological and epistemological questions about the nature of thinking in the 21st century. More speciﬁcally, I here consider algorithmic thought (what it might be and might do) by engaging with some theoretical implications of a computer program being ‘no longer constrained by the limits of human knowledge’, as DeepMind claimed AlphaGo Zero to be. I do not simply repeat what the AI industry says about itself and its products, however; I instead critically address these claims to assess their philosophical consequences by interpreting this declared freedom from human knowledge as a form of autonomy from human modes of abstraction and by relating these issues to questions about representation.3 This article thus continues to develop my theorisation of algorithmic thought by addressing the contemporary expansion of automated modes of abstraction that operate via what computer science calls representation learning. As the computer scientist Yoshua Bengio has put it, the central principle of machine-learning methodologies is ‘the automated discovery of abstraction’ (2013: 3). ‘Representation learning’, LeCun, Bengio and Hinton explain, ‘is a set of methods that allows a machine to be fed with raw data to automatically discover the representations needed for detection or classiﬁcation’ (2015: 436). In this article, I focus on precisely this aspect of current developments in AI technologies: how the extraction and organisation of ‘discriminative information from the data’ (Bengio, 2013: 2) that these technologies perform is speciﬁc to their computational character and how it consequently transcends or is independent of human access. I thus consider the 21st-century development of computational procedures for which, at present, no adequate human cognitive representations exist and for which, signiﬁcantly, human cognitive representations are also unnecessary.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Black Boxes of Decision-Making Research in machine learning is at the forefront of the agenda of AI and data science. As an umbrella term, ‘machine learning’ denotes not a  operations to better ﬁt the requirements of their tasks. These requirements are speciﬁed in the data that these algorithms must handle. ‘Machine learning automates automation itself’ (Domingos, 2015: 9–10), for ‘computers can learn programs that people can’t write’ (Domingos, 2015: 6). Machine learning thus involves ‘a change in programming practice’ as well as in ‘the programmability of machines’ (Mackenzie, 2018: 21). This condition has been described as a ‘quiet revolution’ (Alpaydin, 2016: ix), as a new season after a long and harsh winter in AI research, and as a computational renaissance precipitated by a novel form of AI that in fact draws from old cybernetic ideas.4 Since there are many machine-learning techniques and many devices that successfully implement them, it is important to clarify that deep learning is the approach followed by both AlphaGo and AlphaGo Zero, and the method that Google’s DeepMind echoes in its own name. Deep learning is itself a remarkably multifaceted technique. To simplify, an artiﬁcial neural-network system relies on layers of artiﬁcial neurons to process information.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  These layers of artiﬁcial neurons are connected and inﬂuence each other in a complex web of interacting units, somewhat like biological neurons are understood to do in a biological brain. A lower layer of neurons performs a computation and transmits this result to the layer above, enriching the ﬁnal outcome of the layer at the top. What is obtained in each layer is a new representation, ‘which can be used as input for deeper layers’ (Bengio, 2013: 4). A neural network is said to learn, then, because it can tweak its calculations and modify its interactions by tuning parameters via activation and back-propagation among layers until the desired output (i.e. the desired ﬁnal representation) is produced. The network, however, is called deep if its structure encompasses intermediary ‘hidden’ layers between the input and the output.5 The architecture of a deep-learning system diﬀers from that of a standard artiﬁcial neural network precisely because of the presence of these multiple non-linear hidden layers. Deep techniques are often discussed, as they promise to accelerate the computational automation of today and fuel the digital transformations of tomorrow. Although artiﬁcial neural networks have been around for decades (they are a core technology of connectionism, a biologically inspired approach to AI that emerged in the 1980s), it is only in the past decade, thanks to the volume, velocity and variety (see Beyer and Laney, 2012) of Big Data and the increase in computational power, that AI research and industry have begun to capitalise on artiﬁcial neural networks’ potential.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Computational problems that the AI community  specialised literature and the mainstream media, deep learning has also caught popular attention in a less ﬂattering light. Because of how a deep neural network operates, relying on hidden neural layers sandwiched between the ﬁrst layer of neurons (the input layer) and the last layer (the output layer), deep-learning techniques are often opaque or illegible even to the programmers that originally set them up. While ‘diﬀerent machine learning models provide diﬀerent levels of interpretability with regard to how they reach a speciﬁc decision’, it is thus commented that deep neural networks ‘are possibly the least interpretable’ (Kelleher, 2019: 245). In this sense, deep-learning programs are said to be black boxes: it is clear that they work but often is not equally clear how or why. In computing and engineering, the expression ‘black box’ is borrowed from cybernetics and used to describe an object or a system that is viewed uniquely in terms of its inputs and outputs, and whose internal working therefore remains concealed. When approaching a black box, one is interested only in stimuli and responses; one considers what goes in and what comes out of the black box, not its inner components or operations. While some computer and data scientists might take issue with the popular claim that deep-learning systems are black boxes,6 there remains the fact that, once a deep neural network is trained (or self-trained, as in the case of AlphaGo Zero), it can be extremely diﬃcult to explain why it gives a particular response to some data inputs and how a result has been calculated. The strength of a deep neural network lies in its capacity to ﬁnd non-linear patterns in large datasets and improve this extraction through iterative interactions.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  The other side of the coin, however, is that the automated learning choices of a deep neural network are not yet fully understood by programmers. The knowledge generated in these models remains, in part, implicit due to the non-linear nature of deep learning, its compressed information, and the distributed character of the network’s representations, which rely on the many conﬁgurations of its large sets of variables. Such a complex, layered architecture entails diﬃculty in analytically comprehending what nodes and layers have learned and how they have interacted to transform a representation at one level into another representation at a higher, more abstract step. Moreover, interpretability is not a standard feature of deep learning also because of the diﬃculty of producing a satisfactory mathematical theory as a foundation for these architectures. Interestingly, what makes deep techniques powerful also often makes their theoretical underpinning tentative. Progress comprehending these computational activities is achieved by trial and error, and operations are often rationalised retrospectively. To put this otherwise,  The trope of the black box is a recurring one in the sociology of science and in science and technology studies. Famously, Bruno Latour (1987) described parts of science that have been accepted and are no longer controversial as black boxes.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Science, for Latour, can become a black box when its inner workings are no longer open for scrutiny or debate, when consensus has been reached about certain results, when the success of a theory or a method obscures how scientiﬁc and technical work operates, and when a hypothesis is settled as a matter of fact. So, paradoxically, ‘the more science and technology succeed, the more opaque and obscure they become’ (Latour, 1999: 304). Always within the diverse domain of the sociology of knowledge, social constructivist positions – such as the social construction of technology (or SCOT) – stress the need to ‘open the black box’ to recognise the interpretive ﬂexibility of an artefact while also crediting ‘users as agents of technological change’ (Kline and Pinch, 1999: 113). Opening the black box thus involves counteracting the closure mechanisms that ‘play a part in bringing about both scientiﬁc agreement and the stabilization of an artefact’ (Pinch and Bijker, 1984: 425). Considering deep neural networks, concerns about AI as a black-box technology in part recall these earlier debates in science studies yet also transcend them. The black-box character of deep-learning techniques is, ﬁrst of all, a technical condition. Of course, these techniques are part of the contemporary world, and their predictions, classiﬁcation and clustering impact the everyday lives of millions of people; with respect to this impact, a social constructivist perspective proves useful to explain the concurrent yet multidirectional involvements of relevant social groups and the values and interests that inform their participation. However, if opening the black box means asking ‘how technology is made’ – to paraphrase the title of a famous essay in social constructivist technology studies by Bijker (2010) – then, while doing so, we cannot avoid addressing the ontological and epistemological speciﬁcities of that same technology.8 In the case of deep learning (and machine learning, more generally), my proposition is that we should not overlook the computational and increasingly autonomous character of these technologies.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Insofar as they are computational, these are calculative techniques that involve quantifying and systematising the real world through discrete functions. Above all, since they are computational, deep-learning methods involve decision-making. In a computational context, decisionmaking is the mechanised process that results in the selection of a particular result or output among possible alternatives. This decisional capacity of computational systems is inscribed in the deﬁnition of an  (see Fazi, 2019b), requiring little engineering by hand. In these learned (not designed) systems, transparency is a matter of accountability vis-àvis their automated and quasi-autonomous decision-making capacities, which have been transferred from humans to the AI system. Thus, while all technologies are black boxes to an extent (even a door handle can be approached as one because knowledge of its inner working is not necessary to open a door), the consequences of the black-box character of deep learning are diﬀerent because, in this case, it is agency itself (that is, the capacity of the technological system to operate upon its environment) that is opaque.9 The decision-making of quasi-autonomous artiﬁcial agents powered by deep learning aﬀects millions of people every day. The range of decisions covered by deep learning is vast. It pertains to mechanisms of classiﬁcation, clustering, ranking and pattern-ﬁnding, which are employed, for instance, in credit card fraud detection, spam ﬁlters, search engines, market segmentation, social media advertising, insurance and credit scoring, healthcare management, transport and logistics, loan qualiﬁcation and mobile communication.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  These and other operations were often determined by humans in the past; today, the human user rarely has a concrete sense of the reason or mechanism of certain results or what inputs they follow. The task left to the social scientist, cultural theorist, philosopher, legal scholar and critical theorist is asking what would count as ‘cracking open’ these AI black boxes responsible for so much contemporary decision-making – particularly now that society has entered an era of computational applications whose success is measured by the capacity of computational agents to act on their own. Although involving various arenas of public and academic discussion, this question has been most explicitly developed within the interdisciplinary scholarly debate about the politics and governance of algorithms (see, for instance, Amoore, 2020; Ananny and Crawford, 2018; Beer, 2018; Benjamin, 2019; Noble, 2018; O’Neil, 2016; Pasquale, 2015). It is impossible to review these rich discussions in full here: suﬃce it to say, however, that there is consensus on the fact that automated cognitive agents processing increasingly vaster amounts of data will play ever more signiﬁcant roles in regulating and directing our lives. What academia and the general public alike are asking for is transparency regarding how security, government, media, retail, ﬁnance, science and industry employ AI on a daily basis, often to inﬂuence human action. Explainability is a key word for present and future algorithmic cultures, raising equally unique social and ethical challenges. and debate about explainable AI (XAI) are signiﬁcant and relevant, as they call for the opaque powers of AI to be leashed in the realm of observation so that the mysteries of machine learning eventually surface. I am not referring here to the visual form of machine learning (i.e.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  to how data and data patterns can be made visible thanks to specialised graphics showing something about how a machine-learning algorithm’s output relates to its inputs – see, for instance, how this is discussed in Mackenzie, 2015). Rather, I am gesturing towards the more ﬁgurative sense in which technoscience and technoculture are addressing the possibility to present (or re-present) algorithmic operations to the human mind and thus make the abstractive operations of artiﬁcial cognitive agents (and their internal representations) somehow available to and comprehensible within the epistemic landscape of human cognitive representation. Interestingly, in her sociocultural study of machine-learning algorithms, the information scholar Jenna Burrell distinguished between three types of opacity: (1) opacity as corporate or state secrecy (i.e. algorithms as proprietary, their lack of transparency a form of institutional protection to maintain trade secrets and competitive advantage); (2) opacity as technical illiteracy (i.e. writing and reading code as highly technical skills that require specialised knowledge and are thus inaccessible to most people); and (3) opacity as an inherent characteristic of machinelearning techniques – that is, ‘opacity that stems from the mismatch between mathematical optimization in high-dimensionality characteristic of machine learning and the demands of human-scale reasoning and styles of semantic interpretation’ (2016: 2). The debate on explainability in AI concerns all three types of opacity, but the last one, which pertains to speciﬁc techniques used in machine learning, is the most conceptually challenging. This is a form of opacity that, in the case of deep-learning systems, thrives upon the complexity of their high-dimensional domains – a complexity for which a machine might build a model but a human most likely could not hand-engineer one. Technically speaking, the crux of the problem of explainability in deep learning lies in artiﬁcial neural networks not returning clear representations of their inner workings to programmers.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Deep neural networks lack model interpretability, so when considering why a machine made a particular decision or one prediction instead of another, we remain ignorant at worst and agnostic at best. Returning, for instance, to the case of DeepMind and its AlphaGo machines, to understand how and why AlphaGo or AlphaGo Zero chose a particular move instead of another, the justiﬁcation given by the program may consist of a rendition of the network’s weighted con-  be objected that merely rendering the calculation would hardly count as a meaningful form of understanding.10 This issue links to another open question about when and why an explanation might be considered useful and successful or not. I discussed earlier how establishing a theoretical ground for deep learning could help programmers interpret the choices a deep neural network makes and thus validate its behaviour. Here, however, it should be added that, alongside explorations of deep learning’s mathematical foundations, the growing ﬁeld of XAI focuses on the taxonomies of desiderata and of methods for interpreting AI systems. Research in XAI often explicitly looks for pragmatic approaches to human-readable explanations that can meet the expectations of end-users, whether they are medical doctors and patients in an automated diagnosis scenario or banks and their customers agreeing on a mortgage assessment. Questions about the nature and characteristics of a successful explanation are thus also answered by considering the social dimension of interpretability, and they must confront the fact that, when attempting to produce knowledge about a deep-learning system’s input-output relationship and the aggregate behaviour of its decision structure, ‘we may not even have the words to express the concepts that some parts of the model represent’ (Spreeuwenberg, 2019: 32). In this respect, deep learning may be changing the epistemic possibilities of justiﬁcation and explanation, eﬀectively reshaping how science imparts information and knowledge. My claim, however, is that deep learning is changing the meaning, scope and use of abstractions as well.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  To expand on this point, it is useful to distinguish between the modus operandi of the traditional statistics community and the machine-learning community, which the statistician Leo Breiman (2001) elaborates on in a much-cited paper. Breiman speaks of ‘two cultures’ to explain this distinction: on the one hand, traditional statistics assumes that data models are the best way to solve problems; on the other, scientists working with machine learning believe that algorithmic models can do better. Breiman’s paper attempted to show that the data models of statistics are not applicable to a wide range of problems, so statisticians should allow a wider variety of tools to be employed in their discipline. Breiman himself is a pioneering scholar who helped bridge the gap between computer science and statistics, writing and working when machine-learning techniques were still underexplored in statistical science. In what follows, rather than lingering on Breiman’s advocacy for machine learning, I focus on how his paper addressed black boxes. From a scientiﬁc perspective, Breiman argued, nature is a black box:  from data to produce these descriptions. The relationship between data and models, however, is diﬀerent in statistics and computer science. Breiman explained that, traditionally, the purpose of statistics is to produce an understandable picture of the relationship between the input variables and the end results in the phenomenon or situation observed.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Of course, nature is overwhelmingly complex and rich with variables; statistics hopes to achieve, at best, accurate representational approximations, in which a data model is as close as possible to represent, and thus explain, the black boxes of nature. The development of algorithmic methods of statistical analysis, however, involved doing things diﬀerently. The black box of nature remains an unknown whose underlying workings are not the target of scientiﬁc enquiry. The aim of algorithmic models is not to ﬁnd the ‘true’ data-generating mechanism but to use an algorithm to account for that mechanism as well as possible. In this sense, computer science is less concerned with explanation than with predictive accuracy, and modelling is treated as a problem of function optimisation. ‘The goal is not interpretability, but accurate information’ (Breiman, 2001: 201). Breiman’s argument, of course, is not the only reconstruction of the ﬁeld of machine-learning research. However, drawing from Breiman’s account, one can begin to explain how and why, thanks to the contemporary availability of high computing power and of vast amounts of data, previously undetected or underrated diﬀerences between explanation and prediction have moved to the fore of scientiﬁc practices, such as statistics.11 Moreover, the diﬀerence between explanation and prediction highlighted in Breiman’s paper also speaks about what abstraction is – or can become – in algorithmic modelling.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Following Breiman, we could say that statisticians want interpretable approximations of what they hypothesise happening in the elusive black boxes of nature. In this sense, they use data to abstract away a model.12 In fact, according to Breiman, statistics ends up focusing more on the model than on the problem or the data themselves. Pushing Breiman’s comments further, we could also argue that abstractive procedures work diﬀerently in algorithmic modelling, which seems to acknowledge that human abstraction might never be a particularly accurate predictor. Rather than description, then, construction is the epistemic tool of choice: instead of reducing a black box to ﬁt a simpler model, the algorithmic modelling of machine learning constructs and stands as another black box, thus freeing abstraction from its reductionist role as a means of simpliﬁcation and description. Abstractive operations of classiﬁcation and generalisation have overcome the boundaries of the human mind and are performed via the weights of digital triggers in artiﬁcial neural networks. reconstructing or recasting nature in a speciﬁc form and investigating how it behaves or might behave under certain circumstances.’ ‘Although we can use mathematics to do this,’ Morrison continued, ‘the notion of ‘‘reconstruction’’ can also be instantiated in other ways’ (2015: 2). The operational black boxes of machine learning also seem to be one of these other ways, according to which epistemological reconstruction assumes a life of its own via algorithmic models that do not aim to represent and thus do not wish to explain. Incommensurability Possibly due to much scientiﬁc research in deep learning focusing (quite successfully) on computer vision, metaphors or analogies that refer to the sense of sight are frequently used to describe the operations of deep neural networks.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  So, for instance, it is often said that these artiﬁcial cognitive agents ‘see’ visual inputs diﬀerently.13 In light of what I have discussed so far, however, I claim that deep learning not only involves a distinctive type of sensibility (i.e. a diﬀerent capacity to receive data inputs) but also concerns a speciﬁcally computational relation with the intelligible (i.e. with what is apprehensible only through forms of abstractive activity). To exemplify this claim, let us consider machine learning’s increasing ability to recognise human handwriting. This is something notoriously hard to perform computationally and for which more traditional programming techniques do not work well because it is diﬃcult to preﬁgure and then encode an instruction that would formally describe such a task. In other words, relatively simple, immediate human intuitions of how to identify shapes are not easily expressed in computational terms. With deep learning, however, the situation changes.14 Let us assume that we want a program to recognise a handwritten digit, such as zero. In the case of supervised learning,15 thousands of scans of handwritten zeros are fed to the machine as training examples.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  The program then learns to recognise the digit, not how a human might (e.g. determining that a zero resembles a vertical oval), but by mechanically detecting complex patterns of darker and lighter pixels expressed as matrices of numbers. This is arguably a diﬀerent form of perception (or of input reception), and ground-breaking research on how a computational system can elaborate visual information that humans cannot even receive or perceive is being developed in the ﬁeld of computer vision.16 The point here, however, is that beyond physical data reception, we are also witnessing a speciﬁc form of abstractive capacity – one akin to an automated mode of  feature extraction from raw data. ‘Features’ are the properties and characteristics of data that the system learns to distinguish and organise in order to recognise patterns, make predictions and classify tasks: deep neural networks are algorithms for classiﬁcation from features, and deep learning is largely feature learning. None of this implies that feature learning and conceptualisation are identical. I am addressing the two operations together, however, insofar as I am considering the possibility of algorithmic thought and how abstraction qua generalisation is a key operation in the respective ‘thinking’ structures of both humans and machines.17 The key point is that these abstractive operations remain speciﬁc to the onto-epistemological grounds of humans, on the one hand, and machines, on the other – thus informing human modes of thought as well as algorithmic ones. For instance, returning to the case of the algorithmic recognition of handwritten zeros, the deep-learning model identiﬁes and constructs representations that are more relevant than those that any human programmer could have identiﬁed and given to the machine. In fact, these are representations that a human would have not (and could have not) abstracted in the ﬁrst place.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  The way the program extracts and organises information in terms of features and then generalises this information to form the desired ‘concept’ – or, in computational terms, the desired output representation of zero – is thus entirely and exclusively computational.18 We therefore must be careful when addressing how a human receives and elaborates stimuli or information, on the one hand, and how, on the other, a computing machine might also be said to do the same. It is important to talk here of incommensurability between the abstractive choices of humans and those of computing machines. ‘Incommensurability’ is the right word because the two cannot be measured against each other or compared by a common standard. Considering such an incommensurable dimension is particularly relevant in the context of debates about XAI because it allows us to highlight how explainability is a representational problem that pertains to communication. For abstractions to be successfully represented and thus expressed and shared, a common experience between the communicator and the receiver of the communication must be in place. Of course, this is not possible in the case of human-machine interactions, for no common phenomenological or existential ground exists between human abstractions and those of a computational agent. The speciﬁcity of computational abstraction and its suitability as the grounds of studying algorithmic thought are thus not claims strictly about cognitive science, as they do  incommensurability between how humans and machines build models involves recognising this ontological and epistemological disparity between how humans and computational agents make decisions. Inevitably, this discrepancy is mirrored in how such decisions might be respectively recounted or represented by humans and artiﬁcial algorithmic agents.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Originating in ancient Greek mathematics, the notion of incommensurability denotes the absence of a common unit of measurement between two magnitudes. The development of this concept drove the distinction between geometry and arithmetic and is also central to the study of the ratios of numbers. Outside mathematics, however, the notion of incommensurability is used to denote that for which no shared nomenclature or shared ground for evaluation exists. In this sense, incommensurability is a key concept in 20th-century philosophy of science. Turning to this disciplinary context, in 1962 the philosophers of science Thomas Kuhn and Paul Feyerabend independently (but equally inﬂuentially) argued that successive scientiﬁc theories (with their associated concepts, methods and worldviews) are incommensurable.19 For Feyerabend (1962), incommensurability was a semantic issue which he addressed to challenge conceptual conservatism in science and the approach to explanation, reduction and scientiﬁc advancement employed by logical positivism. In Kuhn’s historical philosophy of science, too, incommensurability was a problem of language; for Kuhn (1962) as well, and to quote Michael Polanyi (whose philosophical work on the practice of science inﬂuenced both Kuhn and Feyerabend), scientists from diverse schools of thought and periods in time ‘think diﬀerently, speak a diﬀerent language, live in a diﬀerent world’ (Polanyi, 1958: 151). Beyond semantics, however, incommensurability was also a methodological and perceptual issue and a problem in taxonomy for Kuhn. He described as incommensurable the stark contrast between theoretical frameworks for which not only nomenclatures do not overlap but also for which no shared perceptions, methods or classiﬁcations exist.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  In the philosophy of science, the notion of incommensurability is controversial; its meaning and usefulness are often contested, and discussions on this topic are never fully resolved.20 I do not chronicle these discussions and their consequences here. Nonetheless, it is valuable to consider how the incommensurable has been introduced and addressed in that philosophical context and tradition of thought: this is because those debates help us situate incommensurability conceptually and, most importantly, because both Kuhn and Feyerabend proposed the concept while assessing the epistemic possibilities of scientiﬁc explanation. what they cannot represent or communicate with metaphors and analogies from their own experiences. So, for instance, we say that a computing machine ‘sees’, ‘listens’ or ‘thinks’, just as we say that an aeroplane ‘ﬂies’ despite our awareness that an aircraft and a bird take ﬂight in profoundly diﬀerent ways.21 In this respect, however, the challenge for both the philosophical and sociocultural studies of computational automation is to ﬁnd or found the epistemological means to theorise, as well as possible, the incommensurable orders of intelligibility and sensibility that automated computational agents produce. Inevitably, the notion of incommensurability to be developed must transcend that proposed in the history of the philosophy of science: the long-term goal is not to apply Kuhn’s or Feyerabend’s respective understandings of the incommensurable to computational media and computational culture but to develop a radical version of the concept to address the speciﬁcities of human and algorithmic modes of abstraction. ‘Upon Opening the Black Box’ To address this challenge, deep learning oﬀers a particularly relevant case study. In the words of Yoshua Bengio, deep-learning research focuses on ‘learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts’ (2013: 1). ‘A deep learning algorithm’, Bengio continues, ‘is a particular kind of representation learning procedure that discovers multiple levels of representation, with higher-level features representing more abstract aspects of the data’ (2013: 2, emphasis in original).\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  While much of computer programming has historically consisted in making human abstraction signiﬁcant and operative within the instrumental remit of algorithmic machines, with deep learning we face the opposite case: the abstractions and consequent instructions the machine gives itself now require interpretation for them to be signiﬁcant and operative for humans. The modes of organisation, categorisation and classiﬁcation that belong to the abstractive operations of these computational cognitive agents are indeed incommensurable. Maintaining a theoretical focus on the nature and possibilities of abstraction as the balance moves between autonomy and automation within AI thus involves acknowledging and working with the prospect of modes of abstracting that might arise within calculation but also surpass the boundaries of human cognitive representation. In the example of recognising human handwriting, the ‘autonomy of automation’ (Fazi, 2019b: 94) regarding abstractive operations is demonstrated by a deep learning system producing internal representations  knowledge. DeepMind’s description of AlphaGo Zero as a form of superhuman intelligence is thus misleading; it would be more appropriate, from the point of view of incommensurability, to speak of non-human or inhuman intelligence (and the term ‘intelligence’ itself should also be problematised according to comparative epistemology). Deep learning demonstrates that, when thinking and talking of computational cognitive agents, our theoretical eﬀorts should attempt to move from strictly phenomenological analyses and existential qualiﬁcations (i.e. from eﬀorts to address objects and situations as they appear to or are understood by human consciousness and through categories of human life and experience) towards more speculative modes of investigation. Adopting a speculative mode of investigation, we should address the critical prospect of understanding what explanation and interpretation might be in the formalising space of computation.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Key to this speculative eﬀort in relation to the study of computational automation is the possibility of constructing a theory of knowledge speciﬁc to computational artiﬁcial agents – a theory that can be advanced only by assessing the ontological and epistemological possibilities of machines. This theory would be valuable not only within the remit of digital studies but also for philosophical investigations of the relation between abstraction and experience and, consequently, the relation between rationality and the world. The following valuable programmatic point can then be drawn from the incommensurability debate in the philosophy of science. Both Kuhn’s and Feyerabend’s understandings of incommensurability have been accused of denying the possibility of progress and truth in science and thus implying irrationality.22 This accusation, however, was rebutted by both scholars: claims about incommensurability do not imply that comparison is not possible but that it is much more difﬁcult than the logical positivism and logical empiricism of the time assumed it was. Both Kuhn and Feyerabend made the notion of the incommensurable a powerful weapon in their post-positivist arsenals, and they used it to challenge evaluation and explanation based on absolute universal criteria or a neutral observation language. Although diﬀerences certainly exist between the contexts and the aims of that debate – which pertained to the possibility of theory comparison – and the present study on deep learning and explainability, I propose that we can also mobilise the concept of incommensurability to problematise the 21st-century (implicit or explicit) positivist approaches to computational culture and society via data science.23 Doing so does not imply relativism but, in fact, quite the opposite: I am arguing for the need to be loyal to the speciﬁcities of humans and machines in our comparisons. models are logical because they are computational and thus based on the possibility of a formal, logico-mathematical account of calculation; however, in a diﬀerent sense, they are also a-logical because they are, at present, inexpressible or unrepresentable by humans (where ‘logos’, according to its ancient Greek etymology, not only means ‘reason’ or ‘proportion’ but also ‘word’, ‘discourse’, ‘speech’, and derives from the \u001f ‘to count’, ‘to tell’, ‘to speak’). Focusing on the notion of incomverb le´go, mensurability, then, allows us to emphasise the paradoxical condition of logico-mathematical abstraction in computation, which despite being a key tool for human attempts to organise and make sense of reality, today also surpasses that human-centric instrumental horizon with its AI implementations.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  For these AI-native models to be held rationally accountable, we should ﬁrst ask whose and what rationality we are discussing. This question is radically open and acknowledges that a comparison between kinds and modes of thought is, to an extent, necessary to study AI’s ‘thinking’ procedures. The use of terms such as ‘thinking’ and ‘intelligence’ (which originated in human epistemology) does not contradict my argument; rather, their use conﬁrms the inevitability of a comparison, although a comparison that will always be incomplete and partial because humans, as observers and interpreters, can only oﬀer epistemic representations that have been shaped within their own ontological domain. In this respect, it must be highlighted that incommensurability is a translation failure: on the one hand, a satisfactory translation between incommensurable entities is diﬃcult or even impossible; on the other, a ‘translation failure’ also signals the limits of approaching explainable AI by searching for the quality or propriety of being translatable. It is important to stress this vis-à-vis current issues in the contemporary quest for fair, accountable, transparent AI precisely because that quest appears to be predicated on research that understands interpretability in terms of translation. It is thus also useful to consider how Kuhn (2000b) attributed the equation between translation and interpretation to the analytic tradition of philosophy. This equation was, in his opinion, misleading: incommensurability does not mean that a theoretical term, for instance, cannot be interpreted (that is, be made intelligible); rather, it means that it cannot be translated, as it has no equivalent in another theoretical language. Returning to debates in and on XAI, such an equation between interpretation and translation can be observed in research that promotes the advancement of future XAI systems by developing new techniques able to produce interpretable models of machine-learning operations; these models, in turn, are paired with interfaces to advance useful human-  as a real issue for the computational systems of today and tomorrow – aims to develop human-centric perspectives in the design of artiﬁcial cognitive agents.24 The challenge, for DARPA and other parties involved in the quest for interpretability in AI,25 is to achieve understanding without compromising the predictive power and overall learning performance of the computational system.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  To do so, DARPA’s XAI initiative encompasses various projects ranging from the design of entirely new kinds of deep neural networks comprising smaller and hence more easily understood modules to the borrowing of insights from the psychology of human expertise and decision-making. What observations can be advanced about DARPA’s XAI in relation to the issue of incommensurability? First, consistent with similar technoscientiﬁc attempts, DARPA’s quest for XAI aims to bring what is beyond human knowledge back into the domain of human cognitive representation. Second, the goal of DARPA’s XAI project is to ﬁnd meaningful representations of the machine’s own abstractions, even though these representations might be only useful or valuable to human actors and not, strictly speaking, necessary for the operativity of machine agency itself. Noticeably, there is not yet an obvious way of designing an artiﬁcial computational system that can explain itself, just as there is no consensus on what that explanation should look like – that is, what such an explanation should aim to represent. Third, then, the following question must be answered: would giving enough speculative credit and attention to the incommensurable operations of artiﬁcial cognitive systems be enough to produce such a shared account of a useful, successful explanation? This question constitutes my conclusion; I leave it open to future research on the topic, which would have to further problematise the possibility of explanation in AI precisely because the opportunity of direct human-machine translations for artiﬁcial cognitive systems that are de facto beyond human representation can be questioned via the notion of incommensurability. In a famous polemical essay, Langdon Winner (1993) criticised imperatives of ‘opening the black box’ being obeyed, in his opinion, by the social construction of technology.\n"}
{"prompt":"Beyond Human: Deep Learning, Explainability and Representation ->","completion":"  Winner noted that, ‘upon opening the black box’, the risk was of ‘ﬁnding it empty’. In a parallel yet distinct sense, we can borrow Winner’s famous expression to consider now whether contemporary XAI’s imperatives of opening the black box are running a similar risk. If there is indeed such a risk, it is less of ﬁnding the black box empty than of realising that there is nothing to translate or to render precisely because the possibility of human representation never existed in the ﬁrst place.\n"}
{"prompt":"Action at a Distance ->","completion":"  ACTION DISTANCE PETERS VAGT  SPRENGER  AT A  Timon Beyes, Mercedes Bunz, and Wendy Hui Kyong Chun, Series Editors  Action at a Distance Archives Communication Machine Markets Organize Pattern Discrimination Remain  Action at a Distance John Durham Peters, Florian Sprenger, and Christina Vagt  IN SEARCH OF MEDIA  University of Minnesota Press Minneapolis London \t\t\t\t  meson press  In Search of Media is a joint collaboration between meson press and the University of Minnesota Press.\n"}
{"prompt":"Action at a Distance ->","completion":"  Zhang Jiuling, “Looking at the Moon and Thinking of One Far Away,” from Witter Byner, The Chinese Translations (New York: Farrar, Straus, Giroux: 1982): 66, copyright 1978 the Witter Bynner Foundation; published by permission. This open access publication was generously supported by the Canada 150 Research Chairs Program and Simon Fraser University. Bibliographical Information of the German National Library The German National Library lists this publication in the Deutsche Nationalbibliografie (German National Bibliography); detailed bibliographic information is available online at portal.d-nb.de. Published in 2020 by meson press (Lüneburg, Germany ) in collaboration with the University of Minnesota Press (Minneapolis, USA). Design concept: Torsten Köchlin, Silke Krieg Cover image: Sascha Pohflepp ISBN (PDF): 978-3-95796-152-5 DOI: 10.14619\/152-5 The digital edition of this publication can be downloaded freely at: meson.press. The print edition is available from University of Minnesota Press at: www.upress.umn.edu. This publication is licensed under CC BY-NC 4.0 International. To view a copy of this license, visit: creativecommons.org\/ licenses\/by-nc\/4.0\/  Series Foreword Introduction  vii  ix  Florian Sprenger and Christina Vagt [1]  Temporalities of Instantaneity: Electric Wires and the Media of Immediacy Florian Sprenger Translated by Erik Born  [2]  A Cornucopia of Meanwhiles  29  John Durham Peters [3]  Physics and Aesthetics: Simulation as Action at a Distance Christina Vagt Authors  78  51  1  “Media determine our situation,” Friedrich Kittler infamously wrote in his Introduction to Gramophone, Film, Typewriter.\n"}
{"prompt":"Action at a Distance ->","completion":"  Although this dictum is certainly extreme—and media archaeology has been critiqued for being overly dramatic and focused on technological developments—it propels us to keep thinking about media as setting the terms for which we live, socialize, communicate, organize, do scholarship, et cetera. After all, as Kittler continued in his opening statement almost thirty years ago, our situation, “in spite or because” of media, “deserves a description.” What, then, are the terms—the limits, the conditions, the periods, the relations, the phrases—of media? And, what is the relationship between these terms and determination? This book series, In Search of Media, answers these questions by investigating the often elliptical “terms of media” under which users operate. That is, rather than produce a series of explanatory keyword-based texts to describe media practices, the goal is to understand the conditions (the “terms”) under which media is produced, as well as the ways in which media impacts and changes these terms. Clearly, the rise of search engines has fostered the proliferation and predominance of keywords and terms. At the same time, it has changed the very nature of keywords, since now any word and pattern can become “key.” Even further, it has transformed the very process of learning, since search presumes that, (a) with the right phrase, any question can be answered and (b) that the answers lie within the database. The truth, in other words, is “in  beyond search engines.\n"}
{"prompt":"Action at a Distance ->","completion":"  Increasingly, disciplines—from sociology to economics, from the arts to literature—are in search of media as a way to revitalize their methods and objects of study. Our current media situation therefore seems to imply a new term, understood as temporal shifts of mediatic conditioning. Most broadly, then, this series asks: What are the terms or conditions of knowledge itself? To answer this question, each book features interventions by two (or more) authors, whose approach to a term—to begin with: communication, pattern discrimination, markets, remain, machine—diverge and converge in surprising ways. By pairing up scholars from North America and Europe, this series also advances media theory by obviating the proverbial “ten year gap” that exists across language barriers due to the vagaries of translation and local academic customs and in order to provoke new descriptions, prescriptions, and hypotheses—to rethink and reimagine what media can and must do. Florian Sprenger and Christina Vagt  A body is never moved naturally, except by another body which touches it. Any other kind of operation on bodies is either miraculous or imaginary. —­Gottfried Wilhelm Leibniz  When Gottfried Wilhelm Leibniz in his exchange with Samuel Clarke in 1715\/1716 famously attacked Newton’s theory of gravity for introducing “imaginary operations” and “occult forces” into physics, he evoked the classic Aristotelian ban of action at a distance: Every motion requires a conjoined mover.\n"}
{"prompt":"Action at a Distance ->","completion":"  No action can occur without a loss of force and thus without duration. Only by postulating some underlying medium could the effects of gravity, as well as electricity and magnetism, be conceived as contact forces or action through contact. Aristotle’s dictum was translated into modern physics: Every transmission of a force from the location of its cause to that of its effect requires a medium to ensure its interaction. In the context of this debate, media were regarded as mediating instances that enabled what was called communication. If cause and effect were not immediately connected but rather spatially separated from one another—­as in the case of gravitation, magnetism, or electricity, for instance—­then there had to be a medium to ensure both the transmission of the force and the causal connection. Leibniz attacked him for, his thinking, exemplary for modern physics, revolved around media: Newton used the terms “ambient medium,” “refracting medium,” or “transparent medium” (each written with lowercase letters) to refer to mechanical transmission capacities that infuse everything, leaving no empty spaces. At the same time, he used the term medium (both in English and Latin) when speaking about transmission media or intermediate media such as air, glass, or the ether. Clarke, as a substitute for Newton in the debate with Leibniz, summarized this necessity as follows: “Nothing can any more Act, or be Acted upon, where it is not present; than it can Be, where it is not” (Leibniz and Clarke 1956, 21).\n"}
{"prompt":"Action at a Distance ->","completion":"  The spirits, ethers, and media introduced by Newton create such a material connection and in turn inaugurate, with the proximal effect explained by them, an action at a distance by means of an imperceptible medium. The intermediary is no longer simply spatial but also transmits forces such as gravitation, electricity, or light (see Spitzer 1948). If things seem to act at a distance—­if gravitation, magnetism, or electricity can overcome distances without evidencing a visible cause for doing so—­then the question of the causalities, continuities, and materialities of this action gains considerable significance. Modern physics as a systematic science has to develop criteria for determining which forces are subject to a medium and which actions were simply miraculous or inexplicable. In this context, the philosophical debates about the structure of space and time were updated in light of their historical background and thus, as far as the present day is concerned, made legible in implicitly media-­theoretical terms. They were propelled by a sense of unease about the material conditions needed for forces to be mediated over distances. For, if no force could be identified to account for such mediation, then the path was cleared for divine intervention, magic, and miracles. In the course of the development of electrodynamic theories and technologies during the eighteenth and nineteenth centuries,  mechanics and the speculative assumption of an intermediary— ­the ether—­as the underlying medium that acts through contact on certain bodies.\n"}
{"prompt":"Action at a Distance ->","completion":"  But the fact that nobody had ever seen or measured it occupied physicists and philosophers alike by evoking dazzling proofs and thought experiments from Immanuel Kant to Hendrik Lorentz (see Vagt 2007). After special relativity finally abolished the ether as physical medium, Albert Einstein famously attacked the theoretical physics of Niels Bohr and others, stating that quantum mechanics with its presupposed quantum states of “superposition” and “entanglement” of particles contained some “spooky” action at a distance (see Barad 2007, 317–­31). Even though these physical debates took place at different times and on different scales (macro-­and microphysics) they both stress the media question concerning modern physics: How is it possible that objects interact with each other from a distance, without touching? When physics describes how things act on each other, how objects exert forces on other objects, it has to take the materiality of transmission into account. Physics, compelled to think about media, is one of the fields of knowledge in which terms of media are forged. This book follows some of the trajectories action at a distance has taken from physics to questions of human interaction, the binding and breaking of time and space, and the entanglement of the material and the immaterial in physics and aesthetics. The three texts each deal with historical constellations in which the mediality of transmission and the materiality of communication are debated as questions of acting at a distance—­an action, it turns out, whose agency lies in a medium. They discuss different episodes of the epistemological history of mediation, and move through different modes of causation from the immateriality of the mind to the materiality of infrastructures and follow the trajectory of the transmission of forces.\n"}
{"prompt":"Action at a Distance ->","completion":"  The common question that brings them together deals with the conceptual history of mediation: they trace the epistemological transformations of what mediation (and the related terms communication and causation) means in  narrated, how does it challenge the boundary of the material and the immaterial, and how does it change in relation to technologies of mediation? In all three texts, the distance that mediation implies, the meanwhile, the difference and the in-­between, turn out to be both the challenging and dis-­unifying potential of mediation and the source of its technical implementations. With the advent of electromagnetic telegraphy in the 1830s, a notion emerging from the history of the sciences of electricity diffused into popular knowledge: the instantaneous transmission of electric action. Ever since Stephen Gray, as described by Florian Sprenger’s essay, explored the possibility of electric transmissions through copper wires in 1730, the speed of electricity was an item of interest and subject of investigation. Speed was conceived as the possibility of nonspeed, as instantaneity means to neglect speed. Instantaneity means that transmission does not take any time. Electricity and telegraphy were described as timeless and thus having no speed. There is a small difference between slow speed and no speed, but this difference means everything to physics.\n"}
{"prompt":"Action at a Distance ->","completion":"  Because nothing can take place in two places simultaneously and because any distant effect requires a medium, the experiments that Sprenger’s paper describes were stalked by phantasms of instantaneity, immediate transmission, and actio in distans. Simultaneity thus becomes a matter of cultural techniques of synchronization. As John Durham Peters shows, such means of control of simultaneity—­be it through knowledge, narration, or action—­are deeply embedded in Western history. His text engages with a host of examples of what he calls “meanwhile structures” situated at the intersections of time and space. For knowledge and for narration, time and space are no barriers and action at a distance is a way of synthesizing them: Being at two places at the same time turns out to be necessary to narrate stories and know the world—­knowledge and narration, again, have an agency that acts also at historical distances. But being at two places at the same time is only possible under the rarest of conditions: when one can work in the no-­speed  efforts at action at a distance are, instead, subject to the demons of microtime, who mischievously filter, distort, block, warp, or delay action at a distance. Action at a distance through language and communication, concepts and models is typically human. German philosopher Hans Blumenberg introduced the Latin neologism actio per distans as a philosophical term that signifies a prominent type of preemptive action among humans: action in absence of the object that is acted upon.\n"}
{"prompt":"Action at a Distance ->","completion":"  Christina Vagt’s paper discusses this version of action at a distance in the form of concepts, models, and simulations in the field of today’s biosciences, where models determine under which conditions material action takes place. When an Australian banksia cone suddenly opens its follicles after a wildfire to release its seeds, cause and effect are evident to the careful observer (the fire gets rid of the competition), but how something that is technically dead can perform this kind of dynamic motion does appear somehow magical—­until imaging and modeling technologies finally enable the scientists to procure a viable model. Addressing the media question underlying material research in the age of computer simulation moves the discussion away from actio in distans and the inherent causality, instantaneity, and simultaneity debates of theoretical physics and toward aesthetic procedures that mediate between matter and mathematics and between scientists and their epistemic objects. The term medium, this book argues, is—­at least partly—­a historical effect of the philosophical and physical challenges of actions across distance, but it also conveys a certain ambivalence: The term medium, Leibniz claimed, was always in danger of being used willy-­nilly to explain a situation that might otherwise seem to be miraculous on account of its unknown logic, causality, or mode of operation: If the Means, which causes an Attraction properly so called, be constant, and at the same time inexplicable by the Powers of Creatures, and yet be true; it must be a  a Chimerical Thing, a Scholastick occult Quality. (Leibniz and Clarke 1956, 94) Miracles, Leibniz thought, were evoked when a mediating principle was needed to explain physical phenomena without explaining their specific operations. Associated with this danger was the fact that the mediation of a physical effect could only be explained by replacing the miraculous with a medium that was itself unexplained. The mediation might have occurred in an inexplicable manner, but the medium did not appear to be miraculous because, by means of its alleged physical properties, it was more or less able to explain the phenomenon in question. Although the mediation of the medium took place in an inexplicable way, it seemed to explain one process or another by its mere introduction, and this was because media, according to the physics of the time, were defined as material connections that ensured the causality between cause and effect.\n"}
{"prompt":"Action at a Distance ->","completion":"  To summarize Leibniz’s critique: If media could be used in such a way to explain physical processes, then they served as “argumentative resources” (Cantor 1981, 152) for explaining the inexplicable while hiding, beneath the cloak of a medium of communication, the fact that the process in need of explanation was not explained at all but rather replaced by the postulation of a causal connection that was itself left unexplained. In all of its arbitrariness, the medium would thus come to acquire a sort of magical power, for it was used to explain the inexplicable simply by being mentioned—­“groundless and unexampled” (Leibniz and Clarke 1956, 94). His advice is a theory of media: Never replace a miracle with a medium, and never mistake a medium for a miracle. The medium always has physical properties that mediate its actions even at a distance. References Barad, Karen Michelle. 2007. Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning. Durham, N.C.: Duke University Press.\n"}
{"prompt":"Action at a Distance ->","completion":"  Cantor, G. N., 1981. “The Theological Significance of Ethers,” in Conceptions of Ether:  Leibniz, Gottfried W., and Samuel Clarke. 1956. The Leibniz-­Clarke Correspondence. With the assistance of H. G. Alexander. New York: Manchester University Press. Spitzer, Leo. 1948.\n"}
{"prompt":"Action at a Distance ->","completion":"  “Milieu and Ambiance.” In Essays in Historical Semantics, 179–­316. New York: Vanni. Vagt, Christina. 2007. “Absolut ruhend.“ In Stehende Gewässer: Medien und Zetilichkeiten der Stagnation, ed. Butis Butis, 151–­62. Berlin-­Zürich: Diaphanes,. Temporalities of Instantaneity: Electric Wires and the Media of Immediacy Florian Sprenger Translated by Erik Born  On a warm summer day in 1729, a copper wire was suspended across a garden in the south of England.\n"}
{"prompt":"Action at a Distance ->","completion":"  When one end of the wire came into contact with an electrified glass cylinder at the other end, in the very same moment, little pieces of brass leaf began to dance along the wire and settled down on it like butterflies. The person who had electrified the wire was Stephen Gray, a passionate researcher and a dyer by trade. In doing so, Gray was able to create an “elecktrick virtue” (Gray 1731a, 27)—­an attraction, an electric force—­from one side of the garden to the other, a result confirmed only by the sound of his friend Granvile Wheler’s voice and without any visual confirmation. It even sufficed to hold the glass cylinder near the wire without touching it. Sometime later, Gray would suspend a schoolboy horizontally and electrify him, in turn, with a glass cylinder, thereby making little sparks shoot out from the boy’s fingertips to the onlookers. At this stage, the invisible force still did not have the power to decide over matters of life and death,  possible to distribute anything more than undifferentiated sparks, or even to charge them with meaning and code. Transmission was still entirely without meaning or application—­a medium without a message, or rather, a medium whose message consisted in the fact that it existed, that it had an effect where there should be none. The wire filled a distance, a space between cause and effect, with its materiality.\n"}
{"prompt":"Action at a Distance ->","completion":"  Electric action transmitted through the wire seemed to be instantaneous, simultaneous, immediate. And it communicated. Gray called the wires “lines of communication” (Gray 1731a, 27). He did not have a concept like “cable” at his disposal. He knew nothing of insulation, states of electrical charge, or electrons. Communication, for the physical knowledge of his times, meant the connection between cause and effect. Between them, a transmission took place: the necessity of a causal link. Every process in the universe, according to the physics of the time, must have a cause from which it can be explained.\n"}
{"prompt":"Action at a Distance ->","completion":"  For electricity to be able to “communicate” in this sense, three conditions are necessary: two separate elements communicating, one at each end, and an in-­between. The transmitter and the receiver have to differ from each other, or else there would be no channel and no connection. There have to be “two” in order for there to be a “one.” However, these two require a “third”: the medium. Communication presupposes a difference, an abyss between sender and receiver (see Peters 2000 and Chang 1996). Connection requires separation. The aim of communication, speaking generally, is to overcome this temporal or spatial difference, to make it disappear. Yet, electricity does not merely jump across this abyss; in Gray’s experiment and in many other instances of the sciences of electricity, it appeared to eliminate this abyss entirely. The transmission of electricity displaces space and makes temporal differences imperceptible, thereby leaving both space and time immeasurable, while also inserting a piece of wire into them.\n"}
{"prompt":"Action at a Distance ->","completion":"  Although cause and effect had been separated from each other, they still appeared to be simultaneous—­and connected through a lengthy copper wire. it appeared not to require any mediation or any code. It was just there, appearing simultaneously at both ends of the channel, which was consequently no longer a channel but still opens up a space between seemingly simultaneous events. The people communicating over the wire did not have to be present at the same place to be connected. But their present coincides. What happened on Gray’s end of the cable appeared to happen at the same time on Wheler’s end of the cable. Between the ends of a cable, there can be an entire garden—­soon, the entire world, measured out in copper wire—­but there can be no minute, no second, no moment, no blink of the eye, no delay. The cable and its communication lead to an investigation of communicability itself.\n"}
{"prompt":"Action at a Distance ->","completion":"  It spans gaps, and, as a medium, it is presupposed by the connection. What Stephen Gray transmitted in that garden in the south of England in the summer of 1729 was transmissibility; what was communicated in this communication was communicability. The Materiality of Temporality Cables connect the world. They are everywhere—­crossing, branching, and interconnecting—­wherever electricity, whether as energy or signal, should be conducted. Our world is universally connected and linked together, on a small scale as on a large scale. Cables are hidden inside every housing, behind every wall, in every ocean. Whether overground or underground, they connect cities and settlements, continents and colonies. As ubiquitous as cables may be in our current media-­saturated world, rarely do they come into view, so concealed is their history.1 So inconspicuous as to be frequently overlooked, the cable, as a medium underlying other media, can contribute to our understanding of our own time and its spaces.\n"}
{"prompt":"Action at a Distance ->","completion":"  Its history is a history of connections and disconnections, of temporalities and spatialities, and it involves a history of mediation and of immediacy. Thus, the history of the becoming of cables to be told here is a history of the overcoming of distances in durations so short that they are deemed nonexistent, though  history of the phantasm of immediacy. Cables, as Nicole Starosielski (2015) has shown, carve up geographic and architectonic spaces, but they are localizable and limited. They overlay geographies and architectures with their own relations by redefining places in terms of the beginning or the end of a material link. The interconnection of cables creates new “spaces of address,” a collection of all the distant places that can be reached from a single place, medially, via cable. In different historical stages, these “spaces of address” are developed with technical means of connection and disconnection from cable networks over wireless transmissions to digital networks. The basic fact, though, remains constant: The cable addresses because it connects. From the time of Gray’s experiments on, the history of the cable is bound to the history of addressing (see also Peters 2006).\n"}
{"prompt":"Action at a Distance ->","completion":"  The cable creates a relation between transmitters and receivers, be they human or technical, thereby bringing about their addressability, perhaps even their identity (Siegert 1999), though at the very least their ability to be spoken to in that they bear an address. Every cable has a beginning and an end, and with that, a goal in and of itself.2 The materiality of the cable, with its two ends, implies two addresses. Transmitter and receiver are functions of the cable, and consequently, writing this history implies writing the history of these addresses, even before they turn into a network. If every hardwired transmission implies a destination, this place is located at the end of a cable. Since that summer in 1729, cables span the world due to two main improvements. The first was in terms of the amount of time that passes during a transmission. Transmission time is extremely quick, supposedly even instantaneous. Eventually, significant debates in physics will revolve around its duration.\n"}
{"prompt":"Action at a Distance ->","completion":"  The second was that the cable establishes a material connection between the places at the two ends of the cable. Laying a cable does not merely open up a space; it also connects points in space. A cable is never only “here,” but always also “elsewhere.”  makes evident the phatic level of the relation between transmitter and receiver—­the fact that there will always be a channel between them before there is any message. The materiality of the cable influences what can be transmitted “over the wire.” It organizes space and time in that it separates transmitter and receiver, spatially and temporally. The cable itself contains a dimension of connection. Disturbances of the cable make it into the object of research, generating knowledge about its potentials including charge, delay, and transmission (see Hunt 1994). The space and time and the phantasms bound to this first electric medium are the subject of this essay. Sciences of Electricity, Practices of Wiring At the time of Gray’s experiments, electricity was commonly understood as an attribute of objects that would attract other objects after being heated or rubbed (see Heilbron 1979).\n"}
{"prompt":"Action at a Distance ->","completion":"  Accordingly, the concept of electricity designated a quality that had to be produced through manual labor. Interest in electricity was focused on researching corpuscles and effluvia, the smallest little bodies that were imagined, according to the most widespread mechanistic theories, to mediate electric and magnetic effects. Space, so people assumed, was filled with these imperceptible bodies, which were the cause of every effect, every phenomena, including that of electricity. Although electricity would gradually emerge as a well-­defined field of study, it was not institutionalized for the time being, since the results of experiments with electricity were too dispersed and the uses of electricity too vague, hardly extending beyond spectacular experiments with illuminating balls, floating brass leaves, and sparking glass—­all of which was an end in itself. Responsible for this delay were the precarious and unclear status of electricity and the insignificance of electric phenomena. Nobody “mastered” electricity; producing it demanded a lot of talent, dexterity, and patience (Schaffer 1997, 464). rules of instrumentation. In the experiments conducted by William Gilbert around 1600 or Francis Hauksbee around 1710, which had marked out the field of electricity before Gray, all the components in the experimental setup were located within a single room and they all had to be visually perceptible.\n"}
{"prompt":"Action at a Distance ->","completion":"  With Gray, however, the framework changes: the spatial “co-­presence” of a “transmitter” and a “receiver” is no longer necessary. Attraction no longer takes place where the electrified objects are located, as in the model of attraction discussed in the context of magnetism. If electricity itself can be transmitted and “communicated,” as Gray’s experiments would subsequently suggest, then the site of its production would no longer necessarily be identical with that of its effect. Electricity, it turns out, can be sent and transmitted. To do so, wires have been bent, hung, compressed, extended, and knotted in a variety of forms. Substances of Communication The path from the wire to the cable leads through several detours. As early as 1708, Gray had written a letter to Hans Sloane, the secretary of the Royal Society, the most influential scientific institution of its time. As a simple craftsman, Gray did not have the privilege of access to the expensive instruments of the Royal Society, falling back instead on simple glass tubes, feathers, and brass leaves.\n"}
{"prompt":"Action at a Distance ->","completion":"  In the letter, Gray describes how he made a glass tube, which had been electrified by rubbing it, attract a down feather at a distance of a meter—­nothing less than a world record in terms of electrical action at a distance: If when the feather is come to the Glass it be held at about 6 or 8 inches Distance from the side of a wall edge of a Table Arme of a Chair or the like it will be drawn to it and thence to the Glass again and that for 10 or 15 times together without ceasing it flies to object at a greater Distance but then does not soe often Return. (quoted in Chipman 1954, 34)  space and time of transmission that the cable will come to occupy. In the letter, he sets himself the challenge of explaining how effluvia that have been made to radiate outward due to rubbing can attract things back to themselves. However, Gray is unable to present a solution to this problem of attraction. He even tries to refer back to phenomena of repulsion, which had long fallen out of the typical framework of observation: When the feather is come to the Glass and thence Reflected if you follow it with the Glass twill flee from it and will by noe means be made to touch it till driven near to the next wall in the Room or some other solid object by which twill be attracted and freely return to the Glass again Repeating its Reflections. (quoted in Chipman 1954, 35) Whenever the feather touched the glass, according to Gray, it was repelled first to the bodies surrounding the glass, and would only then come back to it. Gray’s conjecture here was that all bodies emit effluvia, mutually interacting with one another (see Heilbron 1979, 234), and his later view would be that these effluvia transmit so much electric force through the air that any receiving objects would likely become electric. Since these effluvia were imagined to be something like an atmosphere surrounding an object, they should have affected any surrounding object.\n"}
{"prompt":"Action at a Distance ->","completion":"  As the effluvia were flowing outward, any surrounding body was also supposed to become temporarily electric: “as all bodies Emitt soe they Receive part of the Effluvia of all other bodies that Inviron them and that the attraction is made according to the current of these Effluvia” (quoted in Chipman 1954, 36). For Gray, this exchange of smallest bodies fills the entirety of space and creates a network out of effluvia flowing between separate objects. In this conceptual framework, there is immediately a connection between anything that winds up within electricity’s sphere of influence. This space is open but it extends only a few centimeters. How do objects become electric beyond a distance of several centimeters, Gray was asking himself, without touching? How do things,  question was central to physics since Aristotle, who put forward the principle that there must be spatial and temporal contact between cause and effect (Aristotle 2008; see Hesse 1955). If a cause and an effect are related to each other in spite of the distance between them, then they have to be connected by a medium. As a tenet of medieval Aristotle reception has it, “Every action happens through contact, which is why nothing acts at a distance, unless through some medium” (Omnis actio fit per contactum, quo fit ut nihil agat in distans nisi per aliquid medium).3 In this economy of causality, an immediate effect at a distance, relating two places to each other without time, is strictly forbidden.\n"}
{"prompt":"Action at a Distance ->","completion":"  To circumvent this prohibition and to explain phenomena like electricity and magnetism, various media have been introduced as “argumentative resources” (Cantor 1981, 152), including ethers, spirits, corpuscles, or effluvia. These media ensure continuity even at a distance, conjuring up a connection even without contact—­actio in distans. Gray’s experiments also followed this powerful theoretical guideline of the physics of that time, though he would be the first to build an electric medium. However, his theses about attraction and repulsion did not initially find any resonance. His next publication would appear only twelve years later, an interim during which he worked in the laboratory of Newton popularizer John Theophilus Desagulier. After another ten years of silence, Gray’s publications and influence began to build. In 1731, he demonstrated his experiments to the Prince of Wales, whom Desagulier served as the court physician, and the Royal Society awarded him with the first ever Copley-­Medal, which is still given out today, and did so again in the following year. Gray’s work was part of a larger change in scientific practice—­a movement toward professionalization that would have challenged his authority as a poor dyer had his experiments been conducted only a few decades later.\n"}
{"prompt":"Action at a Distance ->","completion":"  However, it was precisely this manual dexterity, “the dyer’s knack,” (Schaffer 1997, 464) that was decisive for the success of his experiments. As the historian of science Simon Schaffer has shown, Gray’s exceptional dexterity  difficult for those lacking in practice. Action at a Distance Gray’s first, short published statement about electricity of 1720, though not influential in the scientific community, opens with an important observation. After conducting several experiments with glass tubes and a down feather attached to a stick, Gray had come to a crucial realization: even without the glass tubes, the feather would still be attracted to the stick, “as if it had been an Elecktrick Body, or as if there had been some Electricity communicated to the Stick or Feather” (Gray 1720, 104-­5). Gray’s precise description of the phenomena of charge and discharge, which at the time were still not defined as such, was the precondition for his thesis that electricity can be made communicable. The focus of his research changes here from attraction to transmission—­namely, transmitted attraction—­and thus continues the concern with electrification at a distance that the published letter only hints at. Among the objects Gray was able to electrify was himself, as his fingers attracted feathers or hair. At first, Gray was working with threads and paper, “finding them, after they had been well heated before rubbing, to emit conspiciously their Elecktrick Effluvia” (Gray 1720, 106).\n"}
{"prompt":"Action at a Distance ->","completion":"  If many effluvia gather together, Gray thought, they could be passed on through communication, without any corresponding loss or exchange. In his next report, published in 1731 though referring to events of 1729, Gray begins with a mention of more experiments with glass tubes, but then, after several changes of scene, goes far beyond them, and describes electricity in terms of transmission (Gray 1731a). At this moment the cable takes the stage. To prevent dust from entering the open tubes, which were about a meter long and a few centimeters wide, Gray had stopped them up with pieces of cork. To his surprise, the corks at the end of the tubes did not change the effect of the tube, but precisely the opposite: the corks  ence, this should have been impossible, since the corks themselves were not electrified. At first, Gray was not studying action at a distance but action close up, an effect that would be explained today as “induction.” He went on to replace the corks with all kinds of other materials, or he would touch these materials to the corks, thereby transferring electricity from one object to the next without having to rub it. Consequently, the cork became a carrier, whereas the transmission, in previous experiments, had occurred through effluvia in space. Gray was able to transmit electricity from one object to another, even if a wire was attached to a cork perpendicularly.\n"}
{"prompt":"Action at a Distance ->","completion":"  In this manner, diverse objects could be attached to the tubes hanging in the air, and together they formed a new kind of experimental setup. The space of transmission now reached, with the cable, from the tube to the object. This is precisely why Gray was able to electrify things—­because he did not intentionally touch them with his hand, as had always happened up till then. In Gray’s setup, objects are, to use our current terms, “isolated against discharge.” First, several materials had to be constructed as a continuous line. If the effect (which had only been present where something had been electrified) appears now at the end of the experimental setup, then the object in the space between can also be electrified, and it should function as a suitable carrier. The in-­between object becomes the medium of communication. Gray would try out diverse carriers of communication, such as a fishing spear made of Spanish cane, stovepipes, fireplace tongs, as well as whale bones and other sticks or rods, copper and iron wire, cords, a tea kettle, even vegetables. Since the transmission works best with copper wire, the questions arise as to the maximum possible length of this kind of conductor, and the potential distances it might overcome—­an early signal range test, as it were.\n"}
{"prompt":"Action at a Distance ->","completion":"  [Figure 1.1]. Gray’s Cable. Source: Johann Gabriel Doppelmayr, Neu-­entdeckte Phaenomena von bewunderswürdigen Würckungen der Natur (Nürnberg: Fleischmann, 1744), Table II. How these pieces of wire were connected to each other is not mentioned in any of Gray’s reports. At the time, production methods made it possible to create pieces of wire that were at most a few meters long, and these could then be tied to each other to increase the overall transmission distance. However, Gray was not interested in finding a practical use for his experiments. They are not precursors of telegraphy, however much they may be appear to be. After proving that a certain range was attainable, Gray did not continue the experiments.\n"}
{"prompt":"Action at a Distance ->","completion":"  Although a transmission distance larger than a few hundred feet appears to have been theoretically possible, Gray initially had no desire to test it. Alongside the fascination with attraction without a visible cause, there was also fascination with action at a distance that would eventually overcome distances too great for the eye to see. There are spatial limits to this desire. At first, only a few meters. For longer experimental setups, Gray’s room was too small. His first experiments with a horizontal suspension failed, because he was using the same material for attaching things and as a conductor. Only a trip to the countryside in Ottenden Place in the county of Kent, in the presence of his friend Granvile Wheler, a clergyman and Fellow of the Royal Society, allowed Gray to continue his research in spaces larger than those of his room in the city, and subsequently to present them to the public of the Royal Society upon returning to London. Gray’s accounts of these garden experiments show the significance of narrative patterns for anchoring epistemic innovations.\n"}
{"prompt":"Action at a Distance ->","completion":"  What could be more unlikely, in this idyllic setting, than the annihilation (or, at the very least, manipulation) of space and time? Since no one from the Royal Society was able to be present for the experiments, Gray’s narration made the reader of the Philosophical Transactions into a virtual witness. Gray and Wheler began by hanging the tubes vertically, which would then attract brass leaves lying on a wooden stool or a glass pedestal. They were able to continue this sequence by attaching other materials to the tubes and introducing a rod with a piece of ivory at the bottom end. Since Wheler’s house was equipped with a balcony and even a clock tower more than ten meters high, they were able to experiment with longer setups, yet even this height was not enough to exhaust the effect. For his return to London, Gray planned to hang a tube from the highest point of the cupola of St. Paul’s Cathedral, which would have then attracted a brass leaf in the altar sanctuary. However, this plan proved unnecessary when Wheler proposed attaching the conductor to the roof and having the setup proceed horizontally rather than vertically. The advantage of the horizontal setup was that no disturbance was possible through “discharge” on any supporting object, which could itself be a conductor, though not in the right direction.\n"}
{"prompt":"Action at a Distance ->","completion":"  Gray did not supply a reason for this hypothesis, which would become enormously important for further electricity research. Only after several trials did it turn out that the decisive factor was not the thickness of the carrier but its material composition. The experiment succeeded only with silk threads as suspension. This discovery was crucial because insulation—­which Gray was still not able to name as such—­makes of a wire something more than it is: the wire becomes a cable. Insulation is the necessary condition of the cable, since nothing will flow through an uninsulated wire, and the wire will not function as a carrier. The shift in Gray’s experiment  tween conductors and nonconductors, and, with that, a description of insulation in which the wire turns into a cable. As Gray describes the experiment, Then the Cane being rubbed, and the Leaf-­Brass held under the Ivory Ball, the Electrick Vertue passed by the Line of Communication to the other End of the Gallery, and returned back again to the Ivory Ball, which attracted the Leaf-­Brass, and suspended it as before. The whole length of the Line was 147 Feet.\n"}
{"prompt":"Action at a Distance ->","completion":"  (Gray 1731a, 27) In this context, the theories of effluvia that had been influential for centuries are at their limits, since they can no longer explain these occurrences. Nothing can flow from a glass tube over several hundred feet without a connection. The same experiment was continued in open air. Starting at Wheler’s estate, they built a conductor crossing silk threads stretched between two rods. On July 14, 1729, the length reached 666 feet. The return channel, which would allow one experimenter at the end of the “line of communication” to report what happened to his friend at the other end, consisted of the human voice. Wheler and Gray called the results of their tests back and forth to each other. The time delay of this return channel was insignificant: Gray would not have been able to be at both ends of the setup at the same time to confirm what happened or to determine its speed.\n"}
{"prompt":"Action at a Distance ->","completion":"  From a single source, Gray and Wheler created two, even three different conductors, which led off simultaneously in various directions. However, time eventually caught up with the two researchers: We began about Seven o’Clock, or some little Time after, but before Eight the Attraction ceased: But whether this was caused by the Dew falling, or by my being very hot, we could not positively say, but I rather impute it to the latter. (Gray 1731a, 31)  Instead, there was a shift from experimenting with lengths to surfaces: in what may be called an unintentional anticipation of the global village, Gray and Wheler electrified a twenty-­seven-­ square-­foot world map. They also found that a suspended circular wire would attract brass leaves located below it, provided that it was not too far away. While they were able to determine that the attraction worked to the same extent in all parts of the circular wire, they were not able to determine the location of electricity in the circle. What all these experiments have in common is that, no matter how long they attempted to make the connection, the effect was already there. If electrifying objects requires the presence of the experimenter, who rubs the objects to achieve an effect, the transmitted effect must also happen in his absence—­that means when there is no separation in the connection with the cable. Presence is no longer the condition of possibility for making both ends touch but rather the necessary result of the transmission.\n"}
{"prompt":"Action at a Distance ->","completion":"  Because electricity is present at both ends at once, it is present everywhere. The cable has become not only a medium but, more specifically, a medium of immediacy—­which is impossible in the framework of the physics of that time. Bodies no longer merely receive electricity—­they conduct it. In addition to corpuscles, these bodies can also be human bodies. In April 1740, Gray conducted a spectacular experiment that would fascinate audiences throughout Europe and would be demonstrated in numerous derivations in the form of an “electric kiss.” In the experiment, Gray would suspend a schoolboy horizontally from the ceiling, put brass leaves on the floor under his hands and his hand, and then touch his feet with a charged tube. At the opposite end of the boy’s body, the brass leaf would float up to his head. In the electric kiss variation, replacing the brass leaf with another human being would make the latter get hit with a discharging spark. Indeed, as Gray would find out, the schoolboy does not even necessarily need to be suspended from the ceiling; it sufficed  [Figure 1.2].\n"}
{"prompt":"Action at a Distance ->","completion":"  Gray’s Transmissions. Source: Johann Gabriel Doppelmayr, Neu-­entdeckte Phaenomena von bewunderswürdigen Würckungen der Natur (Nürnberg: Fleischmann, 1744), Table II. to put him on a wax pedestal. As in the case of the silk threads, Gray was using the principle of insulation without knowing it. Even when two boys were put on wax pedestals and connected with a wire, they would each exert a force of attraction. The discharging spark eliminated distance, wiping out difference and stressing discontinuity. However, only contact electrifies: “I then bid one Boy put his Finger upon the other Boy’s wrist, and then he immediately became electrical” (Gray 1731b, 402). If human beings are able to conduct electricity, then the experimenter becomes part of the experiment.\n"}
{"prompt":"Action at a Distance ->","completion":"  The presence of an experimenter’s body can explain many failures of the performance of similar experiments, such as when experimenters would touch the electrified tubes with their hands and cause the electricity to get lost at these human outlets. The body no longer functions as an electric receiver, but as a conductor, and, with that, enters into a state of excitement. Two different forms of transmissions come together in Gray’s experimental setup. On the one hand, electricity acts as a mediator, without any apparent medium, between one object and another, whenever these are approached or touched. On the other hand,  become electric and, with that, conductors, transforming the wire into a cable. This distance opens a space. In passing something on from one object to another, a “line of communication” communicates, as in another meaning of this concept, designating military supply lines. But the instances of transmission in this “line of communication” are tripled: from one object to another at the starting point; through an object in the middle; from this object to another at the other end.\n"}
{"prompt":"Action at a Distance ->","completion":"  The middle term can be extended to almost any desired length. In London during the winter of the year following his first experiments, Gray would continue his research in this direction, finding out that the objects “communicating” with each other did not need to be connected to each other directly. There was an effect even at a little distance: no contact was necessary. It was sufficient to bring an electrified tube in the proximity of a conductor: “communication” would succeed even without contact. As Gray realized, the conductor would even attract a brass leaf at a distance: By these Experiments we find that the Electrick Vertue may not only be carried from the Tube by a Rod or a Line to distant Bodies, but that the same Rod or Line will communicate that Vertue to another Rod or Line that is at a Distance from it, and by that another Rod or Line the Attractive Force may be carried to other distant Bodies. (Gray 1731b, 404) It is not necessary for the conductor to “immediately touch” the body at the end, for the ball to transmit immediately, as the French physicist Charles de Cisternay Dufay would report about the same experiment (Dufay 1733). Hence, Gray’s work marks two shifts in electricity research: first, it demonstrates that certain materials are able to transport the force of attraction over long distances when they are insulated; second, it shows that a conducting third can be switched in between two objects. These two shifts allow Gray to create effects that have  a new challenge because it detaches the object of research from cosmology and theories of substances (see Ben-­Chaim 1990).\n"}
{"prompt":"Action at a Distance ->","completion":"  Nonetheless, this communicability of electric effects does not exhaust itself in research on physical conductivity. The early history of electric transmission cannot be described solely in terms of the history of physics. It depends equally on the stubborn materiality of the cable. The wire leads an experimental life of its own. As a medium, it is open to diverse ways of being used—­above all, as a medial binder. It intervenes in experiments because it breaks, is resistant, or leaks energy. A wire can be bent into spirals and circles, squares and cubes. It opens up spaces and times, makes connections possible, and allows for connections to disappear immediately (on the history of wires, see Blake-­Coleman 1992).\n"}
{"prompt":"Action at a Distance ->","completion":"  The Material Space of Distance In his theory of the parasite as the “third” participating in every relation, Michel Serres attempts to grasp the place of difference, which is also the place of the cable: “A third exists before the second. A third exists before the other. [ . . . ] There is always a mediate, a middle, an intermediary” (Serres 1982, 63). As soon as the “line of communication” gets extended to the point that Gray can no longer hold it in his hands, the constellation changes. The channel creates a medial, material connection between two bodies, and constitutes a necessary technical condition of telecommunication. Although the effect apparently proceeds through a medium, instantaneity seems to negate this medium, since the simultaneity of cause and effect seemingly extends beyond any speed. With Gray, the fascination with simultaneity has materialized in an experimental setup for the first time.\n"}
{"prompt":"Action at a Distance ->","completion":"  The same fascination will follow physics up to the present.4 There is a medium, but there is no delay in mediation. Gray makes out “no perceivable difference” in the effects of his experiment (Gray 1731a). An electrified body is seemingly “immediately” electric  Wheler 1739, 100)—­immediately in all its parts, without any time delay or transmission time. What Gray terms a “difference” in the above statement is twofold: the repetition of an attraction that stays the same over the course of multiple tests and a temporal delay that he is unable to recognize as such. Nothing disturbs or inhibits the immediate simultaneity of transmission—­and yet, the difference between the two places in the garden still represents a spatial division between them. This relation of separation and connection is reflected in the dichotomous status of the cable: it is present in both places, but only because the other end is absent in that place. This is how the cable is able to carry proximity to a distance, and play out its function as a medium: it repeats and delays an electric effect. In this sense, transmission determines a difference because it makes a difference: the cable creates a spatial difference in terms of the cable’s ends.\n"}
{"prompt":"Action at a Distance ->","completion":"  According to the rules of Aristotelian and Newtonian physics, any spatial distance requires time to be overcome, if speed is not to be instantaneous. However, the force overcoming space here was electricity, and nobody knew whether it required time (see Marvin 1988). Everything was pointing in the direction that it did not. Since transmission time lies below every sensory threshold, it could be eliminated without any remainder. For Gray, electric transmission appears to be timeless. The events occurring at the ends of the cable do not run in parallel; they are connected through a material medium, and not merely an effluvial or an etherial one. In turn, immediacy is projected onto this medium, which also serves to negotiate the new status of absence and presence. This physics of electricity, evident in the case of the cable, shakes the foundations of science because in its theoretical framework, instantaneous action at a distance is impossible.\n"}
{"prompt":"Action at a Distance ->","completion":"  For this reason, writing the history of the cable and its transmissions requires casting a glance at the transformations of physical knowledge at the time of Gray’s experiments. They are also the setup in which the term “medium” is shaped in the form that became predominant throughout the twentieth century. at a distance were in circulation at the time, Gray’s experiments did not link up with them. “Communication,” in the sense of the physical sciences, cannot simply be equated with “communication” between people, though their conceptual histories are intertwined. Gray’s transmission is not a precursor of telegraphy, despite having an identical experimental system. Its content is itself—­transmissibility. In Gray’s experiments, there is no function or processing, either in the mathematical sense or in the sense of an application, and thus nothing is transmitted other than the transmissibility of electrical attraction. The transmission is not processed, and yet it shows, through attraction, that it exists.\n"}
{"prompt":"Action at a Distance ->","completion":"  There is no content of this communication, which is why it refers to itself and thus exposes its properties. Transmission here means that the same action happens in the same moment at the beginning and at the end. It appears to be instantaneous, without time loss or delay. If there is no transmission speed and thus no separation despite distance, the two bodies involved in the communication are united in their electricity. In this way, electricity is able not only to arrive, “live,” at the other end but also to be present at both places. Only decades later, transmission time, as transport time or signal time, will itself become a topic of inquiry only after there are more precise measuring procedures for displaying speeds and delays. Eventually, it will turn out that every cable influences what it transmits, and that resistance is a variable of transmission. Without this knowledge, long-­distance transmission is impossible.\n"}
{"prompt":"Action at a Distance ->","completion":"  At the time of Gray’s experiments, there was no way to perceive the disturbances and temporal delays of electricity, which will become functions of cables—­for example, in the laying of the transatlantic cable—­since these functions are dependent on measuring devices that divide time or space and make it countable. The sole basis for Gray’s judgment, defining the region in which something can be determined to be “present,” was sensory perception. At best, Gray and Wheler were able to shout when something happened. But as soon as they would raise their voices, it had already happened. Additionally, the experimental setups were too large for perception. As long as no  only be described as instantaneous: it was not possible to study its speed by the means of perception. In the end, the return channel would need to transmit just as fast as the electrical conductor (see Galison 2003). This is true even if the conductor is laid in a circle, thereby bringing both ends together into a single point that can be observed at once.\n"}
{"prompt":"Action at a Distance ->","completion":"  The main aspiration running through all the work in physics on electrical action at a distance is to determine and to measure this time as a physical time, an objective time, a time beyond the experimenter’s limited capacities of perception—­ and as a time of the cable. As the wire becomes a cable, there are several noteworthy changes: a new time-­dimension of transmission appears, and, with that, the possibility of storage. The electric cable transmits only attraction, without storage and without processing. Today, every signal that gets transmitted has to be processed in order to achieve “liveness” and “real-­time” (e.g., in digital television transmissions). Even though processing time increasingly approaches transmission time, the term “real-­time” remains a euphemism, and the rhetoric of “telepresence” skips over the production of that presence (see Sprenger 2015). There is transmission in “real-­time.” Every transmission is always mediated, and it is this delay that all technical media operate with. Real-­time can only mean that signals are arriving at the speed in which they can be processed as quickly as possible: in time rather than real-­time. Real-­time always takes place between two points in time and is therefore not instantaneous.\n"}
{"prompt":"Action at a Distance ->","completion":"  Skipping over this delay means ignoring its influence on how we are connected and disconnected. Allowing the cable to come undone in processes of “instantaneity” and “acceleration” amounts to concealing the spatial relations, the spaces and times of interruption that are created by electric media. It also amounts to obscuring how these media are currently reconfiguring society. However, it is still important to keep in mind the deployment of the cable in the imaginary of its time. In the earliest discourses of telegraphy, there was a hope that the establishment  world, ultimately bringing people, countries, and continents closer together (for example Winkler 1750, 5). In this way, telegraphy catalyzes both new ideas about community and for communities’ self-­perception. As one developer of the telegraph, Carl August von Steinheil, put it: Communication is the strongest bond of the living creation: it connects one individual life to another, reproduces in one that which is a given for all, and thus forms out of individual beings species that emerge again as organic beings. (Steinheil 1838, 3) The centrality of the cable for this imagination of an organic bond can be seen in an illustration of a figure, alluding to Shakespeare’s Puck, alias Robin Goodfellow, who holds both ends of a cable wrapped around the globe: whenever he pulls one end, the other  [Figure 1.3].\n"}
{"prompt":"Action at a Distance ->","completion":"  Historical Sketch of the Electric Telegraph. Source: Alexander Jones, Historical Sketch of the Electric Telegraph (New York: Putnam, 1852), frontispiece. same time and, as such, does not merely connect individual places to each other but rather forms a connection that ends where it began—­exactly in the sense of a line in Shakespeare’s Midsummer Night’s Dream: “I’ll put a girdle round about the earth in forty minutes.” The illustration comes from Alexander Jones’s Historical Sketch of the Electric Telegraph, which appeared in 1852, before the first attempt to lay a transatlantic cable but already anticipating a wired world. Until it became measurable a century later with elaborate devices and experimental setups, electricity appeared not to have any propagation speed but rather seemed to be at different places at the same time. In this instantaneity, electricity is related to media concepts used in the twentieth century to narrate the history of this very medium. “Past, present, and future merge into electric nowness,” Marshall McLuhan will write more than two hundred years after Gray’s experiments (McLuhan and Nevitt 1973, 1). For McLuhan, the instantaneous, simultaneous transmission of the “electric age” will unite the world into a new entity without an outside. For Gray, too, instantaneity no longer refers only to a constellation present before one’s eyes that can be perceived with a single glance, but to the expansion of a transmission in a space no longer based on the senses.\n"}
{"prompt":"Action at a Distance ->","completion":"  In these phantasms of immediacy, the channel recedes from the picture because the instantaneity of ubiquity creates a new entity out of individuals, as in McLuhan’s global village, in which the delays and the materialities of the cable are entirely eliminated.5  Territories of the Cable The geographic space of transmission, the distance from one side of a garden to the other, is not identical with the territory produced by the cable. Whereas this territory depends on the smallest possible times, or even no time at all, the geographic space of transmission remains as it is. Without electric transmission, a cable  once this space can be crossed instantaneously, or almost instantaneously, it ceases to be an obstacle and—­simplifying things, since new problems and possibilities arise—­must be conceived of anew. The separation between transmitter and receiver, between glass tube and brass leaf, ceases to be of minor importance, because the medium between them has been invisibly extended—­and above all, because the length of the cable seems to be irrelevant for transmission time.6 The spatialization of the channel plays no role for time: regardless of how long a cable may be, its end will always already be at the beginning. Opening up a territory by laying a cable creates new spaces and temporal relations. They define a space of address. Materially, the two communicants are relegated to a position at each end of the cable, a position that, in transmitting from a distance, becomes a location within a new spatial structure that is not based on perception. This location can be addressed in both orders—­in the geographic order as in the territorial order of the cable.\n"}
{"prompt":"Action at a Distance ->","completion":"  In each order, however, the cable enters into different relations, and borders different places. While closing off geography, transmission also opens up a new space in which one end of a garden is made to border the other, insofar as both are addresses, just as Washington will later border Baltimore, or Britain will border America, with the construction of the first telegraph lines. Even if transmission is supposed to be instantaneous, its materiality opens new spatial relations that start to change the world. If the space and time of transmission are not conceived of as immediate, the duration of transmission necessarily requires space, and the distance of transmission necessarily requires time. Both are based on a delay that contradicts their presence. Conceiving of the cable in terms of immediacy makes its in-­betweenness disappear, and, with that, space and time of media as well. However, the difference between the beginning and the end of a cable, qua différance, transforms the phantasmal unity of transmitted electricity into a duality. Communication inserts an interval into the  equally different: This différance of the between, this elementary différance of inter-­position or intervals between two surfaces is at the same time the condition of contact and the originarily spaced opening that calls for technical prosthetics and makes it possible, without any delay.\n"}
{"prompt":"Action at a Distance ->","completion":"  (Derrida 2007, 229–­30) In other words, distinguishing A from B requires determining A by determining B, and this implies a delay: temporally, A comes before B, and between them comes the cable. As a spatialization of transmission, the cable causes delays due to the fact that both ends of the cable are predetermined to be addresses of transmission. This is due to the differentiating function of space: wherever A is located, B cannot be located, and, for this reason, there has to be a distance between them, which also differentiates them from each other. In terms of time, however, B can also be A’. The phantasmal immediacy of action at a distance, in which an action can be present at two or more places at the same time, would eliminate all of this: it would make A out of B, thereby wiping out division and disconnection. Ironically, the Leipzig-­based cable researcher Johann Heinrich Winkler, who continued Gray’s experiments a few years later, remarked as early as 1750: “At present, the speed of communicated [or, transmitted] electricity cannot be determined due to a lack of the required space” (Winkler 1750). Thus, the cable is a measuring tape, a stopwatch, and a carrier rolled into one. It serves not only to transmit information or energy, but also to measure these transmissions in terms of their extent, speed, and distance, and to enable research on the space of transfer.\n"}
{"prompt":"Action at a Distance ->","completion":"  In doing so, however, the cable intervenes in the transmission, since the speed of electric transmission, as would later become evident, is relative to cable length. In this sense, the cable requires research about the places where it is laid, such as knowledge about the peaks and valleys it has to cross, or the depth  resistance have ensured that the effect at its end is not identical with that at its beginning; even with the best insulation, there will inevitably be a loss. At first, this was not measurable because there were no corresponding instruments and dimensions, no units transforming space and time into measurable amounts. The history of the cable as a medium between immediacy and mediation is related to a history of measuring and proportioning electricity. After Gray, the subsequent course of electricity research would be inconceivable without the cable. What would become known as the first stable functioning electromagnetic telegraph, created by Carl Friedrich Gauß and Wilhelm Weber in Göttingen in 1833, was initially nothing other than an experimental cable system, which served their research on the galvanic chain and their attempt to validate Ohm’s law. With Georg Simon Ohm, the cable appears as a medium of delay and shows a resistant materiality. Ohm would formalize the principle of electrical resistance, which, in turn, is the foundation for the worldwide rise of telegraphy.\n"}
{"prompt":"Action at a Distance ->","completion":"  The second half of the nineteenth century will become the age of long-­distance cables, not only for the purposes of transmitting information but also, starting in the mid-­1880s, for transferring energy. Thanks to the telegraph network, built to a global scale, the cable will become a medium of universality. Above all, cable research will come into its own, with the laying of the undersea cables, as a unique scientific field with protagonists like William Thomson and Michael Faraday whose starting point will be disturbances of communication and not its success (see Volmar 2009). In short, since Gray’s experiments, the cable temporalizes spatialization, it overcomes space in time, thereby creating a time between two places. The cable requires, systematically and physically, a rudimentary storage function: the contents of any transmission that is not instantaneous have to be stored, at least temporarily, because they have to exist somewhere, in some state, during the duration of the transmission. Electricity and cables, and later on, signals and messages, exist only in their execution,  only in this execution. At the end of every cable, the same effect that entered into it at the beginning should ultimately arrive. In Gray’s experiments with the cable, this repetition consists solely of the effect of attraction.\n"}
{"prompt":"Action at a Distance ->","completion":"  However, with the development of better measuring instruments, more reliable sources of electricity, and, above all, the breakthrough of electromagnetism, this repetition will have become standardized only several decades later to the point that the cable can be equipped with signals, eventually making it the basis for telegraphy and finally the transmission of the binary signals that still constitute our digital cultures. Transmission relocates effects to the places determined by a wire, which, for this very reason, has already become a cable.\n"}
{"prompt":"Action at a Distance ->","completion":"  “Some Electrical Experiments, Chiefly Regarding the Repulsive Force of Electrical Bodies.” Philosophical Transactions 41:98–­125. Winkler, Johann H. 1750. Grundriss zu einer ausführlichen Abhandlung von der Electricität. Leipzig: Breitkopf. A Cornucopia of Meanwhiles John Durham Peters  Oblivious Simultaneity Events have always been happening at the same time. Billions of things are happening this very second around the globe, in my immediate vicinity, and even within my own body, all without my knowing anything about them. If it is overwhelming to think that about six thousand people die and fifteen thousand more are born every hour, abandon all hope of trying to track the mitosis of cells or the work of chlorophyll! Counting would fail if we tried to quantify all the things that happen without notice, especially once we dive into microscales!\n"}
{"prompt":"Action at a Distance ->","completion":"  (Surely the number of unnoticed things vastly outstrips the number of things known or observed.) Oblivious simultaneity, as we might call it, seems simply part of the order of things. Our bits of awareness are rare and scattered lights on a dark landscape of unknowing. So the poets and philosophers have long told us. Everything flows, said Heraclitus; “Mudam-­se os tempos,” wrote Camões; “Nobody knows nothing anymore,” sings Billy Bragg. Conscious or controlling simultaneity, however, is quite a different animal. To know, narrate, or act upon another event occurring at the same time but in a different space requires a logistical link of some kind in matter or mind, in transportation or communication. distance.\n"}
{"prompt":"Action at a Distance ->","completion":"  It compiles a comparative history of meanwhile structures, which I define as techniques of shuttling between two points in space at the same time that are too far apart for the unaided human senses. From a patchwork of examples, several of them from that library of ancient literature gathered in the Bible, I hope a central point becomes clear: that banking time is a way to span space. Anderson: Meanwhile Structures in Modernity—­and Antiquity? Benedict Anderson, in his highly influential Imagined Communities: Reflections on the Origin and Spread of Nationalism (1983), speculates that “every essential modern conception is based on a conception of ‘meanwhile’” (24). He locates this particularly in the modern media (“forms of imagining”) of the novel and the newspaper, and in his second edition of the book (1991), in the census, map, and museum as well. The novel “is a device for the presentation of simultaneity in ‘homogeneous and empty time,’ or a complex gloss upon the word ‘meanwhile’” (25). A novel can jump horizontally between scenes—­same time, different space—­and tell of characters whose lives run in parallel and could cross unwittingly in the street without being aware of their remote links. “In Imagined Communities,” he later wrote, “I argued that the historical appearance of the novel-­as-­popular-­commodity and the rise of nation-­ness were intimately related.\n"}
{"prompt":"Action at a Distance ->","completion":"  Both nation and novel were spawned by the simultaneity made possible by clock-­derived, man-­made ‘homogeneous empty time,’ and thereafter, of Society understood as a bounded intrahistorical entity” (Anderson 1998, 334). (By intrahistorical, Anderson means secular or common time, not eternity; see Culler 1999.) Anderson spins the story elegantly: once upon a time, history and cosmology were inseparable, and time present contained time past and time future. Now we live in a dull and disenchanted  straight line. (Hence the rise of nationalism as an answer to the question of meaning for men and women stripped of ancient religious frameworks.) This tale of a massive shift from sacred to secular, vertical to horizontal, recursive to linear time might be the founding story of modernity. “Our own conception of simultaneity,” he states, “has been a long time in the making, and its emergence is certainly connected, in ways that have yet to be well studied, with the development of the secular sciences” (24). Antique narratives were not capable of cross-­cutting, as the film-­editing technique is called that takes you instantly from one scene to another—­near or far—­in a parallel time.\n"}
{"prompt":"Action at a Distance ->","completion":"  Petronius’s Satyricon, the scurrilous Roman novel, in some ways is a forerunner of the modern novel, but “its narrative proceeds single file” (25). There is no “in the meantime” movement from one scene to another. Anderson places the big shift in the eighteenth century. Evidently borrowing from Marshall McLuhan, Anderson treats the essence of the newspaper as “calendrical coincidence” (33).1 What all the news stories in a daily edition had in common was that they occurred yesterday. (The more recent 24\/7 news cycle changes this circadian rhythm.) Readers of newspapers partake of “the diurnal regularities of the imagining life” (35n63): in both narrative structure (many events, one text) and audience behavior (many readers, one time) newspapers follow a logic of composite juxtaposition. In the middle ages, artists could portray local patrons at the birth of Jesus in Bethlehem without worrying about anachronism; now was then and here was there. Under the regime of modern clock time, in contrast, modern novelists and journalists learned to array events as parallel in space rather than time.\n"}
{"prompt":"Action at a Distance ->","completion":"  At least so goes the argument. Was Anderson right? Could events happening over great distances be coordinated when messages traveled no faster than foot, horse, pigeon, or ship? Were there no robust meanwhile structures before the eighteenth century? Did the apparently instantaneous transmissions of the telegraph enable new modes? Transport Narrative Focus Let’s test Anderson’s thesis with two of the Bible’s most memorable narratives, both of which concern fathers and brothers separated in different places with very different fates. Neither story has any simultaneous back-­and-­forth between parallel developments until the brothers actually come back into the same place, bringing their time streams with them. In the book of Genesis, Joseph is sold into Egypt by his jealous brothers, who assume that he vanishes into servile anonymity.\n"}
{"prompt":"Action at a Distance ->","completion":"  When a terrible famine later drives them into Egypt in search of food, they meet an imposing Pharaonic figure whom they don’t realize is Joseph, who has—­in the meanwhile—­ risen to the heights of the Egyptian world. The narration follows the physical movement of the brothers; it has no wings to jump from Egypt to Palestine. Likewise in the parable of the father and two sons told in the book of Luke, the younger, “prodigal” son demands his inheritance, moves to a far country, and squanders his wad in what the King James Version memorably calls “riotous living.” When he returns in frustrated impoverishment, his father welcomes him home royally, much to the umbrage of the older, faithful brother. We never hear of the two brothers at the same time in different places; the two narrative streams only come together when the brothers do. What is interesting here is not the parallel development of separate stories. That has always happened. What is interesting is the lack of narrative means for saying “meanwhile, back at the ranch.” The narrative proceeds, as Anderson says, single file; it does not outpace the physical limits of the characters’ movements. There is no magic carpet that carries the reader telegraphically to different places.\n"}
{"prompt":"Action at a Distance ->","completion":"  The moment of recognition is only possible with physical presence. Prophetic Vision: Live Feed or Memory? Yet in both the Bible and in Homer, there is such a magic carpet device—­but apparently only for the gifted and for gods. The book  heavens open up to a visionary man located in unusually specific circumstances: by the Kebar river, in Babylon (Iraq), among a group of captives, on the fifth day of the fourth month of the thirtieth year. The Jews are in Babylonian captivity, far away from home. But Ezekiel, with its colorful and weird imagery as well extreme behavior by the narrator, is a psychedelic, literally trippy book, especially with the narrator’s frequent flights between Babylon and Jerusalem. The spirit moves him, levitating or teleporting him through the air, where he witnesses people and buildings, especially the temple in Jerusalem, from his location in Iraq. It is not clear whether he is supposed to be accessing events archived in memory or viewing a live feed.\n"}
{"prompt":"Action at a Distance ->","completion":"  When Ezekiel sees, for example, a prince of the people named Pelatiah die in Jerusalem (Ez. 11:13), is this supernaturally privileged access to news he could not have received so quickly in Babylon by normal means or a recounting of an already known event? No one could know without a system of verification that at that time would have to travel on land. The Homeric Meanwhile? In Homer, the gods of course are not bound to the sluggish speeds of earth travel. Athena can zoom from the Phaeacians to Olympus and back where she appears to the shipwrecked Odysseus in veiled form (Odyssey, book 6); she serves as the puppet master of the several plots in the Odyssey, tracking down Telemachus, the long-­ missed son of Odysseus, in Sparta, for instance, at the opening of book 15 before she jets back to Olympus. Telemachus then approaches Ithaca in his ship while Odysseus feasts and tells identity-­ cloaking war stories with his friend Eumaeus the swineherd. At line 301 the narrative wings from Telemachus steering his way through the rocky islands around the island to the hut where Odysseus, Eumaeus, and others are hanging out.\n"}
{"prompt":"Action at a Distance ->","completion":"  The transition is marked by a well-­known Homeric formula that means something like “but then, on the other hand,” but doesn’t commit us to understanding it as a “meanwhile,” though it is sometimes translated that way.2  a physical viewer could have stood to take in both the hut and the ship synoptically. In a similar way, book 16 of the Odyssey shifts focus between the palace, the hut, and the ship on the shore. The narrative slices through space with the same speed that Athena flies. As these examples suggest, narrative structure with regard to space and time in Homer is highly varied and complex. There is a more than century-­old debate in Homer studies about Zielinski’s law, which decrees that simultaneous events in Homer are always narrated as sequential. Early on, the debate was inspired by the Anderson-­like and perhaps condescending thought that ancient authors could not imagine simultaneous events, but the obvious point that Homer is a poet of enormous narrative prowess who handles time and space in a variety of ways, not always consistent, has been made by many scholars since. (For an excellent overview see Scodel 2008). But for us the relevant point is that brilliant scholars have not been able to settle the question for good whether there are meanwhile structures in Homer.\n"}
{"prompt":"Action at a Distance ->","completion":"  That the question is open is itself a sign that his narrative world was different than that of the modern newspaper or novel, where there could be no such question. Anderson both offers too stark a historical narrative of before-­and-­after and sees something important about modern narrative organization. Eratosthenes: A Priori Synchronization Eratosthenes, the third-­century BCE Greek mathematician, astronomer, and chief librarian of Alexandria, was the first that we know of to arrive at an accurate estimate of the earth’s size. He did so via a thought-­experiment that put two distant places into one time. There are learned debates about his methods—­did he take shadows from wells, towers, or sundials? What are the modern equivalents of his measurements? Did he round his calculations for arithmetic convenience? But here is one account of what he  Alexandria, in northern Egypt, showed a shadow of 7.2 degrees.\n"}
{"prompt":"Action at a Distance ->","completion":"  He also knew that at Aswan, 5000 stadia to the south on the same meridian, there was no shadow at noon on the same date: the sunlight went straight down to the bottom of a well. He assumed a round earth, and perfectly parallel rays of sunlight. He didn’t need a telegraph relay from Aswan to tell him that the sun was casting no shadow at noon; he knew that already and took it as given. The regularity of planetary rotation obviated the need for fresh data. Astronomical constants do not require empirical confirmation and remain invariant compared to noisier and more mutable kinds of data, such as weather data. Using basic geometry—­quite literally, the science of earth measurement—­he inferred that the angle of the shadow at Alexandria would be the same as the angle from the center of the earth to the two cities (see Figure 1). This angle was 7.2 degrees, or one fiftieth of a circle (7.2\/360 = 1\/50), so Eratosthenes figured that the distance from Aswan to Alexandria, known to  [Figure 2.1]. Inspired by Ryan (2016: 372).\n"}
{"prompt":"Action at a Distance ->","completion":"  5000 x 50 = 250,000 stades. If, as one historian concludes, a stade was about 157.7 meters, then Eratosthenes’s estimate was 39,425 kilometers, which is remarkably close to the earth’s equatorial circumference of 40,075 km (Engels 1985). (The earth, like many of us, bulges at the middle, and its meridional or north–­south circumference is 40,008 km.) The Hare and the Hedgehog Eratosthenes engaged in what we can call space-­axis manipulation, a term I owe to Paul Frosh. This is an odd and interesting kind of action at a distance. In such a priori synchronization, a single person combines two observations in the nonlinear time of memory to fly across one fiftieth of the earth’s surface. But let us be more precise. Eratosthenes did not have to fly across the two spaces.\n"}
{"prompt":"Action at a Distance ->","completion":"  He was already in both, or at least had instantaneous knowledge of conditions of both spots at once. He operated in the symbolic realm free of the grind of real time. His memory was a random-­access database. This is timeless simultaneity, as explicated by Hartmut Winkler in a brilliant essay (Winkler 2009 and 2015, 233–­54). Building on the Grimm Brothers tale of a race between a hare and a hedgehog in which the hedgehog, obviously a much slower runner, always wins, Winkler contrasts two modes of operating in space and time. The hare always uses up time in running the race, however little. The hedgehog, however, requires no time to traverse point A and point B because he—­or she—­is already there. That is, the hedgehog cheats by stationing at the endpoint of the track his wife, whom the hare mistakes for the original hedgehog.\n"}
{"prompt":"Action at a Distance ->","completion":"  Whichever direction the hare runs, he finds the hedgehog already there, victorious. The hare can never win against an opponent who spans space instantaneously. The hare must always pay a toll to time. Because the hedgehog has taken advantage of earlier time to pre-­distribute over space, travel is free. Or rather, no travel is necessary. In memory, like any archival system that gathers many moments into an instantaneous array, the past and the present are  Anderson thought uniquely medieval or sacred; it is in fact one of the fundamental modes of—­nonlinear—­temporal organization.) The hare mode is typical of media operations that transmit, such as telegraphy and telephony; the hedgehog mode is typical of media operations that spread all at once in advance, such as publishing. (We ignore the many further subtleties here.)\n"}
{"prompt":"Action at a Distance ->","completion":"  Most narratives inch along in hare mode. A play like Hamlet jumps between different characters and scenes, but the implication is that we are in a weird kind of diachrony. Eratosthenes, rather than rapid movement, had a real simultaneity. So, with help of earth, sun, and memory, meanwhile structures were possible, at least rarely, in the ancient world. The New Moon: Synchronization Plus Buffering Contingent and variable data cannot be handled hedgehog style. Such data perish in time, and so transit speed affects their value. The moon’s phases are an example. The ancient Jewish calendar pivoted on the new moon, which marked the beginning of the month and of many holidays.3 The new moon must be sighted but varies slightly by point of view on earth.\n"}
{"prompt":"Action at a Distance ->","completion":"  A new moon occurs when the moon is between the earth and the sun; it is therefore invisible by the naked eye for a variable period of around twenty-­four hours. The paradoxical challenge is to spot something that you can’t see, so you settle for the first sliver of the crescent as proof of the new moon. Determining when it is at its smallest (= newest) is always a judgment call with potential for a slight geographic bias. Another complexity was that the Jerusalem Sanhedrin held a monopoly on determining the new moon until the fourth century, when Hillel II introduced a regular calendar. To send the signal to a people scattered across the ancient Middle East faced many perils. Its drag left ambiguity about its accuracy: the speed of transmission always affects time-­sensitive information. The solution reached was to grant double holidays to the diaspora: assuming that remote intelligence  sage latency. (Even with instant signal transmission today, most of the diaspora observes double holidays; some pleasant things live on even after the reason for their origin has passed.)\n"}
{"prompt":"Action at a Distance ->","completion":"  Delay was not the only problem: so were faulty or corrupt witnesses, tampering with the fire signals, clouds or fog that obscured sighting of the moon or the fire signal, slow messengers or ones who refused to travel on a holy day, etc. (If the announcement of the holiday causes its messengers to violate its sanctity by traveling on it, this is an odd contradiction. The fact of the holiday would be news that that fact makes unshareable! )4 The strategy here is synchronization plus buffering to allow for lag times to pool and catch up or run ahead. Information Is Never Free It is dangerous to be a messenger. For a messenger bringing unwelcome news to a volatile tyrant, never was McLuhan’s equation of medium and message more fraught. In the first chapter of 2 Samuel, an Amalekite soldier brings news to David of the death of his sometime opponent and father-­in-­law King Saul. David asks how he knows that Saul is genuinely dead.\n"}
{"prompt":"Action at a Distance ->","completion":"  The messenger tells of coming upon Saul after his unsuccessful attempt to fall on his sword. The Amalekite finds Saul badly wounded but agonizingly still alive; Saul asks him to kill him, and he complies. In telling David this, the messenger thought he was currying favor; instead he was confessing to a crime. The admission cost him his life, as David orders his henchmen to murder him. This story leans toward a crucial quantum discovery: that information is never free. Information is ontologically part of the system: you cannot observe a system without engaging it. Maxwell’s demon is the fantasy of costless information—­a fantasy that went down, literally, in smoke. The universe will run down; information is intervention.\n"}
{"prompt":"Action at a Distance ->","completion":"  These two truths have much to do with each other. The nature of the cosmos and the limits of our knowledge are one. And the nature of the cosmos is that time runs in only one direction: anything we know comes at the expense of time (Kittler 2003). A lot can happen while a message is buffering. The book of 1 Samuel tells the episode of the city of Jabesh threatened by the Ammonites. The elders of the city ask for seven days to send messengers throughout Israel to see if anyone of their compatriots will come to their aid. Officially they are asking for time to transmit a message, but they are also gaining time to mobilize. The transmission of the data is also the readying of an army.\n"}
{"prompt":"Action at a Distance ->","completion":"  In such situations signal and ontology most closely approach each other. Much mischief can occur between point A and point B in hare mode. Aristotle, in the Politics, smirks that Babylon was more a nation than a city: “Babylon, they say, had been taken for three days before some part of the inhabitants became aware of that fact.”5 Aristotle thought it absurd that a polis would not be in instantaneous communication with itself. It was supposed to be a single body, “always already in synchrony” as Helge Jordheim remarks.6 But even bodies are not self-­transparent. Herrmann von Helmholtz discovered the finite speed of nervous propagation in the 1840s, forever ending the fantasy of complete self-­unity. “I think, therefore I am” was now “I think, therefore I am belated.” Imagine the split second in which I have died but my brain hasn’t gotten the news yet. Of course, the fact that I am alive enough not to know I am dead suggests I might not yet be dead. The body, like the ancient Jewish diaspora or a metropolis like Babylon, could never be on one precise same time grid.\n"}
{"prompt":"Action at a Distance ->","completion":"  Where the ancient world could only imagine the terror of organic mismatch for the Leviathan of a state like Babylon, after Helmholtz it was a fact written into all nervous systems. That held especially for the Leviathans of Moby-­Dick, whales whose long nerves suggested potentially significant syncing mismatches. Did their two, entirely independent, non-­binocular eyes cause them to live in a synthetically integrated immersive now-­time, or did they require a completely different mode of being in time (see Moby-­Dick, chapter 74)? The problem of communication within the polis moved to the physical body. Separated lovers have at least the moon in common. Probably every generation has rediscovered that the moon can serve as a transponder for bouncing heartthrobs to other parts of the earth. The moon as an instantaneous relay was expressed by the Tang poet Zhang Jiuling (678–­740 CE) in “Looking at the Moon and Thinking of One Far Away” (望月怀远). In one translation (Bynner 1982, 66): The moon, grown full now over the sea, Brightening the whole of heaven, Brings to separated hearts The long thoughtfulness of night.\n"}
{"prompt":"Action at a Distance ->","completion":"  It is no darker though I blow out my candle. It is no warmer though I put on my coat. So I leave my message with the moon And turn to my bed, hoping for dreams. According to Su Hua, one of the lines may be translated more directly as “the sea gives birth to the moon (and) even the ends of the earth share the moment.” She also points to the closing line of a famous poem by Su Shi (1037–­1101 CE), the many-­sided poet-­ statesman of the Song dynasty, called “Water Melody”: “Though three hundred miles apart, we are still able to share the beauty of the moon together.” That poem’s “I” says he wishes to ride the wind but fears the cold of the high altitudes and settles instead on a reverie with the moon beams. In a different mode, Li Bai, perhaps China’s most famous poet and, like Zhang from the Tang dynasty, tells of drinking alone to the moonlight, the moon and its shadow providing company for him and making three total. Here, of course, is no synchronization, only the moon as a companion for the lonely—­as it was a go-­between for the separated lovers in the other poets.7 René Girard’s point, made in a series of books starting in the early 1960s (see Girard, 1961) that romantic love always involves a third party, was never more true. The Christian Gospels recount many episodes of Jesus healing people. Sometimes he touches them, or they touch him, and sometimes he concocts medicaments on the spot of mud and spittle.\n"}
{"prompt":"Action at a Distance ->","completion":"  Yet he also often cures the sick at a distance, and in many instances touch is superfluous. For a comparative history of simultaneity, the most interesting episode (John 4:46–­54) occurs when a royal official hears that Jesus has entered into Cana, a town in Galilee, and approaches him, asking him to come down to Capernaum, presumably a day’s journey, in order to heal his son. Jesus says that he doesn’t need to come and sends the man home, telling him that his son will be fine. The official trusts him and returns, and on the way is met by servants who tell him that his son has recovered. He asks them when it happened. The fever, they report, broke yesterday at the seventh hour (about one in the afternoon). Cross-­checking the timestamp, the man realizes that was exactly when Jesus talked to him; he and his household become firm believers when they realize that the healing must have been caused by Jesus. The Gospel of John uses this retrospectively established simultaneity to make a point about the nature of faith, but it is a simultaneity discovered only after the fact by comparing two separate chronologies—­ standard for a world without any system of synchronizing time across distance.\n"}
{"prompt":"Action at a Distance ->","completion":"  The Genitive Absolute; Or, Event-­Splices If biblical narrative proceeds normally single file, there nevertheless are many examples of two things happening almost exactly at the same time. The four messengers to Job, announcing the four rapid disasters that destroy all his family and possessions, come in quick succession, each one overlapping slightly with the previous—­ following “hard upon,” as Hamlet has it. There are two dramatic event splices, for instance, in Luke’s story of the Passion. Luke 22:47 says that “while Jesus was yet speaking” the mob led by Judas came to arrest him. Peter then follows Jesus at a distance, warming  who think they have seen him with Jesus. After the third denial, again “while he was yet speaking,” the cock crows, Jesus turns and looks at him across the crowd, Peter remembers his promise never to deny and Jesus’s warning that he would do so three times before the rooster sounded, and goes outside to weep bitterly. You can almost imagine the camerawork. Erich Auerbach has wonderfully analyzed this episode already (see Auerbach 1946, chapter 2).\n"}
{"prompt":"Action at a Distance ->","completion":"  I want to reflect more specifically on the ways the text treats time. This is not a modern meanwhile structure, because the figures remain within sensory range of each other; for me, a genuine meanwhile structure must involve cross-­ cutting between remote scenes. But the grammatical structure in Greek of the genitive absolute allows for the juxtaposition of two happenings, one suspended in the absolute, and the other with a finite verb. This kind of event-­splice happens biblically when two happenings are within range of each other, not at a distance. The grammatical structure occurs hundreds of times in the New Testament, and more rarely in Homer, Thucidydes, and Plato (Fuller 2008). It links two happenings—­causally, concessively, consecutively—­by floating one in absolute form, and the other finite. Greek grammar enables meanwhile structures of a sort. But only if one is suspended in a tenseless (timeless) state.\n"}
{"prompt":"Action at a Distance ->","completion":"  Magic Carpet Rides Almost as in Ezekiel, fast travel across great gulfs of space occurs in The Book of a Thousand Nights and One Night. In Richard Burton’s translation: “Prince Husayn . . . spread his carpet upon the court-­ ground behind the Khan wherein he lodged, and sitting thereon, together with his suite and the steeds and all he had brought with him, mentally wished that he might be transported to the caravanserai where the three brothers had agreed to meet. No sooner had he formed the thought than straightway, in the twinkling of an eye, the carpet rose high in air and sped through space and carried  remained in expectation of his brothers’ coming.”8 The carpet is a hare, not a hedgehog, since it takes some time, even if only the twinkling of an eye, but the preestablished meeting point with his brothers suggests hedgehog-­like preprocessing, the use of past time in order to set up a later cost-­free simultaneity. You need to use expensive time to buy free time, or loose time to prepare for tight time. (Chess players know that bad moves lose tempo. A strong position is the same as having spare moves.) Sympathetic Simultaneity Francis Bacon explores eight forms of action at a distance: communicable diseases, light and sound, electricity and magnetism, gravity, interpersonal influences of affection and imagination, the influences of celestial bodies, sympathy, and “emission(s) of immateriate virtues” (Bacon 1844, 2:124).\n"}
{"prompt":"Action at a Distance ->","completion":"  As is typical with Bacon, the list combines elements easily recognizable to us with ones that look weirdly medieval. Bacon clearly is a bit skeptical about the last one but feels called to investigate the idea “that in things, or the parts of things that have been once contiguous or entire, there should remain a transmission of virtue from the one to the other: as between the weapon and the wound” (126). He is referring to the practice of unguentem teli, or anointing at a distance, in which a salve applied to the sword that caused a wound will heal the wound, however far away its victim happens to be. It is a kind of hedgehog argument: an entire system retains its integral virtue, even when sundered. Bacon might have been interested to know of quantum entanglement, which is surely just as weird! Longitude: Chronometer as Telegraph Bernhard Siegert places the deep history of the modern quest for simultaneity at sea: in the problem of how to determine longitude (Siegert 2015). The rise of simultaneity to the forefront of early twentieth-­century physics is not simply the culmination of a long  of an imperial struggle for power, for control over the seas, that goes back to the sixteenth century. Ptolemy, the late Greek astronomer and geographer, already designed a grid system of latitudes and longitudes, but it took on new life as a technology of power under the Portuguese and Spanish seaborne empires.\n"}
{"prompt":"Action at a Distance ->","completion":"  Longitudes, of course, draw imaginary north–­south lines from pole to pole. Because of the remarkably stable rotation of the earth’s axis, north and south are essentially invariant within historical epochs, and latitude is relatively easy to calculate: a clear view of the horizon and a sighting of the North Star allows you find the angle between the two. That angle is your latitude. On the equator, the North Star is on the horizon, and your latitude is zero; at the North Pole, the North Star is directly overhead and your latitude is 90 degrees. (South of the equator you can use the Southern Cross instead of the North Star.) Finding your point on the east–­west axis is, however, another matter. The earth is always spinning; there are no fixed celestial points to designate an invariant east or west. There could be no such thing as an East Star!\n"}
{"prompt":"Action at a Distance ->","completion":"  In 1530 the Belgian mathematician Gemma Frisius had the brilliant thought to use another point on earth as the standard for longitude. The earth rotates twenty-­four hours a day, on annual average, and so a reliable clock on a sea voyage set to the local time of a distant place could indirectly indicate eastward or westward displacement from that longitude. Fifteen degrees of longitude equals one hour of the earth’s rotation. The problem was that no clock could keep accurate enough time at sea to be functional, thanks to many factors including the rocking motion that threw off its spring balances and exposure to temperature, humidity, and water itself. For more than two centuries a reliable sea chronometer was a major agenda item for European science and technology, a problem in mechanics, metallurgy, and waterproofing, until the British clockmaker John Harrison decisively solved it in 1762. (The problem of longitude drove Christiaan Huyghens’s invention of the second hand in 1657, among other innovations.) The notion of pre-  to earth, or rather to sea. The exact measurements of celestial position that astronomers had been making since antiquity went horizontal.\n"}
{"prompt":"Action at a Distance ->","completion":"  My eyes, my finger, that star; here at sea, clock, there at that time. If you know, for instance, that the sun rises at Greenwich at 4:42 a.m. on June 21, and you have a clock that gives you the exact time at Greenwich, and the sun rises for you when that clock says 8:42 a.m., and you are on the same latitude as Greenwich then you know that you are four hours later, i.e. 60 degrees west of Greenwich. (If you aren’t on the same latitude, tables can help you make necessary adjustments.) Here is something remarkable indeed: the complete fulfillment of the hedgehog principle. The ship and Greenwich are already in touch. Like Eratosthenes, there is no need to transmit any data. Both can count on the regularity of the earth and its rotation as a given.\n"}
{"prompt":"Action at a Distance ->","completion":"  Such instantaneous communication might seem magical and silly in Bacon, but Greenwich and the ship do communicate in some odd way out of time. The clock serves as a wireless telegraph avant la lettre, a benign and portable doppelgänger of Greenwich. It receives intelligence from afar regardless of weather, pirates, interference, or glitches. Here is a time-­and-­space coordination system with little vulnerable infrastructure. A watch, said Norbert Wiener, is “a pocket orrery,” or miniature model of the heavens. Heavenly patterns locate ships moving about the globe for economics and empire. Time here is a proxy for space. Synkairization through Networks What if we thought of syn-­kair-­ization as well as syn-­chron-­ization, if you will forgive the ugly term?\n"}
{"prompt":"Action at a Distance ->","completion":"  That is exactly the crazy undertaking of meteorology, the gathering of many kairoi into one synoptic forecast. (Kairos means weather in modern Greek.) Meteorology is a privileged site for seeing changing conceptions of time, and modern weather data is perhaps the clearest of all domains for seeing space-­time compression. the 1780s came the first efforts to track large-­scale weather events with real data. Natural philosophers had long sensed that local weather was dependent on remote conditions but because the speed of weather’s change was greater than the speed of data’s transit, same-­day, large-­scale weather events could only be studied and mapped after the fact. If it was hard to send data about the new moon in antiquity, it was even harder to send sufficient data about the fickle atmosphere. (Meteorology has always been a big-­data science.) The very idea of a weather map was a major innovation—­a map of quickly fluctuating things such as rainfall, temperature, or pressure instead of rivers, shorelines, and mountain ranges.\n"}
{"prompt":"Action at a Distance ->","completion":"  In history maps were generally of constants, not variables. Indeed, until the late nineteenth century, climate science was a branch of geography until it was claimed by the physicists.9 German physicist F. W. Brandes may be the first to have made a weather map (1816). His plea for Europe-­wide help on his project to reconstruct the weather in Europe of 1783 reveals the toil and trouble facing any ambitious weather knower before high-­speed data transfer (Brandes 1819). His grand ambition was to map the temperature in Europe “gleichzeitig” or simultaneously. He complained how “utterly exhausting” it was to sort out a “host” (Heer) or “ocean” (Meer) of “a hundred thousand data-­points” when only a few hundred belonged to each day (625). The glimpse of larger patterns gave some relief (Aufmunterung) from the toil. He was on the brink of discovering low-­pressure cells, which far outspan the observable range of an individual tethered to the earth. (Only with space flight and satellites did global weather come into phenomenological range.)\n"}
{"prompt":"Action at a Distance ->","completion":"  His textbook, Beiträge zur Witterungskunde (1820), also starts with weariness amid heaps of data. He had to sort through 180,000 discrete bits of data, 70,000 of which he gathered himself. The research process took him to the verge of total despair about “die so oft erfolglose Versuche etwas Regelmässiges in diesem Gewirre zu entdecken,” the so often unsuccessful attempts to discover anything regular in this snarl; his  feeling of having accomplished nothing (iv). The subtitle announces his more specific aim: “gleichzeitige Witterungs-­Ereignisse in weit von einander entfernten Weltgegenden.” In 1820, the only way to analyze “simultaneous weather-­events in mutually remote regions of the world” was retrospectively—­and via networks. Weather data had to be composite. A pressure system could be seen only by many eyes and ears. For him, it took several decades to gather enough data to map a single day’s weather. Timelines into Timepoints William Charles Redfield (1798–­1857), one of the first American meteorologists, “didn’t need an observer network, at least not at first,” says Mark Monmonier in his useful history of weather maps (Monmonier 1999, 31).\n"}
{"prompt":"Action at a Distance ->","completion":"  Traveling from western Massachusetts to his home in Connecticut in 1821, Redfield noticed that trees flattened in an earlier storm “were uniformly prostrated towards the south-­east” (21, original emphasis), while the trees that fell in central Connecticut were all facing the northwest. Aha! He thought: “This storm was exhibited in the form of a great whirlwind” (21, original)! A single person, endowed with a purse full of post-­hoc flexible time, could compile observations of a single event whose radius was unübersichtlich in real time. Rather like Eratosthenes, Redfield was his own network: he could cross-­cut in memory. After gathering more data, including discussions with sailors, he reconstructed the storm ten years later in an 1831 journal article (Redfield 1831). His doctrine was the circular motion of storms; hurricanes were like big tornadoes. The piece ends with an appeal that anyone possessing additional facts should “leave a memorandum” with hydrographers Edmund and George Blunt in New York City, sellers of nautical books and charts (51).\n"}
{"prompt":"Action at a Distance ->","completion":"  Redfield shows the centrality of the postal system to eighteenth and nineteenth century meanwhile structures, a critical nationalist medium of imagining untouched by Anderson, but Redfield also shows that one observer can produce their own meanwhile—­rather like a novelist or a journalist. was his Achilles’ heel: the trees could have been flattened by a different or later storm two or three days later (Mitchell 1831, 362). Such is the eternal threat to retrospectively inferred simultaneity: the risk that indeterminate time lags confound the data. Only as the electrical telegraph provided weather data in more or less real time were same-­day weather reports possible. This was a boutique genre in the 1850s and a fledging journalistic genre in the 1860s, in the United States and United Kingdom at least. The telegraph enabled the separation of communication and transportation for the first time in history, says James Carey (1989). That may be, but the telegraph also did something else: it separated weather from climate for the first time! Climate lasts weeks, months, seasons, or years: weather is daily.\n"}
{"prompt":"Action at a Distance ->","completion":"  Brandes reconstructed the weather of 1783 in 1816; Redfield of 1821 in 1831; James Pollard Espy analyzed a June 20, 1836, storm in an 1837 report. The amount of time that it took to cover space was shrinking. The Demons of Microtime Just as the telegraph made instantaneous communication possible, thoughtful souls discovered its bondage to the Hare principle. Electricity travels at the speed of light—­and the speed of light is finite. Even the fastest transmissions cannot exceed 300,000 km\/sec. On a cosmic scale, this is not fast enough to create a central grid of time coordination. The telegraph enabled superfast transmissions and also disclosed the older regime of a universe of asynchrony. This is the discovery of Einstein (Galison 2003).\n"}
{"prompt":"Action at a Distance ->","completion":"  The between-­time is a time for mischief of all kinds, as well as of monopolies of knowledge. The novelist can track between characters. Mathematicians and evangelists can dramatically join separate events. Young meteorologists can read storm patterns they could not have witnessed for themselves. The stock market now operates in microseconds and even nanoseconds, thanks to high-­frequency trading. Paul Baran’s supposedly innocent plan for  a system in which every node could potentially access the whole network, in which every split second was the strait gate through which the spies and hackers could enter (Sprenger 2015). Blindness to the arts of buffering time has cost us all dearly. Oblivious simultaneity is written into our condition, but critical analysis helps us see that synchronization always takes time, affects space, and consumes energy or power.\n"}
{"prompt":"Action at a Distance ->","completion":"  By discussing two experimental systems from the field of biomaterial research in terms of aesthetic theories, this essay pursues two strategies: to demonstrate how the mediation between experimental and simulated data codetermines whether a viable model of a biomaterial structure can ever be procured, and second, to understand scientific computer models themselves as aesthetic procedures that create their own specific objects of study  underlying natural sciences into the realm of digital technologies. Computer simulations belong to a long history of action at a distance through models but also through concepts, and the question they raise does not concern causality and instantaneity so much as the relation between living processes and their mathematical conceptualization. Computer Simulations with Blumenberg Recent decades have produced a growing number of publications on the history and epistemology of computer simulations within the history of science, media studies, and philosophy of science. Peter Galison describes the coming of computer simulations as a new and interdisciplinary way to conduct science beyond the traditional distinction of theory and experiment. Beginning with historic computer simulations that led to the design of the first hydrogen bomb in 1952, computer simulations changed the status of the computer within science and engineering from “computer-­as-­tool to computer-­as-­nature” (Galison 2011, 121). Paul Edwards states that, during the Cold War, simulations had “more political significance and more cultural influence than the weapons that could not be used” (Edwards 1997, 14). Claus Pias (2011) demonstrates the rootedness of computer simulations in so-­called mode-­two sciences that operate in a problem-­oriented, contextualized, and multidisciplinary fashion. They produce second-­order statistics that can model the behavior of systems within complex environmental interactions, and, as a political technology, they belong to preventive risk-­managing strategies of governance.\n"}
{"prompt":"Action at a Distance ->","completion":"  Eric Winsberg (2003) argues that techniques of simulation, like experiments, have a life of their own and carry their own credentials. Meanwhile, Till Grüne-­ Yanoff and Paul Weirich (2010) refer to the flexible distinction between computer models and simulations, while providing a useful overview of the scientific use of simulations that might function as proof, projection, explanation, or policy formulation. Last but not least, Gabriele Gramelsberger stresses the role that computer  life sciences, neurosciences, and climatology and their role for sociopolitical practices that rely heavily on models (Gramelsberger 2011). She also relates computer simulations to textual narrations in fiction, such as a short story, novella, or detective story. Like literature, computer simulations apply different temporalities, and the temporality of the plot is not identical with the time of the plot (Gramelsberger 2008). The following essay builds on this historic and epistemological research, while stressing the role that aesthetic procedures play for computer models and pursuing the hypothesis that computer simulations are aesthetic procedures in and of themselves, because they create their objects of study—­they make things appear that weren’t known before. The starting point for this inquiry into the interaction of technology and aesthetics are two experimental systems in the field of biomaterial research, which investigates structural mechanics performed by animals and plants. The role of imaging technologies for computer models in biomaterial research was obvious from the start, yet, through observations and discussions with the involved scientists and engineers over the period of one year, it also became clear that the models redirect the imaging process.\n"}
{"prompt":"Action at a Distance ->","completion":"  This “loop” between scientists and modelers (Gramelsberger 2008) gave rise to my own research on the function of aesthetics for concepts of matter, because it raised questions about the influence of design [Formgebung] on the conceptualization of biomaterials and living matter. To mobilize aesthetic theories in order to understand the role of imaging and modeling technologies in material sciences might seem an awkward approach—­to scientists and engineers, at least, who usually think of them as tools. What this aesthetic discussion provides is insight into the reality claims of both the model and the modeled object, something that is rarely discussed in science and engineering but is nevertheless crucial when it comes to discussing the outcomes of scientific research with a broader public, especially when modeling plays a central role in politics and policy  trade first-­and second-­order data, allows for a “close reading” of the modeling process itself. Even though no immediate political or ethical questions implied in the research will be discussed here, understanding how imaging and simulation techniques bridge the gap between classic experiments and computer models might also provide insight into how to read more complicated models in which the mediation between object and model cannot be as easily followed, as is the case with climate models (see Oreskes, Stainforth, and Smith 2010). Within their respective experimental systems, computer simulations define living matter as scientific objects in terms of the “space of possibility,” a term borrowed from Michel Serres, who borrowed it from Robert Musil (see Serres 1978). The computer model defines the probabilistic realm that restricts possible data values and behavior—­both experimentally and virtually. This highly dynamic space that—­unlike the classic spaces associated with Newtonian mechanics or Euclidean geometry—­is not fixed once and for all, but rather its actuality depends on its ability to simulate the behavior of the material under specific conditions. And while the model is being used to simulate behavior under variable conditions, it is itself subject to modifications by the modeler.\n"}
{"prompt":"Action at a Distance ->","completion":"  As an epistemological technology, i.e. a knowledge-­generating technology, computer simulations are themselves the outcome of a new statistical concept of matter that started with thermodynamics and electrodynamics and was eventually formalized in nuclear and quantum physics during the first half of the twentieth century. According to quantum physics, matter is conceived as being both discrete and continuous but more importantly as dynamic, since it exchanges energy with its environments. It even defines certain properties of time and space rather than being submerged to fixed space coordinates. Not only does matter stop being passive and inert, it also gives rise to new means of manipulation and technology design. When John von Neumann and Stanislav Ulam designed the first computer model, it happened in the attempt to solve the almost unsolvable  weapon whose physical properties were not understood in detail and that, furthermore, couldn’t be subjected to classic experimentation either, because the forces and temperatures involved were too destructive to be tried out under laboratory conditions? Over the course of the twentieth century, simulating something that cannot be tested under real-­world conditions became the new third category added to the former scientific duality of theory and experiment, according to Galison (see Galison 2005). This “third way” of simulation became particularly productive in engineering.\n"}
{"prompt":"Action at a Distance ->","completion":"  Largely overlooked, however, has been that any procedure for making things appear to the senses—­making things appear where they are not, or rather before they actually come into being—­is an aesthetic procedure. When computer simulations are part of complex experimental systems involving different kinds of measuring and imaging techniques, they mediate between image and model. This process cannot be entirely reduced to semantic or logical terms. It is in fact an aesthetic procedure in the sense of designed sensual cognition [gestaltete sinnliche Erkenntnis], whose outcome depends on the potential and quality of the measuring and imaging techniques that are applied, as well as the design of the model. In this sense, computer simulations themselves can be understood as an aesthetic procedure that requires, like any other aesthetic procedure in literature or art, a certain temporal and spatial distance to real-­world phenomena of the living environment and its corporeal and tactile information. In today’s scientific cultures, computer simulations are a prominent type of action at a distance, a classic concept of agency that does not exclusively refer to physical phenomena, such as electromagnetism or gravitation, but also to cognition. According to Hans Blumenberg, action at a distance signifies physical as well as cognitive processes, and cognition always implies sensual data and therefore aesthetics (see Blumenberg and Haverkamp 2010). The ability to act from a spatial and temporal distance, to act on something in absentia, is not exclusive to humans—­after all, the sun acts  agency to a large degree.\n"}
{"prompt":"Action at a Distance ->","completion":"  For Blumenberg, human action is characterized by an “ontological distance between an object of knowledge and its knower” (Blumenberg and Hawkins 2015, 156). Conceptuality is grounded in this type of remote agency: A Begriff, a notion or concept, is an action that implies the absence of the object. The German notion for “notion”—­Begriff—­implies greifen, which can be translated as “to grasp,” “to grab,” or “to seize,” as does the English notion “concept,” a calque from Latin “concipio’” or “con” (with) + “capio,” where capio means “to capture,” “to seize,” or “to take.” Concepts have to be vague enough to encompass the boundaries of a thing and yet leave enough room for any concrete perception still to come along. Concepts act like a mesh for future sensations, they are a form of preemptive action, which Blumenberg imagines to have started in prehistoric times with the throwing of a spear or the setting of a trap. Preemptive behavior exists in all human societies, at work in hunter-­gatherer cultures as well as in European philosophies of mind, matter, and life. Concepts as preemptive behavior are not simply based on objects—­as a fact, the former constitutes the latter. According to Kant, this is particularly valid for mathematical terms; according to Freud this is true for the notion of the unconscious; and according to Leibniz, it also applies to playing music, a mental power of computation without the awareness that one is generating numbers. Mathematics, the unconscious, music—­these are three very diverse realms that nevertheless are driven by objects that are themselves generated by concepts.\n"}
{"prompt":"Action at a Distance ->","completion":"  In a more general sense, Blumenberg implies that they provide a particular insight into the structure of human reason, which is another example of an object generated by concepts. Human reason as the sum of conceptuality relies on action at distance, on the aesthetic intermediation between concepts and objects. Computer simulations therefore belong to the history of action at a distance through notions and reason, they are a type of symbolic labor [Arbeit am Begriff] with real-­world consequences. And just as concepts and reason evolve through aesthetic processes involving metaphoric, metonymic, and contingent elements, computer simulations—­even  pattern recognition, and design [Formgebung]. The two experimental biomaterial systems that are discussed here serve as close readings of engineering methods applied within the life sciences. They demonstrate how matter and life are converging within the modeling process, and how imaging and modeling techniques bridge the gap between these formerly distinct orders. Of primary interest here are not the scientific outcomes but the modeling process itself, how it can be better understood within the intertwined histories of aesthetics and matter, and how it can inform media-­theoretical discussions on matter and materiality. Imaging Tunicates Tunicates, in Latin oikopleura dioica, are tiny marine animals almost invisible to the human eye.\n"}
{"prompt":"Action at a Distance ->","completion":"  As part of the zooplankton, they inhabit the upper, warmer layers of the world’s oceans, especially coastal waters (Scripps Institute 2019). Their specialty is that they unfold a “house” or “body housing,” also described as “filtering mechanism” that enables the animal to filter the sea water for digestible algae and transports it into the mouth of the animal (see Jany und Razghandi, forthcoming). A research group at Humboldt University in Berlin and the Max Planck Institute for Material Science in Potsdam under the leadership of biologist Thomas Stach investigates the anatomical mechanism that unfolds the house. In order to study the filtering and unfolding operations of the house, they are attempting to build a computer model of the organism in order to eventually be able to simulate the unfolding process of the house as a whole and to find answers to the leading question: Is there a specific design, a biomaterial design, that enables the tunicate to unfold its complex cellulose house approximately every four hours during its short lifespan of seven days? After slicing the material and taking single microscopic images, thousands of slices have to be reassembled both manually and  [Figure 3.1]. Microscopic image of a living tunicate inside its “house.” The head of the animal is dyed yellow and orange, parts of the house are already filled with undigestible purple-­dyed plant particles. Image courtesy of Khashayar Razghandi. [Figure 3.2].\n"}
{"prompt":"Action at a Distance ->","completion":"  As with most biological research, it starts with microscopy. The animal body or biomaterial is cut into ultrathin slices, each only a couple of hundred nanometers thick, and each microscopic image is digitally captured. Image courtesy of Khashayar Razghandi and Thomas Stach; produced in the laboratory of Thomas Stach (Humboldt University, Berlin, Comparative Electronmicroscopy). [Figure 3.3]. A 3D model is then built from the microscopic images. Image courtesy of Khashayar Razghandi and Thomas Stach; produced in the laboratory of Thomas Stach (Humboldt University, Berlin, Comparative Electronmicroscopy). through software into a three-­dimensional model, which is then able to generate parameters to create a second model that can be used to run computer simulations on the material. There are also non-­invasive imaging methods that try to capture the living animal in water.\n"}
{"prompt":"Action at a Distance ->","completion":"  The high-­resolution images and two-­minute-­long microscopic film sequences that are produced grant insight into the motoric skills of plankton. The animals drift directionless, absorbing algae. Their movements are characterized through the pulsating rhythm of their beating tails, and the different degrees of liquidity and firmness, translucence and opacity, create the ambience of a floating dance. Beautiful without question, it is difficult to capture on microscopic film the exact moment when the animal unfolds a new house. Stach’s group has not been able to realize a computer model on the basis of this imagery. There were simply not enough viable data. Among the difficulties of the modeling process lies life itself. Technologies such as Raman spectroscopy and electron microscopy often help to identify the distribution of biochemical components and structural organization within biomaterials, but the biomaterial has to be  [Figure 3.4].\n"}
{"prompt":"Action at a Distance ->","completion":"  Still image from a microscopic film, with a cloud of orange-­dyed algae that the animal will start feeding on soon. After a couple of hours of eating and filtering, the house is completely opaque and congested. The animal leaves its house behind, and after a couple of hours and unfolds a new one. Image courtesy of Khashayar Razghandi. “prepared” in order to employ such technologies, a highly technical process that is also deadly for the animal. The paradox of these efficient measuring and imaging techniques lies in the fact that they cannot be performed on living organisms, and a dead animal can no longer perform the unfolding mechanism. Biomaterials with Bergson and Schrödinger This paradoxical relation between living motion and its visual and conceptual representations lies at the core of science and philosophy—­at least in the view of French philosopher Henri Bergson, who calls it the “cinematographic mechanism” of the human intellect. It signifies a fundamental shortcoming of perception, intellect, and language: Humans perceive, recognize, and verbalize motion by looking at it from the outside, as a succession of discrete  of motion as being sprawled out within a Cartesian coordinate system, allowing for its translation into algebraic formula and calculation (see Bergson 1908, 295–­375).\n"}
{"prompt":"Action at a Distance ->","completion":"  The cinematographic mechanism is probably the most quoted Bergsonian metaphor, ever since Gilles Deleuze based his cinema theory on it. But beyond its historic epistemology of chrono-­photography and cinema and in an even more general sense, Bergson used it as metaphor for human cognition as a mode of simulation. The mechanism that simulates continuous motion by moving a succession of still images at a rate that escapes the human eye is a technical concretization of the relation between intellect and matter—­at work in our everyday perceptions just as in the measuring sciences. Bergson never seems to get weary of pointing out this blind spot in European philosophy, tracing it from ancient Greece to modern physics of the early twentieth century, following the succession of paradoxes on motion and time. The deficiencies of language are not the point of origin for this blind spot, nor does it lie in the mathematical worldview of scientists. Rather, the cinematographic mechanism points to Bergson’s anthropological conception within the structure of the universe itself. It is a necessary intellectual and scientific self-­deceiving mechanism that results from what one might call the will to conceptualization or abstraction from a concrete situation or object that lies at the bottom of both image-­and language-­creating processes—­Nietzsche calls it the “will to metaphor.” It is not restricted to a specific media-­technological apparatus; the apparatus simply demonstrates or concretizes the general act of human cognition, which can only deal with real processes and their perceptual data in their absence, by simulating them: Every continuous motion, be it that of light or that of one’s own arm, is dissected into discrete sections only to be artificially reanimated into a perceivable motion. European thought has been confusing processes of becoming with the successions of forms right from the beginning, from Platonism onward.\n"}
{"prompt":"Action at a Distance ->","completion":"  According to Bergson’s judgment, both science and philosophy are based on this  it as best it can, philosophy needs to reveal it in order to illuminate the mind’s constant simulation of motion, which permits—­through distance—­different, more complex forms of behavior and action. When it comes to simulation, science and philosophy seem to work in opposite directions. This division of labor becomes particularly clear when Bergson elaborates on the history of matter: Most physicists before 1900 and the advent of special relativity theory treated solid matter as if it were identical to geometry, following a concept of passive matter inherited from Descartes and the technique of analytical geometry culminating in Newtonian mechanics. From a historical perspective, the task of physics has been to push representations of matter virtually toward the direction of space, because matter and human intellect (which is itself immersed in a material universe) alike have a natural affinity for space and geometry; matter and intellect share a certain degree of inertia, so to say. As a result, physics before the nineteenth century ignored the temporal aspect of the material universe, the fact that it is immersed in processes of evolution and becoming (see Bergson 1944, 216). Bergson sees the reason for this geometrical bias, this geometrical inclination of science, in the structure of the universe itself: Everything that exists, including matter, is subjected to processes of temporal change and becoming but can only appear to the senses because it is embedded in matter. Science has to overlook the fact that it deals with life only in terms of the cinematographic mechanism, that it has to simulate an object in order to learn anything about it. According to Bergson, concepts of science are but symbolic or visual simulations, mathematical notations, aesthetical procedures, and they could have turned out in many different ways.\n"}
{"prompt":"Action at a Distance ->","completion":"  But even though they are never inevitable or determined, they also did not evolve by pure chance, otherwise science would not have progressed: And yet there is an order approximately mathematical immanent in matter, an objective order, which our science approaches in proportion to progress. [ . . . ] It is true that  ly. For that, it would have to become pure space and step out of duration. (Bergson 1944, 218) Matter appears to be subjected to change and becoming, and at the same time it has a tendency toward the rigor of geometric relations. It is extended between two poles, one of pure space and one of pure becoming, but it will never entirely coincide or converge with either one of them. The artificial or human aspect of modern science is not the geometrical bias itself but rather the need to measure, which paradoxically generates its success: In a general way, measuring is a wholly human operation, which implies that we really or ideally superpose two objects a certain number of times. Nature did not dream of this superposition.\n"}
{"prompt":"Action at a Distance ->","completion":"  It does not measure, nor does it count. Yet physics counts, measures, relates “quantitative” variations to one another to obtain laws, and it succeeds. (218) Against the background of evolutionary theory, Bergson concludes that mathematical order is in itself not factual or real but simply “the form toward which a certain interruption tends of itself, and that materiality consists precisely of an interruption of this kind” (219). Lacking the modern concept of information, Bergson struggles to explain how mathematics introduces negativity into matter, and how this solely serves a communicative, social function: “Negation, therefore, differs from affirmation properly so called in that it is an affirmation of the second degree: it affirms something of an affirmation which itself affirms something of an object” (288). If negation is a process that takes place in time, it is primarily a temporal and not a logical operation and immanent in all material processes. With this understanding of mathematics as a symbolic and socially determined type of interaction with material processes of change and becoming, there is no need to assume a prestabilized harmony between mathematics and the world, because their relation—­being social and communicative in nature—­is not  between actuality and formalism in philosophical systems, spoken or formal languages, social organization, and so on. And yet it [mathematics, CV] succeeds, just because there is no definite system of mathematical laws, at the base of nature, and because mathematics in general represents simply the side to which matter inclines. [ .\n"}
{"prompt":"Action at a Distance ->","completion":"  . . ] we can take matter by any end and handle it in any way, it will always fall back into some one of our mathematical formulae, because it is weighed with geometry. (219) Life and matter are two different motions bound to interrupt each other. In its most extreme forms, matter almost exhibits purely geometrical, mechanistic behavior—­that is why Bergson sometimes refers to it as the “automatic” or “inert order”—­a pretty adequate description of what physics nowadays calls the stillness that befalls quantum systems near absolute zero. Matter near absolute zero does not allow for life, because the living is weighted with becoming and subject to constant change. Transformation cannot happen without matter, matter would not exist without transformation: “Things and states are only views, taken by our mind, of becoming. There are not things, there are only actions” (248). Over the course of the history of Western sciences and their media technologies that measure motion, matter seems to be on its way toward mathematics. In the late 1930s, at the end of Bergson’s lifespan, which saw the coming of relativity theory and quantum mechanics and the settlement of the mathematical Grundlagenstreit through Gödel’s Entscheidungstheorem, matter and mathematics really do seem to converge.\n"}
{"prompt":"Action at a Distance ->","completion":"  But according to Bergson’s prognosis, even though the latest matter models come very close to being completely mathematized, they will never completely coincide, not because of faulty science or mathematics but rather because matter is also subjected to becoming and life. Life and matter are inverse and continuous movements that interrupt (or discretize) each other. movement, and each of these two movements is simple, the matter which forms a world being an undivided flux, and undivided also the life that runs through it, cutting out in it living beings all along its track. (249) Together but in opposite directions, life and matter are part of the same real process, while both human cognition and science can only account for the result of their interaction, namely the cut-­out forms of living beings. Bergson’s image of an “undivided flux of matter” follows the energetic model of late nineteenth-­century thermodynamics and its second law, stating that matter, if left alone, has a tendency toward equal distribution. While matter is subject to the time arrow of entropy, living beings seem to be able to hold off this process of thermodynamic equal distribution (or death) during their lifespan. An organism is able, for as long as it stays alive, to withstand the second law of thermodynamics and decrease the amount of entropy by interacting with its environment. Bergson understands this counterforce to entropy as a vital force [élan vital] (268).\n"}
{"prompt":"Action at a Distance ->","completion":"  Quantum physicist Erwin Schrödinger states the problem in a very similar manner in his book What Is Life?, which resulted from a series of public lectures in 1943. Schrödinger explores, like Bergson, the threshold between physics and biology, but instead of using Bergson’s vitalist term élan vital, Schrödinger invents the concept of “negative entropy”: Every process, event, happening—­call it what you will; in a word, everything that is going on in Nature means an increase of the entropy of the part of the world where it is going on. Thus a living organism continually increases its entropy—­or, as you may say, produces positive entropy—­ and thus tends to approach the dangerous state of maximum entropy, which is death. It can only keep aloof from it, i.e. alive, by continually drawing from its environment negative entropy—­which is something very positive as we shall immediately see. What an organism feeds upon is  sential thing in metabolism is that the organism succeeds in freeing itself from all the entropy it cannot help producing while alive. (Schrödinger 1992, 71) Living matter is able to keep entropy, aka death, at bay by absorbing negative entropy from its environment. Schrödinger did not receive much praise from the scientific community for his neologism, apparently translating the order of the living organism into the order of computable matter did not help.\n"}
{"prompt":"Action at a Distance ->","completion":"  In a rhetorical move, Schrödinger both introduces and abandons the concept in What Is Life, and introduces instead—­for the first time in the history of science—­the concept of a genetic code. The rhetoric of What Is Life? and the emergence of the concept of a genetic code are remarkable, because unlike negative entropy, it has made an almost unprecedented career as a scientific concept within the life sciences over the course of the twentieth and twenty-­first centuries. Revisiting Schrödinger’s disputed and now outdated concept of negative entropy is nevertheless insightful, because it differentiates between the computability of matter and the organization of life, a distinction that the notion of the genetic code effaces (Weigel 2006). Schrödinger and Bergson were convinced that the two orders of life and matter cannot be converted into one, because they are complementary to each other. If they ever converge, it would mean the end of time and life. Their insight, that life and matter, living matter, is not just governed by a single movement but by two (because their movements are essentially inverse or negative toward each other, a form of difference or interruption) effectively gets lost in the models of cybernetics and information theory that succeeded them. But the practical obstacles in building computer models of living matter again brings the two-­ fold aspect of living matter to the fore: When modeling dynamic or living processes, organized and coded processes, both movements have to be taken into account: the tendency of matter toward geometry and its interference with immanent becoming.\n"}
{"prompt":"Action at a Distance ->","completion":"  And the problems of imaging and data analysis do not stop once and for all, indeed they carry on into the actual building of the model itself. Our second experimental system of biomaterial investigates the opening mechanism of follicles of Banksia attenuate. Banksia plants come in diverse sizes and shapes of trees and bushes, and among botanists they are famous for their seed pods. These cones are technically “dead” or “inanimate” because they no longer participate in the active metabolism of the plant, but they nevertheless are able to open after being exposed to the extreme environmental conditions of a wildfire. Its opening mechanism enables this species, endemic to Australia, to compete with other trees. The research group of Michaela Eder at the Max Planck Institute of Colloids and Interfaces in Potsdam is building a computer model that allows them to run computer simulations of this opening mechanism. The model is an example of the standard computer simulation for structural analysis of solid matter and for the design of such, e.g. for airplane and automobile designs, the so-­called Finite Element Method (FEM) (see Clough 2004).\n"}
{"prompt":"Action at a Distance ->","completion":"  FEM is one of the most common types of computer simulations in and outside science today. It has a vast distribution among industrial engineering fields as well as in material science. Many disciplines use it to simulate the behavior of solid-­state bodies under fluctuating environmental conditions such as physical impact, air temperature, and so on. [Figure 3.5]. Banksia pods. After a wildfire, the pods suddenly open their lips and release the seeds. Image by the author. model) in terms of computer mathematics and the governing physical and chemical laws—­including Newtonian laws of motion, the fundamental equilibrium equations of solid mechanics, and the thermodynamic laws for the conversation of energy and increasing entropy—­that mark the boundary conditions for every possible motion: its space of possibility.\n"}
{"prompt":"Action at a Distance ->","completion":"  The virtual model has to comply with the same natural laws that govern the properties of the actual body, but, unlike the real banksia pod, the numeric model can only deal with discrete states and a finite set of elements. Therefore, the material continuum of the solid object has to be transformed into groups of finite numbers of discrete elements. One of the first decisions the modeler has to make, then, is what kind of mesh should be applied to describe the body as a network of joint points: If the mesh is too wide, the virtual system will be unstable, and, if it is too fine, the computer will take forever to run the simulations. After defining all mechanical-­mathematical conditions and laws  [Figure 3.6]. An important step in building the model is the segmentation of the continuous object into discrete elements. Image courtesy of Huynh Nguyen. investigation. Every computer model in biomaterials starts with imaging, and in this case the raw data do not stem from microscopy but from computer tomography scans of the pod in different stages of the opening process.\n"}
{"prompt":"Action at a Distance ->","completion":"  This experimental system has the huge advantage over the tunicate experiment in that the opening process can easily be captured by the imaging technology, e.g. by exposing the pod to wildfire temperatures inside a CT scanner until it opens its lips. It is also quite convenient that CT and MRI already produce 3D images, therefore they do not have to be aligned like laser sheet microscopies. But they do come in a continuous, analog data form, therefore they have to be segmented before they can be fed into the computer model in the form of discrete mathematics. There would be no computer models in biomaterial research without the countless media technologies of data analysis: from simple microscopic films and photograms to x-­rays, CTs, and MRIs, electron microscopies, cryo-­electron microscopies, and so forth. Once a viable computer model has been built, the scientists run simulations on different environmental parameters. The model is constantly revised in the process of simulation and further experimentation on the mechanical and biochemical qualities and properties of the pods. Through this interplay or loop between simulation runs and real-­world data analysis, the behavior of the biomaterial and its mathematical model do indeed converge.\n"}
{"prompt":"Action at a Distance ->","completion":"  In comparison, the two experimental systems point out the difficulties in building a viable computer model of living matter. We also see that the FEM method much better serves to simulate the structural motion of inanimate matter. The obstacles for analyzing the unfolding of the tunicate already start with imaging—­it is quite difficult to gather experimental data when it is impossible to perform electron-­microscopy on the material. The movements that would describe the unfolding of the tunicate’s house seem  [Figure 3.7]. Meshing of the smooth surface. Image courtesy of Huynh Nguyen. [Figure 3.8]. A first FEM model of the pod.\n"}
{"prompt":"Action at a Distance ->","completion":"  Image courtesy of Huynh Nguyen. [Figure 3.9]. Validating the experimental data, the model converges with the experimentally minded data. The term “convergence” refers to the state when the model can finally be used to analyze the actual movement of the cone and predict its behavior according to changing environmental factors like temperature, humidity, etc. Image courtesy of Huynh Nguyen. to be much more complex than those of the banksia pods. The unfolding of the tunicate house transgresses the borders between one, two, and three dimensions, and the unfolding motion of the fragile cellulose houses probably would have been better described in terms of fluid dynamics, since this takes place in water. By running simulations of the banksia opening mechanism, the model has falsified earlier assumptions about the material structures of the follicles.\n"}
{"prompt":"Action at a Distance ->","completion":"  Searching for experimental evidence, a new set of spectroscopies and 3D images was produced, and eventually the opening mechanism was described in a satisfying way (Huss et al. 2017). These research projects count as basic research [Grundlagenforschung], and accordingly the models do not have any design applications. It is obvious, however, that the temperature-­sensitive mechanism built or coded into the structure of the Banksia pods  and could very well lead to new bio-­inspired designs in industry and architecture. Computer simulations are able to deal with materials by focusing on patterns and structures instead of substances and qualities—­ they are entirely ignorant of whether or not they model the behavior of tunicates, banksia, or auto bodies. Their ability to abstract from the immediate impressions of sensual data and their focus on the mathematized functions and possible behaviors of a biomaterial is what makes them so valuable at the interface of science and industry. Their degree of abstraction—­their distance—­from any concrete body or organism enables them to determine the space of possibility, even for the most extreme or even impossible environmental conditions. The model deals with the immanent process of becoming in negative terms by excluding and falsifying everything that the material could not become or do.\n"}
{"prompt":"Action at a Distance ->","completion":"  Unlike cinematic simulations, computer models do indeed converge matter and mathematics. Because they are based on thorough discretization and mathematization, however, they can only be applied after a satisfying amount of data has been collected through classic experimentation. It is therefore misleading to speak of computer simulation as dematerialization—­they just operate from a distance, in absence of the object, like concepts and numbers. Computer Simulations between Physics and Aesthetics Since the discretization of the object can only take place in its absence, action at a distance is a cornerstone in biomaterial science—­not despite but because it also depends heavily on the data gathered through close-­up measuring and imaging technologies such as photography, spectroscopy, and 3D imaging. Both imaging and modeling are inevitable for the simulation of biomaterials, because they intermediate between measurements of the  generates second-­order data—­data gathered through simulations (Pias 2011). Like cinematography, today’s simulation techniques discretize continuous movements and then add artificial motion, but the resulting images and films are data visualizations. Instead of representing past or actual motion, they produce negative maps that chart impossible motions. Like concepts, their most important accomplishment lies in their ability to exclude possibilities: The mapping of possibilities is production of negation (see Blumenberg and Haverkamp 2010, 75–­76).\n"}
{"prompt":"Action at a Distance ->","completion":"  Simulation allows for the recognition of something that cannot be perceived, measured, or experienced in any other way. It enables one to discern gaps within the perceived, the measured, the experienced. Simulations belong to a history of algorithmic images, which are generated in a symbolic space (see Montaña and Vagt 2018). But the numerical models they are based on are also derived from experimental data and operate within theories based on natural laws. Therefore, computer simulations assemble two movements in different directions: one that follows the spatial, geometrical, and immanent order of the model and another of impossible states that are interrupting or rather restricting each other, generated by the runs of the simulation. In this sense, computer simulations do indeed take both spatial and temporal motions into account, something that Bergson, at the beginning of the twentieth century, reserved for intellectual beings. This bridging of life and matter in computer simulations relies equally on physics and aesthetics, the only two inner-­worldly processes that can be called “real,” according to Max Bense. While physics follows the second law of thermodynamics, according to which the time arrow of increasing entropy describes the world in the direction of disorder or the probability of maximum equal distribution, aesthetics can be comprehended as the inverse movement, segregating instead of blending (Bense 1960, 20).\n"}
{"prompt":"Action at a Distance ->","completion":"  In Bergson’s philosophy of the living, this results in two opposed academic cultures of science and philosophy. In Bense’s computer-­  the place that for Bergson still belonged to vital concepts such as élan vital or statistic concepts such as Schrödinger’s negative entropy. Both physics and aesthetics have ceased to simply describe the world as given—­instead they try to figure out how to change it. Neither imitates nature any longer, rather both create their own objects. The computer with its regime of information and organization does not dissolve the boundaries between physics and aesthetics, or science and art. What it does is relate them closer to each other than they had been for a long time. Since computer simulations do not yield to any defined reality but operate within terms of possibilities and probabilities, attempting to create viable scenarios rather than ontological certainties, and abstaining from determining the actual outcome of single events, they are not mere tools or instruments of science. They are aesthetic instruments that change the perception of reality.\n"}
{"prompt":"Action at a Distance ->","completion":"  The idea that the texture of reality itself is subject to historic transformations is not new to the humanities, but it seems to be largely absent in scientific discussions. When Blumenberg distinguishes between different types of reality over the course of European history, he points out that, unlike the incontrovertible and instantaneous reality mediated and guaranteed by Christian theology and ontology in medieval and early modern times, modern realities are neither guaranteed nor instantaneous. Instead, they come with “a sort of ‘epic’ structure, relating to the totality of a world that can never be completed or grasped in its entirety—­a world that can be only partially experienced and so can never exclude different contexts of experience which in themselves constitute different worlds” (Blumenberg 1979, 33). Realities do not refer to one nature any longer but require constant actualization and realization. They often take the form of logical paradoxes, something modern physics incorporated like no other scientific discipline. Quantum and relativity physics have been operating with restricted realities for more than one hundred years and they reflect the boundaries of their validity through physical constants. For physics as well as  mathematical structure: Reality can no longer be considered an inherent quality of an object, but is the embodiment of a consistently applied syntax of elements. Reality presents itself now as ever before as a sort of text which takes on its particular form by obeying certain rules of internal consistency.\n"}
{"prompt":"Action at a Distance ->","completion":"  Reality is for modern times a context [ . . . ]. Now, if aesthetic objects can have such a thing as a specific reality, they, too, are not only bound by the criterion of context as proof of their reality but are also constrained, as regards their scope and the wealth of elements they incorporate, to compete with the context of Nature, i.e., to become secondary worlds: they no longer extract, by imitation, realities from the one reality, but imitate the fact of being real. (Blumenberg 1979, 42) Secondary worlds, worlds that imitate the fact of being real, are simulated worlds. When media theory speaks of computer simulations as artificial nature or world-­making technology, it has to take the interdependence between science and aesthetics into account. It must do so because not only is there an aesthetic context to scientific objects, but science also frames aesthetic objects. What might perhaps be difficult to understand about this relation is the fact that it disables arguments in terms of causality and instantaneity, because the time arrows of aesthetics and physics do not run in the same direction. Furthermore, the efficacy of their interaction, the interdependent calibration, can only be understood through distance.\n"}
{"prompt":"Action at a Distance ->","completion":"  The virtual model has to be reconfigured in accordance with real-­world data and curves that describe the actual behavior of the material under certain stress conditions, such as pressure, temperature, and humidity. Since the computer model is able to converge the actual and the virtual, as well as matter and mathematics, it can reach a degree of reality that allows experiments to be conducted within this model. Once a model converges—­when it reaches an adequate degree of reality, so to speak—­it serves as  tation beyond the limits of actual matter can be conducted. It will never produce certainty; instead it creates new spaces of possibility, be it for the design of new materials according to user and environmental concerns or policy making in regard to phenomena beyond perception, such as climate change. It is not a medium of certainty but of investigation and speculation. Notes The idea for this project emerged from interdisciplinary research on self-­ moving materials at the Cluster of Excellence “Image Knowledge Gestaltung,” a joint venture of Humboldt University Berlin and the Max Planck Institute for Colloids and Interfaces in Potsdam. This article would not have been possible without the work and help of Susanne Jany, Khashayar Rhazgandi, Nhu Huynh Nguyen, Michaela Eder, John Dunlop, and Thomas Stach. In addition, I would like to thank Matthias Koch, who introduced me to Blumenberg’s concept “actio per distans,” and to Jacob Watson for editing this article.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  R. Joshua Scannell  Both a Cyborg and a Goddess  University of Minnesota Press.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  All rights reserved. Deep Managerial Time and Informatic Governance  In her 2012 article “I Would Rather Be a Cyborg Than a Goddess,”1 Jasbir Puar deconstructs and interrogates the relationship between intersectionality and assemblage theories. She convincingly argues that intersectionality, while epistemologically crucial, both mystifies the categories of oppression that it seeks to unpack and solidifies unstable subjectivities under rubrics that are, ultimately, reflective of hegemonic “humanist” power structures.2 Assemblage (or, agencement, as she prefers it) destabilizes the body and distributes it. Taking seriously Donna Haraway’s claim that the body does not “end at the skin,”3 she argues that the assemblages of technocapital are not reflective categories but active producers of mutative, unstable relations. Affective intensities, distributed bodily information, data trails, teletechnology, all commingle in a constantly productive distribution of posthumanist political modulations that are the target of what Gilles Deleuze identified as “the society of control.”4 Puar metonymizes these analytics as goddesses and cyborgs. On the one hand, the reified humanist categories of goddess identity and personhood render a political imagination that exotifies both the subjects it seeks to represent and the political systems that oppress them. On the other, the teleological technical determinism of the cyborg easily slips into a sort of pseudo-intellectual “disruptive” solipsism. Surely, she claims, there must be cyborg goddesses in our midst.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  It is my contention that a figure with the attributes of the cyborg  University of Minnesota Press. All rights reserved. 248  R. Joshua Scannell  object. The becoming-intersectional assemblage of the cyborg goddess not only already exists but is in fact an organizing principle of an emerging logic of algorithmic governmentality. Contemporary forms of data-driven governance conjure an improbable intermingling of historically constructed social arrangements (the intersectional) and nonhuman analysis and prediction that, I argue, construct possible future populations in time scales that are not accessible to human cognition (the cyborg). To intervene in contemporary discourses surrounding “big data,” I look to object-oriented ontology (OOO), which posits that the universe is composed of objects of equal status and unequal force. Rather than envision contemporary data-driven police practices as an extension of old modes of social organizing, I instead argue that they rely on a novel mode of spatiotemporally organizing populations, which is to say matter—and that in doing so, they conjure new social objects. Not exactly human, but extracted and recombined from the human, these carceral quasi-objects thrive on dilating human life chances and debilitating human bodies.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Contemporary modes of data science, and their applications in techniques of governance, have rearranged the terrain of what constitutes the social and must be interrogated. To that end, this chapter uses a brief case study of a relatively new data-processing system employed by the New York Police Department to stage a series of questions about how big data—that most overhyped of buzzwords—suggests a novel mutation in logics of governance and population management. I argue that the capacity to process data streams on the scale and with the speed that the NYPD’s system facilitates forces a shift in the target and rationale of governance away from the production and modulation of statistical populations in the biopolitical, humancentric sense of the term (what I call deep managerial time). Instead, big data drives governance toward the maintenance of the efficiency of algorithmic processing as an end in itself. In conjuring this shift, the sociotechnical commitments of governance inaugurate a new object as the target of modulating power—the hybridized mathematical bundlings of material existence.5 This object is neither an aftereffect of human movement through datafied terrains6 nor a precursor modulation of security  Both a Cyborg and a Goddess  University of Minnesota Press. All rights reserved. The Object of Big Data  249  In hailing this logic as an emergent object, rather than a shift in concepts of governance or a move beyond biopolitics (in other words, as an ontological object rather than an epistemological tactic), I hope to highlight a few points. First, we should not fetishize the “technological exceptionalism” of our expanding present.7 In many ways, the big data revolution is a question of scale rather than of kind.8 These new power configurations do, however, concatenate a certain set of forces that are working on neoliberal biopolitics in uncanny and irreverent ways.9 Developments in the capacity to collect, store, and analyze massive amounts of data extraordinarily rapidly have been spotlighted in popular media and academic research as heralding a major transformation in information-driven governance.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Collected under the name “big data” is a loose array of techniques and technologies that have posited technical, information-dense solutions to problems that have historically fallen under a wide range of disciplinarily and institutionally distinct sets of knowledge.10 Whereas, not so long ago, the logical bases of financial houses, astrophysicists, and urban municipal systems were functionally unrelated, they have in recent years converged on a data-driven informatic solutionism that has steadily eroded disciplinary and institutional borders.11 The skill sets, institutional histories, and goals of scientists using NIH funding to map global genomes are obviously distinct from those of the Target number crunchers who want to granulate demographic position to predict shopping behavior. Yet both of these projects have been written about as examples of the “big data revolution.”12 Practitioners of big data have concerned themselves with finetuning modes of surveillance in an effort to maximize the capacity of ubiquitous information collection to return on a promise of illuminating occulted social relations. Facebook, for instance, invests enormous amounts of money in finding marketable relationships that emerge out of the daily practices of its millions of users idly clicking. Likewise, the NYPD has spent billions on an integrated data analysis software that is designed to make ubiquitous security surveillance accurately predict crime.13  University of Minnesota Press. All rights reserved. 250  R. Joshua Scannell  the most efficient use of “information” and “knowledge” to maximize productivity is a central and transhistorical drive of capitalism.14 Big data analytics appear to be little more than an intensification of already existing processes. This includes an obsession with statistical detail, commitment to technocratic solutionism (and a corollary “rejection” of political “ideology”), demobilization of human labor, highly speculative capital investment, and financialization. However, the quantitative jump in scale and computational capacity that emerges out of neoliberal practice produces a new object of calculative governance.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  This information-dense cyborg goddess, which emerges in relation to technology but is not the technology itself, warps biopolitical logics and confuses neoliberal governmentality.15 Second, governance by algorithm inaugurates a series of practices and dispensation toward the care of the algorithm itself—that algorithmic architectures contain a density that draws labor toward them and that this labor is fundamentally predicated on a governing propulsion that is not “toward” the human but toward the mathematical.16 The care of the algorithm is a care of mathematics, in which the mathematical desires of metrics become the operative basis for producing and transmogrifying the material.17 Algorithms are material, are real, and are not human.18 Thus, we may begin to make sense of the otherwise bizarre decision of major municipalities to spend billions outsourcing the important work of making sense of their cities to mathematicians and computer scientists under the employ of tech conglomerates.19 This, rather than a mere case of privatizing public services, essentially reorganizes the target of urban governance toward algorithms, server farms, and computational nerve centers. Labor and capital are drawn to the care of the mathematical and its infrastructure as a field of vision—as a way to materialize the city for intervention. Rather than use computational capacity to maximize labor power, maximum labor power serves caring for the algorithm. Third, the contours of neoliberal biopolitics demand a much less individuated subject than is often taken for granted.20 They have in fact necessitated massive population blocks and stabilized subjectivities as targets of state and economic intrusion. Rather than pro-  University of Minnesota Press. All rights reserved. Both a Cyborg and a Goddess  251  capitalism.21 I call this ontological stabilization of populations deep managerial time. I do so in an effort to push back against a narrative of neoliberalism as an individuating practice that upends coherent space-time,22 and as a reminder that the violent organization of populations subjected to state violence is an inheritance of plantation capitalism given a technocratic veneer.23 The ontological requirements of plantation capitalism’s metamorphosis into neoliberalism demanded a putatively “flexible” human subject in order to mask the essential stability of state violence and capital expropriation, particularly against women, people of color, and queer populations.24 Neoliberalism’s critics tended, therefore, to focus on how the human subject was constituted for population management through a focus on destabilizing epistemologies.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  This theoretical intervention is often bracketed as the linguistic turn.25 Although often labeled antimaterialist, a reframing of neoliberal ontology as deep managerial time opens the space to argue that it was in fact diagnosing the methodologies of population formation under neoliberalism.26 While neoliberalism still exists, the shift toward algorithmic efficiency as an end in itself suggests that there is a change in the ontological object of governance, in which the “human” ceases to be the desired, massified target and is in fact replaced by the massification of the data trail. In suggesting this, I do not mean to say that this change has inaugurated a practice of governing that is wholly new in the sense of evaporating intersectional realities of distributions of power and violence. Nor do I want to claim that its effects are phenomenologically novel in the sense that denizens of “smart cities” so much as notice the shift. New York is a city that allows its officers to use possession of prophylactics as legitimate evidence to charge gender-nonconforming people with soliciting.27 It deals with criticisms of pervasive police violence and abuse against people of color by suggesting that victims solicit state violence by failing to submit to arrest fast enough.28 It arrests young people of color for dancing on subways.29 The NYPD now pursues a policy of “omnipresence” rather than “stop-questionand-frisk,”30 but white supremacist capitalist heteropatriarchy is alive and well, and tends to target similar bodies over a longue durée. Intersections and their effects, in other words, are real. University of Minnesota Press. All rights reserved. 252  R. Joshua Scannell  shifting horizons of social life.31 It instead refashions such a sociological imagination as speculative rather than reflective.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  The aim is not to take stock of existing conditions and propose likely explanations for why they exist as such, or to look at existing dynamics and infer a future. Rather, it is to try to tease out the implications that advancing technical capacities and shifting aims of governance have for a virtual sociality that is materializing. It aspires, to borrow a term from A. N. Whitehead, toward a prehensive logic of critique,32 rather than a predictive one. Predictive or inferential sociology uses the logics of deep managerial time to produce populations durable enough to solicit prediction in order to mobilize (often state) resources to act on them.33 First, a subject must be sufficiently stabilized theoretically to justify its interpellation in a survey with reasonable expectation that the hailed subject recognize herself as such. We might think of Judith Butler’s concept of the citational practices of gender formation as an emblematic example of how this operates.34 Then, the population parameters of the interpellated subject must be drawn on a naturalized sociality that, while it is perhaps “constructed,” is always constructed by and for “the human.” In other words, to keep with the example: once gender stabilizes as a definite category of investigation, it serves as a methodological organizing point for comparison against a range of social forces. Inferential sociology might ask, for example, What is the relationship between “women” and “wealth” over a “life course”? In mapping the datafied subjects onto the social terrain (otherwise known as demography), a population emerges (women) as having a logical trajectory over a space-time that is either heteronormative or in a dialectical relation to heteronormativity (life course). The tautological assumption of this feedback loop is the stability and centrality of “the human” over spans that are inherited from hegemonic notions of space-time, and which then justify the bringing to bear of state apparatuses for intervention.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  However, in light of the turn to big data, the methodological tools and epistemological justification for the practice of predictive sociology is eclipsed by a mode of data collection and analysis that  University of Minnesota Press. All rights reserved. Both a Cyborg and a Goddess  253  course through a durable present onto a logical or imaginable future. Rather, patterns circulate, emerge, destabilize, robbing “human” temporality of meaning, reaching for virtual life trajectories actualized in the vanishing present of an algorithmic calculation that is already always disassembling and grasping at new objects. In proposing prehensive sociology as an alternative to predictive or preemptive, there is also a necessary rejection of the notion that sociology’s role is fundamentally one of demystification. Instead, we should consider sociology as a mode of practice for what Deleuze called developing new weapons.36 As Karen Gregory argues, “Big data, like soylent green, is made of people.”37 True. But I wonder whether what “people” are becomes increasingly fungible in a period in which the target of governance is not “people” but, rather, the trails of data that cyborged bodies produce and pass through, are instantiated and captured by.38 The fact of the matter is that opening up the black box does not explain social ontologies; it reasserts the supremacy of human ingenuity and capacity (one is tempted to say “mastery”) as the only reasonable mode of explaining the social.39 I would argue that, rather than “always historicize,”40 the call might be to “always mystify” in order to see where these unclear or occluded social relations draw novel spaces for understanding an increasingly mystifying sociality. Algorithms are largely made by people, for people, to do mundane tasks that people are not good at doing very fast.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  But algorithms are also generative social actors that proliferate relations in strange and awkward directions,41 that allure social objects to them and peel off bizarre qualities into their relational matrices.42 I want to follow OOO in arguing, forcefully, that these trails are not traces, nor are they immaterial. They are objects of intervention that are every bit as real, as material, as human beings.43 This emergent object is exactly the cyborged goddess that Puar suggests.44 To think contemporary sociality, we could move away from the central assumption that the phenomenological body is the only logical starting point for thinking social experience and toward these mystical cyborgs as a basic organizing principle of contemporary dispositifs of control. Bodies in this alternative prehensive logic are informational,  University of Minnesota Press. All rights reserved. 254  R. Joshua Scannell  outside production.45 The absence of particular modes of embodiment from fields of data collection are powerful informatic present absences just as much as the fully capturable data profiles of the networked and ensconced digital classes. Metadata on where credit cards are not being swiped and quantified selves are not being tracked are just as useful information as the metadata on where they are.46 This weird logic renders intersections of oppression as computation errors; debility, disability, genetic inheritance move from organizational operative logics of population management to informational glitches of nonoptimal bodily manifestation.47 This is a reformulation of a truth that feminist, queer, antiracist scholarship has known and argued for a long time: that, from the governing perspective of societies of discipline and control, “deviant” bodies have always been computation errors, subject to correction. It is no surprise that the figure of the cyborg has emerged so forcefully out of feminist posthuman scholarship: the cyborg has always been built through a white supremacist heteropatriarchal logic that holds nonnormative (read: not white, not hetero, not male, not able, not wealthy) bodies as always already being-toward-management. And, indeed, it is the commonsense understanding that these bodies call out for intervention (in their hysteria, in their ill-discipline, in their disease, in their melancholia, in their skin, in their muscles, in their affects, in their bodies themselves) that undergirds Michel Foucault’s periodization of the trajectory of biopolitics.48 To tease out aspects of this emerging ontologic, and its implications for sociality, the rest of this chapter is divided into three sections.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  In the first, I consider the example of the NYPD’s Domain Awareness System as indicative of an emerging settlement in the logics of capital and governance on how to properly consider the organization and management of the urban. While I focus on the New York case, I situate it within a more general consideration of “smart cities” and data management systems, and the competitive drive of major informationtechnology concerns (primarily IBM, Microsoft, and Cisco Systems) to carve out shares of the increasingly lucrative market. Part of this process consists of reimagining the material world as eminently math-  Copyright © 2016. University of Minnesota Press. All rights reserved. Both a Cyborg and a Goddess  255  In the second section, I explain how this ontological flattening denotes a significant shift in logics of population organization away from deep managerial time and toward an emergent mode of sociality that Patricia Ticineto Clough, Karen Gregory, Benjamin Haber, and I have elsewhere identified as “the datalogical.”49 Our concept of the datalogical derives from Clough’s recent work that theorizes the shifting relations between materiality, metrics, and measurement in the context of teletechnology and the rise of digital sociality. In this section, I address these concepts specifically to what I understand as a nested transition zone in which the datalogical and deep managerial time uneasily cohabitate. In the final section, I turn to some of the implications of datalogic for life and liveliness.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  I wonder particularly about the necropolitics of the algorithm and the manner in which emergent digital technologies like the Domain Awareness System enact a sort of “furious media” that communicates between incommensurate ontological planes.50 I call this uncanny transubstantiation “digital mysticism” and argue that refusing the mystical qualities of the black box on the grounds that the black box can, in fact, be deconstructed is too easy a move in too classic a critical theory vein.51 Instead, a fruitful speculative sociology might not satisfy itself with demonstrating how digital systems are just code and god is all science, and take seriously the affective captures of a social logic that is so smugly disinterested in the human. Domain Awareness  In spring 2014, NYPD commissioner Bill Bratton testified before the New York City Council at a hearing on the departmental budget and announced that much of the department’s $4.1 billion budget is earmarked for investment in an ominously named “Domain Awareness System” data-processing nerve center.52 The Domain Awareness System (DAS), codeveloped with Microsoft, run by Microsoft technicians and analysts, and sold for Microsoft’s profit to other municipalities (New York keeps 30 percent  Copyright © 2016. University of Minnesota Press. All rights reserved. 256  R. Joshua Scannell  loop, making an apparently cybernetic circuit aimed at clarifying generalized surveillance data into actionable policing information. DAS applies massive processing power to rapidly sort through NYC’s surveillance data. Built with Homeland Security funds under an antiterrorism mandate, its surveillance extends far beyond the obviously “criminal” to include data as exotic as feeds from radiation detectors— sensitive enough to pick up recent chemotherapy treatment in passing bodies—and sophisticated enough to rapidly recall up to five years’ worth of stored “metadata” and temporally unbounded (and undefined) “environmental data” in its continuously mined databases.54 The DAS converts these massive information streams, on the order of several petabytes, into preemptive geospatial representations (maps) that are rapidly filtered down the department hierarchy to identify locations and classes of possible criminal activity.55 The department argues that if it “knows” where the “criminals” will be, when they will be “there,” and what “crimes” they will commit before the “criminals” do, then the department can proactively prevent them. “Real time” capacity to process massive streams of seemingly innocuous or unrelated bits of surveillance data will, the logic goes, produce patterns in the space-time and human geography of criminality that will allow police personnel and matériel to be applied with maximum efficiency.56 At the NYC budget meeting, councilmembers were quick to point out the unsettling ring of such a police praxis.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  In response, an obviously exasperated commissioner chided the Council that, whether civilians like it or not, “Predictive policing is real and it is here. We are beginning to write algorithms that identify in a real-time way paths of criminal activity.”57 While political critics and activists desperately cite the dignity of the human subject as an agent of free will as a necessary condition for sociality,58 the prison–industrial complex gleefully does away with this basic pretension of the Enlightenment. The virtual future here actualizes in the pattern recognition of the expanded present. The distinction between the two blurs, as a new emergent object of datalogical analysis compresses and contorts temporality and embodiment into a strange blur of mystifying sorting systems. What is simultaneously targeted and conjured is not the human but  Copyright © 2016. University of Minnesota Press. All rights reserved. Both a Cyborg and a Goddess  257  Whereas DAS’s predictive capabilities are designed to improve the department’s oracular ability, its crisis-response infrastructure is essentially reactive: designed to optimize the application and economy of force-dispersal.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  When an “incident” occurs on the DAS grid, the system identifies the type of disturbance and its location. It displays this information on a set of massive screens in its downtown nerve center and automatically shows the feeds from all local surveillance cameras. The center’s technicians (Microsoft employees) then coordinate police and emergency service response. At the same time, the system is storing the details of the incident in its metadata banks,59 where they remain indefinitely available for future proactive data mining.60 Thus, the system’s circular functionality repurposes in-progress events as granulated futural data, recombinable as data points in complex algorithms within the entire surveillance apparatus of the city of New York. On the one hand, this datafication of the social world, in order to be circulated in predictive algorithmic architectures, reflects the aim of apparatuses of security to modulate risk at a distance.61 Rather than cordon off a ghettoized “space of confinement” into which criminality can be organized and acted on,62 the DAS distributes the logic of securitized surveillance throughout the social field.63 Its distributed sensor systems make the fluxes and flows of the city the raw informatic material from which it can build algorithms that produce isomorphic knowledge of “paths to criminal activity.” At the back end, the DAS actively maximizes the efficiency of tactical response in the real-time unfolding of crisis. Rather than overwhelming disciplinary police presence, the DAS aims to minimize points of contact between urban municipal apparatus and urban disruption. In neoliberal parlance, this minimization of contact points is called “efficiency.” The orientation of security away from geographically delimited spatiotemporal structures (discipline) and toward diffuse and minimal population modulation (control) does not imply a reduction in applied force. On the contrary, apparatuses of control depend on the maximal application of force at minimal points of contact to most efficiently mobilize population dynamics toward satisfactory ends.64 Extreme technical governance is necropolitical.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Since the DAS aims to distrib-  258  R. Joshua Scannell  Copyright © 2016. University of Minnesota Press. All rights reserved. existing models, it is not uninteresting that the city’s favorite example of this system in action is a 2012 incident outside the Empire State Building in which police rapidly and accurately responded to a violent assault only to accidentally shoot nine bystanders.65 The speed of response time, number of officers deployed, accuracy of DAS geospatial data—in short, the efficiency of maximum application of force— outweigh the consequences of the operation. The useful information gleaned is enough to render such a fraught exercise in the incidental spilling of civilian blood a technological success story. Depending on one’s political disposition and lived intersectional reality, the DAS often reads as either an important new tool in the quest to build a fairer, smarter, safer city or an Orwellian surveillance dystopia. It is, of course, neither. DAS does not care about the “you” of flesh and bone.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  It “cares” about making materiality interestingly mathematical. That is to say, once “the world” is a nebula of informational clusters, the interest of sorting algorithms is to see what sorts of relationships can be mapped and what patterns might emerge. A human’s ontological status of “being” sublimes into the possibilities of finding improbable relations between data sets. Deep Managerial Time and Ontologies of Neoliberal Population  It is tempting to argue that developing techniques that seek to manage and make sense of the “infoglut” of contemporary data collection emerge smoothly out of neoliberal practices and theories.66 After all, these techniques are largely being developed by state and corporate interests that are major boosters for neoliberal ideologies and profit from neoliberal restructuring. I argue, however, that while these sets of practices are concatenating within neoliberal ecologies, they are, by introducing datalogical object-logics,67 in fact warping many of the basic assumptions that have undergirded neoliberal capitalism. As a consequence, novel spaces of necropolitical distribution are metastasizing throughout an increasingly digitized social field. While neoliberalism has been about the devolution of state apparatuses designed to manage the economy, it has never been about  Copyright © 2016. University of Minnesota Press.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  All rights reserved. Both a Cyborg and a Goddess  259  populations that are to be subjected to state violence in the interestsmoothing spaces for the flow of capital.69 Always indistinguishable from biopolitics,70 neoliberalism is, before anything else, a set of tactics and strategies that has human populational (re)productive capacity as its target, and the human security state as its weapon. In the service of this mode of organizational logic, neoliberalism has depended on the deep managerial time of populations, with the human subject as its target. Deep managerial time demands an ontological separation between what is being measured, the population that measurement produces, and the institutional apparatuses that will then be brought to bear. These ontological distinctions presume a diachronic coherence between object measured and population produced as a political justification for taking action to modulate the population. The necessary assumption, in this loop, is that the committed institutional resources will articulate a change at the level of the human thing itself that will then be noticeable on the metric reproduction of the population. This is the requisite temporal durability of deep managerial time: everything will still (more or less) be there when you get around to measuring it once again. Under deep managerial time, the orientation of governance and capital is toward the durable replication and modulation of biopolitical categories.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  This is to say that the nexus of governmental strategies that underwrote the formation and reproduction of a laboring body politic under industrial and postindustrial capitalism imagined sociality as the terrain of the organic, with the human as the figure on which social logics could be drawn.71 Neoliberal capital-state formations rest on an ontological relationship between measuring technologies, statistical populations, and institutional arrangements in which the target of governance is the organized relationship between human demographic groups and capitalized and\/or militarized environments.72 Such social relationships are manufactured by hegemonic heteropatriarchal notions of the “biological,” in which intersectionally informed rhythms of life transmogrify into denuded technocratic assumptions like “life span.”73 Straight, industrial, middle-class temporalities then stand in for sociological projections across “generations,”  Copyright © 2016. University of Minnesota Press. All rights reserved. 260  R. Joshua Scannell  life and the abandonment-toward-death of others drives a particular project of state science geared to the production and assessment of populations as hybrid biological questions, sites of technical intervention, and grounds for probabilistic governance. In other words, the “human” object that is the target of biopolitical governance is a product of its own tautology—produced by exactly the set of techniques that are designed to measure and collate them into probable futures.74 For such systems of power\/knowledge to “make sense,” they must commit to time scales that are conceivable and knowable. Based instrumentally on histories that are spun into recognizable, “meaningful” narratives, the production of human sciences enact a peculiar ontology in which the most significant time-spaces at which measurement might be pursued and honed are oriented around the rhythm of “human” time spans. This biopolitical governmentality of human life—in which institutions of statecraft combine to form knowledge practices that situate a particular convergence of historical, social, and industrial forces as neutrally “human”—is doubly articulated as the raison d’être of the social. It is from where the rationales and funding for measurement emerge.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Such ontological assumptions of concepts like “life course” then demand an imagining of predictive futures that are all committed to a temporality centered on the “human” and the state apparatuses that have produced it. Deep managerial time, in its solicitation of rational or reasonable assumptions of the relationship between government, capital, and organism, do the work of mystifying and reinscribing the very force relations that are purportedly the subject of measure.75 As neoliberalism deterritorializes the ontological premises of deep managerial time, it also reterritorializes. So, with the dissolution of industrial union-based contract bargaining, and that model of labor settlement’s presumption of “straight” time and space, there is the reterritorialization of heteronormative family arrangements as a punitive demand of the state. We can think here of the attacks launched against the urban poor in the twinned dismantling of welfare and rollout of “quality of life” policing as a state project of reorganizing and reinforcing heterocapitalist family formations that had been under pressure in the wake of the collapse of the industrial settlement.76  Copyright © 2016. University of Minnesota Press. All rights reserved. Both a Cyborg and a Goddess  261  was a state retrenchment in security that specifically targeted spaces that were not apparently heteronormative as sites of state violence. To secure the “free hand” of the market’s investment, state apparatuses (particularly in New York) mobilized “broken windows” policing strategies to designate queer, and particularly queer people of color, as populations that are inherently criminal, subject to and deserving of state violence.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Times Square, after all, was “cleaned up”—that is to say, militarily smoothed out for heteronormative capital flows—to attract the investment of the Disney Corporation.77 The violent imposition of heterocapitalist space-time has been a fundamental commitment of neoliberal strategies in governance. Rather than see this as aberrant to individuating and anomic economic structures, we might follow Clyde Woods in pointing out that the violent organization of neoliberalism has inherited its logics from southern “plantation capitalism.”78 He contends that the continuities between plantation capitalism and neoliberalism are clearly articulated in three arenas. First is capital’s consolidation of land ownership effected under neoliberal regimes through new enclosure policies such as asset stripping, rezoning, and “economic redevelopment.” Second is capital’s consolidation over labor power, effected through systematic hammering of labor unions, massive devaluation of labor value, and criminalization of poverty. Third is capital’s necropolitical consolidation over policing power and the systematic inversion of legal frameworks for rights claims and citizenship status79 (what Lisa Marie Cacho has termed “social death”), conducted under the auspices of wars on drugs, gangs, terror, and so forth.80 Neoliberalism has, in other words, always been about the production of spatially static and temporally durable populations deliberately exposed and subjected to systematic state violence. The major distinction is that neoliberalism has historically been articulated and defended in purely technocratic language. Rather than late-capitalist enclosure, state-driven (or at least enabled) projects of capital extraction and land consolidation are framed as “economic redevelopment” or “neighborhood improvement” projects, justified with sociologically bankrupt statistical economic projections. It ought to be shocking to no one that a region’s GDP will increase after the poor are forcibly  Copyright © 2016. University of Minnesota Press.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  All rights reserved. 262  R. Joshua Scannell  points out, such technocratic assessments of economy and the criticisms leveled at them from their “left” rest on the a priori radical elision of the poorest and most vulnerable from the social.81 In other words, it is exactly the force of such a technocratic turn to violently dispossess the poor by producing them as negative populations, as generative populational voids against which the proper body politic can be constituted.82 The pursuit of totalized technocracy that is governance-byalgorithm has inaugurated a mode of ontological organization that dissolves deep managerial time. It has provoked a disarticulating movement away from biopolitical orientations toward life and its political constructions, and toward the speculative technical management of a granulated universe of datafied things. This process has several characteristic features that, borrowing loosely from Deleuze’s concept of the diagram,83 we can analyze to coordinate an emerging mode of calculative governance whose intensity is such that it has instantiated a quantitative shift in the logics of the arrangement of governance and capital that has provoked a qualitative change in the production and management of populations. This rests precisely on (rather than in spite of ) the apparently diagrammatic character of big data analytics technologies across such disparate fields as financial trading, public security, military, weather prediction, and so forth. This is most obviously seen in data “fusion centers” being rolled out across the planet. These centers often rely on algorithms designed for one purpose (like weather prediction) in order to make sense of institutionally distinct information flows (so inputs like traffic patterns and electrical grid efficiency end up as basically equal input data points). Just as the financialization of industry has depended on traders’ capacities to reduce production companies to constituent parts and sell them as speculative values on the financial market, fusion centers depend on the logic that institutional histories and knowledges are reducible to constituent parts that can be algorithmically analyzed diagonally across seemingly differentiated knowledge formations.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Such an orientation explicitly undermines the ontological presumptions behind deep managerial time. Instead of presuming durability, of  Both a Cyborg and a Goddess  263  based on massive data mining explodes temporality and strobes it. Histories and historically based policies and policing are transformed into mobile data points. Such analytic systems require understanding capital and community as contagious sets of zeros and ones.84  Copyright © 2016. University of Minnesota Press. All rights reserved. Digital Mysticism, or The Cyborged Goddess  This necropolitical heterotopia rests on the built-in total indifference of computational governance to make ontological distinctions. In Digital Memory and the Archive, Wolfgang Ernst points out that, within the black box of the computer, the entire notion of “multimedia” is a con.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  There are not multiple medias circulating in the computer’s hardware being translated via a digital interface. Instead, digitization converts material waveforms into binary bits of information that, to the computer, are interchangeable. The phenomenological appearance of multiple medias is incidental to indifferent computer hardware. It is a by-product of the particular arrangement of human bioware.85 This flattening of the material into the digitally transactional extends with smart city systems into the materiality of life itself. Objects may exist, endure, and allure one another,86 but under the regime of informatics, such temporalities become operational formalities rather than ontological substrates. Objects are, in other words, only as real as their capacity to be made computational.87 Bodies are dividuated points of recombinable data, and “humanness” is a slowing modulation of data flow.88 In data-driven systems of informatic governance like the NYPD’s DAS, life is incidental to the collection and circulation of useful data. DAS maps produce space, time, and objects’ secondary qualities as policeable. Under given spatiotemporal, racialized conditions, like gang injunction sites, the color red is a criminal offense.89 The DAS does not determine the policy of outlawing red shirts on black bodies, but it provides the technical know-how to determine where red dye is transubstantiated into an eventuality of violence.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  That the violence provoked by redness is ordinarily police violence is recycled back into a system that understands it as an indicator that “crime is dropping.” That is to say, the criminalization of secondary qualities does not reduce  Copyright © 2016. University of Minnesota Press. All rights reserved. 264  R. Joshua Scannell  justification to flood an area with its own violence—a violence that does not register with departments that understand state violence to be disinterested and therefore not worth collating. So the ratcheting up of state violence, and the distribution of justified violent action toward ever more granulated sites of affective infraction, perversely generates a drop in statistically registered violence. Gang injunction sites, by enabling and amplifying state violence, and proliferating incarceration, insanely indicate to technicians of data collection centers that violence as such is dropping. The DAS is indifferent to the maximization of certain life potentials over others in that life is incidental to the map, no more relevant than credit histories, shopping habits, electrical usage levels, road quality, air quality, radiation levels, real estate values, noise levels, transportation habits, and so forth. It is the capacity to geospatially arrange such derivate populational values in fast time that is the target of this new mode of state-sponsored, Microsoft-driven criminal production.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Racialization and racism’s “state-sanctioned or extralegal production and exploitation of group-differentiated vulnerability to premature death” are the raw material, rather than the end point, of such a mode of governance-beyond-control.90 In such a brutally technical logic of the body politic, the urban poor and mentally ill rot in Rikers Island less because of surplus labor than because of surplus life, because they do not make beautiful math. But, as is so often the case, if the idea behind this system is to “change the world” in any meaningfully phenomenological sense of the phrase, then none of it works very well. Despite hundreds of billions of dollars that cities pour into smart data management systems, “the city” is still a mess. In New York, quality of life arrests and community policing have criminalized so many quotidian practices that the discretion of the police force to stop, question, frisk, and assault is essentially unencumbered.91 The impact of “data driven” policing systems has basically been to disincentivize police officers’ relationships with policed populations. With the building computational intensity of DAS, most officers are rendered little more than remote controlled enforcers, with limited autonomy to do more than make arrest num-  Copyright © 2016. University of Minnesota Press. All rights reserved. Both a Cyborg and a Goddess  265  and “maximized” by algorithms.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  For many on the receiving end, the way DAS predictive policing has played out in real life is indistinguishable from an era before big data analytics became a byword for “good governance” and middle managers started to talk like Ayn Randian technoshamans. And indeed, big data discourses have increasingly adopted a tenor normally reserved for theological considerations. St. Augustine’s proof of the existence of god is repurposed through technobabble about unfathomably enormous data sets pregnant with meaning, but inaccessible to human consciousness. Algorithms appear as gnostic grimoires, with cults of tech priests trained to divine the latent meaning of their communiqués. What systems like DAS are designed to do is to render the social as an undifferentiated nightmare world of information subject to technical intervention and modulation. In its uncanniness, it seems a furious media accessible only through enchanted technological interfaces. Computers are of course hardware. They are nutsand-bolts counting machines that are easily demystified.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Opening the “black box” and looking at its components can bring the mechanism down to earth, and taking apart the algorithm to see its components can remind us of its banality. And yet what they do is apophatic. They translate between incommensurate ontological planes, droving the via negativa of technocratic capitalism. They enact technical shifts in the logics of governance and population that account for something like organic liveliness as an afterthought, as an ontological haunting of the numbers. Both techno-theological fever dream and heavily capitalized reality, the quantification of everything manifests itself in increasingly ubiquitous technologies of datafication and digital surveillance, of which the DAS is but one example. The universe of things is constantly generating data and passing through datafied terrains and conjuring calculated ecologies. The datafication of everything is underpinned by a radical reformulation of liveliness as capacity. A hallucinatory reworking of the possibilities of the body as a field of intervention or ontological object is achieved by a nearly theological encounter with the possibilities of informatics to draw improbable arrangements of  266  R. Joshua Scannell  But not mysticism in the sense of the total fetishization of the commodity that Apple devotees perform, in which iPhones seem like late-capitalist Turin shrouds, or in the sense of ascribing magical qualities to things that are actually quite understandable.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Actual algorithms are often quite boring. It is mysticism as a way to trace how the virtuality of big data has reorganized networks and relations between objects in such a way as to make their “objectness” almost spectral and, crucially, always subject to transubstantiation—into code, into data sets, into efficiency, into ease, into leisure, all of which are ways of saying into capacities of measurement. This measurement, this thirst for metrics, this perverse gnosis enchants the speculative jouissance of affective technocapital and the rapacious desires of a carceral state that yearns for the grounds to commit violence without violation. Not mysticism as metaphor but as an accelerative, iterative logic of power. To the extent that there is much left of a human assemblage to be found here, it is certainly a cyborg goddess. Copyright © 2016. University of Minnesota Press. All rights reserved.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Conclusion  In sum, the emergence of datalogical political calculus from within neoliberalism’s violent population racism is noteworthy not because it abnegates the latter’s violent drives and processes. Instead, it reintegrates neoliberalism’s negative populations as profitable sites of data, and therefore capital, generation. Acting at a distance, governance probes and prods capital’s queer times and places, importing them into its mutable calculus of security. For systems like the Domain Awareness System, the concentration of the absence of digital information is in fact productively generative of new arrangements in the logics and apparatuses of security and capital. From quantified human security regimes to speculative derivatives bundling subprime mortgages to apps purpose-built to guide users on how to evade “sketchy” neighborhoods, the emerging forms of governmentality bundle the Other of deep managerial time, against which institutional capacity is mobilized as a coproducer of informatics security-capital. By way of conclusion, I propose three sets of problematics that the emergent dynamics of data logic suggest. Copyright © 2016. University of Minnesota Press.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  All rights reserved. Both a Cyborg and a Goddess  267  called “big data.” Big data has required heavily capitalized commitments to expanding the reach and power of data analytics tools in the interest of maximizing efficiency and productivity. Often the product of hybrid projects of state and private capital, big data infrastructures and projects have tended to demonstrate a commitment to instrumental and technical modes of governance often associated with neoliberalism. And while the drivers for this investment in such a particular mode of data analytics comports with neoliberalism’s financial imperatives, it signals a nascent rupture with neoliberal governmentality’s institutional mode of measuring and organizing the social. Neoliberalism as a political praxis has always been deeply committed to institutionally driven tactics of drawing, consolidating, and acting on populations in the interest of maximizing the social space for capital accumulation and expansion. I defined and described this set of operative logics as deep managerial time. In tracing the power-knowledge dynamics of deep managerial time, I also hope to have flagged certain shifts in the governmentality of populations. Deep managerial time’s reliance on institutional commitments to the production of populations in the name of capital security has historically demanded the forcible consolidation of populations and spaces that are to be excluded from capital expansion, to be left or made to die or to be rendered surplus.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  Datalogic, though not necessarily less brutal, mutates security’s carceral spatiotemporal logic. 2. Datalogic performs a praxis of surfaces. It is nonideological in the hermeneutic sense of the term. It is postideological and postpolitical in a way that neoliberalism never has been. Whereas neoliberalism’s commitment to deep managerial time presupposed to the ontological stability of a human organism from which to launch the interrogation and production of a polity,92 datalogic dissolves the organismic into an anorganic analytic of computable relations. This, on the one hand, works as a political nonpolitics. On the other, in its postpolitical technocracy, it depends on a certain dissolution of the body into matrices of analytics and control.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  I suggest that we might understand this process as a shift away from the mode of “encounter” in which the body  Copyright © 2016. University of Minnesota Press. All rights reserved. 268  R. Joshua Scannell  the body emerges as an onto-epistemological coproduction with data. The “body” stabilizes as a function of human-indifferent techniques of measurement, an ontological haunting of data clouds. 3. Datalogic rests on a biomediated necropolitical logic. Hegemonic techniques of government cannot reduce everything to zeros and ones without an ontology that does not particularly concern itself with the art of distinguishing between life and nonlife.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":"  These systems are fundamentally agnostic to the organism. These logics of technical governance and capitalization are only possible under conditions in which the blanket killing and incarcerating of everything is imaginable. It is a transmutation of biopolitical logics of eugenics and genocide and extermination into strategic and technocratic organizations of indefinite detention,93 mass incarceration, thanatopolitical free-fire death worlds. If life becomes lively only in its capacity to modulate a data set, death becomes just another technical input. Whereas biopolitics, in its own twisted way, is about maximizing life potentials and capacities, this mode of governmentality is about maximizing the algorithmic efficiency of data analysis. The process of producing death worlds in the name of human security certainly proceeds apace. At the same time, the technical modes by which the production of population are affected have been drawn away from deep managerial time and toward a bizarrely performative, human-indifferent governmentality that is, beyond anything else, about pretty math. Such a mode of governance subjects capital and governance to the aesthetic of the algorithm, rather than the other way around.\n"}
{"prompt":"Both a Cyborg and a Goddess: Deep Managerial Time and Informatic Governance ->","completion":" \n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  Introduction: Capturing the End of the World  At the very beginning of the twenty-first century, a professional photographer with an interest in environmental issues named James Balog decided to record glacier retreat, a phenomenon that is considered the most visible indicator of climate change in the world today (figure 0.1).\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  To realize his project, Balog invested in a number of Nikon DSLR cameras, which he subsequently customized with microcomputers to enable them to capture images over a period of several years, in different weather conditions. The cameras were then installed in high-resistance cases and soldered onto rocks. Exposed to extremely harsh weather in Iceland, Alaska, and the Arctic, these cameras recorded, for years on end, the transformations of the geoand hydrosphere. Upon retrieving them, Balog uploaded the data from the cameras’ memory cards onto his computer, and then edited the still images into time-lapse videos that illustrated the progressive ice loss from glaciers. Subsequently developed into the Emmy-winning and Oscar-nominated documentary Chasing Ice (2012), the project has been promoted worldwide via a series of events under the umbrella of “the Anthropocene”—i.e., the present time interval, going back to at least the Industrial Revolution, in which the human has been recognized as a geological agent that has had irreversible impact upon the Earth.1 The project has also served as a driver for the activities of the Earth Vision Institute, a donor-funded organization headed by Balog whose goal is to help global citizens see the impact of environmental change and envisage a better tomorrow. The above anecdote encapsulates all of the key concerns of Nonhuman Photography. On the one hand, the production process involved in shooting the multiyear collection of images of glaciers from high vantage points  Figure 0.1 Four screengrabs by Joanna Zylinska from the Earth Vision Institute’s time-lapse video of the receding Columbia Glacier in Alaska, 2007–2014, http:\/\/earthvision institute.org\/share-this\/columbia-glacier-alaska\/. increasingly decoupled from human agency and human vision.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  Yet I will also argue throughout the book that even those images that are produced by the human, whether artist or amateur, entail a nonhuman, mechanical element. By this I mean that these images involve the execution of technical and cultural algorithms that shape our image-making devices as well as our viewing practices. On the other hand, the glacier project demonstrates how photography is increasingly mobilized to document and illustrate the precariousness of the human habitat, and also how—through advertising, campaign posters, and Instagram—it is tasked with helping us imagine a better tomorrow and a better life for ourselves. In its conjoined humannonhuman agency and vision, photography thus functions as both a form of control and a life-shaping force. All-encompassing in the workings of traffic control cameras, smart phones, and Google Earth, photography can therefore be described as a technology of life: it not only represents life but also shapes and regulates it—while also documenting or even envisioning its demise. Thanks to the proliferation of digital and portable media as well as broadband connec-  words of Susan Sontag, “To live is to be photographed, to have a record of one’s life, and therefore to go on with one’s life oblivious, or claiming to be oblivious, to the camera’s nonstop attentions.”2 This altered role and agency of the photographic medium calls for a new understanding of photography, I suggest, beyond its traditional humanist frameworks and perceptions. Nonhuman Photography analyzes this new ontological—and political—conjuncture, as well as possible ways of negotiating it, while also refusing to submit to the conventional “human versus machine” narrative. Through this, it outlines a posthumanist philosophy of photography, anchored in the sensibility of what has become known as “the nonhuman turn.” There are good reasons why a new conceptual framework for understanding photography as part of a wider media context may be needed.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  Even though photography has become embedded in our everyday lives on so many different levels, the traditional scholarly and curatorial way of discussing this medium still maintains a relatively narrow set of humanist and human-centric frameworks and discourses on the topic: photography as art or photography as social practice. The first framework is rooted in the methodology of art history, and is encapsulated by numerous histories of photography, typically narrated as stories of the evolution of the medium featuring those rare singular actors identified as “artists.”3 In the art historical view, photographs are positioned as discrete objects that yield themselves to being framed and displayed, individually or in series, on flat surfaces in galleries and other cultural institutions. They are then analyzed in aesthetic, semiotic, and economic terms, for example, in terms of how they affect us, what they mean, and what their value is. The second framework through which photography tends to be interpreted is sociological. It offers a contextual perspective that studies not only how people take and make photographs, but also what they do with photographs: how they store images in family albums, how they join camera clubs, how “professionals” differ from “amateurs,” how they all contribute to the emergence of “popular taste” about photography.4 New ethnographies of the digital which are cognizant of the multiplicity of photographic practices that transcend their visual aspect to embrace phatic communication, narrative orality, and sensory-tactile experience very much inscribe themselves in this trend.5 The area of photography as professional practice—mainly  with the market once again acting as an adjudicator of appropriate categorization.6 Nonhuman Photography adopts a different, and arguably more complex and more multifaceted, perspective in its treatment of photography: that of posthumanist media theory. By this I mean a media-theoretical framework that combines insights from media, communications, and cultural studies with those of continental philosophy and cultural theory, while also raising questions about the human subject as the anchor and main reference point of analysis. In other words, my book positions photography first and foremost as a medium, one that is subject to dynamic and ongoing processes of mediation—only some of which involve humans. Treating photography as a set of processes rather than just objects, it draws on theories of mediation, media ecology, and posthumanism with a view to overcoming the entrenched humanism of the traditional debates on the medium so far.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  Written by a theorist-practitioner, Nonhuman Photography incorporates my various photographic projects as accompaniments to (rather than just illustrations of) the argument, in order to stage a different mode of thinking about and with media, one that involves the simultaneous production of media. Writers, students, media practitioners, and artists attempting to both theorize things and make things will hopefully find in it a number of pointers and openings toward a wider debate on how to do and make media (studies) today. The book also has a companion website (www.nonhuman.photography) that allows readers to see, in color, movement, and high resolution, many of the image-based projects discussed here. Exploring the nonhuman aspects of photography while also building on the work of media theory, including theories of media ecology (Vilém Flusser, John Durham Peters, Siegfried Zielinski), posthumanist philosophy (Karen Barad, Henri Bergson, Claire Colebrook, Gilles Deleuze and Félix Guattari, Donna Haraway, Tim Ingold), and traditional photography theory (Roland Barthes, Geoffrey Batchen, André Bazin, Joan Fontcuberta, Michael Fried, John Tagg), Nonhuman Photography ultimately aims to sketch out a conceptual framework for understanding image-based media, visuality, and perception. Through this framework, it challenges the typical orientation of photography theory toward indexicality, representation,  associations between photography, mourning, and death (as found in Roland Barthes’s Camera Lucida, for example), the book positions photography as a formative practice of life. Although its method is not faithfully or perhaps even recognizably “Deleuzian,” Nonhuman Photography aims to do for photography what Deleuze and Guattari did for cinema, in terms of acknowledging photography’s ontological force and its significance as a life-shaping medium. Its argument is therefore intended to be both affirmative and critical: in analyzing “nonhuman photography” as a cultural condition in which visual enhancement, algorithmic logic, and mediated perception enable different modes of visuality and self-identification, it also raises ethico-political questions about the camera eye’s inhumane or even antihuman interventions. To sum up, the goal of this book is thus to expand the human-centric concept of photography by embracing imaging practices from which the human is absent—as its subject, agent, or addressee.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  The notion of “nonhuman photography” proposed here encapsulates three different yet interconnected conceptual planes: (1) the rather frequently encountered yet often uncanny-looking photographs that are not of the human (depopulated expansive landscapes, say); (2) photographs that are not by the human (contemporary high-tech images produced by traffic control cameras, microphotography, and Google Street View, but also outcomes of deep-time “impressioning” processes, such as fossils); (3) photographs that are not for the human (from QR codes and other algorithmic modes of machine communication that rely on photographic technology through to perhaps still rather cryptic-sounding photography “after the human”). The link that I posit between photography and the Anthropocene—and, more broadly, between photography, biology, and geology—highlights the interweaving of the matter (and materiality) of chemistry, minerals, fossil fuels, and the sun, but also of us humans, with this particular medium. In his introduction to The Nonhuman Turn, Richard Grusin identifies this eponymous “turn” with a decentering of the human as the datum point of the humanities, and with a shift of attention toward questions concerning  a similar vein, Elizabeth Ellsworth and Jamie Kruse have recently postulated something called “the geological turn.”8 By this they mean an increasingly widespread turn toward the geologic as a source that explains and inspires cultural responses to conditions of the present moment. All these authors intimate that the recognition of the vital role played by nonhuman agents in the life of our planetary system needs to shape our understanding of the radical changes brought on by the modern way of life. What are these changes? As Elizabeth Kolbert has explained in her wellknown article in National Geographic titled “Enter the Anthropocene—Age of Man,” “Probably the most significant change, from a geological perspective, is one that’s invisible to us—the change in the composition of the atmosphere. Carbon dioxide emissions are colorless, odorless, and in an immediate sense harmless. But their warming effects could easily push global temperatures to levels that have not been seen for millions of years.”9 We could thus say that there is something in the air at the moment—and this something is a mixture of cosmic dust and human-induced pollution.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  In other words, the Anthropocene describes the changing condition of photography and photomedia because it becomes visible to us through altered light—and through the particulate matter that is reflected in it. But the Anthropocene also serves as an articulator of a new crisis: a crisis of life itself, both as a biological and social phenomenon. Yet, while scientists are still debating whether the designation of a new epoch is justified, the Anthropocene has already been renamed by cultural and political theorists as the Anthrobscene, Capitalocene, Chthulucene, Eurocene, Plantationocene, and Technocene, with questions being raised about the viability of its underpinning structure that “does not exist outside structures of mourning.”10 So even though we are not anywhere near solving the climate issues, in humanities debates we already find ourselves post-Anthropocene.11 Yet, problematic as the term now is, it may be worth staying in its shadow a little longer, for political and ethical reasons. Mindful of these problems, we should therefore perhaps figure the Anthropocene first and foremost “as a critical zone rather than one grand evil mess that includes all of humanity.”12 One of the main reasons I propose to link the light of photography and the shadow of the Anthropocene is that, as demonstrated by the opening anecdote of the photographing of a receding glacier, many responses to  here large-scale art photographs of the damaged environment by Andreas Gursky or Edward Burtynsky, the critical photographic project The Last Pictures by Trevor Paglen, or the many visual works included in Grain Vapor Ray: Textures of the Anthropocene published by the MIT Press in 2015. I will indeed discuss many of these representations and visualizations of climate change and ecological disasters via the trope of “posthuman landscapes.” But I also aim to expand this “representationalist” approach13 to suggest that the concept of “nonhuman photography” can help us see and understand, in a new way, both the photographic medium and ourselves as partly constituted by this medium. My claim about photography’s vital importance in the age of a global crisis of life at various levels thus constitutes the book’s philosophical axis. As I stated earlier, photography is a formative practice of life not only because it represents our lives in various ways but also because it actually shapes life. It does so through images but also through various kinds of material impressions it activates—and also through the forms of perception it generates.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  In a philosophical gesture akin to the one made by Siegfried Zielinski in Deep Time of the Media, my argument here expands the notion of photography beyond “things that humans do with cameras” to embrace imaging processes from which the human is absent—microphotography, space photography, dronemounted cameras. Yet, by way of a conceptual experiment, I also want to take a step further to read human cultural practices as only one section of longer-term processes occurring across “naturecultures.” This will allow us to see photography as occurring precisely across what Zielinski calls “deep time,” as forms of stabilized perception and impression that occur across various media, such as stone, clay, wax, or even skin in tanning—and to consider photographs in terms of fossils. The recognition of the formative role of light across different time periods (in fossils, imprints, photograms, analog film frames, digital snapshots) will also help us shift the debate on photography beyond the analog-digital binary. For me, it is this moment of temporary stabilization which signals a cut in time that differentiates photography from moving media, such as film or video—and that, notwithstanding its kinship with other photomedia, points to photography’s ontological singularity. There are some interesting predecessors to this nonhuman mode of thinking in media, communications, and cultural studies: for example, in  to Welshman Raymond Williams’s linking of culture to the transformation of substance at the biological level, beyond the control or even influence of the human.15 Last but not least, communications scholar John Durham Peters’s 2015 book, The Marvelous Clouds: Toward a Philosophy of Elemental Media, argues that “media theory is about environments and infrastructures as much as about messages and content” and that we need “to think of the media as environmental, as part of the habitat.”16 But the interdisciplinary conjuncture of media, communications, and cultural studies can also remind us why it makes sense for embodied humans of the early twentyfirst century to zoom in on this sliver of geological unfolding we call “history” to try to make sense of it, using the conceptual and material tools at our disposal. It can therefore help us recalibrate the human in relation to geological scales, without losing sight of the significance of that narrow stretch of temporality we call “culture”—and of how we have arrived at it. Indeed, it is the question of seeing—and unseeing—things we take for granted that the interdisciplinary conjuncture of media, communications, and cultural studies has the correct apparatus to address, which is why it provides a useful rejoinder to philosophical, art historical, and sociological frameworks that deal with images and viewpoints. This attempt to “unsee” the seemingly obvious is precisely what I aim to achieve in Nonhuman Photography, by offering the notion of “nonhuman vision” as an alternative vantage point from which to understand ourselves and what we humans have called “the world,” in all its nonhuman entanglements.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  With this, the book responds to Nicholas Mirzoeff’s injunction to “recognize how deeply embedded in our very sensorium and modern ways of seeing the Anthropocene-aesthetic-capitalist complex of modern visuality has become.”17 And thus chapter 1, “Nonhuman Vision,” poses a challenge to the traditional tenets of the self-focused, capital- and fossil-fueled, masculinist I, who is supposedly in control of his own vision and (world)view. It also explores the possibility of developing some better modes of seeing and imagining both the present and the future. Drawing on the work of Donna Haraway, Vilém Flusser, and James Gibson, it outlines an ecological model of perception as a more embodied, immersive, and entangled form of image and world formation. This model opens up a passageway to being-with,  medium at a time when, for many, photography has become synonymous with image deluge, banality, and narcissism. The chapter is followed by images from my project Active Perceptual Systems. Chapter 2, “The Creative Power of Nonhuman Photography,” continues with the argument that nonhuman photography does not just mean photos taken by agents that are not human, such as CCTV cameras, body scanners, or space satellites, and posits that all photography is to some extent nonhuman. While this nonhuman aspect of photography can no doubt produce inhumane practices, I also suggest that it is precisely in its nonhuman aspect that photography’s creative, or world-making, side can be identified. Rather than therefore contribute to recent jeremiads about photography—in which it is seen as supposedly dying in the digital era because it is no longer authentic or material enough, or imploding due to its excessiveness and banality, as evidenced on Instagram and in the muchmaligned selfie phenomenon—I argue that it is precisely through focusing on its nonhuman aspect that we can find life in photography.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  It is the existence of images, and, in particular, light-induced mechanical images known as photographs, after the human that is the main focus of chapter 3. The “after the human” designation references the present imagining of this disappearance of the human world as a prominent visual trope in art and other cultural practices. Such “ruin porn” has some historical antecedents: from the sublime romantic landscapes of ruined abbeys, all the way through to paintings such as Rotunda by Joseph Gandy, commissioned by John Soane, the architect of the Bank of England, and depicting the aforesaid bank as a ruin even before it was built. Yet the visualization of ruins has gained a new inflection in the Anthropocene, a period that is said to be suffering from a dual “eco-eco” crisis: the current global economic crisis and the impending—and irreversible—ecological crisis. We can think here of the haunting images of Detroit but also of TV series imagining our demise as a species, such as History channel’s Life after People. Extending the temporal scale beyond that of human history by introducing the horizon of extinction will allow me to denaturalize our political and aesthetic frameworks through which we humans understand ourselves. It will also help me take some steps toward visualizing a post-neoliberal world here and now. In chapter 4, “Photography and Extinction,” the horizon of extinction  world, what it can cast light on, and what the role of this light (or, more broadly, light as such seen through the photographic lens) is in approaching questions of life and death on a planetary scale.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  Considering the history of photography as part of the broader nature-cultural history of our planet, I trace parallels between photographs and fossils, and propose to understand photography as a light-induced process of fossilization occurring across different media. Photography thus can be said to bear a material record of life rather than just its memory trace. But I also turn to photography’s original reliance on the natural light emanating from the sun to explore what photographic practice can tell us about energy sources, and about our relation to the star that nourishes our planet. I do this via an engagement with photographers who have consciously adopted the horizon of extinction as their workspace—from the nineteenth-century geologist-photographer William Jerome Harrison through to contemporary artists such as Hiroshi Sugimoto. I also look at practices in which the work of the sun has been taken on as both a topic and a medium, including the postdigital work of Penelope Umbrico. Chapter 5, “Ecomedia between Extinction and Obsolescence,” builds a link between geological and technical perspectives on media by developing parallels between biological extinction and technical obsolescence. It addresses the current transformations in our media landscape, whereby many objects traditionally considered stable or fixed—photographs, imaging systems, technological networks—are radically changing both their identity and their visibility. In this context, the photographic image is seen as existing in a dynamic set of entangled media relations, and hence as a process rather than as a discrete object.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  This rethinking of photography in more dynamic and processual terms leads to a broader discussion of producing, curating, studying, and looking at images in the currently transforming media landscape—but also of the constantly updated apparatuses that are producing these images. Picking up the Anthropocene thread, I suggest that we should not worry so much about the (frequently pronounced) death of photography but rather about the multiple deaths of cameras and other equipment—and about the piles of e-waste resulting from those “deaths.” The chapter includes a series of images from my artwork The Vanishing Object of Technology. binary—and beyond the instrumental, industry-imposed focus on the technical future of the medium. Exploring anxieties over the challenge digitization poses to our established notions of art, culture, and the media, it also questions some of the ways of defending these established notions and values via multiple strategies of remembrance, archiving, and data storage. Although photographic arts—in particular, Tacita Dean’s found-image project Floh—provide a focal point for the discussion, the argument focuses on sociocultural and political, as much as aesthetic, issues. The “amateur” becomes for me a pivotal concept in trying to rethink the relationship between media production, media consumption, and art, and in considering what it means to both photograph and archive photographs “seriously” in the age of digital cameras, Flickr, Pinterest, and the ubiquitous Delete button. The chapter incorporates images from my artwork We Have Always Been Digital 2.0. Looking at laser-enabled photographic modeling of worlds past and future, the conclusion to the book aims to reclaim “life” in photography, beyond and outside the human control of the photographic apparatus and the photomedia it produces.\n"}
{"prompt":"NonHuman Photography: Capturing the End of the World ->","completion":"  But it is also a historically located, humananchored tribute to photography as a mode of thinking, sensing, and seeing across time. For cost reasons, the color photographs featured in this book have been converted to black-and-white. However, a free-access companion website features the key images and projects discussed in the book, including those from my own practice. There readers will be able to see works analyzed in Nonhuman Photography in color, access film and animation clips, and follow additional leads. They will also be able to find links to some of the images that I was unable to reproduce in the book, either due to the difficulty of obtaining permissions or because several artists’ representatives wanted control over what I wrote about the works. (Chapter 6 discusses in more detail issues of accessing, curating, reproducing, and licensing images in the digital age.) Please visit the online gallery for an augmented experience of “nonhuman photography”: www.nonhuman.photography\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  4  Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in\/of AI Adrian MacKenzie and Anna Munster  In a greenhouse in Osaka, cameras, ‘trained’ on tomatoes ripening, collect thousands of images over a season, providing agri-science with large datasets promising to ‘solve’ information bottlenecks in plant phenomics, the study of variations in plant traits (Minervini et al.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  2015). In an ostensibly dissimilar scenario, large volumes of chest X-ray and CT scans were amassed early in the COVID-19 pandemic by Chinese and Turkish viral epicentres, which had insufﬁcient testing kits. Such large-scale scientiﬁc image collection projects are conjoined by their machine-learning (ML)-driven approaches to knowledge production. As scientiﬁc researchers and others reiterate, the image ‘masses’ can no longer be observed or managed without the intervention of nonhuman machine vision. The explosion of device-based observation generates images for machine learners, as happens with the cameras in greenhouses, assembly lines, satellites, streets, clinics, drones, and phones. The images avalanche into a moving substrate across which artiﬁcial intelligence (AI) assemblages weave back and forth as they learn to ‘see’. They detect, for instance, the early-onset lung inﬂammation in COVID-19 patients. The image mass and its perception confront us at every turn as we track the dataframed modes of knowing so common in the sciences, on media platforms, in the smartening of cities, or in any place where images and their observation are rerouted through the statistical operations and predictions of machine learning.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  This poses a question: what does this massing drift of images do to perception? When machine-learning- and neural-network-based AI models ‘observe’ an image, they usually look for things by name. Faces, places, people, plants, pathologies, and the like are all asked to state their names. However, as researchers working within machine-learning-based computer vision have quickly recognised, machine learners are “easily fooled” (Nguyen et al. 2011) into mistakenly naming things. Many people have seen the inevitable category errors that result. The problem of perception amidst high-volume image circulation is more interesting  Oscilloscopes, slide-rules, and nematodes  65  modelling, classifying, labelling, segmenting, or otherwise learning from image collections. We ﬁnd it generative to treat various sciences – computer science in particular – as themselves producers of streams of images in the form of graphs, diagrams, plots, models, and sensor data, images that often ﬂip image collections into predictive perceptions.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The wager of feeding machine learning its own image outputs was that we might ﬁnd ways to activate in ourselves some comprehension, some sensation of how AI has conﬁgured itself around images. On what forms might the vast, distributed corpus of effort to see images, at least, as rendered in the visual artefacts of the last two decades of machine learning be converging as it trains up on the global image streams? Following a range of experiments in sensitising ourselves to machine learning (Tan et al. 2021),1 in this chapter we suggest that a “pure experience” approach (James 1976) to machine learning might be useful in moving beyond critiquing the (human) epistemological biases of AI. A different empiricism might be immanent to the enterprise of ‘observation’, more akin to James’s (1976) radical empiricism in its insistence that ‘things’ hang together in event(s) and activities of continuity. Perhaps what is playing out in the observational artefacts of machine learning, computer vision, and associated ﬁelds should not be conﬁned to the highly efﬁcient nominalism of deep learning, the referential claims of data science to ‘ground truth’ in the data or in the proﬁtably pragmatic data-behaviourism of the social media platforms. The non-optical visualities of AI – observation, detection, recognition, classiﬁcation – are entangled with, yet differentially propagating, human and nonhuman perceptual ﬁelds. We know that the labels on machinelearning training datasets propagate through the convolutions of the model architectures.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The intricacy and scale of those architectures are, like the varying ventilation of a termite nest (for a discussion of ant behaviour, see Chapter 2 in this volume), constantly shifting in shape and size, but always turning around the labels of the training data and its perceptual cuts. In these shifts, there is a provocation or at least an occasion to reconstruct and restore to experience some of the gradients and wildly oscillating continua that are ‘cut and dried’ in many habits of perception. Experience, as James (1976, p. 71) suggests, passes along paths of perception shading off in gradients of anticipation, and intermediate shoals of memory and habit, on its way to various destinations. It is an at once ongoing, diverging, accumulating, partially organised but always incomplete movement. A Jamesian ‘pure experience’ approach to machine learning might take us some way toward recasting perception in the light of amassing image conditions. Predictive observations  66 Adrian MacKenzie and Anna Munster the data machine learners use, these observations are not to be found in a wellorganised and tabulated collection. They themselves are not typically regarded as data. By contrast, the scientiﬁc image datasets used in machine-learning-oriented scientiﬁc research tend to be task-speciﬁc, comprehensive, heavily equipped with metadata and often already somewhat homogeneic in their adherence to scientiﬁc data standards.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  EMPIAR, the Electron Microscopy Public Image Archive, for example, contains approximately 8.5TB of raw, 2D electron microscopy images used across biosciences in the automated classiﬁcation of molecules and particles, creating models and simulations of biological molecular models. Such datasets are understood within their scientiﬁc communities of practice to be primarily images ‘of’ some empirical phenomena. One would search in vain for a dataset of images of machine learning. Despite the heavy dependence of many contemporary sciences on machine learning, there are no datasets that include both the imaging of empirical phenomena and the observational visual forms of machine learning. The entangled modes of knowledge production that we term ‘re-imaging the empirical’ are not themselves archived, as such. Such processes of ‘re-imaging’, which involve the ascendancy especially of computer and automated modes of vision, deploy machine learning to re-contour a broad seeing and knowing of the empirical world.2 Sourcing the visual observations of machine learning is challenging. Many such observations are ephemeral and have little public existence. Where these observations do endure, they are usually found in the tangled layouts of scientiﬁc publication.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  We settled on a pre-publication repository – www.arXiv.org, ﬁrst established in 1991 – that hosts scientiﬁc research papers, including many ﬁgures whose apparent function is to evidence and disseminate the papers’ ﬁndings.3 This is not an isolated or singular constellation of scientiﬁc research. It has analogues in the biosciences, ecology and conservation, health and medicine, psychology, humanities, social and behavioural sciences, and media and communication studies, to name but a few.4 Together, these overlapping ‘arXivs’ criss-cross ﬁelds of perception pushed to the limits of space, time, sensation, collective and individual histories and embodiments. In this chapter, we report on experiments in sensitising ourselves to machine learning using a large collection of ﬁgures drawn from pre-prints deposited in the arXiv repository across the period 1991 to 2019. We extracted the ﬁgures from the surrounding textual apparatus of the scientiﬁc papers. The ﬁgures became a dataset, albeit one that mostly lacked the labels on which many machine-learning techniques rely. Their ‘bare’ image status – by which we mean that they were simply raw unlabelled or uncategorised data – in the dataset made them only ‘barely’ observable by the machine-learning techniques we deployed. The  Oscilloscopes, slide-rules, and nematodes  67  than being predictable, the ﬁgures resisted easy machine classiﬁcation as ‘types’ or forms. Even the simple classiﬁcation of ﬁgures in terms of where they originated – a sensor such as a camera or a model running computer vision, for example – proved difﬁcult.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  Instead, the ﬁgures pushed back against the foundational statements of machine learning and its claims to recognise, classify, and predict. Like any perceiving, machine learning cuts or freezes the ﬂow of movement we call experience along particular lines. It channels movement along trajectories or vectors immanent to how ‘things’ come to be, to be encountered and known. The perceptual cuts of machine-learning observation are like the acquisition of a habit. They depend on many encounters in which observed ‘features’ and associations between them accumulate. Running or training a model is just this accumulation, this weighing up and apportioning of values or model parameters in response to the image data. What we look at when we expose machine learners to the machine-learning image dataset is a laying out of continua that do not make sense at the level of machine learning’s own imperative to classify and segment experience (James 1976). We suggest, therefore, that a different empiricism might be immanent to the enterprise of ‘observation’ as it is currently being undertaken via AI’s visual modellings and observations – something perhaps more akin to James’s radical empiricism in its insistence on continua (James 1976).\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  James proposed that ‘things’ hang together in event(s) activities of continuity, which range from what he calls the “vehicles of continuity”, such as space–time, to “practical paths of continuity”, such as “lines of inﬂuence” (52), that organise the relations of things to each other. Continua of experience are constantly cut at their conjunctions by perception, knowing, habit, action, anticipation, and recollection. (For a discussion of experience and plasticity in James’s work, see also Chapter 7 in this volume.) As David Lapoujade (2019, p. 44), reading James, asks (and we, taking Lapoujade to machine learning, wonder): “through such questions about continuity and plurality, the following question arises: how is knowledge to proceed effectively, once our concepts work through discontinuous and unifying slices?” In this chapter, we attempt to locate the cut-ﬂow oscillations of radical empirical experience within the ﬁeld of machine-learning observation and its ﬁgures. Cuts: leaves and petals in a ﬁeld of hybridising irises The iris dataset appears often in machine learning and statistics more generally.5 The dataset records measurements of petal and sepal dimensions for three iris species growing in a ﬁeld on the Gaspé Peninsula, Quebec. Irises bloom in summer, blanketing large swathes of North America from Alaska to Mississippi. The iris dataset, a mainstay of many machine-learning textbooks, how-tos, tutor-  68 Adrian MacKenzie and Anna Munster that two of the species grew together, while the third, virginica, formed a separate colony. The 150 ﬂowers, the ruler, and the table of 600 numbers are, in one central respect, quite ordinary since they evoke a direct experiential encounter, an event in which the perception of irises took place against the background of the forests and ﬁelds of the Chic-Choc Mountains.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  But in another, obvious respect, the generation and proliferation of numbers spanning the perceived differences between petal and sepal dimensions of iris setosa, iris virginica, and iris versicolor are quite weird. The three-dimensional model of the “precise geometrical relationships in petal and sepal size and proportions” (Anderson 1936, pl. 23; Figure 4.1) Anderson later built to represent the aggregated measurements of each species – rendered spatially via a literal subtraction\/cut-out of total sepal measurements from petal measurements and differing in size for each of the three iris species – still does what perception always seems to do. That is to say, perception cuts out something from experience, slicing it along particular lines that steer or align forms of movement – especially movements, in the case of such models, of the eyes. The events of that day were swarming with perceptions, as Anderson moved amongst the irises. Each perceptual event fed into accumulations of experience, some more readily than others. We can imagine some tricky cases, where a ﬂower hovered on the borderline between two species, perhaps showing hybridisation or  Oscilloscopes, slide-rules, and nematodes  69  mutation (irises have a propensity to hybridise), which made it hard to distinguish easily. Anderson’s ﬁeld day had a cognitive bent.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  He was not there to smell the ﬂowers, even if he did smell, touch, and gaze in wonder (or boredom) as the hours passed. His ruler-driven foraging among the ﬂowers, themselves densely and rhizomatically clumped, was animated by a diagram of variations pivoting on the genetics of speciation or the origin of differences, a problem he built out, in, and through his cut-out multidimensional model, but also on various ideographs and maps published as ﬁgures (Anderson 1936, p. 488). Anderson’s ﬁeld of research was focused on the development of techniques for quantifying geographic variation, and intensive scrutiny of minute quantitative variations was his daily grind. The irises of the Gaspé Peninsula were just one clump amongst his transcontinental survey of the distribution and variation of irises, but an unusual clump because all three species were found growing together with surprisingly little variation. The subsequent itinerary of those direct iris perception events – beginning with the article “The Irises of the Gaspé Peninsula” (Anderson 1936, pp. 2–5), and then through R.A. Fisher’s (1936) still-cited “The Use of Multiple Measurements in Taxonomic Problems”, published in the Annals of Eugenics, in which Fisher introduced the inﬂuential machine-learning technique of the linear discriminant analysis (LDA), which became the gold standard statistical, and later computational, means for sorting classes of data – has sustained that ecological anomaly to  70 Adrian MacKenzie and Anna Munster a hyper-intensive degree. The dividing of the ﬂowers into species differences, including variations in colour, shape, size, and perhaps other features, such as the blues and greens of iris versicolor not amenable to observational measurement with a ruler, stands at the beginning of an efﬂorescing chain of transformations and redistributions that continues to this day. Much of Anderson’s perceptual cutting of the ﬂowers during that day in the ﬁeld is greatly compressed, but still inscribed, in the iris dataset.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The scatterplots, cluster diagrams, decision trees, and data visualisations that ﬁgure the iris dataset in the machine-learning literature strip away the genetic, botanical, geographical, geological, and institutional complexities surrounding its inception. A small irony here is that Anderson and indeed Fisher were interested in demonstrating that the three species were not easy to separate, and that iris versicolor could be understood as a hybridisation or mixture of iris setosa and iris virginica. Cut ﬂowers, t-distributed Statistical treatments of perceptual occurrences now skip the ruler and secateurs, and work directly on measurements of images. Figure 4.3 is an algorithmic montage of 2000 ﬁgures extracted from the arXiv ﬁgure database ‘Computer Science Computer Vision’ (cs.cv) category. The montage maps similarities between  t-distributed Stochastic Network Embedding (Maaten and Hinton 2008) – takes high-dimensional datasets and ﬁnds ways of squashing their multidimensional variation in all directions onto the ﬂatness of a plane – a ‘network embedding’ renderable on a screen. Like Anderson’s geometrical model of ﬂower dimensions, or Fisher’s linear discriminant function, the t-SNE montage planes down a many-dimensional conjunction to something visible. The ﬁgures arranged in the montage are rather more hybridised than other scientiﬁc images because, coming from the ﬁeld of research of computer vision, they concern techniques, processes, and methods for statistical machine learning of images. They are the working images of computer vision.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  But the arrangement of the ﬁgures in the montage is symptomatic in several ways. It is riddled with errors of misclassiﬁcation, bias, and mistaken similarity, some of which can be easily seen. Observe the left-hand side of the montage, where the outline of a dancing ﬁgure lies alongside the Chinese character ying or ‘ﬂower’. While the Chinese character and the silhouette of the dancer have, ﬁguratively, arms and legs, they are not closely semantically identiﬁed ﬁgures in the scientiﬁc papers. The same dancer ﬁgure appears in slight variations in other parts of the montage. For instance, it appears again towards the bottom left, adjacent to a cluster of images, slightly right of centre, near some images that all share black backgrounds. Like iris versicolor, the outline of the dancer has hybridised multiple times over the course of several decades of computer vision research. Many pieces in the montage vary slightly from each other, suggesting that large image collections grow through replication.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The montage becomes increasingly erratic as ﬁgures become more abstract. The t-SNE algorithm, indifferent to the device sources or visual cultures of the images, or of the referential disparities between image and ﬁgure, diagram and photograph, data graphic and sensor, ﬁnds good resemblances when it comes to horses, trains, cars, buildings, faces, and birds. It knows nothing of ontologies that divide person from thing, or living from non-living, states of matter, or, more abstractly, practices of knowing. Rightly, we might say, it groups together a species of ﬁgure concerned with outlines. But the upper region of the montage contains many data graphics and plots jumbled together. Similarly, towards the left edge there is a collection of montages. Here, in a mise-en-abyme of montage, the algorithm prehends montages as a ﬁgure, in some sense showing its own seeing (see Figure 4.4). A ﬁnal symptomatic element of the montage cannot be seen optically.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  Like the linear discriminant underpinning Fisher’s response to the taxonomic problem of classifying hybridising irises, the organisation of the montage derives from a rather massive calculation concerning the perception of differences in the world. What connects different zones of the montage? The montage, for all its map-like ﬂatness, has some hidden depths. As if Anderson’s three-dimensional cut-out model of iris measurements has splintered into many dimensions, the t-SNE montage rests on a model that deals with images by a thousand perceptual cuts. The t-SNE  72 Adrian MacKenzie and Anna Munster  Figure 4.4 A subset of the t-SNE montage of 8000-plus images from www.arXiv.org cs.cv. Source: The authors. The deep convolutional architecture of VGG16 makes few assumptions about perception as such, but inherits or embeds, like many other image classiﬁers, the taxonomic ontology of ImageNet, itself institutionalised in the high-proﬁle ImageNet Large-Scale Visual Recognition Challenge (ILSVRC). Because the ILSVRC challenges competitors to classify images according to 1000 categories of things selected from ImageNet, these 1000 categories back-propagate into many leading image inference engines, including VGG16, as in the following sample of 1000  Oscilloscopes, slide-rules, and nematodes  73  cheetah, chetah, Acinonyx jubatus, sloth bear, Melursus ursinus, Ursus ursinus, German shepherd, German shepherd dog, German police dog, alsatian, otter, koala, koala bear, kangaroo, bear, native bear, Phascolarctos cinereus, tusker, echidna, spiny anteater, anteater, wallaby, brush kangaroo, platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus, wombat, revolver, six-gun, six-shooter, chambered nautilus, pearly nautilus, nautilus.7 The interesting wrongness of the montage deepens in the light of the underpinning ImageNet\/ILSVRC categories and their almost encyclopedic taxonomy of things in the world.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The montage lays out the cs.cv ﬁgures after they have been processed by VGG16. How would an ImageNet-based inference engine such as VGG, even a very deep convolutional network, make sense of what it encounters in the arXiv imageset, given that it has been trained on pictures of echidnas, accordions, umbrellas, and Phascolarctos cinereus or koalas? Presented with a million images drawn at random from the arXiv manuscripts, VGG16 sees 140,000 oscilloscopes, 120,000 websites, 100,000 slide-rules, as well as cranes, nematodes, gondolas, stupas, pugs, spider-webs, and trafﬁc lights. How could it not get things terribly wrong, given the ontology on which it has been built, the taxonomic hierarchy of things in the Princeton WordNet linguistic ontology, itself rooted in the ultimate perceptual cut, ‘entity’?8 Tasked to classify the operations and relations of computer vision research provided by cs.cv ﬁgures, VGG16 classiﬁes things in terms of what it was trained on. The scientiﬁc diagrams, ﬁgures, and abstractions, the relational forms of data plots, and the halftone output of sensors and scientiﬁc instruments all lie a long way from the animals, plants, tools, buildings, places, and artefacts of the web-photograph-derived ImageNet. The table below is an example of what VGG16 sees in the arXiv ﬁgure dataset (top 20 only):  Count  Thing  14050  oscilloscope  11707  web_site  10607  rule  9830  slide_rule  7775  envelope  5965  menu  3249  bow  74 Adrian MacKenzie and Anna Munster Count  Thing  1066  hook  1052  crossword_puzzle  1023  jigsaw_puzzle  982  wall_clock  871  analog_clock  640  scale  609  stupa  Superimposed orders of error If almost everything has been misclassiﬁed here, due to this superimposition of the diagrammatic artefacts of machine learning on an object-oriented taxonomy, we have possibly achieved one of the worst predictive performances of recent times. This achievement is especially notable if we remember that the ﬁeld of computer vision, and machine learning more generally, is ﬁxated, to an almost clinical degree, on the reduction of error. The drive to bring down classiﬁcation error rates governs much of the research activity in these ﬁelds, prompting, amongst other things, competitions such as ILSVRC, where winning or losing is decided by error rates on classiﬁcation tasks.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  Our montage is similar to Anderson’s colonies of irises before he cut them out of the forest; it is a site of continuous mixing, with blurred patches of similarity where that mixing has gone further. The t-SNE algorithm lays out the montage by ﬁnding a way to position the ﬁgures according to measures of similarity. But these measures rest on the wrongness of the VGG16 classiﬁcations of arXiv cs.cv ﬁgures, and the wrinkles VGG introduces into the tSNE similarity ordering is a space of lively error, a site animated by crossovers, hybridisations, leakages, contamination, and inﬁltration – by, in short, material ﬂows that mix the habitual perceptual thresholds of object perception with other conjunctions of edge, light, and colour patches. Given the wobbly underlying thing-based misclassiﬁcations, given its shaky foundations in perceptually snapfrozen objects, what similarities matter? The t-SNE has deﬁnitely generated perceptible similarities. It has found paths through the millions of arXiv ﬁgures that traverse research papers whose ostensible objects might lie light years apart. The tSNE ﬂattens something that has already been ﬂattened, or at least folded into ﬂatness in the process of aligning 138 million image parameters to best classify things in the 1000 categories of the ILSVRC. Oscilloscopes, slide-rules, and nematodes  75  websites, rules, slide-rules, and envelopes in arXiv ﬁgures.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  These particular entities are by no means unusual or exotic. They are mostly instruments or devices concerned with measuring – epistemic things not so distant from the scientiﬁc ﬁelds in which arXiv ﬁgures take shape. These include the domains of high-energy or astrophysics where signals from instruments – images generated far aﬁeld of the scales and temporalities of everyday perception – are assembled, measured, compared, and summarised. Viewed in the light of the technical-epistemic instruments of physics, the constant misrecognition of our classiﬁers has another logic alongside the ImageNet\/ILSVRC training bias. It is no accident that computer vision has long played a role in arXiv. In the many ﬁelds of arXiv, the observation of remote or inaccessible objects is central. One might, in fact, understand the archivality of arXiv as pertaining principally to that which is hidden or remote from common perception. Figure 4.5 is a typical ﬁgure in the arXiv dataset.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The plot is from a paper entitled “HST Hot-Jupiter Transmission Spectral Survey: Haze in the Atmosphere of WASP-6b’ (Nikolov et al. 2015), an astrophysics paper deposited in arXiv’s ‘Stellar and Solar Physics’ category. The paper describes how two instruments – a space telescope imaging spectrograph (STIS) on the Hubble Space Telescope (HST) platform and an infrared array camera on the Spitzer Space Telescope – measured  76 Adrian MacKenzie and Anna Munster light or near-visible electromagnetic radiation coming from a ‘hot-Jupiter’ gas planet (WASP-6b or Boinayel) orbiting close to a star (WASP-6), 600 light years from earth in the Aquarius constellation. Readings from various transits or orbits of Boinayel are shown in the ﬁgure. Each curve in the plot traces a series of observations at a particular frequency of light. The combination of frequencies constitutes a ‘spectrum’, or, more precisely, a ‘transmission spectrum’, since the readings pertain to light from WASP-6 passing through the atmosphere of Boinayel. The authors describe the “overall spectrum characterised by a slope indicative of scattering by aerosols” (16): that is, “haze”. The VGG16 predictions of what the plot shows are interesting.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  It ﬁnds an oscilloscope, a shower curtain, window shades, a solar dish, and a jigsaw puzzle. Note that the perceptual arrangement from which the observation of Boinayel derives is not unusual, at least not in the context of arXiv. The observation that the planet’s atmosphere is “hazy” derives from many layers of instrument reading and modelling arranged along a path that runs from the nearearth orbit of the HST and Spitzer platforms, through the radio-telescopic dishes of NASA’s Deep Space network stations in Canberra, Australia, Goldstone, California, and Madrid, Spain, or via NASA’s Tracking and Data Relay Satellites (TDRS), through to the image calibration and analysis processing pipelines9 of the astrophysics community, and then through various models of other stellar sources (such as WASP6 or other neighbouring astronomical objects, indexed by the ‘residuals’ or error bands plotted on the right-hand side of the ﬁgure), to produce the ﬁnal measurements of light intensity, or the ‘normalised ﬂux’ of the vertical axis labels in the ﬁgure. The ﬂuxing stellar light, as the gas giant transits in front of WASP-6, stages an atmospheric show like dawn – a staging that Nikolov and his co-researchers observe through the many alignments of instruments, platforms, and infrastructures funnelling into their model of the transmission spectra. The ﬁndings concerning Boinayel’s atmosphere are not earth-shattering, except in the transport of perception to the haze of a distant planet. Perceptually, the colour of the sky is blue precisely because light incident on the earth’s atmosphere is scattered much more uniformly in all directions than the other colours. The colour of the hot sky on Boinayel no doubt differs. arXiv is densely stocked with ﬁgures deriving from situations in which far-scattered probes, sensors, lenses, dishes, platforms, communication infrastructures, databases, and models have been arranged, oriented, aligned, calibrated, and operated to add to our sense of what lies remote from immediate perception.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The list of techniques, places, people, things, arrangements, and events on which an observation of Boinayel’s atmosphere depends is likely to be as long as the categories of things in ImageNet. There are probably many ways in which WASP-6b’s atmosphere could be instructive here. What stands out for us is the meticulous and highly contingent ensemble of elements needed to observe a planetary atmosphere 600 light years away  Oscilloscopes, slide-rules, and nematodes  77  generally? Does this practice of observation, with its continuous chain of instruments, materialities, perceptual and platform bases, better orient us to the images of the t-SNE montage? If we return to the montage (Figure 4.2) in the light of the observational practices of Boinayel, the clustered montage of images drawn from arXiv’s ‘Computer Science Computer Vision’ category looks rather different. VGG16 detects oscilloscopes, window shades, and shower curtains in the transmission spectra of WASP-6b, pointing, perhaps awkwardly, to the time-varying signals, to shuttered and hazy views of the planet. But VGG16, conﬁgured as an apparatus for perceptual resonance, does something different. Can we imagine a similar approach to the arXiv ﬁgures?\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  Unlike the images of things, people, and places found in ImageNet, on which VGG16 was trained, the image collection of cs.cv includes many diagrams and ﬁgures of signals, variations, thresholds, peaks, and trends. Like the measurements of spectral transmission through Boinayel’s atmosphere, these proﬁles of change can be constructed only through chains of accumulation of observation. Large portions of the montage pertain to accumulations of observation. The fact that these machinelearning-enabled observations concern collections of images derived from everyday life worlds of city streets, interiors, nature, or industry does not detract from its accumulating partial observations, arranging them in forms that permit their variations to become continuously perceptible. The sensor–diagram continuum Continua, running across thresholds positioned along different classiﬁcatory or differential axes, might be the pivotal feature of Figure 4.3. The vast error of the montage is that it attempts to place all the images of cs.cv, whatever their provenance, on the same plane. The generative wrongness of the montage is its insistence on the continuum, enforced by the t-SNE embedding of the many dimensional difference measures by VGG16. It connects all ﬁgures on the same plane.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The question of how to traverse the plane remains open, but, in principle, many traversals are possible. The sense of any path between them – for instance, between all the instances of ying or the dancer ﬁgure – will be determined by speciﬁc circumstances, in the same way that the use of the Spitzer infrared camera measurements were conﬁgured by the selection of certain frequencies, certain times, and precise points of orientation to observe Boinayel’s atmosphere. Amongst our various experiments in traversing the ﬁelds and thresholds of the arXiv ﬁgure dataset, a most instructive failure came from an attempt to classify ﬁgures in terms of how they were made. We might think that a photograph and a diagram present radically different visual organisations, and afford ready categorisation in terms of whether they derived from a sensor – a camera, a sensor, or a  78 Adrian MacKenzie and Anna Munster thousand such ﬁgures, we were often forced to resort to a third category – ‘sensor–diagram’ – to deal with cases that were neither simply sensor-based nor diagrammatic. In this third category, which accounted for around 20 per cent of the ﬁgures, elements of sensing mixed practices of line drawing in various geometric, diagrammatic, numeric, linguistic, and formal compositions. The presence of arrowheads is symptomatic since the arrowhead brings with it conventions of geometric organisation of space, ﬂow of time, sequences of processes, and indexicality or pointing-out, often adjacent to language-based signs. Even with a training set of 10,000 arXiv ﬁgures labelled using the ‘sensor’, ‘sensor–diagram’, and ‘diagram’ categories, our attempts to train a deep neural net machine learner to infer categories for arXiv ﬁgures were difﬁcult to evaluate. We disconnected the ImageNet classiﬁcations from the output layer and substituted the sensor–diagram continuum classiﬁcations, then retrained a VGG16 deep learning neural net on the arXiv ﬁgure dataset.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  With a model trained to predict whether images are sensor, sensor–diagram, or diagram-derived, we classiﬁed collections of images in various arXiv sub-ﬁelds. As with the other poor-performing or sub-optimal predictive models described above, the failure and errors of the sensor–diagram classiﬁer are more generative. VGG16 and other similar deep learning architecture have been pre-shaped by object-oriented perceptualism, even as their wide application in medical imaging or astronomy to sense lesions or atmospheres shows that they have no inherent relation to the perceptual cuts of a world of static things. Varying distributions of the sensor–diagram continuum run through arXiv. Figure 4.6 shows some of these  Oscilloscopes, slide-rules, and nematodes  79  distributions for a few selected categories of the arXiv ﬁelds of physics, mathematics, computer science, statistics, electrical engineering, quantitative biology, economics, and ﬁnance. The cs.cv category, the repository of computer science research on vision, shows the greatest growth in sensor-derived images, more so than astrophysics (instrumentation and methods) or condensed-matter physics (strongly correlated electrons) or nonlinear sciences (cellular automata and lattice gases), some of which might be expected to present many sensor-derived images. This difﬁculty of drawing a line between sensor and diagram indicates another continuum in experience – a path that diagonally crosses between sensing and thinking, sensation and abstraction. This is the Jamesian element of pure experience, its continuous differential gradients prior to the cuts or breaks that stabilise perception in habits and forms that align and order experience.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  Conclusion Irises of the Gaspé Peninsula, the Chinese character ying or ‘ﬂower’, a silhouetted dancer, and the hazy atmosphere of the gas-giant Boinayel: it might seem that a vector of artiﬁcialisation runs from close direct perceptions (Anderson cutting ﬂowers in the ﬁeld) to the far fringes of experience (haze in the atmosphere of a distant planet), with detours via cameras and then machine-learning techniques (the drawing of a character or a ﬁgure). Actually, we are suggesting a different line of movement, along a pathway edging or erring through conjunctions forged of devices, instruments, visual forms, and habit (oscilloscopes, slide-rules, shower screens, and nematodes) along plural continua. We move through this haze of associations in a daze because most of what counts as perception is dazzling. We know from Henri Bergson’s Matter and Memory (Bergson 1988), or from William James’s radical empiricism, or even from Maurice Merleau-Ponty’s mid-twentiethcentury The Phenomenology of Perception (Merleau-Ponty 1982) that perception is like a cut ﬂower. The cuts of perception produce a dazzlingly bright solution to the problem of how to move amidst the slippery plurality of experience, in its free ranging across senses, precarity, and contingency of events, and durational iridescences of glaciation and transience. Many perceptual solutions to the problem of experience ﬁxate on cut-out forms. Such solutions are institutionalised, mobilised, inscribed, and enforced in practice. Infrastructures, customs, habits, norms, and values come to rest on and conﬁrm them.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The perceptual cut is a problem. Not because it errs, but because it goes too smoothly. Experience varies and shades off into haze all around. We ﬁnd in the errors, however, in arXiv, many forms of becoming sensitive to experiential haze. Experiments, devices, and models track the near-horizon structure of escape  80 Adrian MacKenzie and Anna Munster statements. What is archived in arXiv? The t-distributed Stochastic Network Embedding of arXiv ﬁgures as observed by a convolutional neural network, itself trained on millions of photographed things in the world, can instil a sense of vertigo, despite its ﬂatness. The continuum of the t-SNE, with its far reaches immersed in perception events, its many faces and ﬁgures, recessed montages and, above all, its over-abundance of diagrams of hills, gradients, slopes, peaks, and spikes, renders something of what James called pure experience.\n"}
{"prompt":"Oscilloscopes, slide-rules, and nematodes Toward heterogenetic perception in AI ->","completion":"  The montage’s errors, its erring, alert or sensitise us to pure experience. They run across the overlapping arXiv ﬁgures, skipping breaks or discontinuities. They run in all directions, between things and concepts, between sensing and abstraction, between event and structure, between contingency and regularity. One way to sense what is happening to perception in arXiv, and perhaps in any ﬁeld where the species of perception hybridise, is to deviate from the bright lines running between light striking a surface and the enunciation of statements of fact: ‘a ﬂower’, ‘iris setosa’. Collected together and observed in the modes machine learning makes possible, a different proposition takes shape in arXiv’s ﬁgures. Non-classiﬁable intermediary ﬁgures – for instance, the sensor–diagram – emerge, variously distributed throughout regions\/categories of knowing in arXiv. The collecting and probing of a heterogeneous collection of scientiﬁc ﬁgures suggest that observation conducted using AI’s own operations is less likely to stick to the stable cut-outs. arXiv’s ﬁgures, as image ensemble, constantly melt, evaporate, and deviate from attempts at solidity.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  8 The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision Stamatia Portanova  The origin of this article coincides with two different but parallel events.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  The ﬁrst is my recent rereading of Gilles Deleuze and Felix Guattari’s book Anti-Oedipus. Capitalism and Schizophrenia (2000), followed by my reﬂection on the possibility (or necessity) of adopting and adapting some of its key concepts into our time. In his Preface to the Anti-Oedipus, Michel Foucault explained how, in the particular climate of the 1970s, being anti-oedipal was a truly revolutionary lifestyle, a way of living and thinking in constant opposition to all hierarchies and fascisms (including, among the latter, the rigidity of the psychoanalytical and Marxist schools of thought, and all those petty micro-fascisms ‘that constitute the tyrannical bitterness’ of modern daily life) (Foucault in Deleuze and Guattari 2000, XIII). This lifestyle was described by Deleuze and Guattari themselves as ‘schizophrenia’, a horizontal relational attitude that induced one to be inspired by a multiplicity of things rather than guided by a unique dominating principle, to become multiplied into a crowd rather than remain the same individual; in other words, to produce a life in collaboration rather than obey the exclusive and solipsistic logic of a dominating ego. What about our epoch, I thought, while reading those fascinating pages, an epoch in which capitalism itself seems to have adopted an anti-oedipal style, and to prefer what is multiple and constantly in motion (objects, people, ideas) over what is unique and static? Signiﬁcant evidence of this capitalist anti-oedipalism is given by the contemporary visual culture industry, with its multiplication and dissemination of all kinds of images (onand ofﬂine) around the world, and with its simultaneous decomposition of their texture into a myriad of pixelated fragments with no easily recognizable author (see also Cubitt 2015, this volume). In fact, as Deleuze and Guattari point out, it has always been in the nature of capitalist regimes to act (like their opponents) in a schizophrenic way, and to develop themselves between fascism and anarchy, chaos and control, an unlimited churning of products  and desires and the regimentation of people’s perceptions and possibilities. As an example, we can think of Jonathan Crary’s study of that crisis of attentiveness which was already a crucial aspect of modernity in the 19th century, something that was produced by the ‘changing conﬁgurations of capitalism’ as ‘an endless sequence of new products, sources of stimulation, and streams of information’, and to which capitalism itself used to respond ‘with new methods for managing and regulating perception’ (Crary cited in Terranova 2013, 7).\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  Following this line of thought, I would like to argue that, if something has indeed occurred that differentiates our societies from the industrial states of the 19th and 20th centuries, this something should be seen as a neurotic degeneration of the same old capitalist schizophrenia, a degeneration that takes the shape of a peculiar perceptual phenomenon, and in which digital technology plays a crucial role: it is not so important that digital images are everywhere all the time (as analogue ones have also been); more important is the fact that images are now being seen as digital, everywhere and all the time. I call this phenomenon the ‘obsessive digital’: a qualitative rather than simply quantitative modiﬁcation of the visual style of our age – what is gestured to within this volume as the notion of the postdigital. As a concrete example, the New Aesthetic has been deﬁned by Bruce Sterling as an investigation of ‘how contemporary reality looks to our pals, the visionary machines’ (Sterling 2012) – in other words, how digital processors see the world: the perception of computers, the mathematics of binary algorithms made not only visible but a vision in itself. Most of the contemporary ‘new aesthetes’, together with their critics and commentators, have taken this as an occasion to focus on the beauty of the digital, while exploring the effects of technological vision on the contemporary aesthetic sense. The New Aesthetic, in other words, insists in pointing out to us the wonder of seeing the world through a computer’s eyes. It is my intention to complement such perspectives with a parallel analysis, one that puts the phenomenon into a more critical and wider relation with the socio-technical psycho-physical neuroses of contemporary capitalism, of which it constitutes the main perceptual form. My encounter with the New Aesthetic was, thus, the second event that induced me to write this article. New aesthetic as neurotic style: The obsessive digital While the New Economy has already attributed to digital computation and mathematical models the ethical capacity of driving most ﬁnancial decision making, the New Aesthetic, Michael Betancourt argues, makes ‘[t]he technical aspects of digital technology become style – thus new aesthetic – [with] a transfer instantiating the immaterial in a physical form, a “print-out” whose tangibility [ .\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  . . ] becomes the operative dimension in asserting the presence of an immaterial, digital “information space” ’ (Betancourt 2013). Digital technology acquires aesthetic capacity and dictates the contemporary style  (or the way in which the world is produced and perceived) as a proliferation of pixelated images, composing reality as a juxtaposition of bits and pieces, and visualizing all space as information space or cyberspace. This kind of cyber-vision appears as a digital metamorphosis of what Foucault deﬁned as the anti-oedipal style of the 1970s, still a way to perceive and produce the world ‘by proliferation, juxtaposition, and disjunction’ (Foucault in Deleuze and Guattari 2000, XXIII), but this time in horizontal collaboration with algorithms. Now, understanding contemporary vision as a neurotic rather than a schizophrenic phenomenon requires a further step in the thinking process initiated by the reading of the Anti-Oedipus. Before taking this step, we need to clarify the difference between schizophrenia and neurosis as they are deﬁned in the book. Summarizing Deleuze and Guattari’s point, we can say that a schizophrenic being (not necessarily human) does not have any pre-existing (subjective or objective) structure, but is always different information and contributes all its energies, in a ﬁeld of ﬂuid relations, to the production and organization of a body (where the difference between individual and collective body does not make sense any more). ‘But at the very heart of this production, . . . the body suffers from being organized in this way, from not having .\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  . . no organization at all’ (Deleuze and Guattari 2000, 8). The neurotic, on the other hand, is trapped within social rules or rigid norms as principles of self-organization that channel its energies into an obsessive and sterile ego-centrism. There is no relation, therefore, between the two styles. Capitalism, Deleuze and Guattari argue, has always been aiming not only at the production of speciﬁcally organized psycho-physical and social bodies (the worker, the family, the factory, the state, etc. ), but also at the dissolution of these bodies and all their regulated, codiﬁed ﬂows (of goods and tools, of money and workers, of perceptions and desires, of information communication) into a ‘Body without Organs’, an unorganized, pure ﬂuid running in a free state. What this means is that a freely ﬂowing value (the abstract value of surplus money, or industrial capital) becomes the only true producer, distributor and consumer of all the other ﬂows, that which generates them, combines them and at the same time dissolves them: a self-generating process of ‘production for production’s sake’ characterizing the schizophrenic nature of the capitalist regime (Deleuze and Guattari 2000, 224). In this sense, on the one hand, the proliferation of images in the modern culture industry becomes another ﬂow among ﬂows, a visually coded magma of sensorial stimuli tightly coupled to the production of capital. On the other hand, in our times, the fact to be particularly noted is the new behaviour of the ﬁnancial market acting ‘as if’ it could erase or ignore all ﬂows and their attached bodies (all bodies, those of brokers and investors included), as if it could act as a solitary mind producing surplus value in the name of pure information, of abstract quantities of money, of a new unique ﬂow tracing  an autonomous and self-regulating economic territory.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  Productive energies and bodies end up constituting the repressed ‘id’ of a more neurotic capitalism that constantly tries to forget them through its illusory narcissism.1 It is the new form of an old dissimulation: while hiding the discrepancy of value existing between payment money and ﬁnancing money was part of the old capitalist strategy, the operation of hiding takes now on a totally different meaning and aim. It is not the double soul of capital that has to be dissimulated, but one of its two souls, or, more precisely, its body. What does this socio-economic neurosis have to do with the New Aesthetic? Cognitive and intellectual labour often seems to be affected by the same kind of oblivion as that pervading the ﬁnancial sphere, the same ﬁxation on the digital, which is this time conceived not simply as a realm of abstract proﬁt but, in Bridle’s words, as ‘a space of the imagination’, one that has ‘not yet quite come into being in the physical world’ (Bridle 2011). This sheer enthusiasm for all that is digital was admittedly acquired by Bridle after his encounter with a kind of tangible material object that is proliferating in the world, objects such as a pixelated cushion on sale in a furniture store. And yet, nothing of the colour, size, shape, fabric, texture, consistency, weight, smell, temperature, comfort . . . of that cushion becomes a part of his imaginative space, except for its pixelated look, or what can be deﬁned as an ‘obsessive digital’: an isolated pattern or style detached from any productive relation with the material qualities of the object. The relation between this perceptual neurosis and the abstract character of contemporary capitalism is more than evident, as material and social experiences simply happen to compose the forgotten fabric of stocks as the new economic objects, whereby the algorithmic nature of ﬁnancial data constitutes the basis for the abstract representations of the capitalist market performed by digital processors (see Golumbia 2015, this volume).\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  And yet, as Steven Shaviro points out, you cannot process information without simultaneously dissipating energy: all minds (digital as well as human) are systems of energetic accumulation and dissipation, encounters or relations of forces, before being systems for information processing.2 A cushion has a particular colour, and the economy is made of productive force and tiredness, of potency or impotency to consume. In times when the ‘non-human turn’ (or thinking beyond the human) is characterizing the contemporary debate in most areas of the humanities, it is not (or not simply) in terms of a resurgent preoccupation with the human that the neurotic ﬁxation on data and information processing, and the simultaneous lack of attention to energetic force dynamics (such as chromatic quality, but also fatigue and poverty), is being critically highlighted here. Before being personalized as a human subjective problem, this lack of attention needs to be understood as a condition in contemporary socio-techno-psycho-physical systems, systems in which a schizophrenic capitalism gives itself a digital style; a neurotic condition in which, to put it in Shaviro’s words again,  the process of cognition is perceived as happening without affective consequences. Another way to understand this channelling of attention from energy to information, or this reduction of affective forces to cognitive units (pixels or stocks), is by returning to Whitehead’s notion of ‘importance’, where what is taken to be an important fact simply emerges in a system as the result of a gradation in the relevance of the totality of all facts that constitute the environment of that system (Whitehead 1968, 7–10). In this sense, it is possible to see the contemporary codiﬁcation of the aesthetic and the economy into data, not as a total depuration of matters-of-fact from their ‘noisy’ environment, but as a gradation of importance that, starting from the minimum relevance given to those energetic environmental forces that are indispensable for the very existence of a datum, arrives at the maximum relevance given to the datum itself: a perceptual gradation leading, in our case, from the complex dynamics of a chromatic experience to the pure fact of a pixel, or from the economy to ﬁnance. A certain perspective prevails in the contemporary capitalist system, as Whitehead would say, upon the universe of things felt, so that pixels are the ﬁrst to leap out to the artist’s eyes, and algorithms become for the economist the most reliable modes of thought. In her book Contagious Architecture (2013), Luciana Parisi undertakes a fascinating investigation of the way in which chaos does not simply appear as a physical contingency but is already part, under the guise of computational incompleteness, of the axiomatic of computer programs. In this sense, randomness signiﬁcantly becomes the condition of the contemporary programming culture (that is, of post-industrial capitalism), and of a dominating socio-technical system that no longer needs smooth control, or a total comprehension of the real, in order to subsist.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  We therefore feel that the real issue at stake, as evidenced by Parisi’s analysis, is the new autonomy of algorithms, apparently proliferating in dissociation from their physical origin, and functioning in a transcendental isolation that connotes the style of our age. Acquired by the Google Inc. corporation in 2004, Google Maps represents, for example, one of the many visual models of contemporary capitalism. This model, it is true, still acts as a controlling grid, and yet it is an empty one that persistently ignores its intrinsic involvement with the materiality of the world (that is, in the case of Google Maps, with the motion of tectonic plates and the dynamism of the Earth, or with the non-visual feelings and memories that bodies have of movements and routes).3 But capitalism, let us remind ourselves, is ﬁrst of all a system of bodily production. The presumption of separating a style, or a modality of perception, from a body (such as when Bridle isolates a pixelated pattern from a whole aesthetic experience, or when Google isolates a map from a place and a route) is a trap for thought, an absolutization that can generate catastrophic events (such as the events provoked by the running of the stock exchange market by abstract mathematical algorithms). Of course, a body can be intended as an object (and an object as a body): computers are  also bodies, with their own algorithmic, pixelated, gridded style. And the common ontological status shared by human bodies and inanimate objects certainly cannot be founded on their bare material existence; it needs to be deﬁned via their properties, or via the ideas they realize.4 From this point of view, it is therefore true that material reality needs to be deﬁned via properties that are abstract (or, in Whiteheadian terms, via ‘eternal objects’, such as the tendency of computers to ‘pixelate’): an object without properties would be a body without style (a real impossibility, such as an image without colour, or a computer without software). It is precisely by virtue of their different ideas that digital computers and human bodies take different experiential routes. But, on the other hand, my purpose here is to detach the metaphysics of the idea from its most obvious Platonic connotations, redeﬁning it as a true relation whereby no algorithm or idea can really be left to run on its own, without a thought for its effects on all the involved bodies, while no body can be thought separately from its own style, or its modes of experience.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  An actual occasion (as Whitehead deﬁnes his bodies-objects) is always the parallel encounter between an abstract quality to be actualized and a physical experience actualizing it: a meta-genetic (metaphysical and ontogenetic) event creating, for example, an image and a looking eye, or a perceptual event, through the ingression of colour as abstract potential. Every occasion of experience is dipolar, which means that every idea is associated with a physical feeling of some sort (Whitehead 1985). On this basis, our discussion of the New Aesthetic as both a perceptual and a conceptual phenomenon cannot but take into consideration the bodies and feelings implied in the actualization of digital algorithms. It happens that digital algorithms today often materialize on screens (or other displaying surfaces) to which the bodies and minds of artists, economists, workers or users are often attached. It seems, therefore, important to mention at least brieﬂy the phenomenological effects of screen ubiquity on the style (intended as physical, but also the mental posture) of these users. As an example, exploring the use of video cameras to capture ﬁrsthand accounts of the Syrian revolution, Rabih Mroué’s art focuses on contemporary Lebanon as a digitally mediated space. Why, Mroué asks [ . . . ], do people risk their lives to make photos and videos, even to the point of continuing to ﬁlm while being shot at?\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  He shows a few instances when it is clear that the person behind the camera sees the gunman turn towards them, raise his weapon and take deliberate aim. Still they keep ﬁlming as the gun is ﬁred. Mroué makes the point the videos are also weapons, when distributed in Syria and beyond, and are essential to feeding the resistance; also that the phone camera is not used like ﬁlm cameras of old but becomes a prosthesis, an extension of the eye which is continually active [ . . . ]. (Stallabrass 2012)  In fact, going well beyond the concept of the camera as a prosthetic extension of the human body, and also beyond the phenomenological vision of a technologically altered human body-subject, this extreme example shows how the perceptual experience (and life itself, or in this case survival) has been totally remediated or, as Jay Bolter and Richard Grusin (2000) would say, ‘hypermediated’: a continuous, obsessive intercession of screens and technological devices is, in other words, occurring in all the interstices of lived experience. At the same time, the two theorists also suggest, contemporary visual culture generates a sense of immediacy by neurotically ignoring or denying the presence of the medium and its mediation, and by pretending to put the viewer in the same space as that of the technical machine’s vision. Realistic immediacy and mediated saturation, in short, are the two coexisting material forms through which technology creates the contemporary perceptual style as a posture of bodies and minds, where the multiplication of screens and media generates the paradoxical sensation of a direct experience of the real (Figure 8.1). ‘And so when you see a picture like this’, James Bridle (2011) asks, you see pixels, right?\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  Those aren’t pixels. Those are ﬁelds. They’re irrigated ﬁelds on the border of Namibia and South Africa. But because we expect to see things in a certain world, our understanding of where the border between physical and digital is has changed, because we’ve experienced this kind of imagery and these kind of views before, and we’re unconsciously comfortable of them being mixed up. We see pixels even when they are not there. As an effect of the constant attachment of bodies and minds to computer screens, mediated immediacy does not only imply what Bridle deﬁnes as an extraordinary and magical perceptual phenomenon: that of seeing, like a computer, pixels everywhere. Important neuronal modiﬁcations, which Tiziana Terranova (2013), for example, identiﬁes with anhedonia and attention deﬁcit disorders, but which can also include (and I am simplifying here) conditions such as anxiety or depression, seem to emerge when the technical machine is incorporated in the body of the user and colonizes its perception and thought, and are therefore directly implicated in ‘our symbiotic relation with digital screens’. Rather than remaining enclosed in the subjective sphere of individual psychopathology, these conditions increasingly characterize a whole socio-energetic system that coincides with 21st-century techno-capitalism.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  From this point of view, the neurotic aspect of this techno-induced societal symptomatology does not really emerge when the body–mind–computer relation is disrupted by a break (of the nerves, muscles, articulations, psyche . . . ), but delineates itself with more clarity in the peculiar ‘patio ergo sum’ that derives from new processes of machinic subjectiﬁcation and constitutes the really new conﬁguration  Figure 8.1 NASA Earth Observatory image created by Jesse Allen, using EO-1 ALI data provided (Courtesy of the NASA EO-1 team and the United States Geological Survey)  of the contemporary techno-aisthesis. If, in other words, the particular form of depression ‘triggered by interaction with information and communication technologies’ is indeed readable, as by Terranova (2013), as a libidinal disruptive process interrupting the excessive working time of cognitive labour, conversely a problematic aspect emerges when this state is entrapped into the spacetime of human–computer interaction, as a dysfunction born and to be solved between our selves and our technologies (for example by installing an internet timer, or by leaving the task to the action of some drug): a condition very different from Erin Manning’s description of depression as a productive (or schizophrenic) and self-exploding (or antioedipal) condition, a ‘chaosmosis at the heart of the “not-me” ’ (Manning 2013, 3). Conclusion: There is more than pixels I would like to conclude these brief reﬂections on the neurotically digital style of our age with the hope that they are not read as a mere negative critique of the New Aesthetic movement, the postdigital, or digital technology itself. The main purpose was, in fact, to grasp the digital in its effects on capitalist (or post-capitalist) systems of perceptual production, and to complement the current discussions of ‘new aesthetes’ with these reﬂections. On this basis, I would like to regenerate one of the main ideas offered by Deleuze and Guattari in the Anti-Oedipus, and propose a reconsideration of the digital experience under a more anti-oedipal aesth\/ethic light. For this purpose, one of the most important ideas that can be extrapolated from the book is that in order to become schizophrenic, which means in order to be really creative, ‘Not creative of capitalism’s “newest new,” but creative of new forms of value, of new ways of valueing modes of existence . . . ’ (Manning 2013, 15), perception (all perception) ﬁrst of all needs to loosen its tight connection with its self, or to somehow disperse and disorient itself.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  The collective is a mode of perception before being a form of socialization. Rather than simply coinciding with digitally augmented perception, a non-human collective assemblage intended in the Guattarian sense would therefore require a detachment from all perceptual habits or styles, digital and human alike. This non-human, but also non-digital, perception can be deﬁned, echoing Manning’s words (2013, 4), as a capacity to ‘perceive the world in its edging into experience’, an intensive sense for relation in the making, a collectivizing (rather than dividing or isolating) style. For Manning (2013, 5), a particular instance of this open style or collective sense of perception can be found in those systematically pathologized subjects commonly deﬁned as ‘autistic’, for whom ‘[w]alking into a room, . . . [means] not at ﬁrst perceiving tables, chairs, people, but seeing the edging into experience of ﬁelds of colour, tendings toward form. [and for whom] The ecology of experience is itself directly perceived in all its relationality.’ At the other extreme of the visual spectrum, we ﬁnd that neuro\/typical tendency to chunk the world into parts, or into subjects and objects, that is proper to sectorialized capitalism and, in a more technical sense, to computer vision. Produced through a direct comparative relation between the selected features of an image and those contained in a database, digital object and face recognition systems are an example of the perceptual style, or physico-cultural habit, based on algorithms. Another signiﬁcant example, as revealed by WikiLeaks and shown by YoHa and Matthew Fuller’s art installation Endless War, would be the algorithmic perception of war, its reduction to a set of data and computational processes, and to ‘an endless permutation of jargon, acronyms, procedure recorded, crossreferenced and seen as a sequence or pattern of events’ (YoHa and Fuller 2012).\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  But let us look at the algorithmic vision of computers in a bit more depth. What happens when a pair of eyes focuses on a screen? In its encounter with human perception, the digital chunking produces a loop. First, the machine reduces a ﬁgure to a series of numbers, and then to a constellation of luminous pixels that, disposing themselves on the screen according to the combinatoric of the algorithm, constitute a ﬁeld of perceptual potential. Second, from the pixelated grid, perception receives a new, emerging ﬁgure, an object or a face. In fact, the ﬁgure–grid perceptual loop is never entirely closed. According to Manning, perception always follows a tendency to perceive what she deﬁnes as ‘more-than’ (more-than ﬁgure, more-than grid, morethan pixels): every perceptual event generates an openness that stretches the perceiver\/perceived relational in-between as a resonating dimension of potential.5 From this potential, ‘normal’ human and technological perception reconstitutes the ﬁgure–grid circuit by selecting a particular object, while ‘autistic’ perception keeps moving in the dynamic ﬁeld: ‘Once the environment ends to stabilize into form, the difference in coming to perception persists for the autistic . . .\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  The ray of light or the intensity of a sound or the quality of a colour often turn out to be more enticing than the face of another individual’ (Manning 2013, 5). In the end, the concept of morethan-ness even allows us to go beyond the normal–autistic polarity, and to conceive every form of lived perception as having its autistic side, or its relational germ. A wider (and not metaphorical) deﬁnition of all perception as autistic thus gives a different sense to the ‘non-human’. In this sense, the non-human is not comparable to the algorithmic of digital processing in its strict technical sense, because the overcoming of the subjective and the objective as ﬁxed perspectives derives ‘more from a logic of the affects than from a well-circumscribed, comprehensive logic’, an affective logic where ‘the relational ﬁeld vibrates and the sense of a pre-constituted self falls away’ (Manning 2013, 9–10). Finally, let us remember the archaic Romans, who saw every place as inhabited by a singularity, or a ‘genius’, with which to enter into dialogue; as an affective, non-subjective and non-objective landscape full of geniuses with whom to negotiate one’s perception until one loses oneself, more than a neutral space to see or capture into a grid-map: perception as fabulation, the process that makes the invisible emerge from the visible. This ancient fabulatory act is certainly not being recalled here as an exhortation to return to our pure origins, but as an invitation to rethink the technologized perceptual style of our time, together with the pixelated images, grids and maps of the postdigital, according to the sensations and the feelings of the virtualities accompanying them (see Berry 2015, this volume); to see that, behind and beyond the map, the landscape becomes invisible because the more we conquer it, the more we lose ourselves in it. [In the end,] to reach the landscape we must sacriﬁce as much as we can  all temporal, spatial, objective determination; but this abandon does not only attain the objective, it affects us ourselves to the same extent. In the landscape we cease to be historical beings, that is to say, beings who can themselves be objectiﬁed.\n"}
{"prompt":"The Genius and the Algorithm: Reﬂections on the New Aesthetic as a Computer’s Vision ->","completion":"  We do not have any memory for the landscape, we no longer have any memory for ourselves in the landscape. We dream in daylight with open eyes. We are hidden to the objective world, but also to ourselves. This is feeling. (Straus cited in Deleuze and Guattari 1994, 230, note 6)\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The ceremony must be found Traditional, with all its symbols ancient as the metaphors in dreams; strange with never before heard music, continuous until the torches deaden at the bedroom door. John Peale Bishop, \"Speaking of Poetry\"  It would be the fact of the ceremony that Henry  would balk at: Bon knew this. It . . . would be the  ceremony, a ceremony entered into, to be sure, with a negro, yet still a ceremony. William Faulkner, Absalom, Absalom  These doctors of philosophy never concede the  moon to be less polished than a mirror; they want it to be more so if that can be imagined, for they deem that only perfect shapes can suit perfect bodies. Hence the sphericity of the heavenly globes must be absolute. Galileo, Dialogues The establishment of a royal cult (the Bakama) was  an economically demanding development. None the less the political advantages accruing ... appear to be substantial.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  This when added to the other ritual  oppositions ... neutralized the Bacwezi as a politicoreligious force.... The (new) fundamental relationship can be reduced to: Bakama: Purity\/and Safety,  Culture. Bacwezi: Putrid\/and Danger, Nature. Peter Schmidt, Historical Archaeology: A Structural Approach to African Culture  As a result of rallies we got courses in 'black literature' and 'black history' and a special black  adviser for black students and a black cultural  center.., a rotting white washed house on the  nether edge of campus.., reachable.., by way of a scramble up a muddy bank.... And all those new courses did was exempt the departments from the unsettling necessity of altering existing ones, so they could go right on advertising a course in \"American Fiction\" that explicitly includes \"Hawthorne, Clemens, James, Wharton, Hemingway,  Fitzgerald, and implicitly excludes Chesnutt,  Hurston, Richard Wright and Ralph Ellison.\" David Bradley, \"Black and American, 1982\" I. The Studia Humanitatis: From Heresy to Orthodoxy The crisis of irrelevance and of growing student defection to the vocational areas of education is part of an overall crisis of the episteme\/organization of knowledge that was put in place, as Foucault shows, in the nineteenth century (Foucault, 1973). This episteme, based on the triad, biology, economics and philology\/Lite-  rary Studies, found what Vandamme calls-in the frame of his concept of the efficiency theory of truth-its efficiency criterion (Vandamme, 1983), in the context of the rise and expansion of the Industrial Age. And the crisis of our times is precisely that of the selfdissolution of this Age.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Sir Stafford Beer summed up the extent of this crisis in his introduction to a book by the Chilean biologists, Maturana and Varela. He argued that contemporary scholarship is trapped in its present organization of knowledge in which, while a man \"who can lay claim to knowledge about some categorized bit of the world, however tiny, which is greater than anyone else's knowledge of that bit, is safe for life,\" and in which, while papers increase exponentially, and knowledge grows by \"infinitesimals,\" our understanding of the world \"actually recedes.\" And, because our world is \"an interacting system\" in dynamic change, our system of scholarship \"rooted in its own sanctified categories, is, in a large part, unavailing to the needs of mankind.\" If, he concludes, we are to \"understand a newer and still evolving world; if we are to educate people to live in that world; if we are to abandon categories and institutions that belong to a vanished world as it is well nigh desperate that we should .. then knowledge must be rewritten. \"'1  The main hypothesis of the argument is that it was such a  rewriting of knowledge that constituted the founding heresy of the  original Studia Humanitatis, seen in their broader sense as human knowledge of its sociohuman world, the heresy that laid the foundations of our modern rational world, whose ordering discourses were no longer to be interwoven with the mythos and the theologos (Habermas, 1979). The term \"heresy\" is used here in the context in which it is used by the Polish philosopher, Kolakowski. He argues that all realms of culture, philosophy, as much as art and customs, exemplify a fundamental antagonism, whereby everything that is new grows out of the permanent need to question all existing absolutes, with every  current of thought that tries to break away from \"existing finalities coming in turn to establish other ones of its own,\" so that though \"every rebellion is therefore metamorphosed into a conservative  state,\" nevertheless \"each of these movements makes room for the next phase where its own absolutes will, in return, be the target of criticism.9\"2 This movement can therefore be defined as a dynamic one in which the Jester's role in the pursuit of human knowledge alternates with the Priest's role-transforming heresies into new orthodoxies, the contingent into modes of the Absolute. Hans Blumenberg illustrates this dynamic, arguing that the  movement of secularization that we know as the phenomenon of humanism, together with its \"teaching office\" (Heidegger, 1977), the Studia, can only be understood in the context of the crisis of the Late Middle Ages.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  That age was one of those epochs in human history that might be called a \"phase of objectification,\" a phase in which events and their functioning spin out of the control of human motivation and purpose. At all such times, a great counter-exertion is needed to bring these events back to serving the logic of human purposes rather than  the reverse. Blumenberg points to the signs of this objectification, to the theological Absolutism of late Scholastic thought with its positing of the Maximal God-as the Aristotelian Final Cause (Reidl\/Kaspar, 1984), rather than the image of the Caring Father-and therefore to the downgrading of human existence represented as almost the  incidental by-product of a God who created for the sake of his own  Glory. This was the hegemonic system of theology against which the discourse of Humanism and the institutionalized system of lay learning came into being as a counter-exerting force, as the Jester, pulling the \"high seriousness\" and the self-justifying pathos (Bakhtin, 1981) of heresies staled into orthodox Absolutes, down to earth  (Blumenberg, 1983). Blumenberg also makes a key comparison between the phase of objectification embodied in the theological Absolutism of the late Middle Ages and the parallel phase of our own times, one dominated by the Absolute of the Technological rationality, which, increasingly directed to the purposes of its own goal-seeking rather than by human purposes, determine Events that are once more out of the control of human motivation (Blumenberg,  1983). While it is the absolutism of this technological rationality that is leaving the humanities \"naked in the market place,\"'3 this rationality is itself only the culminating form or Summa of the new ordering (ordonnance) system of knowledge initiated by the Studia, in the overall context of the secularization of the human Subject-one whose mode of being would be no longer guaranteed by the \"higher  system\" of the divinely sanctioned mythos and theologos. While this  first secular form of the Subject has been transumed (Bloom, 1982) into differing variants-from man defined as \"natural Man,\" the  generic possessor of Reason, to man as defined since the nineteenth  century as a \"natural being\" on the analogy of a living organism (Foucault, 1973)-it is this first form of the definition of the human  being, its related \"rational world view\" (Reidl\/Kaspar, 1984), and its  ordering body of knowledge, that is now in crisis. As a result, the rewriting of knowledge for which Stafford Beer calls, and towards which our own growing irrelevance compels us, must necessarily entail the un\/writing of our present normative defining of the secular mode of the Subject.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Defining, rather than definition, because the latter does  not exist as a reality except by and through our collective system of  behaviors, systems which are themselves oriented by the ordering  modes of knowing or epistemes of each human system. And the ordering epistemes are themselves reciprocally \"verified\" by those collective systems of behaviors which Derrida defines as \"writing\" in the broader sense, that is, by our putting into play the classificatory principle of Sameness and Difference, or systemic code about which each human system-ensemble, as a trans-subject's entity, effects what Maturana and Varela call the autopoesis through which all that lives realizes its mode of being (Maturana & Varela, 1980).' For it is our  putting into play the classifying principle that bonds us as such a Group-Subject that we define ourselves as such a normative mode of  the Subject, about which each system-ensemble auto-institutes itself reciprocally, bringing that specific normative template of identity into living being. Because of the dynamic reciprocal interaction of our modes of  being\/knowing, the de-structuring of the principle of Sameness and Difference which ontologizes us as specific modes of the I\/We-in our  case the I\/We as \"natural beings\"-necessarily entails the destructuring also of the ratiomorphic apparatus or rational world view,  through which the mode of the Subject or template of human auto-  speciation,5 like the speciating template of all things living, knows the world in relation to the telos of its realization as a dynamic living entity. It is this destructuring that is implied, therefore, in the call for a rewriting of knowledge, the same destructuring\/restructuring that was effected by the great mutation embodied in the discourse of humanism and, dynamically, in the practice of the Studia. For the Jester's heresy of the Studia, as indeed of the one to which we are now challenged, should be seen in the wider context of the evolution of the cognitive mechanisms of living organisms, of a process as old as Life itself (Riedl\/Kaspar, 1984), as well as in the context of a process unique to the human. That is, it should be understood within the context of the process of human evolutionary epistemology\/modes of self-troping, in which the rupture with the higher  system of the theologos implicit in the practice of the Studia was a  mutation at the level of the cognitive mechanisms through which each  human Group-Subject knows the world, as do biological organisms, in relation to the securing of the conditions of the realization\/actualization of their mode of being (Reidl\/Kaspar, 1984): genetically constituted in the case of biological organisms, rhetorico-symbolically in  the case of humans. As Lanham points out, with the cultural revolution of the Renaissance, \"rhetorical man,\" who had been proscribed at the margins by the canonical dogmas of theologies, at last left the margins.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The delights of the original humanists in rhetoric was, therefore, something that went beyond that of a mere fad. For the humanist had glimpsed here that, contrary to Plato, man was indeed double; that he invented for himself a second self and then acted to verify this  self, acting \"from role sustaining motives in a dramatic reality\"  (Lanham, 1976). In his analysis of the role played by the discipline of rhetoric in the cultural revolution effected by the humanists, Ernesto Grassi traces the heretical role that their involvement with rhetoric, their turn  to the model of Cicero and to his insistence on the complementary nature of rhetoric and philosophy (since their common original function consisted in recognizing and \"analysing the meaning of language in the historical process\")6 played. This emphasis on rhetoric was to serve, then, like Kolakowski's Jester, as a questioning of the temporal absolutes of medieval philosophy, above all revaluing the historicity of the human community-humanitas as contrasted to divinitas-and of the knowledge to be gained from studying this  historicity, against its negative stigmatization by the then ruling order of knowledge. \"Natural Man\" and his works, as pertaining to the category of the post-Adamic Fallen Flesh (only redeemable by the rebirth in  Christian Baptism) was thereby being revalued and brought into being as the first secular definition of Lanham's rhetorical man, constituted no longer by the Divine Name, Christ, but by the Verbal Symbol Man  (Whyte, 1950). Since, as O.D. Creutzfeld points out, it is the mode of symbolic self-representation which functions as the external loop that links up with the neurophysiological machinery of the brain to  create our \"worlds of mind\" or modes of consciousness, the world views through which we know Self\/World and orient our behavior, the shift from the Divine Name to the Verbal Symbol Man-as in 1917, from Man to the Verbal Symbol, Proletarian7-was a shift to the first secular mode of human consciousness. This self-imaged, self-troping Self now came to function as the Final\/Formal cause which determined behavior for the human, as the mode of genetic speciation had determined behaviors for other biological organisms.8 For the hominid-into-human, psychogeny replaced  philogeny as the determinant of its cognitive mechanisms or ratio-  morphic apparatuses.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  And the related inheritable programs would be stored in the systems of figuration, encoded in the body of  traditions\/knowledges that would be called \"culture. \"9 There was one  central continuity, however, to which we have already referred: that  the cognitive mechanisms of human groups respond to a law that is applicable to those of all biological organisms. They therefore must know the world, too, in response to the telos of securing the conditions of the subject's realizing its system-specific mode of being, as imagined in its governing template of identity. And this law  applies whether one was an Iron Age Bahaya, now defined through the royal, rather than the local Bacwezi template of identity; or Galileo's Aristotelian antagonists who insisted on the if\/then linear abductive inference of the founding structural opposition (the perfection of the lunar realms, the degradation of the terrestrial) on which the Christian medieval template had been based; or the naturally noble monarchical Subject, Othello; or the Puritan Southern slave-owning \"empirico-transcendental man\" (Foucault, 1973) that was Faulkner's Henry. And they would therefore each act upon the world in the mode of the template's categorical imperative, obeying its related proscriptions and prescriptions, so as to fulfill the rolesustaining motives of the mode of the self in a \"dramatic reality.\" Paolo Valesio has pointed out, in the context of his proposal for the disciplinary matrix of a new rhetoric, that all human orders are held together by specific macro-organizing topoi which are the necessary conditions of our shared and common human nature(s) (Valesio, 1980).10 And since meaning preexisted the utterance of the first word\/speech, we must recognize the complex relation of language to pre-linguistic biological processes. The argument here is that the link of continuity\/discontinuity is the shift from genetic to rhetorical-figurative systems of group bonding, with the latter carrying affective loadings from the former and the inheritable programs which determined cognition\/behaviors being transferred to the governing systems of figuration called religion. For it was this system of figuration which now took the place of the environment of its rewards\/punishment sanction systems, replacing it with the sanction systems of the gods and then of the Single God.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  First Whyte and later Habermas pointed to a formative  tendency or evolutionary process at work which correlates the evolution of human cognitive mechanisms with the evolution of human modes of co-identification, from the relatively closed aesthetic orders of the particularistic Paleolithic groups to the increasingly more inclusive ones. Monotheism, White argues, marked a high point in the evolution of human cognitive mechanisms. Once a Singie Divine Name had been postulated, the human could now come to know the world in relation to a single universal correlator; the concept of uni-  versality could then itself come into being. But because the varying monotheisms had come into being amongst different peoples in response to different needs, their universalities remained finally parti-  cularistic. What was needed was a single defining impersonal principle which would take the place of the Divine Names; of their specific conceptions of Life\/Death; of the absolutization apparatus of the higher sanction system of the mythos (the Logos of Paleolithic systems of identity) and of the theologos: that of creedal systems of  identity. What we refer to as the founding Jester heresy of humanism and the Studia Humanitatis is sited here. For as Riedl\/Kaspar point out, once humans had broken with genetically sanctioned inheritable  programs and cognitive mechanisms, a risk factor had now entered the evolutionary processes of life. This was due to the fact that \"our  conscious cognitive powers,\" because they were the most recent superstructures in a continuum of cognitive processes contemporaneous with the emergence of life (with human reason, as a latecomer, being the least refined and tested against the real world), the  potential for self-deception and the dysfunctionality of human world  views could spell disaster in the context of humans' increasing  mastery over the environment.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The sanction system of religion had, therefore, been iso-  morphic with the hominization process of the human itself. It enabled  this new mode of being, the bearer of self-consciousness, to win its  way from more closed to more open programs of co-identification and  of cognition, handing down what it had won, as Gowlett notes, as a human cultural heritage in the long perspective of the processes-many terrible and idiotic as Nietzsche notes, yet con-  stituting that \"morality of mores\" by which the human made himself  calculable-of the human's collective self-making (Gowlett, 1984). The heresy of the Studia was, therefore, to lie in its break with the  higher system of divinely sanctioned identity and with its absolutized world views or ratiomorphic apparatus; in its release of rhetorical man  from the margins, orienting his behaviors by a new ordering secular Logos, the Natural Logos of Humanism which took the place of the Christian Theologos. A co-Christianity was made possible by the central Figure\/Image of a new baptismal birth in which Christians were reborn in the spirit, leaving behind the \"natural man\" of the Flesh, itself degraded by the Original Sin, inherited by all mankind from Adam's Fall. This bonding topos of the medieval Christian Group  Subject was sanctioned by \"the authoritative light of the  suprasensory\" (Heidegger, 1977). So, too, was the \"inheritable program\" of stored pre-judgments based on the interpretation of the Bible and on canonical dogma as well as on the overall system of knowledge of Christian medieval society. The normative order of knowledge, which was embodied in  theology, expressed the founding structural opposition generated from the bonding topos of the order: the opposition between the category of the \"Spirit\" (the new \"life\" to which one attained, pari passu, with Christian baptism) and the \"Flesh\" (the life of unregenerate \"natural\" man before rebirth, a life that was now \"death\"). According to the inferential logic of its system of figuration-Bateson's abduction schema, Sperber's symbolic mode of knowledge, a mode largely expressed through the right hemispheric functioning of the brain1'-the Spirit\/Flesh order of value was also expressed in a parallel order of value: between theology-as knowledge of things Divine, celestial, of the category of the Spirit-and lay knowledge, the knowledge carried by the laity-as knowledge of the category Flesh, i.e., of the socio-human world whose Works were the Works of natural unregenerate man, knowledge, then, that was marginal, secondary and partaking of the inferiority of all things terrestrial.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  For the Christian principle of spiritual Sameness and fleshly Difference-in the same way as traditional Neolithic orders had made use of what Levi-Strauss calls the \"totemic operator\" of the stable system of differences of the animal species to at once conceptualize (Levi-Strauss, 1960) and absolutize the principle of Sameness\/Difference encoded in their bonding topoi-here made use of the represented planetary system of Sameness\/Difference to at once conceptualize and absolutize itself.12 Verified in Christian Ptolemaic astronomy, this planetary grid, as a represented physico-ontological difference of substance between the degraded fallen category of the earth, subject to the corruptibility of material generation, change and decay (as contrasted to the incorruptible perfect lunar world) expressed a Divinely caused principle of Christian Sameness (the realm of the perfection of the Spirit), and of Difference (that realm which marked the Negation that was Natural man, unregenerate). This structural opposition then came to function as the ordering principle of the status-organizing processes of medieval societies. It determined the Clergy\/Laity order of value, also expressed in the represented difference of substance between Noble Blood and non-noble, which underpinned the system of castes\/orders of the feudal system;  just as, at the same time, the Christian medieval template of identity  which had become fused and interwoven with the Feudal mode of the  Subject-its aristocratic conception of Life\/Death-psychogenetically determined the ratiomorphic apparatus of the order. Peter Winch points out that all human groups institute their social orders about specific conceptions of \"Life\/Death\" which take  the place of their biological life, orienting their behaviors. These conceptions in all human orders are encoded in founding structural oppo-  sitions, defined by Uspenskij et al, as the inclusion\/exclusion of an-  tithesis, by and through which alone human orders are enabled to define themselves into being, each type of culture having to create its \"corresponding\" type of \"chaos\" which \"represents\" just as active a \"creation\" as that of the order itself (Uspenskij et al, 1978). All founding oppositions, such as that of the Bakama\/Bacwezi cults of the Bahaya peoples of Iron Age East Africa or of the lunar\/sublunar of  Galileo's antagonists, express the fact that human as organized  orders not only struggle against the opposing \"chaos,\" but have need  of it as well, not only destroying but also continually creating it  (Uspenskij et al, 1978). For it is the specific \"type of non-culture\" which enables its self-definition as that specific type of culture.3 Hence the oppositions, seen from inside cultures as culture\/nature, done\/undone, raw\/cooked, or, as in our case, Spirit\/Flesh or  Civilized\/primitive, are oppositions through which the order\/chaos,  entropy\/ectropy, seen from a point of view external to the domain of the cultures, are enabled to function as the order-informing systemic code or replicator unit (Dawkins, 1983). Others, like Hayden White, have followed upon Levi-Strauss's  analysis of these oppositions, which in all cases express the con-  ception of Life\/Death.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Peter Schmidt, in his study of the corpus of  myths which reach back to Iron Age East Africa, has shown how the  triumph of the mode of organization of a new royal dynasty over that  of the local indigenous peoples organized about the spirit-medium cults of the Bacwezi, the canonizers of the local template of identity, only fully succeeded when, as the narrative representations of the myths reveal, it had managed to transform the conceptions of Life\/Death, Order\/Chaos, with its newly created Bakama cult coming to signify Culture\/Safety and the Bacwezi coming to be figured as a \"dangerous uncivilized force\" against which the royal order needs to confirm its legitimacy as the bearer of \"Life\" to Bacwezi \"death.\" In the shift, the local template of identity has been made into the Deilos to the new Agathos of a royally mediated identity (Schmidt, 1978). '14 The title of this paper, borrowed from the multi-level meanings of Bishop's fine poem, here refers to the fact that once these structural oppositions have been put in place, they must then function according to laws applicable to all human systems, from that of the royal dynasty of Iron Age East Africa to that of Christian medieval Europe or to that of our own. By marking the mode of Desire-the desire of Life and of Aversion to Death-these structural oppositional codes function to orient the parameters of motivations\/behaviors of the order. They are thus the very condition of the collective behaviors through which each human system realizes itself as such a system. The basic law of their functioning must therefore be the interdiction of any ceremony which might yoke the antithetical signifiers and breach  the dynamics of order\/Chaos, through which the order brings itself into living being; a dynamics which functions like the code of the  presence\/absence of butyric acid for the tick, for example, to prescribe the seeking\/avoiding behavior through which one realizes  oneself as one or the other form of the self-troping rhetorical human. The ceremonies therefore cannot be found for the doctors of  philosophy to wed the Earth to the Moon, for Othello to remain wedded to Desdemona, for Bon to marry a \"negro,\" since the group Subjects to which they belong are bonded by a system of meaning or  semantic charter (Maranda, 1980) which determines the meaning of  their meaning1 on the basis of these oppositions (Derrida, 1976). For it is these behavior-orienting oppositions which, through the mediation of their connotative system of good\/evil, induce stable and shared  desiring\/aversive endogenous waveshapes in the brain  (Thatcher\/John, 1977), and constitute the morphogenetic fantasy or mode of the cultural imagination through which the group Subjects are led to imagine themselves'16 as such a Group Subject: one which, internally mediated by these structural oppositions and their related imagery\/figuration system, is defined by the fact that its members  participate in the same mode of mimetic desire (Girard, 1965) and of  aversion (Fanon, 1964).\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The order\/chaos figuration of a physico-ontological principle of Sameness and Difference was the axiom about which the mode of  cultural imagination, the status-organizing process, the aesthetic and the conceptual ordering rational world view of Christian Medieval world, was founded and represented as divinely caused\/ordered. The lay knowledge of Natural Man of the human historical world belonged to the category of \"chaos\" which defined the order as such an order. The heresy of the discourse of Humanism and of the Studia lay in their deconstruction of this principle or systemic code, by the Studia's very coming into being as an alternative system of learning whose referential authority was no longer that of Christian theology. The heresy was not anti-christian as Kristeller points out. Many, like Erasmus, only wanted to get back to a reading of the original text, uncontaminated by some of the later interpretations, back to the simple piety of the early father and to the original Greek texts believed to be able to elucidate pristine meanings. Yet it was here that a mutation occurred in that a reversal had taken place. Instead of subordinating the lay activity of learning to the authority of theology, theology was now being submitted to the authority of the lay activity of textual and philological scrutiny in the name of the accuracy of historical meaning. The category of the celestial was being submitted to the activity of the humanista, bearers of the inferior mode of knowledge, a mode which had now begun to constitute itself as a new  ordo or studium.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Even more, a new higher sanction system, one based on the self-correcting processes of human knowledge was here being proposed and put in place, in the context of a normative knowledge whose axiom, as Waterston points out, had been that God had ordered the world according to certain principles, and the role of fallen man was merely to decipher these principles and abide by  them, but not seek to question and have knowledge of things celestial which, unaided, his corrupted human knowledge could not  encompass. Indeed, according to this axiom, fallen man could not hope to know the laws by which God had ordered his Creation. '7  Neither could the Works of Man as a creature of the degraded Earth  be of efficacy to the true telos of the Christian, that of the original humanists lay in their use of the Back-to-Rome\/Greece movement in order to revindicate this Natural Man, using the auctoritas of their non-Christian legacy of the Graeco-Roman tradition of thought and literature to project an alternative mode of life and being. And the revindication of the mode of learning of fallen Natural Man, of his  Works, was effected by a counter-system of figuration, in which, through the great writings of the ancients, one underwent a new Counter-Birth, a renaissance, in which one now became not Christian, but more humane\/rational, shifting, in this central re-figuring, the  conception of Order\/Chaos, bringing in the first form of a secular imaging of Life\/Death. The return to the ancient models, the founding basis of the  Studia, even their borrowing of the term, Studia Humanitatis, from the  Romans (who had used it with the same valorizing intention), was, at  the level of figuration, a return which, so to speak, gave to the secular-  izing European man his Scriptures and \"patristic\" literatures, as a  counter-exertion which enabled the projection of Maximal Man over against that of the Maximal God. Here the very implementing of a lay  system of knowledge, the knowledge of Natural man, and of his arts  of rhetoric, philosophy, profane literature, as a valorizing activity in its  own right, constituted, before Copernicus, a breach of the physico-  ontological principle of Sameness\/Difference. It was also a breach  with the principle of Divine Causality which this latter principle had encoded, and by this, a rupture with all other human cognitive mechanisms hitherto sanctioned by the \"authoritative light of the  suprasensory.\" The word humanista coined on the model of legista (since the  study of law based on the revised Justinian codes had been the first  order of knowledge to begin to claim autonomy from the referential authority of theology) was therefore itself the expression of this heretical violation of the earlier order of value, in which knowledge of the Works of Natural unregenerate Man was, relatively, the \"chaos\" to the true knowledge or the knowledge of the Divine.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The rewriting of knowledge of the Studia was therefore a counter-writing to the order of knowledge of the clergy, the new knowledge in whose context a new template of Identity, that of Natural Man, was being brought into existence in the new narrative representations of Renaissance Europe. In whatever forms, whether humanist or platonic, the common thrust was directed towards the valorization of the new emerging sense of self, of that which defined itself no longer as Spirit but as Natural Reason carefully cultivated. Hence the motif of the \"dignity of Man\" as a counter to the motif of fallen man;'8 and the valorization by the original humanists of the practice of rhetorics and of their worship of style, the style by which the new secular mode was writing itself into being (Lanham, 1976). Walter Ullman links the origins of humanism and of the Studia to the political humanism of the Middle Ages, which accompanied the rise of a new socio-historical force, that of the new men of the City States, in the context of the beginning Urban Commercial Revolution. These new men, having no legitimate place in the feudal Christian order of things, wanting to be citizens with political rights, struggled for a revaluation of Natural Man in political terms. Neither nobly born nor peasant, these freemen, without a lord, came to define themselves by the Verbal Symbol \"man\"-in opposition to \"noble\"-universalizing it, in opposition to Christian, as the first non-religious definition of the human that was ostensibly universally applicable. Since the Christian Word was interwoven with the Feudal category structure or representational system, their valorization of Natural Man logically moved outside the Christian schema, both in political and commercial terms, as the new socially mobile and rapidly enriching new men also began to detach allegiance, in key aspects of their lives, from the ordering religio-Christian schema (Ullman, 1977). In other words, there was a conjuncture in which an overall challenge was being mounted to the founding structural opposition of the order, absolutized by the instituting analogy (Bateson, 1979) of a divinely determined physicoontological principle of Difference, a difference in substance between the degraded matter of the earth and the crystalline perfection of the lunar and supra-lunar realms.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Here one might speak of the figurative impact of the Studia, its counter-figurative schema, of a rebirth of Man through profane Works, one that spoke of a new kind of freedom, that of human reason, and of its power to gain knowledge of all things including things celestial. As  Hubner points out, the epistemological break of Copernicus can only  be understood in this wider emancipatory context of the new ordering discourse of humanism \"which aims at bringing man closer to God,\"  thus at once contradicting \"Ptolemaic astronomy for which the earth is coincidental with the place of a status corruptions,\" contradicting, then, an \"astronomy tied to the theology of its times.\" That Copernicus was himself a bearer of this new discourse and its telos can be seen in the fact that when faced with having to eliminate a contradiction-that between \"the humanism of his time and the existing astronomy\"-he sought to resolve the contradiction in a way  favorable to humanism,\"'8 even if he had to do this with difficulty, with  new problems arising from his resolution. As Hans Jonas has pointed out, the really revolutionary movement of the Copernican break was his revelation that Nature offered no empirical support for the represented physico-ontological principle of Difference that, in fact, as Galileo's telescope was to verify and Newton's equally applicable laws to confirm, the earth was a star, and the stars were earths. '9 Humanism and the Studia's projection of Natural Man with his Natural Logos was, therefore, as Hubner notes, part of a comprehensive thrust in which \"the entire world had begun to transform itself\" pari passu with the \"discovery of new continents and new seas,\" which was to bring in changes that shook the hitherto entrenched \"sacred\" structures of society, as the secularization of the State and the printing presses and the rise of the middle classes destroyed the \"old hierarchies and privileged classes. \"'20 Out of this train of events, a mutation of the human cognitive mechanisms was set in motion, one in which the idea rose \"that the Divine Creation,  like the construction of a great cosmic machine had to be understandable by and through human reason\" (Hubner, 1983). It was in the context of this special and overall mutation of the cultural imagination of the human, that the discontinuity that would constitute the new order of the natural sciences had begun, and that the later technology of Galileo's telescope had its origins. Central to the comprehensive attempt to bring men nearer to God, to breach the interdiction of ceremonies between the  Agathos\/Deilos categories of the celestial and the terrestrial, was to be the rise of the vernacular narrative representations, paripassu with  the Studia's turn to the ancient models and its valorization of profane letters and the auctoritas of their deployment-their valorization, then, of the works of the human imagination vis a vis the Scriptures as Divine Revelation.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Even though the early humanists would mainly write in Latin, the valorization of profane letters was to contribute to the breaching of another order of value, that between Latin as the language of the Church and the vernacular. Already with Dante the vernacular had been canonized poetically. But with the Renaissance, the earlier founding works began to be drawn together, as a mutation now took place. This was to be the shift out of the religio-aesthetic ordering of the modes of the human imagination to the purely aesthetic ordering, with the rise to centrality of the new profane narrative representations that we have come to call \"literature\"-a secular figurative order that would no longer function as an adjunct and contestatory twin to the theological system of figuration but would gradually become hegemonic, taking its place. Hans Blumenberg has pointed out that the counter-exertion to bring men nearer to God had already begun in the fourteenth century with Nicholas of Cusa, who went as far as was possible to re-form the mode of thinking within the traditional schema, to re-translate its internal logic.21 His projection of the dialogue figure of the layman wiser than the theologian, within the antithetical concept of wise ignorance, was paralleled by ongoing transformations in the systems of figuration of the narrative discourses, by the projection of carnivalesque upside down figures. Bakhtin points to the existence in these modes of a dialectic of rigidification and rupture, beginning in the Middle Ages with the codevelopment of \"forms of high literature\" together with the  contestation of \"low folkloric and semi-folkloric forms\" that tended  towards satire and parody, with the latter, rising from the dregs of society and giving rise to the projection of subversive \"prominent types\" such as the rogue, the clown and the fool. These types, while they were to be central to the later development of European literature, were also types whose \"images go back even further... into the depths of a folklore\" emerging from the represented \"chaos\" against which the vertical medieval order instituted itself as such an  order. For what Habermas sees as the coexistence of an evolutionary  process based on Piaget's analogy of the ontogenesis of the child-in  which the human, as it moves into more widely inclusive aesthetic structures, begins to divest itself of the centricities of the cognitive mechanisms of the closed aesthetic orders of more local modes of  being-was quite clearly here at work in the evolution of precisely these aesthetic-affective orders which program the limits of coidentification (Habermas, 1979), by means of systems of figuration or group-boundary maintaining imagery systems.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  These newly projected figures served here as the subversive detonating force that began the destructuring of the boundarymaintaining system as it was imagined\/experienced by the Christianmedieval Group-Subject. And they initiated that transformation of the \"imagery system\" of the governing religious order of the imagination, replacing it at the public level with the \"figuration Work\" of that ordering of the now secular imagination that can be described as the function of \"literature\" only if we describe the \"imagining Subject\" as a function of that ordering. The psycho-aesthetic structures that sustained the increasingly ossified Christian-feudal order of things was the target of these parodic anti-types erupting from the \"chaos\" of the margins with their ludic weapon of laughter. Their form of the Jester heresy lay, Bakhtin argues, in the new right that they claimed to be \"other\" in the feudal world, and \"not make common cause with any single one of the existing categories,\" since \"none of these categories suits them.\" Their parodic laughter and stance of \"not understanding\" the social  logic\/illogic of the existing structures, begins to make visable the  \"vulgar conventionality\" that deformed human life in the decaying feudal structure, a structure which canonized its own rigidified order in the context of a new environment in which both its epistemic and aesthetic orders were anachronistic and dysfunctional. The resulting falsehood and duplicity of the governing mode of the cultural  imagination led to a situation in which real life, denied creative imaginative directives, became \"crude and bestial\" (Bakhtin, 1981). Against this falsehood that had \"come to saturate all human relationships,\" fabliaux and Schwanke satiric verses, parodic cycles in the folk traditions, began to clear the ground, as new forms such as the  novel, with the antitypes of rogues, clowns, and fools as the major  protagonists, carrying over the original carnivalesque inversion  function, breached the interdictions, the vertical structuring principle,  by parodying the \"high seriousness\" of its self-justifying discourse. The theological absolutism of the Late Middle Ages, which had  taken the \"simple executive solution\" of repressing any awareness that \"causes come to us from many sides\" and that humans live in a  \"multi-linear, multi-reinforcing causal world\" (Riedl with Kaspar, 1984), had opted for the solution of a single original Cause, made into the Final Cause, of which the Maximal God was the exemplar.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  This led to an orienting \"practico-theoretic logic\" of extreme idealism which negated the existence\/validity both of the temporal material world and of the complementary nature, along with the \"spiritual,\" a negation of their causal inputs (Riedl with Kaspar, 1984). Over against the \"overvalue of this representation\" (Ricoeur, 1979), the projection of the  figures of clown\/rogue\/Fool now paved the way for an inversion, for the novel's appropriation of that \"spatio-temporal world,\" the world of \"Natural Man,\" the world in which, consequent with this mutation in  the figuration of Self and World, as Hubner writes, \"America was  being discovered, a sea route to India opened up, new fields of the natural sciences and mathematics were being established. And the way was being prepared for an utterly new way of seeing. \"'22 It was to be an utterly new way of feeling, of imagining Self and World, and a mode of imagination that would no longer find its referential figurative auctoritas in the great religious schemas and symbols, but rather in a new referential figurative auctoritas, that of the fictional poetic\/dramatic schemas of the phenomenon we call \"literature.\" Literature in its new role\/ordering function, and the Studia were, therefore, to be twin forms of each other, forms through whose internal mediation, the human, who had hitherto imagined its mode of being through mythic\/theological figurative schemas, would now come to imagine itself-and to act upon the world in the mode of that imagination-through the great poetic schemas which refigured and configured the first form of the secularly chartered human being: the world of its order of things. For it is not, as Marx thought, the Earthly Family that holds the secret of the projection of the Holy Family. It is, rather, the reverse. The cap and bells of Bakhtin's parodic figures was to transform the modes of projection\/figuration of Self\/Group self and, therefore, of the mode of Not-The-Self, the entropic Chaos to the order of  the dominant model of Being.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  They were, then, to refigure the aesthetic order, expanding the limits of the boundary-maintaining system of the We, and its new spatial extracultural space (Uspenskij et al, 1978). In this they were performing an aesthetic function analogous to that of the original humanists, who, in turning to the auctoritas of their pagan legacy to legitimate the heresy of the study of profane letters which no longer found its sanction system in theology, but rather in what the Spanish humanist, Sepuilveda, called the purely \"literary,\" were to transform the mode of functioning of human cognitive mechanism: our aesthetemes, to coin a phrase, and  our epistemes. Once the authoritative light of the suprasensory had been displaced, something, as Heidegger points out, had to take the empty  place of its vanished authority. Here the authority of Reason,23 the  Reason coded by the Natural Logos of humanism based on the explanatory principle of a Natural Causality verified by the truth of empirical reality, moved into the place of the vanished authority. And the configured macro-concept of Natural Causality now took the place of Divine Causality as the Original Cause, the extra-human source of the new principle of Sameness and Difference, expressed in a new structural opposition, that of Reason and its Lack-state. A central rhetorical strategy (analyzed by Valesio in another  context as that of the topos of iconicity, a topos which is able to yoke a member of a class with the class of classes, to configure the part of the whole)24 now projected the image of the new men as the image of  man-in-general. It also projected the ratiomorphic apparatus or mode  of reason, which functioned to orient the autopoesis of this new mode of human being, as isomorphic with reason-in-general, with the reason of Nature herself: nature \"as life. . bursting forth with existence\" (Valesio, 1980). It was a reason ostensibly attached to the figures of the mercantile upper bourgeoisie and newly landed gentry.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  In fact, it was the mode of reason of the template of identity of Natural Man, the first self-representation of the secular human, one which  would absolutize itself no longer through the auctoritas of the gods but through that of a Mono-Logos\/Reason, which stigmatized any alternative mode of the Logos\/Reason as the Lack-state of its reason and, therefore, of Reason-in-general. A shift now took place. Since physical nature, knowledge of which had been freed from serving a verifying function in the order\/chaos dynamics of the system-ensemble, another mode of nature, human nature, would now be installed in its place. The representation of a naturally ordered distribution of degrees of reason between different human groups enables what might be called a homoontological principle of Sameness\/Difference, figured as a by\/nature difference of superiority\/inferiority between groups, and could now function tautologically as the verifying proof of an infrasensorily ontologized,25 naturally caused status-organizing principle, a principle based on differential endowment of Reason (rather than of Noble Blood) and verified dynamically in the empirical reality of the order. The figuration of this reason, as reason-in-general, was now effected by a series of great internments (Foucault, 1971). First, that of the New World peoples in encomienda systems. Here began that reenactment of Ptolemaic astronomy which Foucault analyzes in his book dealing with the internment of the Mad in seventeenth-century France: that of a new order of discourse whose function was now to  encode the homo-ontological principle of Sameness\/Difference and the basic structural opposition of order\/chaos. For if, as Foucault argues, a society's self-imaging or identity rests (as Said explains  further) upon its detachment from what was not itself, the \"rational\" discourse of every order must function \"lawfully,\" in response to the  governing system of figuration generated from the structural opposition of the imaging of Self and Other, to domesticate the repre-  sentations of the Other, whose mode of difference alone enables the mode of Sameness, expressed in the bonding topos of the order, to be  imagined\/experienced as a mode of conspecific sameness.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  In other words, the representation of the Other must function in a rulegoverned manner to domesticate its figuration-Work to the exigencies of the ordering made of discourse which charters the mode of the Self\/Group Self. Hence the humanist Gin6s de Suptilveda was the first to reenact in humanist rather than in theological terms,26 the function of Ptolemaic astronomy, and to fit the representation of the New World  peoples to the exigencies of a discourse whose function was to  legitimate their internment, on the basis of a projected by\/nature dif-  ference which had ordained that they should be \"natural slaves.\" His  \"proofs\" of this were taken from the empirical reality of the cultural differences of two vastly different modes of life, a difference which he defined as a hierarchy, coding his symbolic mode of logic in a series of rhetorical antitheses. The New World peoples were homunculi (little men) when compared to the man, the magnanimous Spaniards; as women to men\/children to parents\/monkeys to men. The proof of this was that they lacked Letters and written monuments to their history. The fact that they offered humans as a sacrifice to their gods proved that they Lacked Natural Reason.27 Uspenskij et al point out that the expansion of any sphere of cultural organization leads to the expansion of a sphere of nonorganization. If the \"narrow world of Hellenic civilization\" had its cor-  responding narrow sphere of encircling \"barbarians,\" the spatial growth of ancient Mediterranean civilization was accompanied by the  growth of the \"extracultural world.\" With the shift of Mediterranean man into a planetary dimension, the Greek Barbarians would be refigured as the homunculi-natives, defined not by their lack of the Greek mode of order, but by their Lack-state of the first form of  secular human reason, projected as isomorphic with Natural Reason: as the irrational Chaos, then, to the naturally rational order of the  human.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The internment of the New World peoples would be followed by  that of the African lineage groups, homogenized under the commercial trade name of \"negro.\" This objectification of the human was justified at first in religious terms as divinely caused by the Curse  placed on Ham. Soon the shift would be made to the humanist con-  cept of Natural Causality, of a by\/nature determined difference of reason, in which the African mode of cultural reason was seen as a  non-reason; and his internment in the plantation system as slave labor, as being carried out for the purpose of rationalizing him\/her as an inferior mode of being in need of rational human baptism. The great internments of the encomienda\/plantation archipelago was followed in Europe itself, within the internal logic of the same ordering discourse, with that of the Mad as the opposed icon of  that Defect of Natural Reason, which mnenomically equated the  secular humanist mode of reason with reason-in-general.28 Interned  with the mad were also the jobless and the poor. The three categories,  the homunculi\/native\/negro, the Mad, the poor and the jobless, functioned to express what might be called a ratio-ontological principle of Sameness and Difference: to express, and empirically  verify the rhetorical macro-Figure of a Natural Causality which differentiated human groups along a continuum of different degrees of rationality, a differentiation which was part of a universal law of Nature beyond human control.29  Natural Reason and the degrees of its possession-and this was verified by one's position in the social structure-functioned, therefore, as Noble Blood had done, as the criterion for the status stratigraphy of the order. In this order of figuration the \"negro,\" al-  though equated with the missing link between Man and Ape, was made, in the Linneaan system, the Negative Order on the basis of his  lack of Reason. While his Lack of Reason excluded him from  governing himself, as the European could, he was nevertheless incorporated into the same table of being, the schema of the structural op-  position between Reason\/Lack-of-reason and of the discourses generated from its related Classical episteme.30 A mutation would occur, however, with the transumption31 of the principle of Sameness\/Difference to a new bio-ontological form. In this new form that would underlie the expansion of the Industrial Age, the figure of Chaos would no longer function as the Icon of a Defect of Natural Reason, since with the rise of purely middle class culture, the Defect or Lack-state of the Fullness of being was now to be that of the Lack of a mode of human being, the Indo-European, now made isomorphic with Being human itself.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  As Mosse shows, in his book on the Nazi holocaust and on the  enabling discourses that made the holocaust possible, the Figure of the Semite and the \"Negro\" now in the context of this shift, functioned as the Chaos to the new Norm of the human; as the  negative antitypes to the \"aesthetic criteria\" of the Greeks, whose  classical sculpture was now made isomorphic, phylogenetically  speaking, with being human. And an entire range of the  heroes\/heroines, based on the equation made by the pseudoscience  of phrenology between the Ideal external physiognomy and moral innocence and moral evil, from Ivanhoe to Star Wars, was now being put in place. In the overall range of this bio-aesthetic system of figuration, the Negro\/Semite's physiognomy would now come to be experienced as equated with moral evil (Mousse, 1978) and, therefore, lynchable,  exterminable.32  For with the rise and expansion of the Industrial Age and the rise to hegemony of the groups who spearheaded the Industrial Revolution, a transumption of humanism's \"natural Man\" took place. The new template of identity was based on the imagining of the Self\/Group-Self on the analogy of a living organism. As the State became a service function of the new regulatory activity of the economic life-the expression of the conception of Life\/Death on the analogy of a biological organism, impelled by the reflex impulse of hunger and of self-preservation-33-the former Reasons-of-State political Logos now gave way to a new Reasons-of-the-organiccommunity Logos whose structural oppositions governed the organization of knowledge in the new episteme or ratiomorphic apparatus. It was a Logos in which the Indo-European mode of human being was canonized through the discourse of philogists and literary scholars, such as Schlegel and his pupil Lassen,34 as the expression of the most perfect \"organic\" realization of that biogenetic elan vital that was the superior\/will being of its peoples. This was incarnated in the great Aryan\/Sanskrit language family that was as unique to their being as was the epic literature which distinguished itself and them from the more rootless egoistic, non-epic-owning Semite Other.35 At this level of Otherness the \"negro\" was not even considered, since he was not imagined even to have languages worth studying, nor to partake in culture, so total was his mode of Nigger Chaos. The social behaviors that were to verify this topos of iconicity which yoked the Indo-European mode of being to human being in general, and the new middle class model of identity to the exemplary Norm of this new \"empirico-transcendental doublet,\" man (Foucault,  1984) (imagined\/experienced as if a \"natural being\"), would be carried  out by the complementary non-discursive practices of a new wave of great internments of native labors in new plantations orders (native wage labor), and by the massacres of the colonial era36-leading logically to their Summa in the Auchwitz\/Belsen and in the  Gulag\/Cambodia archipelagoes.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Through all this, different forms of segregating the Ultimate Chaos that was the Black-from the apartheidt of the South to the  lynchings in both North and South, to their deprivation of the vote, and confinement in an inferior secondary educational sphere, to the logic of the jobless\/ghetto\/drugs\/crime\/prison archipelagoes of today-ensured that, as Uspenskij et al note, the \"active creation\" of the type of Chaos, which the dominant model needs for the replication of its own system, would continue. It thus averted any effort to find the ceremonies which could wed the structural oppositions, liberating the Black from his Chaos function, since this function was the key to the dynamics of its own order of being. As Las Casas had argued against Sepilveda-when refuting the latter's humanist theory that human sacrifice carried out by the New World peoples was proof of the fact of their Lack of Natural Reason and, therefore, that it was just to make war against them to protect the innocents who were sacrificed and to take over their territory-\"to sacrifice innocents for the good of the commonwealth is not opposed to natural reason, is not something abominable and contrary to nature, but is an error that has its origin in natural reason itself. \"37 It is an error, then, not in the speaking\/behaving subjects, but in the ratiomorphic apparatus generic to the human, the cognitive mechanism that is the \"most recent superstructure in a continuum of cognitive processes as old as life on this planet,\" and, as such, \"the least tested and refined against the real world\" (Riedl\/Kaspar, 1984). And it is only with science, as Riedl and Kaspar (quoting Roman Sexl) observe, that there is ever any true \"victory over the ratiomorphic apparatus\"-such as that of  Galileo's and his telescope over the abductive logic of the if\/then  sequence of inference dictated behind the backs of their consciousness to the Aristotelian doctors of philosophy as the speaking subjects of the Christian-medieval system ensemble. II. Re-enacting Heresy: The New Studies and the Studia as a Science  of Human Systems  The main proposal here is that the calls made in the 1960s and  1970s for new areas\/programs of studies, was, although non-  consciously so at the time, calls which re-enacted in the context of our times a parallel counter-exertion, a parallel Jester's heresy to that of the Studia's. But because of our non-consciousness of the real  dimensions of what we were about, we asked at first only to be incorporated into the normative order of the present organization of knowledge as add-ons, so to speak.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  We became entrapped, as a  result, in Bantustan enclaves labelled \"ethnic\" and \"gender\" and\/or  \"minority studies.\" These enclaves then functioned, as David Bradley notes, inter alia, to exempt English Departments from having to alter their existing definition of American literature. Even more, these enclaves functioned to exempt the callers for the new studies from taking cognizance of the anomaly that confronted us, with respect to a definition of American literature which lawlikely functioned to exclude not only Blacks, but all the other groups whose \"diverse modalities of protest\" (Detienne, 1979) in the 1960s and 1970s had fueled the call for new studies. Thomas Kuhn points out that the recognition of anomalies is the first step which leads to changes in the paradigms of the natural sciences 38And in the same context the linguistic scholar Whatmough  has argued that human observers are parts of the cosmos which they  observe, that since all the knowledge that orders our behavior is  gained from these human observers, such knowledge must either be  solipsistic or reduce man to a part of his environment. This knowledge is, therefore, not to be trusted unless the observer in his role as knower finds the means to convert himself into an \"external  observer.\" Among the means which he proposes is the taking of the \"all pervading regularity noted in language,\" rather than the speaking subject, as the object of investigation. And these regularities appear \"all along the road through the heirarchy of language, from everyday chit chat through law, and religions, liturgy and homily, poetry, 'literature,' science and philosophy to logic and mathematics. \"39 These regularities, he goes on, will enable the knower to make use of  what he calls the mathematike techne, which enables her\/him to treat  languages like chemistry, for example, according to their grammars of regularities, as if man, i.e.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  the speaking\/thinking\/representing subject, \"did not exist at all.\" One problem remained, however: that of the perception of these regularities. For, because the regularities are, so to speak, \"built in\" to the discourses, the users of these discourses cannot normally isolate the existence of these regularities (Whatmough, 1967). And, as Foucault reminds us, this problem is applicable not only for the boundary maintaining \"true discourse\" of the positivism inherited from the nineteenth-century episteme, but also for the eschatology of positivism's counter-discourse, Marxism, both generated from the same ground (Foucault, 1973) of a materialist metaphysics, and each dialectically the condition of the post-atomic dysfunctional sovereignty of the \"grammar of regularities\" of the  other. The anthropologist, Legesse, has pointed to the extent to which we are trapped in the ordering \"categories and prescriptions\" of our epistemic orders. He notes, however, that the liminal groups of any order are the ones most able to \"free us\" from these prescriptions, since it is they who existentially experience the \"injustice inherent in structure\" (Legesse, 1973), that is, in the very ordering of  the order which dictates the \"grammar of regularities\" through which the systemic subjects perceive their mode of reality as isomorphic  with reality in general. The normative categories of any order-for  example the aristocratic category of European feudalism-are normative precisely because the structure of their lived experience is isomorphic with the representation that the order gives itself of itself. The liminal categories like those of the bourgeoisie in the feudal order of things, on the other hand, experience a structural contradiction between their lived experience and the grammar of representations which generate the mode of reality by prescribing the parameters of collective behaviors that dynamically bring that \"reality\" into being.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The liminal frame of reference, therefore, unlike the normative, can provide what Uspesnkij et al call the \"outer view,\" from which perspective the grammars of regularities of boundary and structuremaintaining discourses are perceivable, and Whatmough's \"external observer's position\" made possible. What the calls for New Studies at first overlooked, however, was precisely the regularities which emerged into view in the wake of the \"diverse modalities of protest\" whose non-coordinated yet spontaneous eruption now brought into unconcealedness-not only the lawlike rule-governed nature of the exclusion of the diverse protesting groups\/categories as group-subjects from any access to the means of representation, but also the regularities of the exclusion of their frames of reference and historical\/cultural past from the normative curriculum, an exclusion so consistent as to be clearly also rule-governed. This consistency was reinforced by the emergence of the equation between the group\/categories excluded from the means  of representation and the ratios of their degrees of socio-economic  empowerment\/disempowerment in the world outside. The dynamic presence of rule-governed correlations which de-  termined rules of in\/exclusion, was, however, only perceivable by the non-orchestrated calls for New Studies, calls like \"the diverse modalities of protest\" in the Greek city states analysed by Detienne, which,  by breaching parallel dietary and other rules, not only called the ontology of the religio-political order of the city-state into question, but made perceivable, through what they protested against, the founding Order\/Chaos oppositional categories which underpinned the boundary\/structure maintaining dynamics of the polis (Detienne, 1979). These regularities pointed to a fundamental question which, at the time, remained unasked. It had to do with the anomalous implication that they were determined by rules which transcended the conscious intention of the academics who enacted the decision-making processes as to what to in\/exclude, just as the rules of inference of Galileo's doctors of philosophy were dictated by the ratiomorphic apparatus or rational world view based on the a priori of an order of value between the imperfect terrestrial and the crystalline perfection of the lunar realm: the Order\/Chaos opposition of the autopoetic dynamics of the Christian medieval-system ensemble. What, in this case, then, determined the rules which determined the decision-  making processes by which individual scholars, working with integrity and according to the criteria of objective standards, in\/excluded? What determined what should and should not be defined as American  Fiction, and the mode of measure of the \"objective\" standards of  individual scholars?\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The question was not to be asked, however, until the after side of the experience of disillusion which the callers all underwent and which David Bradley traces in his article, \"Black and American in 1982.\" For it was to be a recognition, made by us all on the other side of that experience, of the existence of objective limits to the incorporation of Blacks into the normative order of being\/knowing of the present order, that would lead to our further recognition of the need for an epistemological break. Bradley was one of a group of Blacks for whom Affirmative Action, by countering the \"inbuilt distribution bias\" of the dynamics of the order, had worked. The interference of Affirmative Action with the normative functioning of the order with respect to the distribution-at the group category level-of unequal ratios of access to educational empowerment, had enabled Bradley, together with a group of young Blacks like himself, to breach the rule-governed nature of the proscription which confined Blacks-as-a-group to a secondary educational orbit, relative to their White peers-as-a-group. Bradley at the time, observing his father's great joy, had determined to do everything to prove his father's and his own private hope true. His father's  hope was that at long last Blacks were to be allowed to break out of  the secondary orbit to which their lives and dreams had been confined, and if this hope would not be realized in time for his own life to  be graced by the change, it would in time at least be realized for his  son's. Bradley's own hope had been that once Blacks were included in vast numbers in the highest levels of higher education, and had worked hard and proved themselves, they would be so numerous, so  no longer the token exception, that they would eventually have to be  distinguished by criteria other than by \"the uniform of skin.\" However,  he experienced on the campus both the overt and covert forms of  anathematization which met the breaching of the interdiction that the  black presence-as-a-group implied (since what Hofstadter calls the category structure of the \"representational system\" \"America\"'40 is  based on the dynamics of the contradiction between individual equality and group heirarchy).\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  These experiences slowly stripped away the illusion of any fundamental change in the ordering of group relations. The shouts of \"Nigger! Nigger!\" in the citadel of reason in the heart of the non-redneck campus, the phoned bomb threats, the fragile defenselessness of the Black students in the face of a mindless hostility, the ineffective wringing of hands of concerned Liberal Whites, were paralleled by the more discreet acts of partition (Detienne, 1979) by university administrators, whose proscription of the financially starved Black Culture Center, always a whitewashed rotting house to be reached by a scramble up a muddy bank, mainly always on the nether edge of campus, once again gave the rulegoverned regularity of the game away. Blacks would be allowed on the campus as a group, admitted  to have even a culture, as long as this \"culture\" and its related  enclave studies could be made to function as the extra-cultural space, in relation, no longer to a Wasp, but now more inclusively to a White American, normatively Euroamerican intra-cultural space; as the mode of Chaos imperative to the latter's new self-ordering. (The re-  adapted Western culture Core Curriculum is the non-conscious expression of this more \"democratizing\" shift from Wasp to Euro.) Indeed once this marginalization had been effected, the order of value recycled in different terms, with the category homeostasis returning to its \"built in normalcy,\" the abuse and the bomb threats ceased. Order and Chaos were once more in their relational interdefining places, stably expressing the bio-ontological principle of Sameness and Difference of the present order, as the rule-governed discourse of Galileo's doctors of philosophy functioned to verify the physico-  ontological mode of Sameness and Difference on which the Christian medieval order rested before the Studia and Copernicus, before the Jester's heresy of the figures of rogue\/clown\/fool, had pulled the \"high seriousness\" of its self-justifying self-representation down to  earth.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Bradley now recognized that he had been wrong to hope that Black lives, from his father's to his own, had to \"run along the same  line.., one that rises and falls like a sine wave,\" one that is \"a  graphed function not of a mathematical relation between sides and angles but of a social relationship between Blacks and American society itself.\" Sometimes the line could be \"on the positive side of the base line,\" at other times on the negative side. If the effects were different, the function had always to remain the same. Thus his hope  for the next generation of Blacks, in this case for his young godson,  would have to be cut down to realistic size. His hope could only now be that by the time his godson came of age, the \"graph of black will once again be on the upswing,\" giving him, as Bradley himself had had, \"a little time to gain some strength, some knowledge, some color to hold inside himself.\" For that would\/could be, \"all the hope there is.\" Yet the beginning of hope also lay here. The recognition of the regularities pointed outside the \"functional rhetoric\" of the Liberal creed to the existence of objective limits and, therefore, of laws of functioning which, beyond the conscious intentionalities of their subjects-White or Black-determined the limits to the order's normative incorporation of those whose lives in a \"free\" country had to be made to serve as the \"graphed function\" of the boundary maintaining system, as its markers of Chaos, the Not-Us.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The Spanish historian Americo Castro had noted the existence  of this systemic function of Blacks in the comparison he made between their function and that of Jew and Moor in sixteenth-century  Spain. Although converted Christians and, therefore, \"according to the gospel and the sacraments of the Church,\" forming a part of the \"mystical Body of Christ and His Church,\" these categories had been stigmatized as being of unclean blood and heretical descent (i.e., not  Spanish-Christian). Their proscribed lives-they were excluded from jobs; many were burnt at the stake by the Inquisition for \"heresy\"-enabled them to function as the mode of Difference from which the new secularizing bonding principle of limpieza, which came to constitute the \"boundary maintaining system\" of the Statal Group  Subject of monarchical Spain, could be generated as an ontologized principle of Sameness. Here Am6rico Castro pointed to the regularity  of the parallel by which the subordination of the lives of the categorybearers of difference to their \"grasped function\" is repeated in the lives of present day American Blacks, who are today re-enacting and \"living a drama similar to that of the Spanish moriscos and Jews,\" even though according to the Constitution they form part of the  American We (Americo Castro, 1977) or group-Subject. Only with their complete strategic marginalization did the by  now bantustanized enclave studies begin to rethink their function: to grasp a connection with that of the Liminal outsider Jester's role of  the original Studia, a role to which they were heir. This became clear as they began to take as their parallel objects of inquiry the representations which had been made of their groups by the order of discourse of mainstream scholarship; as they began to find that these representations, too, functioned according to across the board,  objective rules. What was here revealed, when taken all together, were the regularities of the \"figuring\" of an Other excluded series, with the discourse functioning to constitute them as a \"human species\" totemic operator which paralleled that of the \"animal species\" totemic operator of traditional Neolithic societies as well as the planetary grid of the Christian medieval order. This discourse, then, operated to serve the same extra-cognitive function of Ptolemaic astronomy in the Middle Ages.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  It re-enacted the celestial\/terrestrial physico-ontological  principle of Difference in new terms: this time in terms of a bio-  ontological principle of Sameness\/Difference, expressed, not in the Spirit\/Flesh order of value of the Christian-medieval order, but in the rational\/irrational mode of Order\/Chaos of our own. Whatever the group-women, natives, niggers-whatever the  category-the Orient, Africa, the tropics-the ordering principle of the discourse was the same: the figuration of an ontological order of value between the groups who were markers of \"rationality\" and  those who were the markers of its Lack-State. And the analyses which  had begun to perceive the lawlike regularities of these ordering dis-  courses went from Virginia Woolf's observation of the compulsive  insistence by \"angry male professors\" on the mental inferiority of women, through Carter G. Woodson's diagnosis (1935) of the lawlike  manner in which the curriculum in American schools distorted history so as to represent the Whites as everything and the Blacks as  nothing, to Aime Cesaire's Discourse on Colonialism, which again diagnosed the regularities with which the colonizers rewrote the past to show themselves as having done everything and the colonized nothing, and, more recently Abdel Malek's\/Edward Said's dissection of the phenomenon of Orientalism.41 What began to come clear was  the reality of the reflex automatic functioning of rules of figuration, parallel to those of Galileo's doctors of philosophy, which went beyond the intentionality of the objectively rational scholar, rules which then revealed that the objectivity was that of the ratiomorphic apparatus or cognitive mechanism of our present organization of knowledge, one by which we are all, including the liminal Others, nonconsciously governed. A parallel suspicion of something automatic functioning  beyond the conscious control of the human had impelled the exchange of letters between Einstein and Freud, which was to be published under the title, Why War?. In the early decades of the century Einstein had written Freud, asking if his new discipline could provide some hope with respect to, and in the context of, the acceleration of the phenomenon of inter-human wars. Freud had responded that there was his theory of the instincts but that as yet he had no overall answer. Psychology as a discipline, however, was to confront the question by focussing on the connection between the phenomenon of nationalism and the processes of socialization which exacerbated nationalist allegiances as a primary causal factor. And in his History of Sexuality, Michel Foucault suggested that with the shift from the monarchical order of things to the bourgeois order in its pure  state-the transposition from a governing figurative \"symbolic of blood\" to what might be called a \"metaphorics of naturality\" in which the bourgeoisie comes to image its boundary-maintaining GroupSubject system on the analogy of a living organism-the imperative of the self-preservation of the \"natural community\" (nation-Volk, race, culture) metaphorically ontologized as a \"biological\" Body, had led to the acceleration of wars between men who were now led to imagine themselves, for the first time in human history, as \"natural beings.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  \"'42 Recently Lewis Thomas, the biologist, has again focussed on the connection between nationalism-which he sees as an  evolutionary blind alley for the human as a species-and the threat of nuclear extinction. Like Einstein earlier, Thomas has glimpsed that hope, if it is to exist, would have to be found in a new order of knowledge. And he suggests that the disciplines that were concerned with the problems of human behavior, although still in a groping uncertain stage, are the only ones capable of providing an answer to  mankind's quest for social hope; that one day there would emerge from these uncertain attempts, a \"solid\" discipline as \"hard\" as physics, plagued \"as physics still is with ambiguities\" yet with new rules \"and new ways of getting things done, such as for instance getting rid of patriotic rhetoric and thermonuclear warfare all at  once. \"43  The proposal I am making is that such a discipline can only  emerge with an overall rewriting of knowledge, as the re-enacting of the original heresy of a Studia, reinvented as a science of human systems, from the liminal perspective of the \"base\" (Dewey, 1950) new Studies, whose revelatory heresy lies in their definition of themselves away from the Chaos roles in which they had been defined-Black from Negro, Chicano from Mexican-American, Feminists from  Women, etc. For these have revealed the connection between the way we identify ourselves and the way we act upon\/know the world. They have made clear that we are governed in the way we know the world by the templates of identity or modes of self-troping speciation, about which each human system auto-institutes itself, effecting the dynamics of an autopoetics, whose imperative of stable reproduction has hitherto transcended the imperatives of the human subjects who collectively put it into dynamic play. The proposed science of human systems, therefore, decenters the systemic subject. Instead, it takes as the object of its inquiry the modes of symbolic self-representation (Creutzfeld, 1979), about which each human system auto-institutes itself, the modes of self-troping rhetoricity through which the Subject (individual\/collective) actualizes its mode of being as a living entity.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  In addition, it takes the ratiomorphic apparatus or episteme, which exists as the enabling rational world view of the self-troping mode of being as an object of inquiry in the comparative context in which it is definable as one of the cognitive mechanisms determined by the \"psychogeny\" of the human rather than by the phylogeny of purely biological organisms. Taking the connection that Thomas makes between \"patriotic rhetoric\" and \"thermo-nuclear warfare\" as a key linkage, a science of human systems will take most crucially as an object of its inquiry the modes of cultural imagination of human systems-Jerison's \"imagery systems\"-together with the laws of functioning of the rhetorically coded mode of figuration, which, with its internal mediation of the mimesis of Desire (Girard, 1965) and of Aversion (Fanon, 1967), orients the normative seeking\/avoiding\/knowing behaviors of the systemic subjects. For it is this governing system of figuration generated from the mode of self-definition which integrates with the neurophysiological machinery of the brain, that functions as the shared integrative mechanism, determining not only the mode of consciousness or \"world of mind\" of the order, but serving also, at the aesthetico-affective level of the order, to stabilize the response to the  target-stimuli of Desire for all that is the Self\/Order and of Aversion to all that is the Chaos of the Self, the Death of its Life. It is by thereby securing shared and predictably functioning endogenous waveshapes in the brain (Thatcher\/John, 1977), of the normative Subject of the order, that the system of figuration sets limits to that Subject's mode of imagining its Self\/Group-Self and, therefore, to the knowledge that it can have of its world. A science of human systems which takes the laws of figuration of human systems as its objects of inquiry must, therefore, adopt a synthetic rather than categorized approach to its subject. In order to study their rhetor-neurophysiological laws of functioning, it must above all breach the distinction between brain\/minds, the natural and the human sciences. For one of its major hypotheses is that systems of figuration and their group-speciating Figuration-Work essentially constitute the shared governing rhetor-neurophysiological programs or abduction schemas through which human Group Subjects realize themselves as boundary maintaining systems. These governing rhetor-neurophysiological programs-which can often function as regressive defects of social fantasy (Thatcher\/John 1977), as in the case of limpieza de sangre and of Aryaness, as well as of an ontologized \"whiteness\"-are the  mechanisms which determine the limits of the figuratively coded \"boundary-maintaining\" systems.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  They then function, as in the case of the American order, to set objective limits (such as those to Bradley's hopes) to the definition of its fiction; and to the possible non-proscription of the Black Culture Center at the nether edge of the campus, as the physical expression of the rhetorical configuration of the mode of chaos to the order's self-troping definition of itself. Hence the paradox of the major proposal that we make: that it is the literary humanities which should be the umbrella site for the transdisciplinary realization of a science of human systems. The archaeologist McNeill argues that the representational arts have played a central role in all human orders, reaching from simple tribal societies to our more complex contemporary ones, and this role has been that of explaining the world not in terms of  factuality but of religious schemas from some mythology. These  schemas-the phenomenon defined by Bateson as the informing morphogenetic fantasy, by Winch as the schemas which encode the order's conception of Life\/Death-once in place, function as the \"independently real\" (Winch, 1970) for that society, orienting behaviors. McNeill further argues that \"literature and the humanities in general,\" as the modern form of these representational arts, should be \"studied objectively from the outside\" just as ethnographers would investigate \"the parallel arts in tribal societies\" (McNeill, 1981). If these propositions have validity, the major paradox would seem to be that the literary humanities, as they were organized in the context of the nineteenth century's re-ordering of the episteme-a conceptual-organizational frame in which they still function-were set up precisely to guard against any such heretical co-identification. It was a frame that posited the \"civilized,\" defined by its having a written literature, against the \"primitive,\" defined by its Lack; human groups studiable from the external observer's position of Western anthropologists against the West's \"native model of reality\" seeable by its native subjects within the limits of its governing episteme as isomorphic with reality itself (Legesse, 1974). A reality (and its literary artifacts) then, without the possibility of an external observer's position, with the latter ungraspable as a unique variant of the continuum of the representational arts common to all modes of human-  kind.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Since the 1960s, however, with the advent of structuralism and  of deconstruction, literary studies have become the discipline most aware of the problem of the \"external observer\"; of how to find a metalanguage which could enable the human observer to step outside the \"normative pathos\" of the order of discourse of the \"figural domain\" (Norris, 1982). The dimensions of this break must be seen in the context of the normative order against which it transgressed. As Foucault points out, with the mutation of the episteme in the nineteenth  century, and the reorganization of the system of knowledge whose new function was to constitute \"man\" as an \"empiricotranscendental doublet,\" literary studies came to play a specific role\/function in the overall schema of the new episteme (Foucault,  1973). For in the new system of figuration and of its conception of  Life\/Death-in which man was imagined as a \"natural being\"-\"lite-  rature\" came to function as the transcendentalized index of the  degree of \"Culture\" which the biological heredity of the Group  Subject was imagined to have led it to achieve. For Culture, in the new  episteme, now took the place that Reason had played in the Classical episteme, as the index of the degree of that human being which \"knew\" Self\/World in the context of the program of prejudgments of the new rational world view; as the index, therefore, of the GroupSubject's ratio of bio-ontological value, the value which enables it to transcend the mere physical materiality of less endowed human Group Subjects. In this projected schema literature was the highest manifestation of langauge, as differing languages (e.g., Schlegel's \"organic\" and noble Indo-European languages versus the non-organic and egoistic Semitic) were now the index of the superior or inferior Will or elan vital of differing peoples, of \"the fundamental will that keeps a whole people alive and gives it the power to speak a language belonging solely to itself\" (Foucault, 1973). And \"Literature\" was the very incarnation of this defining language, of the collective dynamic impulse of a people represented as incarnated in its poetry, drama, fiction, in a word in its \"high\" Culture which expressed the unique self-transcendence of a particular people. Further, as philology's subject, language became more and  more knowable; literature as the Incarnation of transcendence was now represented as having no other law, except that of \"affirming its own precipitous existence.\"\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Thus as the transcendent expression of the Group Self, studied in national departments of literature, as such, literature became more and more impenetrable to knowledge. No longer having anything to do with values as in the eighteenth century its discourse became totally unyoked from that of ideas (Foucault, 1973). And its narrative representations, set apart from all other forms of discourse, were now to be deciphered-rather than cognized as artifacts\/powerfacts-with taste and sensibility, within what de Man defines as the \"ethical coercion of their normative pathos\" (Norris, 1982). The humanist, Blackham, argued that while literature is comprised of works in which man makes an object of himself, the study of these objects, unlike the objects of the natural sciences, can be of no  public utility since they can provide \"no formulable truths about  man,\" that, rather, their study was instead intended to \"humanize\" by  enabling the \"contemplation of Man in his Works.\" This formulation precisely expresses the role in which literary studies had been  \"interned\" in the knowledge order of the nineteenth-century episteme. And from this would grow the conviction of its irrelevance, that it had nothing to contribute to the kind of knowledge \"available to the needs  of mankind.\" Here, too, can be seen the logic of the definition of American  Fiction, since the contemplation of Man in his Works was the contemplation of the natural\/national Group Subject in its works. Literature now functioned as the transcendent expression of the  Group Subject as a boundary-maintaining system which set itself apart from that which was Not-the-Self, demarcating the Group Subject from the Chaos of the merely physical animality of  those-the raw to its cooked, the nature to its culture-who had not attained to such an expression by reason of an innately determined biogenetic principle of difference.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Thus those groups who were the markers of its mode of Nature to its mode of Culture had, figuratively and logically, to be excluded from any such co-definition.44 Here, too, a regularity appears between the exigencies of the rules of definition\/exclusion and of the exigencies of the figuring of the Other (Said, 1975) in each human order of discourse. For if the exigencies of the latter must domesticate the figuration of the Other to the structuring logic of the Order\/Chaos modality of the specific human system, the exigency of the former, that is, to define itself by detaching itself from what it is not, is quite clearly carried out by the  definition of American Literature. Hegel's \"analysis\" of the \"negro,\" in his The Philosophy of World History, as \"the natural man in his completely wild and untamed state,\" is to the point. Since \"nothing harmonious with humanity [was] to be found in his character,\" so that even if the Mohammedan religion had managed to bring him within the range of  culture, left to himself, the \"negro's lack of self control\" made him  \"impossible of development or culture.\" As we note in this discourse, Lack-of-Culture has taken the place of Lack-of-Reason as the Chaos state of the new order, as in the royal dynastic order of Iron Age East  Africa in which Lack-of-the-Bakama-cult had taken the place of the  earlier template of identity, Lack-of-the-Bacwezi, as the new figuration  of the conception of Life\/Death, the conception whose laws of Order\/Chaos figuration are universally applicable to human systems. If the Hegelian discourse functions to fit the Black to the exigencies of expressing the a priori of a bioontological principle of Sameness and Difference, it is within the same governing laws of figuration and its internal logic that the Black Culture Center was  proscribed to exist on the nether edge of the campus. It functioned as the target stimuli of aversion, with respect to the Euroamerican order at the center of the campus, which is then enabled to function as the  object stimuli of desire. The relation, functioning dually at empirical  and at valorizing levels, if stably kept in phase, ensures the stable pro-  duction of the same shared endogenous waveshapes, in Black students as well as Whites-the same shared normative seeking\/valu-  ing, avoiding\/devaluing behaviors.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Hence the paradox that, after the  turbulence of the 1960s and the 1970s the Black Culture Centers in  their nether-edge-of-the-campus place function to enable the recycl-  ing (in cultural rather than racial terms) of the Order\/Chaos dynamics of the system-ensemble. In effect they functioned\/function to return it  to the in-phase coherence of a category-structure in which Black  would remain to White, Afro- to Euro-, non-Western cultures to  Western, as the Bacwezi to the Bakama of the Iron Age royal dynasty. Since the proscription is effected and kept in play by a govern-  ing mode of the cultural imagination induced by the rhetorical  strategies of the Figuration-Work of its abduction schema or morphogenetic fantasy (Bateson, 1979), it is only the discipline of literary scholarship, whose normalizing role is ordered by this very schema, that possesses the rhetorical techne, inherited from the founding heresy of the Studia as well as from the long practice of working with the figurative logic of poetry and fiction, not only to take our governing modes of figuration and their feats of \"semantic engineering\" (Maranda, 1980) as the objects of inquiry, but also to reveal the laws of human behavior as that behavior is ordered by projected verbal-rhetorical schemas: the laws of human systems, whose structuring Order\/Chaos oppositions are the human version of what Dawkins calls the universally applicable replicator units or systemic codes (Dawkins, 1983)45 which everywhere function to absolutize the modes of our always rhetorical \"natures\"; the natures whose bonding topoi determine how we think about Self\/World. As Norris points out, this key question of the metaphoricity of our thought, a proposal which at once re-enacts the heresy of the original humanists' equation of rhetoric and philosophy, had been raised quite some time ago by I.A. Richards. The latter had pointed out that all thought was metaphoric, proposing that an attempt should be made to secure a \"discussable science\" which could develop the implications of this with respect to human knowledge. The problem that Richards overlooked, however, Norris argues, was that of finding a metalanguage by which one \"could step outside the limits of the  figural domain and survey its peculiar contours\" (Norris, 1982). Piaget points out that the child moves out of the stage of his body-ego bound centricity in which he reduces the object to his perception of it, only when he experiences friction between how he sees the object and how others see it.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  The proposal here is that the positing of an \"external observer\" with respect to the inside of the \"figural domain\" of each human order can be effected by adopting the bootstrap model offered by some quantum physicists. This model envisages the bringing together of that which is observed from many different observer positions, enabling each to extend and to cancel  out elements of the other. In this context it can be seen that it was  only when the observations made from the differing perspectives of  all those who called for new areas of Studies were brought together,  that each group was able to escape its own form of solipsism and to observe regularities and common features pointing to the functioning of rules of discourse beyond the conscious awareness of the discursive Subject, rules which were \"built in\" and therefore normally invisible. These observations, from differing observer positions yet all  pointing to a rule-governed discourse generated from the normative  observer position of mainstream scholarship, could now begin to  provide it-and in this sense, Said's Orientalism, although limited to one aspect, was an Event-with the kind of friction that would enable  it to become conscious of the relativity of its own viewpoint as the viewpoint of the ratiomorphic apparatus of a specific template of human identity. The spearheading of this thrust towards an external observer position will be necessarily carried out by those Liminal categories who existentially experience the mode of Chaos to the mode of order of the governing system of figuration, whose will to affirmation, like that of the original humanists, depends on the unwriting\/rewriting of the present schema and order of knowledge. As Dewey points out, the insistence on the knowability of the celestial laws of functioning of the Divine Creation by means of \"mechanical formulae\" was necessarily spearheaded by the \"base\"  artisans who had to do with mechanics, or by those not too distant in the social sphere, all of whose will to affirmation was confined in the social parallelism of the conceptual schema according to which the celestial creation was unknowable by merely human cognition. Thus while knowing the heavens by base mechanical formulae would seem sacrilegious to the normative groups of the order, it would be the \"base\" fellows who would have an interest in effecting this knowability, sweeping away the order of value between the highest, the \"celestial,\" and the lowest, the sphere of the earth, of the mechanical (Dewey, 1950). Equally, the New Studies, stigmatized as \"subjective\"-with  the most stigmatized of all sited in the Black Culture center-will have every interest in challenging an order of figuration which programs their own negation, in sweeping away the distinction of  objective\/subjective within the general question of the metaphoricity and relativity of all human modes of knowledge.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  It will also have every interest in proposing that we come to know the sociohuman world we inhabit according to laws of functioning made graspable from an external observer's position, itself made possible by the application of \"rhetorical formulae\" to the regularities of representation whose authority of reference is the abductive schemas or morphogenetic fantasy that function to ontologize and absolutize the instituting analogy-man as a natural being-in relation to which, normatively, we infer the world according to the analogy's oppositional conception of Life\/Death, Order\/Chaos, and to its necessarily materialist metaphysics. As Dewey also points out, it was the democratizing movement of social transformation which emancipated human knowledge of Nature from its subordination to metaphysical purposes. This egalitarian movement was to be the condition of possibility for the rise of the natural sciences and, with the insight from Copernicus to Galileo to Newton, for the conclusion that there was no ontological  order of value between the heavens and the Earth, since there is a  \"homogeneity of material processes everywhere throughout the  world. \"46  It is in this context, from the frame of reference of the Black  Culture Center-which refuses the stigmatization of so-called \"primitive\" cultures as the Lack-state of the civilized, and sees itself as the  bearer, in Gowlett's terms, of the \"long perspective\" on the  human-that a re-definition of the concept of the Studia Humanitatis  is proposed, one which reenacts in different terms the founding heresy of the Studia. For it proposes the long processes of the selfmaking (i.e., the hominization of the human and of its corpus of narrative representations, all functioning according to equally applicable laws, from the figuration-work of Iron Age East Africa to that of Hegel's philosophy) as the proper sphere of the humanitas now conceived as isomorphic with the global human rather than with merely its Indo-European expression. But since the \"negro\" as a category of the human was only  constituted and constitutable by the great rupture that transformed  the mythos and theologos into a secular order of things, it also insists on the uniqueness of those narratives defined as \"literature\" precisely because of the new role that these ordering narratives of secular man, whose mode of being would be imperatively global, would play. Here the view from the Black Culture Center puts the emphasis on the new function of literature-in a world no longer sustained by the auctoritas of the suprasensory-as itself the new  auctoritas for the secular modes of the cultural imagination. The absolutization apparatus of such an imagination was no longer the higher system of the gods, but rather the powerful rhetorical strategies of the systems of figuration which imaged the new secular conceptions of Life\/Death by which the human would now orient itself.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Its mode of human being would be mediated not by gods but by metaphors. The view from the Black Culture Center therefore insists, heretically, that far from \"literature having no function,\" as it is assumed, it is we who are the function. It is as specific modes of imagining subjects of the aesthetic orders which literature's figuration-Word weaves in great feats of rhetorical engineering that we come to imagine\/experience ourselves, our modes of being. Since it is in the narrative representations of literature that the  data exists, it is here that \"formulable truths\" are to be made about the laws of functioning of human motivations\/behaviors, as well as about the modes of cultural imagination through which the human is constituted as Subject. And this leads to a new conceptual  synthesis.47 It is by taking as the object of our inquiry the mode of imagination of each order as it is constituted by the governing imagery\/figuration systems generated from the bonding topoi and their related structural oppositions-the integrative mechanisms which, working with the neurological hyperneurons of the brain, produce the phenomenon we know as mind or, rather, modes of mind-that the psychogenetic reality of the human can be known. While the laws of figuration are quite clearly applicable from myth to a present day poem, literature in secular societies would have to play a role\/function no longer sustained by the gods. One might say it would have to take their place. For if, as Creutzfeld argues, our brains function by and through the modes of symbolical selfrepresentation, and if their constitution of world is as real to us as is physical reality, then the mode of self-representation through which  the first form of secular man auto-speciated it\/himself, as well as the  \"real world\" this new form constitutes, would have now to be  canonized, no longer in religio-aesthetic, but in purely aesthetic terms.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Hence, in secular society, literature as well as the arts in general would come to play a ritual canonizing function. In place of the religious schemas, whose systems of figuration would become increasingly privatized, it would generate powerful new imaginary schemas. And their conception of Life\/Death would now orient behaviors. At the same time, their rhetorically powerful herofigures-in the same way as Christian saints had functioned for the suprasensorily guaranteed medieval society-would incarnate secular normative ideals\/models of identity generated from the emerging topos underlying the more inclusive orders of European  post-feudal society. These new systems of figuration would thereby effect an ongoing evolutionary shift at the level of the aesthetic processes of co-identification, which would accompany the evolutionary processes of human epistemology. Since these aesthetic orders are coded by our narrative repre-  sentations, with the shift to the secular order, literary critics took, in a  sense, the place of the theologians in keeping the new imaginative schemas in phase and free from aesthetic pollution, an ever present danger from Hitler's Germany to today's mass pornography. Within the context of a science of human systems, however, literary critics  would now have to function, in Paolo Valesio's terms, as rhetoricians  rather than as rhetors, diagnosticians rather than as \"grammarians\" (Legesse, 1973), outside what de Man calls the \"normative pathos\" of the figural domain that constitutes each order. They would have to  find the view of the external observer, using the  rhetorical\/neurophysiological techne, which takes the FigurationWork of the texts, whose projected schemas function as the  auctoritas of the mode of self-imagining of the scular human subject,  as its domain of investigation.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  It would then seek for the regularities  of practices by which old templates of identity are stabilized and new templates and their modes of imagining are brought into being by the rupture precipitated by great feats of poetic semantic engineering. It  would, that is, seek for the modes of imagining, knowledge of which would make human behavior predictable. For it is the mode of the  imagining of Self\/Not Self that constitutes the integrative unthought  and rhetorical structural opposition encoded in the analogue system of the brain's right hemisphere. And it is these that orient and stabilize the mode of mimetic desire (Girard, 1966) and mimetic aversion (Fanon, 1964): at once the human form of the  seeking\/avoiding mechanisms of biological organisms and the dynamic expression of the conception of Life\/Death, of Agathos\/Deilos, that is everywhere the Original Cause (Riedl\/Kaspar, 1984) and telos-orienting purpose which motivates all modes of the psychogenetic behaviors we define as \"human.\" For the first time in the history of humankinds we are now con-  fronted with a common environment. As a post-atomic one, it challenges us with the demand that we reinvent our present conflictive  modes of group integration. This demand implies that we must now consciously alter our mode of self-troping, together with the related orienting desire\/aversion machinery of our orders of discourse and the related semantic charter (Maranda, 1980) or rhetor-neurophysiological program that constitutes our \"world of mind.\" This is the price, in the face of the possibility of our extinction, of our selfrealization as a species.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Thus, re-reading the texts from the perspective of their configuring function in the rhetorico-symbolic processes of human auto-speciation constitutes for literary criticism  its Copernican epistemological break. It is this break, we propose,  that would enable the literary humanities to appropriate the \"external observer's\" multiple and polyglossic (Bakhtin, 1981) frame of reference, the frame inserted by the \"base\" new studies, as well as by the Derridean and de Manian de-figurationism, the Girardian thesis of human desire as always mimetic, and the Fanonian concept of learned self-aversion (with all these giving new turns to Levi-Strauss's founding binary oppositions) within the overall context of Valesio's proposed new disciplinary matrix of a rhetorics. It is this break\/turn that would enable the literary humanities to re-enact the original heresy of the Studia and to recapture its contestatory dynamic within the matrix of a science of human systems. Such an epistemological break would call for the kind of rereading of all texts and narrative representations of the past that could isolate and identify the feats\/strategies of poetic and semantic engineering (Maranda, 1980) by which discontinuities were effected from one order of discourse to the other; by which an earlier and more particularistic conception of Life\/Death and figuration of Desire\/Aversion was re-figured into a new and more inclusive mode of \"human nature,\" as one aesthetic-affective order based on an  imagined mode of Sameness\/Difference and its related \"world of  mind\" (Creutzfeld, 1979) was configured, transumed\/sublated into  another. There has been no other discontinuity more dramatic and epoch-making than the shift effected by the figurative discourse that was humanism, by its teaching office, the Studia, and by what Dewey called the \"daring astronomers.\" This discontinuity was simply the shift from the traditionally religious conception of Life\/Death to the first form of a secular one. And the mutation at the level of the  aesthetic-affective-the most recalcitrant to transformation-was,  as Bakhtin reminds us, effected by the carnivalesque projection of the parodic forms of the Clown, the Fool, the Rogue; forms which pulled  the high seriousness of the self-dissolving Late Middle Ages down to  earth (Bakhtin, 1981), clearing the space for the retroping, the reimagining of the Self\/Group-Self. However, after the medieval mode of imagination had been  undermined by subversive laughter, a new space, a new ordering dis-  course and self-projection had to be re-constituted.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  And this was to be the central function of the sixteenth- and seventeenth-century  European dramatic genre with its new range of heroes\/villains, incarnating the structural oppositions that configured and gave expres-  sion to the first forms of the secular conception of Life\/Death, remodelling the post-theological logical mode of the human imagination in its first dynamic form. Thus old interdictions gave way  to new. If in Golden Age Spain (sixteenth\/seventeenth centuries),  where the structural opposition shifted-in the context of the rise of the more inclusive order which displaced that of the medieval system  ensemble-from Noble\/Non-Noble, Spirit\/Flesh to Limpiolnon Limpio  (Clean\/not clean, of descent and Christian faith), and a real life Black figure, Juan Latino, a slave, Humanist\/poet, and Professor of Latin,  projected as a hero figure in a play of the same name,48 can wed his Desdemona, with the villain figures being Jew and Moor, in the  parallel case of Shakespeare's Othello the outcome is more complexly other. If the ceremony is found within the logic of the meta-  phorics of the Spanish play, in Othello-the play whose post-  Reformation referential life world, England, is already caught up in the  dynamic of a thorough-going secularizing historical process which  will determine its rise to world supremacy as Spain's empire begins to  decline-the ceremony, as Bishop finely images, is found only clandestinely. It is then lost, and only \"found\" poetically with Othello's \"dying upon a kiss.\" For the outcome of both plays is predetermined by the differing bonding topoi from which these are  generated. The metaphorics of the first play is generated from the specific bonding topos of conlimpieza (we-who-are-the-same-clean descent\/  Faith-nature) of the post-feudal Spanish monarchical order. Here the shift from the Noble as Norm to the Limpio monarchical Subject as Norm (from Noble Blood to Clean Blood as the metaphysical measure  of Being) was socially emancipatory for the non-nobly-born Spaniards,  especially the new letrado category (Men-of-Letters vs. the Noble Men-of-Arms) who staffed the Church and State of the first world  empire; the category of whom, the \"naturally\" intelligent, naturally loyal\/orthodox Juan Latino is the projection and \"instrumental signifier.\"\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  In Othello, the religio-secular topos of the Spanish play is displaced-although Othello is the earlier play49-by the fully secular topos of connaturality (we-who-are-of-the-same-naturally-noble-  nature), in this the first of its many to be transumed variants. And if Othello, in the context of these variants, functions on the one hand as  the projection of a new rising social force, that of the newly landed gentry\/upper mercantile bourgeoisie-for whom the codes of \"natural nobility\" and of \"natural honor\" verified by honorable behavior, as against the more exclusive nobility of birth, blood and honor as the prerogative of descent, was emancipatory-he functions, on the other hand, in relation to lago as an other, marginalized, and yet prophetic  projection. In the first projection, Othello incarnates the shift taking place  from Lanham's \"centered Christian self\" to \"rhetorical man,\" and  from a suprasensorily ordered world to a secular self-ordering one. He  therefore self-orders his behavior according to the first secular selfregulating code, that of Honor,so i.e., nihil magis honore.1 In this code  he is expected, if the configured natural-metaphysical order of the monarchical state is to be sustained, and Chaos not come again, to make use of his Natural Reason to order and govern both his household, his general's command, and the passions of his lower \"nature.\" By doing this he acts as the Norm Subject of the order to put into play the \"natural\" ratio-ontological principle of Sameness that bonds the caste of the gentry and of Difference that separates this caste from the lower order. For it is this principle about which the secularizing new order auto-institutes itself, transuming the earlier Spirit\/Flesh opposition of the medieval topos of co-Christianity. The \"tragic flaw\" of Othello is that, in allowing the passion of his \"unbookish\" jealousy to cloud his reason, he makes it possible for his judgment of truth\/non-truth to be manipulated by lago. Thus, believing in the \"ocular proof\" of the handkerchief and in the abductive logic of lago's fabricated system of \"evidence,\" he infers\/judges wrongly.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  He thereby transforms what, in the internal logic of the play was the obligation of honor to execute a wife caught in adultry, into a murder, one which, transgressing the State's justice, \"traduced\" the State. As the apotheosis of the self-regulating man of honor, Othello redeems himself at the end of the play by this time judging truly, sentencing and executing himself-\"that in Aleppo once, where a malignant . . . Turk\/. . . traduc'd the state\/. .. I smote him, thus. \"5'2 As the Othello manipulated by lago, on the other hand, he functions as the inverse of this projection. In this dimension Othello is made \"egregiously an ass\" by lago, a man of the middling classes aspiring to be professionally mobile in a world arranged to privilege the wellborn Cassio or gifted nobly-born strangers like Othello, a man for whom success depends on his manipulating the honor code, feigning \"honesty,\" his word never his bond-\"I am not what I am.\"\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  For by his animalizing of Othello-\"a black ram topping a white ewe\"-lago, excluded from the caste of the noble gentry both allies himself with the senator Brabantio and the wealthy Rodrigo, ensuring their help in his attempt to secure the downfall of Othello, and bonds\/classes himself with them on the basis of a new emergent code, that of a shared \"natural value\" rather than \"nobility.\" This code, which anticipates the full-fledged realization of the bourgeois over the monarchical order, makes possible a bio-ontological principle of Sameness and Difference, one whose figurative function is to transume the caste principle of Noble Blood into the \"race\" principle of an innate biologically determined shared superiority, a mode of Sameness made possible by the mode of Difference of metaphysically excluded Others. As a result, while in the Spanish play, Juan Latino, the hero figure, the Metaphysical Other of Jew\/Moor projected as villains, functions as the Lack-state of the naturally \"clean\" Spanish-born monarchical Subjects, the figure of Othello, represented in his animalized dimension (as contrasted with his apothesis and self-execution as an Ideal man of honor) is projected as the very Lack of the human, as bio-ontologically inferior to the Venetians. He thus  prefigures, however briefly, the degrading \"internments\" of  Undermen, under-classes, underpeoples, under-cultures, under-  creeds, that will be legitimated and determined by the abduction schema whose instituting analogy was to be that of the human as a \"natural being\" (Foucault, 1973). It is in the \"figural domain\" of this mode of self\/grouplSelf  imagining, and of its mode of Sameness and Difference that the ceremony is still unfindable. Othello and Desdemona still meet clandestinely, and Black culture centers remain proscribed by the laws of a Godelian type of internal consistency on the nether edge of the campuses; proscribed along with the revelatory heresy of the selfdefining, self-troping, yet always systemic rhetoricity of all modes of human being. And it is this definition, made into a priestly Absolute,  together with its related bio-ontological principle of Sameness and Difference, which traverses its speaking\/imagining subjects and pre-  determines the rule of in- and of ex-clusion that define American  fiction. It is a definition, as Bradley noted, that, therefore, logically exludes Ralph Ellison's Invisible Man, a novel whose ludic moment of conversion (Girard, 1965) comes when the Narrator, awakening from the mimetic desire which had him chasing his \"natural\" and\/or his \"proletarian\" and\/or his \"black\" identity, breaks through all the interdictions and eats the proscribed Southern baked yam in the streets.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  He thereby re-enacts the subversive laughter of all the  rogues\/fools\/clowns that ever brought the priestly forms of \"high  seriousness\" down to earth, quipping \"I Yam what I yam!\" The novel here parodically pulls down to earth the canonical models of Identity: the incest-dreaming Mr. Norton, the glass-eye-wearing Brother Jack, and, with them, the \"true discourses\" of Liberal positivism and Marxian eschatologism, laughing away the self-justifying pathos of their twin and conjoined heresies staled into orthodoxy. And it takes as the object of its irreverence the very system of figuration (the \"inner eyes with which they look through their very physical eyes upon reality\") whose rule-governed principle of Sameness and Difference excluded it from the definition \"American Fiction.\" In the  basement underworld of the novel's counter-metaphorics, the urban  margins of Lanham's rhetorical man, the sound of Louis Armstrong's  trumpet, that \"lyrical beam of light,\" and his gravelly voice (\"My only sin is in my skin\/What did I do\/To be so Black and blue?\") re-enacts  Galileo's telescope, challenging ontologies with the subversive  sounds of the lumpen-poetics of the Blues. Both the Bakama\/Bacwezi mythic narratives and the dramatic plots of the two plays, Juan Latino and Othello, all too briefly discussed here, reveal the \"formulable truth\" that all changes in human affairs-Bateson's mutation of abduction schemas when  \"thought itself becomes impossible\" (Bateson, 1979)-although always brought about by a conjuncture of factors, are experienced by humans as primarily transformations of the governing systems of figuration and of the shared systems of meaning of each order's semantic charter. The antithetical projection of hero-figures whose  external \"begrimed visages\" contrast, in the one case, with the innate  \"natural limpieza\" revealed by limpio\/loyal behaviors, by a \"natural\"  intelligence \"unharmed as to salutory doctrine,\"'53 and in the other, of  an innate villainy of an lago whose exterior \"fairness of visage\" contradicts his \"true\" nature, effects an epochal shift from the  explanatory hypothesis of Divine Causality to that of a Natural Causality, the shift which heralded the first form, at the level of the  human, of the secular \"order of things. \"''54 It is by means of such transformations as that from the religio-feudal to the secularizing monarchical order of figuration effected by the poetic re-engineering of the two seventeenth-century European plays referred to that the evolution of more inclusive modes of group integration, which are themselves linked, as Whyte and Habermas note, to increasingly  generalizable concepts and evolutionary advances in the thrust of human cognitive mechanisms towards what Gellner calls \"the  autonomy and extra-territoriality of human congition\" (Gellner, 1974), are achieved.\n"}
{"prompt":"The Ceremony Must be Found: After Humanism ->","completion":"  Nevertheless, as Habermas also notes, once put in  place, systems of figuration\/integration and their related systempreserving behaviors and \"worlds of mind\" or codes of  knowledge\/modes of imagination, can, even after they have lost their  validity in a now transformed environment, remain as powerful barriers to the emancipation of the new human energies called for. Thus we remain in our present crisis, enthralled and made captive by the secular abductive schema55 of the nineteenth-century epistemes, and the self-regulating codes of Natural\/Labor value, the codes which  replaced that of \"natural honor\"56 just as Othello was replaced in the system of inference engineered by lago until his disenthrallment, by what one critic aptly calls the exorcism of Emilia, who, dying, deconstructs the system of inference and releases Othello and the world of the play from the wordcraft of lago. For in that world, as in ours, \"truth\" was no longer guaranteed by the higher system of the suprasensory. From here on it would be up to the self-correcting processes of the cognitive mechanisms of the human. Yet in a world in which even the self-correcting process of the natural sciences finds itself threatened by the increasing hegemony of a technoscience which seeks to manipulate the physical processes of nature in order to enhance the military and economic power of some human groups over others, a counter-exertion is called for parallel to that of the Studia's original heresy. The Studia must be reinvented as a higher order of human knowledge, able to provide an \"outer view\" which takes the human rather than any one of its  variations as Subject; must be re-formulated as a science of human systems, which makes use of multiple frames of reference and of Valesio's proposed rhetorical techne-the techne, perhaps of a rhetor-neuroscience?-to attain to the position of an external  observer, at once insideloutside the figural domain of our order. As such a new cognitive mechanism it must, as we have proposed, take as its proper sphere what Gowlett calls the \"long perspective\" of the hominid-into-human self-making\/modelling\/figuring,7 as this is docu-  mented and enacted in narrative representations, in art and ways of life, and in the laws of functioning of human behaviors which enable  the autopoesis of each mode of the human. It is only, we propose,  through the counter-exertion of such a new science that Bishop's  ceremonies will be findable, that the hope sought by Bradley, Einstein, Freud, and Lewis Thomas, will be realizable, enabling us to write in our traumatic time with something of the certainty with which a Francis Bacon wrote in his:  And therefore it is fit that I set forth these con-  jectures of mine which make hope in this matter reasonable; just as Columbus did before that wonderful voyage of his across the Atlantic, when he gave the reasons for his conviction that new lands and continents might be discovered besides those which were known before; which reasons though rejected at first, were afterwards made good by experience, and were the causes and beginnings of great events.\"\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Original Research Article  How the machine ‘thinks’: Understanding opacity in machine learning algorithms  Big Data & Society January–June 2016: 1–12 !\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  The Author(s) 2016 Reprints and permissions: sagepub.com\/journalsPermissions.nav DOI: 10.1177\/2053951715622512 bds.sagepub.com  Jenna Burrell  Abstract This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm. Keywords Opacity, machine learning, classification, inequality, discrimination, spam filtering  This article considers the issue of opacity as a problem for socially consequential mechanisms of classiﬁcation and ranking, such as spam ﬁlters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualiﬁcation, and credit scoring. These are just some examples of mechanisms of classiﬁcation that the personal and trace data we generate is subject to every day in net-  of how or why a particular classiﬁcation has been arrived at from inputs.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Additionally, the inputs themselves may be entirely unknown or known only partially. The question naturally arises, what are the reasons for this state of not knowing? Is it because the algorithm is proprietary? Because it is complex or highly technical? Or are there, perhaps, other reasons? By distinguishing forms of opacity that are often  institutional self-protection and concealment and, along with it, the possibility for knowing deception; (2) opacity stemming from the current state of aﬀairs where writing (and reading) code is a specialist skill and; (3) an opacity that stems from the mismatch between mathematical optimization in high-dimensionality characteristic of machine learning and the demands of humanscale reasoning and styles of semantic interpretation. This third form of opacity (often conﬂated with the second form as part of the general sense that algorithms and code are very technical and complex) is the particular focus of this article. By examining in depth this form of opacity I point out shortcomings in certain proposals for code or algorithm ‘audits’ as a way to evaluate for discriminatory classiﬁcation.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  To examine this question of opacity, speciﬁcally toward the task of getting inside the algorithms themselves, I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight audit. Along the way, I relate these forms of opacity to technical and nontechnical solutions proposed to address the impenetrability of machine learning classiﬁcation. Each form suggests distinct solutions for preventing harm. So, what is new? The word algorithm has recently undergone a shift in public presentation, going from an obscure technical term used almost exclusively among computer scientists, to one attached to a polarized discourse. The term appears increasingly in mainstream media outlets. For example, the professional body National Nurses United produced a radio spot (heard on a local radio station by the author) that starts with a voice that sarcastically declares, ‘‘algorithms are simple mathematical formulas that nobody understands’’ and concludes with a nurse swooping in to rescue a distressed patient from a disease diagnosis system which makes a series of comically wrong declarations about the patient’s condi-  (including private sector ﬁrms and public institutions) have had internal procedures that were not fully understood to those who were subject to them. These procedures could fairly be described as ‘algorithms’.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  What should we then make of these new uses of the term and the ﬁeld of critique and analysis emerging along with it? Is this merely ‘old wine in new bottles’ or are there genuinely new and pressing issues related to patterns of algorithmic design as they are employed increasingly in real-world applications? In addition to the polarization of a public discourse about algorithms, much of what is new in this domain is the more pervasive technologies and techniques of data collection, the more vast archives of personal data including purchasing activities, link clicks, and geospatial movement, an outcome of more universally adopted mobile devices, services, and applications and the reality (in some parts of the world) of constant connectivity. But this does not necessarily have much to do with the algorithms that operate on the data. Often it is about what composes the data and new concerns about privacy and the possibility (or troublingly, the impossibility) of opting-out. Other changes have to do with particular application areas and evolving proposals for a regulatory response. The shift of algorithmic automation into new areas of what were previously white-collar work reﬂected in headlines like, ‘will we need teachers or algorithms?’2 and into consequential processes of classiﬁcation that were previously human-determined, such as credit evaluations in an eﬀort to realize cost-savings (as so often fuels shifts toward automation) (Straka, 2000). In the domain of credit and lending, Fourcade and Healy point to a shift from prior practices of exclusionary lending to a select few, to more generous credit oﬀered to a broader spectrum of society, but oﬀered to some on unfavorable, even usurious terms.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  This shift is made possible by ‘the emergence and expansion of methods of tracking and classifying consumer behavior’ (Fourcade and Healy, 2013: 560). These methods are (in part) implemented as algorithms in computers. than the algorithmic logic is being examined. Such analyses are often particular to an implementation (such as Google’s search engine) with its speciﬁc user base and uniquely accumulated history of problems and failures with resulting parameter setting and manual tweaking by programmers. Such an approach may not surface important broader patterns or risks to be found in particular classes of algorithms. Investigating opacity: A method and approach In general, we cannot look at the code directly for many important algorithms of classiﬁcation that are in widespread use. This opacity (at one level) exists because of proprietary concerns. They are closed in order to maintain competitive advantage and\/or to keep a few steps ahead of adversaries.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Adversaries could be other companies in the market or malicious attackers (relevant in many network security applications). However, it is possible to investigate the general computational designs that we know these algorithms use by drawing from educational materials. To do this I draw, in part, from classic illustrative examples of particular machine learning models, of the sort used in undergraduate education. In this case I have speciﬁcally examined programming assignments for a Coursera course in machine learning. These examples oﬀer hugely simpliﬁed versions of computational ideas scaled down to run on a student’s personal computer so that they return output almost immediately. Such examples do not force a confrontation with many thorny, real-world application challenges. That said, the ways that opacity endures in spite of such simpliﬁcation reveal something important and fundamental about the limits to overcoming it. Machine learning algorithms do not encompass all of the algorithms of interest to scholars now studying what might be placed under the banner of the ‘politics of algorithms.’3 However, they are interesting to consider speciﬁcally because they are typically applied to  While not all tasks that machine learning is applied to are classiﬁcation tasks, this is a key area of application and one where many sociological concerns arise.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  As Bowker and Star note in their account of classiﬁcation and its consequences, ‘each category valorizes some point of view and silences another’ and there is a long history of lives ‘broken, twisted, and torqued by their encounters with classiﬁcation systems’ such as the race classiﬁcation system of apartheid South Africa and the categorization of tuberculosis patients, as they detail (Bowker and Star, 1999). The claim that algorithms will classify more ‘objectively’ (thus solving previous inadequacies or injustices in classiﬁcation) cannot simply be taken at face value given the degree of human judgment still involved in designing the algorithms, choices which become built-in. This human work includes deﬁning features, pre-classifying training data, and adjusting thresholds and parameters. Opacity Below I deﬁne a typology starting ﬁrst with the matter of ‘opacity’ as a form of proprietary protection or as ‘corporate secrecy’ (Pasquale, 2015). Secondly, I point to opacity in terms of the readability of code. Code writing is a necessary skill for the computational implementation of algorithms, and one that remains a specialist skill not found widely in the general public. Finally, arriving at the major point of this article, I contrast a third form of opacity centering on the mismatch between mathematical procedures of machine learning algorithms and human styles of semantic interpretation. At the heart of this challenge is an opacity that relates to the speciﬁc techniques used in machine learning.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Each of these forms of opacity may be tackled by diﬀerent tools and approaches ranging from the legislative, to the organizational or programmatic, to the technical. But importantly, the form (or forms) of opacity entailed in a particular algorithmic application must be identiﬁed in order to pursue a course of action that is likely to mitigate its problems. ﬁltering, attract those who want to ‘game’ them as part of strategies for securing attention from the general public. The ﬁeld of ‘search engine optimization’ does just this. An approach within machine learning called ‘adversarial learning’ deals speciﬁcally with these sorts of evolving strategies. Network security applications of machine learning deal explicitly with spam, scams, and fraud and remain opaque in order to be eﬀective. Sandvig notes that this ‘game of cat-and-mouse’ makes it entirely unlikely that most algorithms will be (or necessarily should be) disclosed to the general public (Sandvig et al., 2014: 9). That said, an obvious alternative to proprietary and closed algorithms is open source software.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Successful business models have emerged out of the open source movement. There are options even in ‘adversarial learning’ such as the SpamAssassin spam ﬁlter for Apache. On the other hand, Pasquale’s more skeptical analysis proposes that the current extent of algorithmic opacity in many domains of application may not be justiﬁed and is instead a product of lax or lagging regulations. In his book The Black Box Society: The Secret Algorithms that Control Money and Information he argues that a kind of adversarial situation is indeed in play, one where the adversary is regulation itself. ‘What if ﬁnanciers keep their doings opaque on purpose, precisely to avoid or to confound regulation?’ he asks (Pasquale, 2015: 2). In reference to this, he deﬁnes ‘opacity’ as ‘remediable incomprehensibility.’ The opacity of algorithms, according to Pasquale, could be attributed to willful self-protection by corporations in the name of competitive advantage, but this could also be a cover for a new form of concealing sidestepped regulations, the manipulation of consumers, and\/or patterns of discrimination. For this type of opacity, one proposed response is to make code available for scrutiny, through regulatory means if necessary (Diakopoulos, 2013; Gandy, 2010; Pasquale, 2015). Underlying this particular explanation for algorithmic opacity is an assumption that if corpor-  Opacity as technical illiteracy This second level of opacity stems from an acknowledgement that, at present, writing (and reading) code and the design of algorithms is a specialized skill.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  It remains inaccessible to the majority of the population. Courses in software engineering emphasize the writing of clean, elegant, and intelligible code. While code is implemented in particular programming languages, such as C or Python, and the syntax of these languages must be learned, they are in certain ways quite diﬀerent from human languages. For one, they adhere strictly to logical rules and require precision in spelling and grammar in order to be ‘read’ by the machine. Good code does double-duty. It must be interpretable by humans (the original programmer or someone adding to or maintaining the code) as well as by the computational device (Mateas and Montfort, 2005). Writing for the computational device demands a special exactness, formality, and completeness that communication via human languages does not. The art and ‘craft’6 of programming is partly about managing this mediating role and entails some well-known ‘best practices’ like choosing sensible variable names, including ‘comments’ (one-sided communication to human programmers omitted when the code is compiled for the machine), and choosing the simpler code formulation, all things being equal.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Recent calls for greater diversity in STEM ﬁelds and for general eﬀorts toward developing ‘computational thinking’ at all levels of education (Lee et al., 2011; Wing, 2006) are relevant. Diakopoulos (2013) likewise suggests ways that journalists might play a valuable role in reverse engineering algorithms to inform the general public, but notes that this poses a challenge of ‘human resource’ development, one of developing code and computational literacy in journalists or others who wish to do this sort of examination. To address this form of opacity, widespread educational eﬀorts would ideally make the public more knowledgeable about these mechanisms that impact their life opportunities  number of hours required to untangle the logic of the code within a complicated software system. This valid critique is nevertheless non-speciﬁc about diﬀerent classes of algorithms and their particular logics. I further argue that there are certain challenges of scale and complexity that are distinctive to machine learning algorithms. These challenges relate not simply to total number of lines or pages of code, the number of team members on the engineering team, and the multitude of interlinkages between modules or subroutines. These are challenges not just of reading and comprehending code, but being able to understand the algorithm in action, operating on data. Though a machine learning algorithm can be implemented simply in such a way that its logic is almost fully comprehensible, in practice, such an instance is unlikely to be particularly useful.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Machine learning models that prove useful (speciﬁcally, in terms of the ‘accuracy’ of classiﬁcation) possess a degree of unavoidable complexity. Machine learning in particular is often described as suﬀering from the ‘curse of dimensionality’ (Domingos, 2012). In a ‘Big Data’ era, billions or trillions of data examples and thousands or tens of thousands of properties of the data (termed ‘features’ in machine learning) may be analyzed. The internal decision logic of the algorithm is altered as it ‘learns’ on training data. Handling a huge number especially of heterogeneous properties of data (i.e. not just words in spam email, but also email header info) adds complexity to the code. Machine learning techniques quickly face computational resource limits as they scale and may manage this, using techniques written into the code (such as ‘principal component analysis’) which add to its opacity. While datasets may be extremely large but possible to comprehend and code may be written with clarity, the interplay between the two in the mechanism of the algorithm is what yields the complexity (and thus opacity).\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Better understanding this complexity (and the barriers to overcoming the opacity it eﬀects) is the concern of the following examples. example, a classiﬁer that does spam ﬁltering takes a set of features (such as email header information, words in the body of the email, etc.) and produces one of two output categories (‘spam’ or ‘not spam’). A decision support system that does disease diagnosis may take input (clinical presentation\/symptoms, blood test results) and produce a disease diagnosis as output (‘hypertension,’ ‘heart disease,’ ‘liver cancer’). However, machine learning algorithms called ‘learners’ must ﬁrst train on test data.7 The result of this training is a matrix of weights that will then be used by the classiﬁer to determine the classiﬁcation for new input data. This training data could, for example, be emails that have been pre-sorted and labeled as ‘spam’ or ‘not spam.’ Machine learning encompasses a number of models that are implemented in code in diﬀerent ways. Some popular machine learning models include neural networks, decision trees, Naı̈ve Bayes, and logistic regression. The choice of model depends upon the domain (i.e.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  loan default prediction vs. image recognition), its demonstrated accuracy in classiﬁcation, and available computational resources, among other concerns. Models may also be combined into ‘model ensembles,’ an approach often used in machine learning competitions that seek to maximize accuracy in classiﬁcation. Two applications of machine learning using separate models will be considered below. Visualizing opacity in a neural network The ﬁrst model and application of machine learning I wish to consider is a ‘neural network’ applied to an image recognition task. Because this is an image recognition task, it lends itself to an attempt to ‘see’ the weights output by the training algorithm. The classic example for teaching neural networks to computer science undergraduates is handwriting recognition.8 To simplify the computational task for educational purposes, the code is implemented to recognize handwritten digits only (the numbers 0 through 9). To further  Figure 1. A set of examples of handwritten numbers that a machine learning algorithm (a ‘learner’) and, in this case, a neural network could be trained on.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Figure 2. A handwritten number in an 8 x 8 pixel square. each node in the hidden layer is connected to an output  Figure 3. Graphical depiction of a neural network. Figure 4(a) illustrates the hidden layer in a neural network. If you look at one of the 25 boxes you can see which part of a handwritten number it cues in on. Each box represents a single node in the hidden layer and each pixel within the box illustrates the value of the weight coming from one input layer node into that particular hidden layer node. In sum, each box shows the set of weights for a simpliﬁed neural network with only one hidden layer.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  The regions in the box that are black are the speciﬁc pixels the node in question is most sensitive to. The top left box, for example, shows a hidden layer node that cues in on darkened pixels sort of in the lower left part of the quadrant and a little bit in the middle. A combination of the calculations coming out of these hidden layer nodes yields a classiﬁcation of the inputs to a number from 0 to 9. What is notable is that the neural network doesn’t,  Figure 4. (a) The hidden layer: the black areas in each box are the areas (strokes or other patterns) that a particular hidden layer node cues in on in a handwritten digit. (b) This shows the result of the same learning algorithm being run a second time with the same training data. The reason (a) and (b) are not identical is because of the random initialization step that defines the set of weights initially to very small random numbers. for the computer processor on the other.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Where an algorithm does the ‘programming’ (i.e. optimally calculates its weights) then it logically follows that being intelligible to humans (part of the art of writing code) is no longer a concern, at least, not to the non-human ‘programmer.’ The primary purpose of this ﬁrst example is to give a quick, visual sense of how the machine ‘thinks.’ Figure 4(a) should appear unintuitive, random, and disorganized. However, handwriting recognition specifically is not a ‘conscious’ reasoning task in humans either. Humans recognize visual elements in an immediate and subconscious way (thus there is certainly a kind of opacity in the human process of character recognition as well). Such an example may not seem to provide much insight into broader real-world questions about discrimination in classiﬁcation. However, a recent case where automated classiﬁcation in Google Photos labeled a set of photos of African-American people as ‘Gorillas’ suggests otherwise.11 To further  Spam ﬁltering is, for this reason among others, a better application domain for thinking about machine learning based classiﬁcation as socially consequential. Messages that are categorized as spam are messages that do not get through to their intended recipients. Consequently, this example relates more directly to ongoing conversations about the politics of search, ranking, and ﬁltering content.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Where a legitimate message is categorized as spam (a ‘false positive’), this is a message that has, in eﬀect, been unwittingly censored. One question is whether the design of spam ﬁlters could make certain individuals more susceptible to having their legitimate messages diverted to spam folders. For example, does being located in a hotbed of Internet fraud or spam activity, say West Africa (Nigeria or Ghana) or Eastern Europe, create a tendency for one’s messages to be mislabeled as spam? In Ng’s Coursera course, support vector machines (SVMs) are the machine learning model used to implement spam ﬁltering. SVMs are another type of machine  of words.’ There is no posited semiotic relationship between the words and no meaning in the messages is extracted, nor is there an attempt in the algorithm at narrative analysis. I oﬀer a lightweight ‘audit’ of the algorithm and an examination of the weights produced for each word and how we might make sense of them. In particular, I focus on a type of spam email, the Nigerian 419 scam, a genre with which I have deep familiarity (Burrell, 2012). The 419 scam raises an interesting concern as far as network access and spam ‘false positives.’ In particular, are place names, particularly ‘Nigeria,’ a trigger leading to a greater likelihood of categorizing as spam?\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  In fact after running the training algorithm on an (admittedly) very dated public corpus12 a list of place names can be produced with their associated ‘weights.’ These weights are in a range from 1 (highly associated with non-spam emails) to 1 (highly associated with spam emails). Reassuringly perhaps for the general population of Nigerian email users, the weight associated with the word ‘Nigeria’ contained within an email is 0.001861. This means the word ‘Nigeria’ is essentially a neutral term.13 Looking at the totality of spam, this makes a certain amount of sense. On the balance of it, the vast majority of spam does not originate in nor make mention of Nigeria. Presumably, the number of totally legitimate emails that mention Nigeria would further dilute an association between the country and spam email. The words that are in fact most associated with spam (note, these have been destemmed so that groups of words such as guarantee, guarantees, and guaranteed can be handled as equivalent terms) are the following: our (0.500810) click (0.464474) remov (0.417698) guarante (0.384834) visit (0.369730) basenumb14 (0.345389) dollar (0.323674)  as spam by the simpliﬁed SVM spam ﬁlter (for the full email see Appendix 1): My Dearest, Greetings to you my Dear Beloved, I am Mrs Alice Walton, a citizen of United State. I bring to you a proposal worth $ 1,000,000,000.00 which I intend to use for CHARITY but I am so scared because it is hard to ﬁnd a trust worthy human on earth . . .\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  In reading this email, I notice the formality of language and words like ‘dearest’ and ‘beloved.’ The mention of being a ‘citizen,’ oﬀering ‘charity’ and looking for someone ‘trust worthy’ as well as a reference to ‘fraud’ also strike a note of suspicion. None of these words, however, are cued in on by the SVM spam ﬁlter. Rather it is the mention of money, the words ‘please,’ and ‘contact’ that are the most heavily weighted terms found in this particular email. In fact after removing the mention of money and the word ‘please’ from the email and running it through the ‘classiﬁer’ algorithm again, it is no longer classiﬁed as spam. Now for comparison, consider this email from a friend and research collaborator of the author, an email that has many of the same markers of the scam email genre (formality, religiosity, expressions of gratitude, etc.) but is not a scam email: Dear prof. Thank you for continually restoring hope and bringing live back to me when all hopes seem to be lost. With tears and profound gratitude I say thank you. . . . Am able to get a big generator, air-conditioned, a used professional Panasonic 3ccd video camera and still have about 150 dollars in my account for taking care of my health. . . .\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  I pray you continually prosper. Much regards and Bye. The spam classiﬁer accurately categorizes this email as not spam, again based purely on the words it contains (with no knowledge about the author’s pre-existing relationship with the sender). Nonetheless, when run  of spam strategies of social engineering and persuasion may tip the balance of the classiﬁcation. Humans likely recognize and evaluate spam according to genre: the phishing scam, the Nigerian 419 email, the Viagra sales pitch. By contrast, the ‘bag of words’ approach breaks down texts into atomistic collections of units, words whose ordering is irrelevant. The algorithm surfaces very general terms characteristic of spam emails, often terms that are (in isolation) quite mundane and banal. My semantic analysis attempted to reconcile the statistical patterns the algorithm surfaces with a meaning that relates to the implicit strategy of the text as a whole, but this is decidedly not how the machine ‘thinks.’  Reconsidering ‘interpretability’ The example provided of classifying Nigerian 419 style spam emails gives some insights into the strengths and shortcomings of a code audit.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Finding ways to reveal something of the internal logic of an algorithm can address concerns about lack of ‘fairness’ and discriminatory eﬀects, sometimes with reassuring evidence of the algorithm’s objectivity, as in the case of the neutral weighting of the word ‘Nigeria.’ On the other hand, probing further into the ‘why’ of a particular classiﬁcation decision yielded suggestive evidence that seemed suﬃcient as an explanation, but this imposed a process of human interpretive reasoning on a mathematical process of statistical optimization. In other words, machine thinking was resolved to human interpretation. Yet ambiguities remained, such as the weighting of innocuous words like ‘visit’ and ‘want’ as indicators for spam. This raises doubts about whether an explanation produced in this way to satisfy the ‘why’ question was necessarily a particularly correct one. Computer scientists term this opacity issue a problem of ‘interpretability.’ One approach to building more interpretable classiﬁers is to implement an enduser facing component to provide not only the classiﬁ-  words present in an email or a single sentence description) provide an understanding that is at best incomplete16 and at worst false reassurance. Further complicating the attempts to draw a direct line between ‘weighted’ inputs and classiﬁcation outcomes is the mathematical manipulation that happens in between. Unlike the examples of handwriting recognition and spam ﬁltering presented here, it is often the case that the relationship between a feature and a dimension in the model is not one-to-one. Ways of manipulating dimensionality (through principal component analysis or the ‘kernel trick’ in SVMs, to give two examples) are often employed to manage computational constraints or to improve accuracy.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  The continuing expansion of computational power has produced certain optimization strategies that exaggerate this particular problem of opacity as the complexity of scale even further. With greater computational resources, and many terabytes of data to mine (now often collected opportunistically from the digital traces of users’ activities), the number of possible features to include in a classiﬁer rapidly grows way beyond what can be easily grasped by a reasoning human. In an article on the folk knowledge of applying machine learning, Domingos (2012) notes that ‘intuition fails at high-dimensions.’ In other words, reasoning about, debugging, or improving the algorithm becomes more diﬃcult with more qualities or characteristics provided as inputs, each subtly and imperceptibly shifting the resulting classiﬁcation. For handling this fundamental opacity there are various proposed approaches. One approach, perhaps surprisingly, is to avoid using machine learning algorithms in certain critical domains of application.17 There are also ways of simplifying machine learning models such as ‘feature extraction’, an approach that analyses what features actually matter to the classiﬁcation outcome, removing all other features from the model. Some solutions perhaps wisely abandon answering the ‘why’ question and devise metrics that can, in other ways, evaluate discrimination (i.e. Datta et al.,  The goal of this article was to look more deeply into machine learning algorithms and the nature of their ‘opacity’, relating this to sociological interests in classiﬁcation and discrimination. This is part of an ongoing reorientation of the scholarship on ‘digital inequality’ which has frequently focused on the distribution of computational resources and skills (Hargittai, 2008) but not, until recently, the question of how people may be subject to computational classiﬁcation, privacy invasions, or other surveillance in ways that are unequal across the general population and could be in violation of existing regulatory protections (Barocas and Selbst, 2016; Eubanks, 2012; Fourcade and Healy, 2013).\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Legal critiques of algorithmic opacity often focus on the capacity for intentional secrecy and lead to calls for regulations to enforce transparency. Pasquale (2015) argues for the use of auditors who have access to the code and can assure that classiﬁcations are non-discriminatory. Another approach is to educate a broader swathe of society in code writing and computational skills to lessen the problem of a homogenous and elite class of technical people making consequential decisions that cannot be easily assessed by non-members. However, the opacity of machine learning algorithms is challenging at a more fundamental level. When a computer learns and consequently builds its own representation of a classiﬁcation decision, it does so without regard for human comprehension. Machine optimizations based on training data do not naturally accord with human semantic explanations. The examples of handwriting recognition and spam ﬁltering helped to illustrate how the workings of machine learning algorithms can escape full understanding and interpretation by humans, even for those with specialized training, even for computer scientists. Ultimately partnerships between legal scholars, social scientists, domain experts, along with computer scientists may chip away at these challenging questions of fairness in classiﬁcation in light of the barrier of  combination of approaches will depend upon what a given application space requires.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Acknowledgments Thank you to the many who reviewed and provided comments in the early stages of writing this paper including Sebastian Benthall, Laura Devendorf, Shreeharsh Kelkar, Marion Fourcade, Michael Carl Tshantz, Solon Barocas, David Bamman, Steve Weber and the members of the UCBerkeley Social Science Matrix seminar on ‘algorithms as computation and culture.’  Declaration of conflicting interests The author(s) declared no potential conﬂicts of interest with respect to the research, authorship, and\/or publication of this article. Funding The author(s) received no ﬁnancial support for the research, authorship, and\/or publication of this article.\n"}
{"prompt":"How the machine ‘thinks’: Understanding opacity in machine learning algorithms ->","completion":"  Solon Barocas’s work focusing on machine learning algorithms specifically is a major exception to this trend (Barocas, 2014a; Barocas, 2014b; Barocas and Selbst, 2016). 4. Except for the part (generally totally invisible to users) that may be done manually by human workers who do content moderation, cross-checking, ground truthing and  7. This refers to the subset of machine learning approaches called ‘supervised’ learning which, for the sake of clarity of argument, is what is specifically considered here. 8. Giving some sense of perhaps how little the algorithms themselves have changed, this is the exact same example used to teach neural networks in the course I took as an undergraduate in 2001 as well as in the Coursera course I completed in 2013. 9. ‘Welcome’ video, Coursera course on machine learning.\n"}
{"prompt":"Four Theses on Aesthetics ->","completion":"  The Otolith Group, Zone ll, ���� (right). Issue #��� September ����  Why rethink aesthetics now, when catastrophe has become the watchword of the day, and when all but the most restrictive pragmatism could easily be construed as little more than bourgeois frivolity? Is this not, after all, the age of Antonio Gramsci’s “morbid symptoms,” in which the many heads of fascism are rearing across the globe? Yet the fascism which liberal modernity and civil society have always required has never abided by this order’s mendacious separation of the political from the aesthetic. Genocide, now as before, is an aesthetic project. The question, then, should not be why rethink aesthetics now, but rather how do we survive the aesthetic regime that carves and encloses the very shape of our question? “The quest(ion) of blackness,” to draw my accomplice Denise Ferreira da Silva’s words from my own mouth, can only be enunciated through losing one’s voice, or rather through yielding to the polyvocality that is always already the condition of possibility of speech. Thus, in writing together, Da Silva and I have not so much pursued a theoretical synthesis as a reticulation, a raveling of the threads of our thoughts, which already twisted and frayed in one another’s text(ilic)s. Four theses, another declension from the Hegelian triad.\n"}
{"prompt":"Four Theses on Aesthetics ->","completion":"  Our open proposition. —Rizvana Bradley  This is the ontological �gure consolidated in post-Enlightenment European thought, whose presupposed capacity for selfdetermination and self-development is both indistinguishable from the expropriative displacement of ecological entanglement that animates (bio)history, and, further, tantamount to the capacity for aesthetic experience and judgement. The Subject’s sensus communis, of course, only emerges through the constitutive excommunication of the Savage (THE CONQUERED), the Negro (THE COMMODITY), the Primitive (THE OTHER), and the Traditional (THE underdeveloped) —�gures who nevertheless come to haunt Man as the bearers of an ontological dissonance, an immanent declension, we might call blackness. What else can be said about the conquered, the commodity, the other, and the underdeveloped, besides the fact that they apply to all who do not fall within the spatiotemporal borders of the post-Enlightenment �gure of Man, that is, the transparent I? Not much, would be the appropriate answer, if all that is taken into account is what is o�ered by way of the constraints of dichotomist thinking. That is, if the question were not raised about the conditions under which the universal protective force held by the ethical would be extended to some humans (whether that force is bequeathed by the divine ruler or author, in their mastery of the transcendental form that is reason). If the question were not raised, that is, about why blackness is so “naturally” visited by total and symbolic violence. When the categorial force of blackness is confronted with the total violence that its historical trajectory cannot but recall, it cannot but refract and fracture the transparent shoal (the threshold of transparency) that protects the Subject’s ontoepistemology across his scienti�c and aesthetic moments.\n"}
{"prompt":"Four Theses on Aesthetics ->","completion":"  The total exposure of blackness both enables and extinguishes the force of the modern ethical program, insofar as the disruptive capacity of blackness is a quest(ion) toward the end of the world. Blackness is a threat to sense, a radical questioning of what comes to be brought under the (terms of the) “common.” If the ordered world secures meaning because it is supposed to be knowable, and only by Man, if that world is all the common can comprehend, then blackness (re)turns existence to the expanse: in the wreckage of spacetime, corpus in�nitum. Re\/De\/composition Thinking the artwork as poethical, as “a composition which is always already a recomposition and a decomposition of prior and posterior compositions,” requires being poised for the advent of becoming as matter, and its immanent interrogation of the temporality of forms.� In contradistinction to understandings of the artwork as an autonomous totality, or those that would consign the artwork to some iteration of Kant’s forma �nalis—that is, the reductive ascription of a formal purposiveness to the object—a poethical reading stresses the provisional ground where questions of form, formlessness, and abstraction collide. The artwork, a singular composite, need not simply anticipate or reiterate questions which presume the formal principles of external causation (causa e�calis), interior determination (causa �nalis), or abstract perception (causa formalis). For these senses, calci�ed as the only tools for comprehending nature (the realm of objectivity) and world (the kingdom of subjectivity), have sustained the tautology of modern thinking precisely through being rendered axiomatic. Once released from the anticipation of order and the presumption of meaning, the artwork becomes liberated from its representational obligations to nature and world. As a poethical piece, the artwork extends the question(ing)s of causa materialis, the undeterminable of  its beauties or horrors, cannot help but be the renewal of catastrophe. But this history of aesthetic revitalization is preceded and exceeded by another kind of innovation, which we may call aesthetic, even as the aesthetic can never account for it.\n"}
{"prompt":"Four Theses on Aesthetics ->","completion":"  What, then, might open and be opened by an inquiry into black practices of seriality? What takes form, or is deformed, in “the di�usion of terror and the violence perpetrated under the rubric of pleasure, paternalism, and property,” as Saidiya Hartman pro�ers?� How to come to terms with such serial self-fashioning without recourse to an idea of the open in which boundlessness becomes only another name for frontier, which is to say an enclosure, an expropriation, a clearing?� For the interminable historicity and impossible history of blackness has always come before the horizonality of Man’s freedom, as its e�aced footing and ineluctable limit. How do we regard the insistent and ongoing re\/de\/composition of the (black) �gure, in the midst of contemporary art’s simultaneous exaltation and reduction or relegation of the �gural to the scene of racial representation? How do we comprehend such �gurations as part of a suite of interventions—an epigraphic seriality, as Fred Moten might put it—which denotes not the refusal of serially imposed violence as political end, but rather the reanimate means through which any aesthetic inquiry into the social life of form must pass?� We insist that, even as such means bear the terrible burden of di�usive terror and the terror of di�usion, black seriality cannot be thought of as reducible to separability, sequentiality, or the determinacy of individuated forms and objects. In other words, our aesthetic thinking refuses to presume black seriality as wholly coterminous and coextensive with the serial imposition of antiblack violence that constitutes the modern �eld of representation and the history of form, as if the violent enumeration of black bodies were truly a ledger of or accounting for injury. Here, black art �nds an anticipatory rapport with avant-garde art movements and their respective performances of refusal— the rejection of modernism’s gridded dispossession, for instance, which is also a cartography of disposability, disregard, abusive violation, cultural erasure, and social death. However, the very fact that these performances are both denied to and refused by blackness throws into sharp relief the radical disjuncture between these respective modalities and traditions of artistic labor. Black artistic labor, which takes the fabric and substance of social existence as an alternative means of production, refracts the conceptual legacies of the autonomous totality of the artwork, and wonders about the image left on the retina.\n"}
{"prompt":"Four Theses on Aesthetics ->","completion":"  Rather than thinking blackness as di�erence notwithstanding worldly violence, we regard the serial recomposition and decomposition of blackness as incitation to an utterly divergent gestic imagination. Our critical attentiveness to these incitements remains attuned to a gestural di�erence that is irreducible, both to the serial violence of the racial regime of representation and to the so-called “politics” that clamors for recognition within it.� Generativity If the poethical artwork is no longer preoccupied with the perils of departing from the onto-epistemology of modernity, and its rendering of existence through the certainties of being, then how might aesthetic considerations start from and stay with the “object”—which is at the same time “thing” as well as “commodity” and “other”—without returning to Man or the Subject, the Human or Humanity, the Ego or Subjectivity. If our aesthetic thought begins with the “other” as commodity, as Hortense Spillers recalls, does it unavoidably (re)confront the violence that is modernity’s condition of possibility, devastating any solace that might be found through the �gurations of the colonial, racial, and cis-heteropatriarchal matrix?� Does such a thought  modernity’s grammar, marks and is marked by the art of passage without coordinates or arrival, the art of life in departure.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  On Becoming Human An Introduction  Becoming Human: Matter and Meaning in an Antiblack World argues that key texts of twentieth-century African diasporic literature and visual culture generate unruly conceptions of being and materiality that creatively disrupt the human–animal distinction and its persistent raciality.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  There has historically been a persistent question regarding the quality of black(ened) people’s humanity. African diasporic literature and cultural production have often been interpreted as a reaction to this racialization—a plea for human recognition. Becoming Human takes a different approach, investigating key African American, African, and Caribbean literary and visual texts that critique and depose prevailing conceptions of “the human” found in Western science and philosophy. These texts move beyond a critique of bestialization to generate new possibilities for rethinking ontology: our being, fleshy materiality, and the nature of what exists and what we can claim to know about existence. The literary and visual culture studied in Becoming Human neither rely on animal abjection to define being (human) nor reestablish “human recognition” within liberal humanism as an antidote to racialization. Consequently, they displace the very terms of black(ened) animality as abjection. Becoming Human argues that African diasporic cultural production does not coalesce into a unified tradition that merely seeks inclusion into liberal humanist conceptions of “the human” but, rather, frequently alters the meaning and significance of being (human) and engages in imaginative practices of worlding from the perspective of a history of blackness’s bestialization and thingification: the process of imagining black people as an empty vessel, a nonbeing, a nothing, an ontological zero, coupled with the violent imposition of colonial myths and racial  the Different Classes of Uterine Tumors, Octavia Butler’s “Bloodchild,” Ezrom Legae’s Chicken Series, and key speeches of Frederick Douglass both critique and displace the racializing assumptive logic that has grounded Western science’s and philosophy’s debates on how to distinguish human identity from that of the animal, the object, and the nonhuman more generally. In complementary but highly distinct ways, these literary and visual texts articulate being (human) in a manner that neither relies on animal abjection nor reestablishes liberal humanism as the authority on being (human).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Instead, they creatively respond to the animalization of black(ened) being by generating a critical praxis of being, paradigms of relationality, and epistemologies that alternately expose, alter, or reject not only the racialization of the human–animal distinction found in Western science and philosophy but also challenge the epistemic and material terms under which the specter of animal life acquires its authority. What emerges from this questioning is an unruly sense of being\/knowing\/feeling existence, one that necessarily disrupts the foundations of the current hegemonic mode of “the human.” While we often isolate African diasporic literary studies from the fields of science and philosophy, I contend that African diasporic literature and visual culture introduce dissidence into philosophical and scientific frameworks that dominate definitions of the human: evolution, rights, property, and legal personhood. By reading Western philosophy and science through the lens of African diasporic literature and visual culture, we can situate and often problematize authoritative (even if troubling) conceptualizations of being and material existence, demonstrating that literary and visual cultural studies have an important role to play in the histories of science and philosophy. Using literature and visual art, my study identifies conceptions of being that do not rely on the animal’s negation, as repudiation of “the animal” has historically been essential to producing classes of abject humans. Becoming Human reveals that science and philosophy share many characteristics with literature and visual art despite the espoused objectivity and procedural integrity of scientific and philosophical discourses. In debates concerning the specificity of human identity with respect to “the animal,” science and philosophy both possess foundational and recursive investments in  of philosophy and science as separate and unrelated sites of knowledge production, my study reveals their historical entanglement and shared assumptive logic with regard to blackness. As conceived by evolutionary theory and Western Enlightenment philosophy, extending into legalistic conceptions of personhood, property, and rights, antiblackness has sought to justify its defacing logics and arithmetic by suggesting that black people are most representative of the abject animalistic dimensions of humanity, or the beast. While many scholars have critiqued the conflation of black humans with animals found in Enlightenment discourses, I argue that prior scholarship has fundamentally misrecognized the logic behind the confluence of animality and racialization.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  I reinterpret Enlightenment thought not as black “exclusion” or “denied humanity” but rather as the violent imposition and appropriation—inclusion and recognition—of black(ened) humanity in the interest of plasticizing that very humanity, whereby “the animal” is one but not the only form blackness is thought to encompass. Plasticity is a mode of transmogrification whereby the fleshy being of blackness is experimented with as if it were infinitely malleable lexical and biological matter, such that blackness is produced as sub\/super\/human at once, a form where form shall not hold: potentially “everything and nothing” at the register of ontology.2 It is perhaps prior scholarship’s interpretation of this tradition as “denied humanity” that has facilitated a call for greater inclusion, as a corrective to what it deems is a historical exclusion of blackness. One consequence of this orientation is that many scholars have essentially ignored alternative conceptions of being and the nonhuman that have been produced by blackened people. This project examines how African diasporic literary and visual texts generate conceptions of being that defy the disparagement of the nonhuman and “the animal.” The terms of African diasporic art and literature’s canonization have suggested that African diasporic cultural production does little more than refute racism and petition for assimilation into the very definition of humanity that produces racial hierarchy or, as Henry Louis Gates Jr. would put it in The Signifying Monkey: A Theory of African-American Literary Criticism: “[T]he texts of the slave could only be read as testimony of defilement: the slave’s rep-  of the possession of a humanity shared in common with Europeans” (Gates 140).3 Rather than seek an assimilationist transubstantiation via the “Talking Book,” the texts in my study are better understood as providing unruly yet generative conceptions of being—generative because they are unruly. Yet, they are not always framed as an explicit critique of the dominant—thereby refusing the terms of liberal multicultural recognition, which require either the evocation of animalized depictions of blackness in order to point out the suffering these images cause or the reversal of stereotype in a bid for “inclusion.” Instead, they often just get on with upending and inventing at the edge of legibility. The chapters in this book explore the critique and innovative thought that emerge from within the contradictions of competing conceptions of modernity’s crucible—the human. I argue that the cultural production examined in the following pages reveals a contrapuntal potential in black thought and expressive cultures with regard to the human–animal distinction. In order to facilitate a fuller appreciation of the conceptions of ontology identified in Becoming Human, I pose three arguments that fundamentally reframe the animalization of blackness.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  First, I argue that philosophers’ and historians’ emphasis on antiblack formulations of African reason and history have overlooked the centrality of gender, sexuality, and maternity in the animalization of blackness.4 Namely, I argue that black female flesh persistently functions as the limit case of “the human” and is its matrixfigure. This is largely explained by the fact that, historically, the delineation between species has fundamentally hinged on the question of reproduction; in other words, the limit of the human has been determined by how the means and scene of birth are interpreted. Second, I demonstrate that Eurocentric humanism needs blackness as a prop in order to erect whiteness: to define its own limits and to designate humanity as an achievement as well as to give form to the category of “the animal.” Third, I look beyond recognition as human as the solution to the bestialization of blackness, by drawing out the dissident ontological and materialist thinking in black expressive culture, lingering on modes of being\/knowing\/feeling that gesture toward the overturning of Man. In debates concerning the specificity of human identity with respect to “the animal,” science and philosophy foundationally and recursively  sexuality are central to the autopoesis of racialized animalization that philosophers, theoreticians, and historians of race hope to displace. While black feminist and queer theories of race have underlined the intersectional nature of gender, race, and sexuality, few studies have ventured to identify the autopoetic operations of these very intersections (Maturana and Varela 78). Therefore, any study that attempts to provide an account of how racialization operates must offer an explanation of the intransigent, recursive, self-referential, and (re)animating power of abject constructs of black gender and sexuality. Contributing to studies of the longue durée of antiblackness and “afterlife of slavery,” I offer a materialist theory of both blackness’s ontologized plasticization and the temporality of antiblackness whereby I extend and revise Sylvia Wynter’s theories of sociogeny and the autopoesis of racialization, in other words, antiblackness’s auto-institution and stable replication as a system and its consequences for our being both bios and mythos.5 Much has been written about the roles of Reason and History in the production of “dehumanization.” This discourse is most commonly represented by Georg Wilhelm Friedrich Hegel’s claim that “the African,” never attaining immanent differentiation or the clarity of self-knowledge, is imprisoned by immediacy and is, in other words, ahistorical. However, in the chapters that follow, I am most interested in the roles of gender and sexuality in the production of blackness as “animal man.” Negating discourses on African “history” and “reason” are not the only—and perhaps not even the most frequently deployed— concepts through which “the African” is posited as animal.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Gender and sexuality feature prominently in animalizing discourse, as a measure of both the quality of the mind and an index of spirit. Gendered and sexual discourses on “the African” are inextricable from those pertaining to reason, historicity, and civilization, as purported observations of gender and sexuality were frequently used to provide “evidence” of the inherent abject quality of black people’s human animality from the earliest days of the invention of “the human.” Christian Europe had already privileged gender and sexuality as indicators of “civilization,” and visual observation, namely culturally situated perspective, had not emerged as an epistemological problem for thought (Haraway, “Situ-  could overcome the practical problem of differences in worldings. Thus, observation of gender and sex was deployed in the interest of producing race as a visualizable fact. The body was believed to provide presence—a supplement to the immateriality of reason and historicity. The black body’s fleshiness was aligned with that of animals and set in opposition to European spirit and mind. As Winthrop Jordan documents in White over Black: American Attitudes toward the Negro, 1550–1812, Africans and apes were linked through physiognomic comparison and sexuality. Englishmen had only encountered nonhuman primates vicariously through travel writing and gossip. They were unfamiliar with anthropoid primates, such as gorillas, chimpanzees, and orangutans.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Encounters with sub-Saharan Africans occurred adjacent to these encounters, leading to unbridled speculations linking primates and Africans (Jordan 29, 229). These speculations were an outgrowth of an epistemological foundation that had already been circulating tales of mythical human-animal hybrids and humanoid animals based on ancient reports and medieval morality (Jordan 29). Africa was seen as a land of new monsters. Though Africans were rarely perceived as a kind of ape, it was more commonly suggested that Africans and apes shared libidinous sexual characteristics or were sexually linked (Jordan 32, 227, 230–32, 237). For the English, sex was barbaric, as the body was host to sin; and when they did not perceive Africans as observing the same Christian worldview, they evaluated them negatively. According to Jordan, Africans were linked with sins of the body, and their blackness was believed to testify to their unlawful and ungodly nature (Jordan 17–20, 36, 41). The purported carnality of the African female was thought to be exemplary of African sexuality more generally, as the female sex was the measure of a race’s civility (Jordan 35). While the discussion here notes Jordan’s comments on the role of sexuality in the antiblack production of the discourse of African animality, one could reasonably suggest that at times this now-classic text naturalizes racial difference as a visualizable fact of the body with immediate, unitary aesthetic effects for Europeans.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  In Kathleen Brown’s reinterpretation of Jordan’s early modern sources, she notes that divisions of household labor between the sexes, manners and customs, and mores were as, if not more, central to West Africans’ function as foils  reading Jordan’s conclusions, skin color was not the essence of racial difference in the pre-1650 sources: writers of the period devoted considerable space to descriptions of indigenous peoples’ adornments of their bodies, “the consequences of which were no less startling to English observers than differences which allegedly originated in nature” (K. Brown 90). The common criteria for bestial otherness were measures of degrees of civility in Iberian and English sources rather than complexion. One of the most common refrains in early European accounts of people living near the so-called torrid zones was “the people goeth all naked” (K. Brown 88). The appearance of allegedly naked bodies had contradictory evocations: on the one hand, nakedness conjured images of the garden of Eden and a prelapsarian state of mind, arrested development, and innocence; on the other hand, “Nudity also communicated sexual promiscuity and the absence of civility to Europeans, which they sometimes described as ‘beastly’ living” (K. Brown 88). Rather than simply, or decisively, a matter of color, projected sexual mores and virility were crucial determinants for measuring the being of Africans. As Jennifer Morgan has shown, the imagined proof of the enslaved’s incivility and degraded humanity was frequently located in African females’ purported childbearing and child-rearing practices, whereby the breast of the enslaved took on mythic proportions. In this context, the breast took on an emblematic status: “European writers turned to black women as evidence of a cultural inferiority that ultimately became encoded as racial difference. Monstrous bodies became enmeshed with savage behavior as the icon of women’s breasts became evidence of tangible barbarism” (191).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  African female breasts were depicted as exaggeratedly long, even as bestial additional limbs. As Morgan asserts, what this history demonstrates is not that “gender operated as a more profound category of difference than race,” but rather that “racialist discourse was deeply imbued with ideas about gender and sexual difference that, indeed, became manifest only in contact with each other” (169). What observers and commentators did not question was their own universality, their grid of intelligibility, and how it conditioned not just what they saw, or even how they observed, but how they knew what they saw. This is an issue of perception that exceeds the question of what was actu-  go about evaluating any empirical truth claim. This calls into question how we “know what we know,” not only about a world “out there” but also how we “know ourselves.” Epistemology is a problem not of the past but one that is constituent with our being. By the nineteenth century, the Chain of Being’s physical anthropology, using human and animal physical measurements, sealed the connection between Africans and apes as scientific fact. One must only recall the manner in which Sara Baartman, the so-called Hottentot Venus, was displayed for the British and French public as both pornographic spectacle and scientific specimen (Gilman 88). Her physiognomic characteristics— posterior and genitals—were presumed to signal a difference in sexuality that was pronounced enough to further divide the categories of “female” and “woman”: an idealized white femininity became paradigmatic of “woman” through the abjection of the perceived African “female” (Gilman 83–85).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Female, rather than woman, African femaleness is paradoxically placed under the sign of absence, lack, and pathology in order to present an idealized western European bourgeois femininity as the normative embodiment of womanhood (Gilman 85–108). In this context, the potential recognition of womanhood in blackness, and especially black femininity, is placed in tension with the discourses on black female sexuality. Hortense Spillers put it this way: “In the universe of unreality and exaggeration, the black female is, if anything, a creature of sex, but sexuality touches her nowhere . . . the female has so much sexual potential that she has none at all that anybody is ready to recognize at the level of culture” (Black, White, and in Color 155, emphasis in original). The perpetual specter of black female lack in the realm of culturally and historically produced femininity, at the register of both performativity and morphology, produces “the African female” as paradigmatically indeterminate in terms of gender and paradigmatically the human’s limit case. The spectacularization of the posterior has perhaps blinded our critical attention to the manner with which ontologizing racial characterization not only divides and stratifies gender but also calls into question the very meaning of sexual difference. Shifting critical attention from the posterior to the breast, I demonstrate that racism not only posits cleavages in wom-  is sexuating, whereby so-called biological sex is modulated by “culture.” In other words, at the registers of both sign and matter, antiblackness produces differential biocultural effects of both gender and sex. Such a frame raises the stakes of recent feminist materialism’s inquiry into both the inter(intra)actional relations of discursivity and materiality as well as the gendered politics of hylomorphism, or the form–matter distinction.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Thus, antiblack formulations of gender and sexuality are actually essential rather than subsidiary to the metaphysical figuration of matter, objects, and animals that recent critical theory hopes to dislodge. I argue the plasticization of black(ened) people at the register of sign and materiality is central to the prevailing logics and praxis of the human and sex\/gender. Recent scholarship in black queer theory suggests we can no longer presume that gender is a metonym for “woman” and sexuality a metonym for “queer.” The wanton manipulation of gendered and sexual codes is essential to the production of antiblackness generally, irrespective of self-identification.6 Queer theory scholars have argued that the masculine– feminine dynamic is on the register of the symbolic, rather than the biological, even though it masquerades as if the borders dividing masculine from feminine map neatly onto the “natural” polarity of sex.7 What feminism has not sufficiently interrogated is the manner in which the masculine– feminine dichotomy is racialized. We have neither adequately identified that racialization is intrinsic to the legibility of its codes and grammar, namely that antiblackness constitutes and disrupts sex\/gender constructs, nor determined the consequence this has for the matter of the sexed body. Such a predicament creates conditions of gendered and sexual anxiety and instability. As Spillers states, “[I]n the historic outline of dominance, the respective subject-positions of ‘female’ and ‘male’ adhere to no symbolic integrity,” as their meaning can be stripped or appropriated arbitrarily by power, as black females’ claim to “womanhood and femininity still tends to rest too solidly on the subtle and shifting calibrations of a liberal ideology” (“Mama’s” 204, 223). Thus, while codes of gender are cultural rather than prediscursive, one must also attend to the matter of the body, as the body’s materiality is thought to provide the observable “fact” of animality. The African’s “failure” to achieve humanity has historically been  to come back to itself in self-reflection, never achieving the distance required in order to contemplate the self (Mbembe 190).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Gender, and especially sexuality, was leveraged against counterclaims acknowledging black reason and civility. For thinkers such as Thomas Jefferson, black gender and black kinship stood as an impediment to black progress. So, while it seems that the human must be reconsidered, a critical engagement with the discourses of gender and sexuality must be coincident to our interrogation of both dominant and emergent praxes of being. At this time, most feminist scholars can agree that an “intersectional” approach to the question of subjectivity is required, but scholars have not clarified how the different elements of subjectivity braid together historically and culturally. In the chapters that follow, I hope to provide more precise thinking in this area. Our task would be to take seriously the particularization of gender and sexuality in black(ened) people in the context of a humanism that in its desire to universalize, ritualistically posits black(female)ness as opacity, inversion, and limit. In such a context, the black body is characterized by a plasticity, whereby raciality arbitrarily remaps black(ened) gender and sexuality, nonteleologically and nonbinaristically, with fleeting adherence to normativized heteropatriarchal codes. In such a context of paradoxical (un)gendering, and by gendering I mean humanization, power only takes direction from its own shifting exigencies—a predicament that might be described as chaos.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  This chaos by design is used to marginalize black(ened) genders and sexualities as the border of the sociological: a condition I refer to as ontologized plasticity. Plasticity in Becoming Human describes what Stephanie Smallwood, in her study of the Middle Passage and slavery, identifies as “an enduring project of the modern Western world”: the use of black(ened) flesh for “probing the limits up to which it is possible to discipline the body without extinguishing the life within” (36). “Plasticity” has been, as concept and thematic, taken up by a range of thinkers including Hegel, LéviStrauss, Darwin, and most notably Catherine Malabou. I distinguish my concept from these alternatives in chapter 1. Here I would like to distinguish my usage from Kyla Schuller’s more recent use of a similar term: impressibility. Recently Schuller, in The Biopolitics of Feeling, (re) interprets nineteenth-century US biopolitics, arguing that in Lamarck-  inheritance rather than determinism, and that somatic potential was qualified by purported degrees of binary sex differentiation, cast as the crowning achievement of the “civilized.” By comparison, black(ened) people appeared to be inert and undifferentiated—in other words, excessive to the domain of sexual difference.8 In contrast, the concept of plasticity in Becoming Human indexes a mode of domination that conditions the discourse and practices of optimization at the center of nineteenth-century sentimentality and accompanying theories of evolution, by suggesting that racial slavery fleshed out its imagination and provided the experimental means for exploring the possibilities and boundaries of the kind of optimization Schuller elucidates.9 Plasticity’s telos, I argue, is not the optimization of life per se but the fluidification of “life” and fleshly existence. Plasticity is certainly an antiblack mode of the human concerned with apportioning vitality and pathologization, but it is more than that. Plasticity is a praxis that seeks to define the essence of a black(ened) thing as infinitely mutable, in antiblack, often paradoxical, sexuating terms as a means of hierarchically delineating sex\/gender, reproduction, and states of being more generally.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  My suggestion is that slavery, as an experimental mode, sought to define and explore the possibilities and limits of sex, gender, and reproduction on the plantation and beyond in a manner distinct from but relational to the assumed proper subject of “civilization,” and, in fact, enabled hegemonic notions of sex\/gender and reproduction such as “woman,” “mother,” and “female body.”10 I demonstrate that racial slavery as well as early modern proto-racializing conceptions of “monstrous” races and births are integral to ideas of sex\/gender, reproduction, and indeed what it means to possess a body such that receding and emergent idea(l)s of mutability and optimization provide cover for historical and ongoing discursive-material modes of domination that precede and surround its idealized and retroactively constructed white(ened) subject and from which historical and current biomedical and philosophical discourses of plasticity seek to distance and obscure. Because antiblack modes of sex\/gender and reproduction are generated by means and in terms different from the dominant, it is commonly as-  modern raciality reveals that the production of the “civilized” subject of sex\/gender and reproduction is a retroactive construction and dependent on modes of generating sex\/gender and reproduction imagined as excessive to its proper domain or otherwise invisibilized. Liberal humanism’s basic unit of analysis, “Man,” produces an untenable dichotomy—“the human” versus “the animal,” whereby the black(ened) female is posited as the abyss dividing organic life into “human” or “animal” based on wholly unsound metaphysical premises. Thus, as a result of being abjectly animalized, those marginalized have had to bear the burden of a failed metaphysics. Becoming Human furthers black studies’ interrogation of humanism by identifying our shared being with the nonhuman without suggesting that some members of humanity bear the burden of “the animal.” My second intervention is to demonstrate that exigencies of racialization, have, commonly, prefigured discourses on animals and the nonhuman, more generally and that the categories of “race” and “species” have coevolved and are actually mutually reinforcing terms. Current scholarship in posthumanism, animal studies, new materialism, and theories of biopolitics has begun a broad inquiry into the repercussions of defining “the human” in opposition to “the animal.” Much of the recent scholarship suggests that race is a by-product of prior negation of nonhuman animals. These fields, particularly animal studies, are slowly advancing the thesis that human–animal binarism is the original and foundational paradigm upon which discourses of human difference, including, or even especially, racialization was erected. The chapters that follow will take an alternative approach.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Far from being an inevitable feature of our thought, this dualism has been traced to none other than René Descartes. In “The Eight Animals in Shakespeare; or, Before the Human,” Laurie Shannon argues that historical attention to lexicons reveals that the “human–animal divide” descends from “Enlightenment modes of science and philosophy that have been largely qualified in contexts like subjectivity, rationality, and liberalism . . . To put it in the broadest terms: before the cogito, there was no such thing as ‘the animal’” (474). To illustrate the recentness of “the animal” as an impounding preoccupation, Shannon makes a striking observation:  the entire verbal expanse of Shakespeare’s work. His practice on this point of nomenclature tilts overwhelmingly against the word” (Shannon 474). Two of the eight uses of the word, Shannon notes, “involve persons failing a (gender-vexed and class-inflected) human standard”: “lack of selfgovernment,” “unchastity,” quoting Much Ado “savage sensuality,” and in Love’s Labor’s Lost animality is evoked as intellectual inferiority. Philosophers of race and Caribbeanist literary scholars have also detected the incipience of modern racialization in the work of Shakespeare.11 This scholarship notes that in The Tempest, Caliban, too, is placed under the sign of “the animal,” namely irrational and sexual intemperance. My argument is not simply that Caliban is animalized but rather that figures like Caliban are constitutive to “the animal” as a general term.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Arguably more a personified idea than a traditional character, Caliban emerged in the context of publicity surrounding European voyages to the coast of Africa and the Caribbean.12 The black body, held captive as a “resource for metaphor,” has been discussed in the work of Frantz Fanon, in which he contends that black men’s bodies, like Caliban, are projection screens for white anxiety about sexuality (Spillers, “Mama’s” 205). But, instead of recognizing their projections as just that, projection, white anxiety imposes an image of black(ened) men as a bestial sexual threat: a powerful sexual menace, initiator of sexual activity unrestricted by morality or prohibition, or one who monopolizes gendered sexual pleasure. The result is envy, punishment, or masochistic pleasure; for the black is not the symbol of sexual threat but is sexual threat—the penis becomes the synecdoche of black manhood (Fanon 170, 177). My suggestion is that these subjects—“animal” as a generic term and the racialized masculine figure of Caliban—are intertwined and that their interrelation is ordered in relation to the absent presence of the material metaphor of the black female as matrix-figure.13 By uncovering the centrality of racialized gender and sexuality in the very human–animal binarism that scholars are looking to problematize or displace, I demonstrate the necessity of the abjection and bestialization of black gender and sexuality for both the normative construction of “the human” as rational, self-directed, and autonomous and as the reproduction of the scientific matrix of classification. and philosophic definitions of “the human,” Becoming Human clarifies the terms of the relationship between what Cary Wolfe calls the “discourse of species” and racial discourse by demonstrating that racialized gender and sexuality serve as an essential horizon of possibility for the production of “the animal” as a preoccupation of Modern discourse (Animal Rites 2). Reading the existential predicament of modern racial blackness through and against the human–animal distinction in Western philosophy and science not only reveals the mutual imbrication of “race” and “species” in Western thought but also invites a reconsideration of the extent to which exigencies of racialization have preconditioned and prefigured modern discourses governing the nonhuman. As I demonstrate, at times antiblackness prefigures and colors nonhuman animal abjection. I argue that anxieties about conquest, slavery, and colonial expansionism provided the historical context for both the emergence of a developmental model of “universal humanity” and a newly consolidated generic “animal” that would be defined in nonhuman and human terms.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  In this context, discourses on “the animal” and “the black” were conjoined and are now mutually reinforcing narratives in the traveling racializations of the globalizing West. I demonstrate that both science’s and philosophy’s foundational authority articulate black female abjection as a prerequisite of “the human,” and this abjection helps give credence to the linear taxonomical (ontological) thinking present scholarship is trying to displace. Thus, racialized formations of gender and sexuality are actually central rather than subsidiary to the very human–animal binarism recent scholarship hopes to dislodge. Becoming Human emphasizes cultural production that philosophically challenges the abjection of animality and highlights alternative modes of being. The cultural production examined here does not figure the challenge of transforming ways of relating to animality as separate from the urgent need to reimagine (human)being because the semiomaterial burden of living as black virtually forecloses the “on behalf of ” structure that characterizes so much of animal studies and, especially, its antecedents—animal ethics and animal rights philosophy. As I have established thus far, Western humanism has not produced African diasporic subjectivity in a manner that would permit black people to decisively remove themselves from being subjected to violence against “the  black philosophical dissidence highlighted in this book speaks to the biopolitical entanglement of discourses on animals, environment, and African diasporic peoples. Thus, critical black studies must challenge animalization on at least two fronts: animalizing discourse that is directed primarily at people of African descent, and animalizing discourse that reproduces the abject abstraction of “the animal” more generally because such an abstraction is not an empirical reality but a metaphysical technology of bio\/necropolitics applied to life arbitrarily. Additionally, this project is not limited to a critique of anthropocentricism.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  As I have suggested here and will elaborate in the pages that follow, antiblackness’s arbitrary uses of power do not comply with the hierarchies presumed by critics of anthropocentricism. Furthermore, viruses, bacteria, parasites, and insects all commonly exercise dominance over human populations. Thus, critics such as Jacques Derrida and Cary Wolfe have foregrounded a need for a critical and accountable humanism rather than seeking ever-vigilant forms of anti-anthropocentricisms.14 However, it is crucial to critically engage with what it means to be in a biopolitical context that is characterized by entanglements of humans both historically recent and distant, nonhumans both big and small, and environments both near and far. This criticality would interrogate the epistemology of “the human,” as an idea, and that would guide its ethico-political practices rather than reify the presumptuous conceit of a received notion of the humane. A critique of anthropocentricism is not necessarily a critique of liberal humanism. Critics have advocated “on behalf of ” animals without questioning the epistemic and material project of liberal humanism. Many critics of anthropocentricism have mistakenly perceived that the problem of our time is anthropocentricism rather than a failed praxis of being. Such critics of anthropocentricism often proceed by humanizing animals in the form of rights, welfare, and protections without questioning how advocates are constructing themselves in the process.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  In other words, they do not subject the very humanity they want to decenter and\/or expand to sufficient interrogation.15 As a result, they authorize the violence of the state, one that protects, criminalizes, enforces, and prosecutes differentially based on race, class, gender, sexuality, national origin, religion, ability, and immigration status. For example, advocacy projects that seek  odds with impoverished people in African nations that have been burdened by IMF and World Bank policies. Such nations may not be able to provide even limited protections for their human citizens and even fewer economic opportunities for the people who would be prosecuted under international animal protection legislation. An impoverished person may participate in capturing animals for pay, given that the illegal wildlife trade is the world’s second largest transnational trading industry, estimated to be worth $20 billion annually, second only to drugs. Yet, impoverished people do not gain the majority of the monetary value derived from the trade; the captured animals and the wealth generated from their labor spiral upward to the West—but not the criminal prosecution.16 In this context, it is not difficult to glean how such international (read: universalist) legislation drafted by exponents from more powerful and stable nations (because they continue to be imperialist) places strain on already fragile postcolonial state resources (because they continue to be colonized). One really does have to wonder what we mean by justice and rights when states and their citizens are put in such untenable positions. At present, animal studies scholarship tends to presume a humanity that is secure within the logic of liberal humanism rather than engage with a humanity that is often cast as debatable or contingent.17 To render one’s humanity provisional, where the specter of nullification looms large, is precisely the work that racism does. Yet when the authors of this field speak of a human, they most commonly speak of one whose ontological integrity is assumed and idealized rather than plasticized, even when the goal of posthumanism and animal studies is ultimately to interrogate or undermine that certainty.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  For these fields to do accurate, fully theorized, and principled work, they must show how the question of the animal bears on the question of hierarchies of humanity. In the pages that follow, I investigate blackness’s relation to animality rather than presuppose black(ened) people’s relative power and privilege as human, vis-à-vis nonhuman animals. Thus, my work focuses on humans whose humanity is a subject of controversy, debate, and dissension in order to reveal the broader political stakes of “the animal” as a problem for contemplation. In what follows, I hope to demonstrate that the African diaspora does  studies need to be historicized and transformed, namely, the presumption that all humans are privileged over all animals by virtue of being included in humanity, or that racism is a matter of suggesting that black people are like animals based on a prior and therefore precedential form of violence rooted in speciesism. The chapters that follow are an attempt to clarify, historicize, and more precisely situate black(ened) humanity vis-à-vis animality. I engage contemporary critical theory in the fields of biopolitics, posthumanism, new materialism, and animal studies. However, my intent is to critically build on these fields’ insights, not to replicate them. What you will find in the subsequent chapters is less a systematic critical engagement with preexisting arguments in posthumanism, the new materialisms, and animal studies and more an establishment of a different conversation on ontology with different entry points because Becoming Human is more interested in redefining terms than entering into preestablished ones.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Becoming Human contends that the aforementioned fields, in the main, position blackness in the space of the unthought, and therefore are not sufficient grounds for theorizing blackness. This is not to suggest, however, that their insights hold no purchase for black studies. Departing from such a reactionary position, Becoming Human is instead learned and deliberative—borrowing freely from and extending these fields’ insights when and where it is useful to do so. To the extent to which Becoming Human does engage the fundaments of these fields, its primary aim is to clarify how blackness conditions a given discourse. Becoming Human observes some crucial distinctions: there is a difference between identifying how (anti)blackness is a condition of possibility for hegemonic thought and assuming the hegemonic terms of a given discourse. Moreover, not all engagements with a given discourse are a ceding of ground but might very well be the generative unsettling of it. By placing scholarly and creative work on blackness in dialogue with posthumanism and related fields, I am able to more fully theorize the binaristic and hierarchical logics that structure relations among humans and between animals and humans. I not only show that antiblackness is actually central to the very construction of “the animal” that recent scholarship wants to interrogate and move beyond but also that (anti)blackness upends these fields’ frameworks of analysis and evaluative judgments.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  of human recognition as a solution to the bestialization of blackness. Recognition of personhood and humanity does not annul the animalization of blackness. Rather, it reconfigures discourses that have historically bestialized blackness. In the chapters that follow, forms of human recognition—inclusion in biological conceptions of the human species and the transition from native to universal human subject in law and society—are not at odds with animalization. Thus, animalization is not incompatible with humanization: what is commonly deemed dehumanization is, in the main, more accurately interpreted as the violence of humanization or the burden of inclusion into a racially hierarchized universal humanity. The inquiry into being and matter here does not justify itself by reproducing the specter of the flesh, of the bestial, of the passions, of nature in need of human domination. The black cultural producers in this study have chosen representational strategies that redirect modern technologies (the magazine, ink-and-paper drawing, photography, painting, the short story, and the novel) by disrupting the foundational racialized epistemological presuppositions and material histories embedded in the archive of these forms. These are technologies that have not only reflected abject animalized depictions of blackness but invented them as well.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Rather than solely rehearse debates about the ideological potential or pitfalls of genres and technology, the cultural production in my study mobilizes these technologies differently, producing not only disruptive conceptions of blackness but also of ontology and epistemology more generally. African diasporic cultural production intervenes productively in reconsidering the role of “the animal” or the “animalistic” in the construction of “the human” by producing nonbinaristic models of human–animal relations, advancing theories of trans-species interdependency, observing trans-species precarity, and hypothesizing cross-species relationality in a manner that preserves alterity while undermining the nonhuman and animality’s abjection, an abjection that constantly rebounds on marginalized humans. I suggest that only by questioning rather than presupposing the virtuousness of human recognition will we be able to develop a praxis of being that is not only an alternative to the necropolitical but opposes it (Derrida, The Animal xi). Ultimately, I suggest that the normative subject of liberal humanism is  cally plastic. Therefore, the task before us is realizing being in a manner that does not privilege the very normativity cohered by notions of abject animality and the discursive-material plasticity of black(ened) flesh. This requires that scholars of race extend the radical questioning of “the human” established by African diasporic critics of Western humanism in a direction potentially unanticipated by prior scholarship, by interrogating the very construction of the animal beyond a condemnation of its racialized application and scope. Both critics who seek more equitable inclusion in liberal humanism and those who pursue a radical transformation of the normative category of “the human” have commonly overlooked the centrality of the animal question for black existential matters. Becoming Human extends the insights of African diasporic critics of “the human” by demonstrating that key texts in black cultural production move beyond a demand for recognition and inclusion in the very normative humanity that theorists such as Frantz Fanon, Lewis Gordon, Saidiya Hartman, Hortense Spillers, Fred Moten, Aimé Césaire, Sylvia Wynter, Frank Wilderson III, Katherine McKittrick, Christina Sharpe, Denise Ferreira da Silva, Achille Mbembe, and Alex Weheliye have shown is fundamentally antiblack, while also calling into question the presumptive logic undergirding the specter of animalization.18 The cultural production examined here spans three continents and three centuries because antiblackness has been central to establishing national borders and readily crosses them.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Antiblackness has also been diasporically challenged and refused, making it central to what comprises the very notion of the African diaspora and of blackness. It is precisely through rather than against historically demarcated regional, national, linguistic, and state preoccupations that this discourse cyclically reorganizes itself. Antiblackness’s pliability is essential to the intransigent, complementary, and universalizing impetus of antiblack paradigms. Irrespective of the innumerable and ever-transient definitions of black identity across the diaspora, which by definition are ephemerally produced, all black(ened) people must contend with the burden of the antiblack animalization of the global paradigm of blackness, which will infringe on all articulations and political maneuverings that seek redress for present and historical violence. from (or acts as an insurance policy against) ontologizing violence. Departing from a melancholic attachment to such an ideal, I argue that the violence and terror scholars describe is endemic to the recognition of humanity itself—when that humanity is cast as black. A recognition of black humanity, demonstrated across these pages, is not denied or excluded but weaponized by a conception of “the human” foundationally organized by the idea of a racial telos. For Wynter, the Negro is not so much excluded from the category Man and its overrepresentation of humanity but foundational to it as its antipodal figure, as the nadir of Man.19 I argue that the recognition of humanity and its suspension act as alibis for each other’s terror, such that the pursuit of human recognition or a compact with “the human” would only plunge one headlong into further terror and domination.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Is the black a human being? The answer is hegemonically yes. However, this, in actuality, may be the wrong question as an affirmative offers no assurances. A better question may be: If being recognized as human offers no reprieve from ontologizing dominance and violence, then what might we gain from the rupture of “the human”? Animalization is a privileged method of biopolitical expression of antiblackness; however, historians’ and theoreticians’ response to the centrality of animalization has been inadequate, as scholars have misrecognized the complexity of its operations. Binaristic frameworks such as “humanization versus dehumanization” and “human versus animal” are insufficient to understand a biopolitical regime that develops technologies of humanization in order to refigure blackness as abject human animality and extends human recognition in an effort to demean blackness as “the animal within the human” form. This is not to say that expressions and practices of antiblackness never radically exclude black people from the category of “the human”; rather, the point is that inclusion does not provide a reliable solution because, in the main, black people have been included in (one might even say dominated by) “universal humanity”— but as the incarnation of abject dimensions of humanity for which “the human” is foundationally and seemingly eternally at war. Thus, black people are without shelter, whether invited into or locked out of “the human.” I seek to investigate black revisionist and counter-discursive practices in the context of liberal humanism’s selective and circumscribed recognition  the global historical present, nevertheless, I argue that the severe limitations of liberal humanism and notions of “the human,” the conscripting humanity imputed to black people, has led to a radical questioning of “the human,” and in particular the status assigned to animality, in key works of black cultural expression.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  This questioning is suggestive of a desire for, perhaps, a different “genre of the human” or may even signal, as I propose, an urgent demand for the dissolution of “human” but, in either case, is not simply a desire for fuller recognition within liberal humanism’s terms (Wynter and Scott 196–197).20  Making Humans: Animalization as Humanization Everything happens as if, in our culture, life were what cannot be defined, yet, precisely for this reason, must be ceaselessly articulated and divided. —Giorgio Agamben, The Open No, they were not inhuman. Well, you know, that was the worst of it—this suspicion of their not being inhuman. It would come slowly to one. They howled and leaped, and spun, and made horrid faces; but what thrilled you was just the thought of their humanity—like yours—the thought of your remote kinship with this wild and passionate uproar. —Joseph Conrad, Heart of Darkness The uncompromising nature of the Western self and its active negation of anything not itself had the counter-effect of reducing African discourse to a simple polemical reaffirmation of black humanity. However, both the asserted denial and the reaffirmation of that humanity now look like two sterile sides of the same coin. —Achille Mbembe, On the Postcolony (emphasis in original)  As Achille Mbembe in On the Postcolony observes, discourse on Africa “is almost always deployed in the framework (or on the fringes) of a  centuries Western philosophy’s architects, figures such as Hume, Hegel, Jefferson, and Kant, constructed a theory of blackness’s inherent animality based on either “the African’s” purported physical or mental likeness to nonhuman animals, or as a result of the underdeveloped condition of African humanity.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  The former relied on the establishment of “laws of nature” whereby Africans and animals found on the African continent developed similar deficiencies based largely on geographical determinants. In such a model, privileging human–animal comparison, the environment itself is black(ened), and its inferiority in turn stymies African humanity. Thus, African peoples qualify as human but only tentatively so, given their purported physical or mental similarity to nonhuman animals and vice versa. In the latter case, a developmental model, humanity is marked as an achievement and teleology. Here “the African,” while also human, is nevertheless defined by their animality. Rather than being animal-like, black people are animals occupying the human form. The two positions have different routes but the same destination: in short, black(ened) people are the living border dividing forms of life such that “the animal” is a category that may apply to animals and some humans. Thus, the category of “the animal” develops in a manner that crosses lines of species.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Furthermore, in either case, in the process of animalizing “the African,” blackness would be defined as the emblematic state of animal man, as the nadir of the human. By virtue of racialization, the category of “the animal” could even potentially racialize animals in addition to animalizing blackness. The debate over whether blackness is a subspecies of the human or another type of being altogether haunted scientific debates concerning “monogenesis versus polygenesis.” However, the line between these two approaches is only partially maintained in the thinkers discussed across this book’s pages. It is not always clear, not only on what side of the border “the African” is placed, but also the total number of borders posited at any given point in this debate. What is certain, though, is that monogenesis or racially inclusive constructions of “the human” complemented rather than detracted from animalized depictions of blackness. Such debates were instrumental in codifying and institutionalizing both popular and scientific perceptions of race. There are too many examples to enumer-  Much of this history is known; it is commonly referred to in critiques of humanism that advance a conception of “dehumanization,” in which dehumanization is treated as sufficient shorthand for humanist thought (especially Enlightenment thought) concerning blackness. Enlightenment is a multivocality with contradiction and moving parts, and thus not reducible to its more infamous ideas.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  However, this section reinterprets a powerful and ever-present strand of racist Enlightenment thought.21 After careful investigation, I have come to some new conclusions that inform the chapters that follow: First, I replace the notion of “denied humanity” and “exclusion” with bestialized humanization, because the African’s humanity is not denied but appropriated, inverted, and ultimately plasticized in the methodology of abjecting animality. Universal humanity, a specific “genre of the human,” is produced by the constitutive abjection of black humanity; nevertheless, the very constitutive function of this inverted recognition reveals that this black abjection is transposing recognition, and an inclusion that masks itself as an exclusion. Second, blackness is not so much derived from a discourse on nonhuman animals—rather the discourse on “the animal” is formed through enslavement and the colonial encounter encompassing both human and nonhuman forms of life. Discourses on nonhuman animals and animalized humans are forged through each other; they reflect and refract each other for the purposes of producing an idealized and teleological conception of “the human.” Furthermore, antiblack animalization is not merely a symptom of speciesism; it is a relatively distinctive modality of semio-material violence that can be leveraged against humans or animals (Singer 6, 18, 83). Similarly, speciesism can be mobilized to produce racial difference. Thus, the animalizations of humans and animals have contiguous and intersecting histories rather than encompassing a single narrative on “animality.” This is a crucial point, as it allows us to appreciate the irreducibility of both antiblackness and species as well as investigate the respective semio-material trajectories of black(ened) bodies and nonhuman animal bodies take in their historical and cultural specificity. Hume extrapolated from his understanding of the natural environment that “inferior” climates produce “inferior nations.” He believed that if plants and “irrational” animals were influenced by degree of heat  all the higher attainments of the human mind,” which prompted him to “suspect negroes and in general all other species of men to be naturally inferior to the whites . . . No ingenious manufactures amongst them, no arts, no sciences” (Hume 125n).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  He went as far as to infamously declare, “In Jamaica, indeed, they talk of one negroe as a man of parts and learning; but it is likely he is admired for slender accomplishments, like a parrot who speaks a few words plainly” (Hume 213). Hume, like most Enlightenment thinkers mentioned here, accepted the Aristotelian conception of the human as an animal, but what marked human’s uniqueness, according to Aristotle, was rationality.22 The human was a “rational animal.” Thus, humanity was not defined in strict opposition to “the animal,” but one’s humanity was determined by the nature of one’s rationality. For Hume, in the case of African rationality, it was either deficient or negligible. Therefore, the humanity of the Negro “species of men” was acknowledged, but in a hierarchical and taxonomical frame. Kant, like Hume, looked to “the animal kingdom” as an analogue for humanity, but what is astonishing is the manner in which his articulations of “species” and “race” are interdependent and concentric epistemological constructions. Whether in the work of Carl Von Linne, Georges-Louis LeClerc, Comte de Buffon,23 or in the following statement by Kant, animal and human “race” are co-articulations: Among the deviations—i.e., the hereditary differences of animals belonging to a single stock—those which, when transplanted (displaced to other areas), maintain themselves over protracted generation, and which also generate hybrid young whenever they interbreed with other deviations of the same stock, are called races. . . . In this way Negroes and Whites are not different species of humans (for they belong presumably to one stock), but they are different races, for each perpetuates itself in every area, and they generate between them children that are necessarily hybrid, or blendlings (mulattoes). (17)  In such formulations, there is much anxiety about maternity and sexual difference.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  It is difficult to maintain that either the logic of raciality  demand for taxonomical and hierarchical races is foundational to the project of assimilating newly “discovered” plants and nonhuman animals into a system, as the vastness of nature would overwhelm and exceed the limits of the time and location’s reigning epistemological frame (but not its appetite for mastery).24 Race can only be subsidiary to the desire to animalize nonhuman animals or make “nature” knowable if one abstracts this desire from its historical context: “The Age of Discovery,” which is to say the age of slavery and conquest.25 If, as Foucault maintains in The Order of Things, our current hegemonic, “universalist” conception of “man” is a mutation of prior metaphysical conceptions of being, then I would qualify this insight by insisting that this mutation was and remains an effect of slavery, conquest, and colonialism. The metaphysical question of “the human,” as one of species in particular, arose through the organizational logics of racialized sexuation and the secularizing imperatives (largely economic, but not exclusively so) of an imperial paradigm that sought dominion over life, writ large. At the meeting point of natural philosophy and the so-called Age of Discovery, natural science instituted its representational logics of somatic difference in ever-increasingly secularized ontological terms. Hegel represents perhaps the most extreme articulation of “the African’s” animality, one in which animality is thought not only to be a feature, but the essence of African life. At times, from reading Hegel’s (and arguably Kant’s) geographical theories, one could conclude that his theory of nature and animals is animated by a desire to fix race as teleological hierarchy: to make race knowable and predictable. For Hegel declares: Even the animals show the same inferiority as the human beings. The fauna of America includes lions, tigers, and crocodiles. But although they are otherwise similar to their equivalents in the Old World, they are in every respect smaller, weaker, and less powerful.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  (163)  In this case, it is not the native’s likeness to animals that defines human animality; instead animals’ likeness to American Indians defines ani-  thoughts on nonhuman animals are merely a justification for his theories of race, but rather it does demonstrate that we cannot assume that racism does not animate conceptions of some of our most foundational theories of nature and nonhuman animality. Most of the humanist thought discussed here was developed during the eighteenth and nineteenth centuries when the slave trade was increasingly under scrutiny by abolitionists. Contestation had risen to unprecedented levels, and as a result, slavery increasingly required justification (Jordan 27, 231–232). These justifications relied heavily on the African’s purported animality. Even Georges Leopold Cuvier’s classification of humanity into three distinct varieties—Caucasian, Mongolian, and Ethiopian—emphasized the superiority of the Caucasian and is elaborated in his book titled Animal Kingdom (Cuvier 50). In Notes on a State of Virginia, Thomas Jefferson attempts to qualify the essence of black people’s humanity. What is crucial is that Jefferson defines black people as “animal” not based on a direct correlation to nonhuman animals but on the specificity of black people’s humanity, particularly with regard to black embodiment, sexuality, intelligence, and emotions: aesthetically displeasing form, bestial sexuality, and minor intelligence and feeling. Regarding the heart and mind, he states: They are more ardent after their female; but love seems with them to be more an eager desire, than a tender delicate mixture of sentiment and sensation.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Their griefs are transient. Those numberless afflictions, which render it doubtful whether heaven has given life to us in mercy or in wrath are less felt, and sooner forgotten with them. (Jefferson 46)  Jefferson’s arguments recognize black humanity, but the question is what kind of humanity is imputed to black(ened) people? As he states, “It is not against experience to suppose, that different species of the same genus, or varieties of the same species, may possess different qualifications” (Jefferson 151). Following Aristotle, humanity and animality are not mutually exclusive terms in much Eurocentric humanistic thought—however, there is an important qualification: the logic of conquest, slavery, and colonial-  tion of black people’s humanity did not unambiguously and unidirectionally elevate black people’s ontologized status vis-à-vis nonhuman animals. “Being human” instead provided a vehicle for reinforcing a striated conception of human species. Thus, the extension and recognition of shared humanity across racial lines is neither “denied” nor mutual, reciprocal human recognition; rather, it is more accurately deemed bestializing humanization and inverted recognition. Instead of denying humanity, black people are humanized, but this humanity is burdened with the specter of abject animality.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  In fact, all of the thinkers above identify black people as human (however attenuated and qualified); thus, assimilation into the category of “universal humanity” should not be equated with black freedom. Assimilation into “universal humanity” is precisely this tradition’s modus operandi. But what are the methods? And what are the costs? Too often, our conception of antiblackness is defined by the specter of “denied humanity” or “exclusion.” Yet as Saidiya Hartman has identified in Scenes of Subjection: Terror, Slavery, and Self-Making in NineteenthCentury America, the process of making the slave relied on the abjection and criminalization of slave humanity, rather than the denial of it. Hartman asks: suppose that the recognition of humanity held out the promise not of liberating the flesh or redeeming one’s suffering but rather of intensifying it? Or what if this acknowledgment was little more than a pretext for punishment, dissimulation of the violence of chattel slavery and the sanction given it by the law and the state, and an instantiation of racial hierarchy? What if the endowments of man—conscience, sentiment, and reason—rather than assuring liberty or negating slavery acted to yoke slavery and freedom?\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Or what if the heart, the soul, and the mind were simply the inroads of discipline rather than that which confirmed the crime of slavery. (5)  Hartman contends that the recognition of the enslaved’s humanity did not redress slavery’s abuses nor the arbitrariness of the master’s power since in most instances the acknowledgment of the humanity of the  enslaved’s humanity served as a pretext for punishment, dissimulation of chattel slavery’s violence, and the sanction given it by the law and the state (Hartman 5). What’s more, rather than fostering “equality,” this acknowledgment often served as an instantiation of racial hierarchy, as the slave is “recognized” but only as a lesser human in (pre)evolutionist discourse or criminalized by state discourses. In other words, objecthood and humanization were two sides of the same coin, as ties of affection could be manipulated and will was criminalized. The enslaved bifurcated existence as both an object of property and legal person endowed with limited rights, protections, and criminal culpability produced a context where consent, reform, and protection extended the slave’s animalized status rather than ameliorated objectification. From this perspective, emancipation is less of a decisive event than a reorganization of a structure of violence, an ambivalent legacy, with gains and losses, where inclusion could arguably function as an intensification of racial subjection. Echoing Hartman, I would argue for reframing black subjection not as a matter of imperfect policy nor as evidence for a spurious commitment to black rights (which is undeniably the case) but rather as necessitating a questioning of the universal liberal human project. “The human” and “the universal” subject of rights and entitlements assumed a highly particularized subject that is held as paradigmatic, subjugating all other conceptions of being and justice.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Furthermore, if the following assertion by Achille Mbembe is correct, “the obsession with hierarchy . . . provides the constant impetus to count, judge, classify, and eliminate, both persons and things” in the name of “humanizing” the colonized, I ask, how can we confidently distinguish humanization from animalization (Mbembe 192)? What we have at hand is more complicated than a simple opposition such as “exclusion versus inclusion,” “the human” versus “the animal,” and “humanization versus dehumanization.” Consequently, a new epistemology and transformative approach to being is needed rather than the extension of human recognition under the state’s normative conception. As long as “the animal” remains an intrinsic but abject feature of “the human,” black freedom will remain elusive and black lives in peril, as “the animal” and “the black” are not only interdependent representations  forms of antiblack racialization based on ethnicity, gender, sexuality, and national origin, for instance, these particularizing discourses are in relation to the organizing abstraction of “the animal” as “the black.” To disaggregate “humanity” from the production of “black humanity,” the one imposed on black(ened) people, assumes one could neutralize blackness and maintain the human’s coherence. But the neutralization of blackness requires the dissolution of discourses on “the animal” and vice versa, but that is, to say the least, unlikely because “the animal” is a mode of being for which Man is at war. What is more plausible is that attempts to neutralize blackness and “the animal” will continue to be in practice, if not word, a means of discipline and eradication. When humanization is thought to be synonymous with black freedom, or even a means to freedom, one risks inadvertently minimizing or extending the violence of “universal humanity.” The “universal” is a site of imperial imposition and constant contestation rather than simply an ideal. The ongoing process of universalization is purchased precisely through the abjection and ontologizing plasticization of “the African.” As Hegel argued, Africans are barred from universal humanity or spirit because they are not aware of themselves as conscious historical beings, a consequence of two intrinsic qualities.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  First, Africans worship themselves or nature rather than God. Second, Africans kill their king, which is a failure to recognize the superiority of a higher authority than themselves, whether that of God or law. The African character, according to Hegel, springs from a geographical climate hostile to the achievement of spirit. Hegel builds on earlier theories that suggest that climate is not simply fertile ground for the cultivation of nature but is also the root of a teleological human character. He believed the “torrid” and “frigid” zones, “where nature is too powerful,” do not provide the sufficient conditions for the dialectic of becoming, or the attainment of “freedom by means of internal reflection,” whereby humanity is achieved in opposition to nature (Hegel 154). One achieves spirit by rising above nature, distinguishing oneself from one’s natural surroundings. Only by passing through this stage is one able to recognize the presence of God as separate from the self and above Nature. Thus, God “exists in and for itself as a completely objective and absolute being  man in all his savagery and lawlessness” and the African’s “primitive state of nature is in fact a state of animality” (177, 178).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  The practice whereby Africans “worship the moon, the sun, and the rivers,” animating these natural forms “in their imagination, at the same time treating them as completely independent agents,” Hegel believes, ultimately makes the mistake of identifying nature’s power without identifying that nature has an eternal law or providence behind it, providing universal and permanent natural order (Hegel 178). The African’s “arbitrariness” triumphs over permanent natural order. Thus, the African is not capable of the rational universality embedded in the concepts of law, ethics, and morality. As free rational laws are, for Hegel, the bases of freedom, Hegel formulates most systematically a conception of “the African” that is both of humanity but not in humanity. Thus, humanity is not strictly a biological imperative but a cultural achievement in Hegelian thought. Hegel pronounces “the African” an animal precisely through the rejection of African political and spiritual rationality, even while denying the existence of African rational capability all together. One must ask, how can one deny the presence of African rationality through a method that acknowledges its existence? And, to what extent is black humanity “excluded” when it is central to the construction of European humanity as an achievement?\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Infamous pronouncements aside, Hegel’s conclusion is circular: his logic collapses against the weight of his precepts and method. This circuitous logic is one we inherit when a difference in Reason is interpreted as absence or chaos.26 As Mbembe notes in On the Postcolony, the problem of universal humanity shapes current conditions of ethics and justice: Each time it came to peoples different in race, language, and culture, the idea that we have, concretely and typically, the same flesh, or that in Husserl’s word, “My flesh already has the meaning of being a flesh typical in general for us all,” became problematic. The theoretical and practical recognition of the body of “the stranger” as flesh and body just like mine, the idea of a common human nature, a humanity shared with others, long posed, and still poses, a problem for Western consciousness. (2)  competing conceptions of being and justice that are not rooted in the opposition between Man and Nature. A conception of humanity that Hegel dismissed as “nature-worship” animates the work of famed South African artist Ezrom Legae, in particular his Chicken Series (Hegel 133). Legae created artworks in ink and pencil as well as totemic bronze sculptures (Figure P.1). In 1977, Legae expressed his feelings about the gunned-down child protesters during the Soweto uprising and the murder of Bantu antiapartheid leader Steve Biko at the hands of the police through chiaroscuro, a set of pencil and ink drawings. In Biko’s Ghost, Shannen Hill asserts that the Chicken Series remains among two of the best known of all works that explore Steve Biko’s death (116).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  A medium that mobilizes the polarity of black:white, by mixing light and substance, according to Richard Dyer, chiaroscuro can become a key feature of the representation of white humanity as translucence: privileging the “radiant white face” and obscuring “the opaque black one,” “which is at the very least consonant with the perceptual\/moral\/racial slippages of western dualism” (115–116). Channeling Anne Hollander, Dyer argues that chiaroscuro is a technique used to “discipline, organize and fix the image, suggesting the exercise of spirit over subject matter” (Dyer 115). If, as Dyer suggests, chiaroscuro “allows the spiritual to be manifest in the material” because it selectively lets light through, Legae’s subversion, his chiaroscuro’s representation of spirit, bends the semiotics of the Christian West and black South Africa in a direction that calls for the overthrow of (state) hierarchies of race and “the human” rooted in polarities of the enlightened and benighted.27 In the drawings, there are fragile domestic fowls and human–bird hybrids: broken bones, battered, impaled, crucified, fragmented, and swollen. Tortured bodies are alongside eggs, figures of renewal. The drawings collectively speak to the torture, sacrifice, and regeneration of South Africa’s Black Consciousness movement. As John Peffer notes, in terms of its manifest content, the image is that of Christian martyrdom: a crucified chicken. However, the animal aspect is not simply a metaphor for the pained existence of human life under the rule of apartheid; it also illustrates the animal potential of the human. This felt conception of humanity’s animal potential is rooted in  powerful, such as community leaders or healers, harness the spiritual and even physical characteristics of animals.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  For South Africans such as Legae, those depicted in his work are no longer simply human, as they are transformed by the taking on of the physical and psychical potential of animals. Thus, they are not merely metaphorically animals, but are altered in a physical and psychical sense. His work is a challenge to Manichean distinctions between the physical and the spiritual as well as “human versus the animal” (Peffer 58–59). When the prevailing notion of (human) being becomes synonymous with “universal humanity” or “the human” in discourses of law and popular consciousness, this is an outcome of power, whereby one worldview is able to supplant another onto-epistemological system with a different set of ethical possibilities. The more “the human” declares itself “universal,” the more it imposes itself and attempts to crowd out correspondence across the fabric of being and competing conceptions of being. The insistence on the universality of “the human” allows for the multiplication and proliferation of this abstraction’s aggression. To overcome a competing model, Western humanism has historically harnessed the force of the state; not only does this take the form of direct state violence, but it is also accomplished by epistemic erasure. Attacks on indigenous forms of knowledge are essential to the process of normalizing a colonial episteme.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  In bids for recognition and legibility of suffering, within national and global judicial bodies, one’s legal identity and injury must speak the language of a particular philosophy of the human. This is so despite the fact that universal humanity, as defined by Hegel and taken up in liberal humanist judicial bodies, is rooted in an anti-African epistemology. However, under the circumstances, Legae’s protest did benefit, to an extent, from its opacity and incommensurability with respect to the state’s conception of the human, as its critique was obscured from the state. Its cosmological codes, its animating conception of humanity, were rendered illegible by the same force of law that sparked his outrage and grief. However, what was opaque to the state was immediately identifiable to South Africans like himself. The current conception of universal humanity does not move beyond a Western, secularized cultural mode and  conception of universal humanity aggressively negates Legae’s conception of being and world. Namely, Hegel’s humanism disregards the rationality, reflexivity, and abstract reasoning and idiom of representation that constitute Legae’s vitalizing mode of insubordination. According to Hegel, such a considered act could never spring from “nature-worship” cosmological worldviews (133).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Ironically, the manner in which “the human” announces its universality provides the occasion for Legae’s protest to slip under the radar of the apartheid South African government and elude censorship. Evoking the latent animal potential of those brutalized by the state’s violence, an alternative mode of being (human) and attendant to spirit, the Chicken Series bypasses the problem of the representationalism and its historical reification of the traumatized black body. Thus, Legae could provide powerful witness to events barred from public discourse by an apartheid government, challenging apartheid state terror overtly (opaque). His conception of being, or ontology, defends indigenous African life from the encroachment of a humanism that universalizes itself through torture and intimidation, yes, but also via imperial epistemology, ontology, and ethics.28 Considering that much of the world does not adhere to a worldview guided by human–animal binarism nor is legible within these terms, I wonder what other modes of relating, epistemologies of being, and ethical possibilities exist beyond the horizon of “the human” and “the animal”? Some believe, like Lewis Gordon, that black people must be humanists for the “obvious” reason, that the dominant group can “give up” humanism for the simple fact that their humanity is presumed, while other communities have struggled too long for the “humanistic prize” (Gordon 39–46). But what if the enslaved and colonized “no longer accept concepts as gift, nor merely purify and polish them, but first make and create them, present them and make them convincing?” (Nietzsche 409). The elusive “humanist prize”—the formal, symmetrical extension of European humanism—makes achieving its conception of “the human” a prerequisite of equitable recognition, yet its conception of humanity already includes the African, but as abject, as plastic. Thus, in order to become human without qualification, you must already be Man in its  We misdiagnose the problems of Western globalizing humanism when we take universalism at its word, seeing its failures as simply a problem of implementation or procedure.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  This results in a further misdiagnosis of the causes and outcomes of freedom and unfreedom. Freedom itself is an evolving practice rather than a normative ideal (D. Roberts, Killing 183). As an ideal, freedom is shielded from critique by alternative conceptions rooted in another order of being\/knowing\/feeling. That said, I also believe that we have misrecognized the refractory desires of black culture, which are commonly not to assimilate but to transform. After Man In the Enlightenment thought mentioned above, “the African” is a discourse that develops out of the specific historical context of slavery and expansionism beyond the so-called temperate zones, an expansion into what came to be called Africa and the Caribbean. The discourses that developed to narrate Africa as a land of abject bestial humanity spiraled out and sought to take possession of all African diasporic peoples beyond the geo\/ethno\/linguistic specificities of “the African” and “the Hottentot.” As Mbembe puts it, “What we have said about the slave also holds for the native. From the point of view of African history, the notion of the native belongs to the grammar of animality” (236). Thus, while the black thinkers in Becoming Human were born in different nations—South Africa, Cuba, Kenya, the United States, among others— all must define themselves in a globalizing antiblack order that raises “the animal question” as ultimately an existential one.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  In this project, I am interested in how African diasporic writers and artists not only critique animalization but also exceed critique by overturning received ontology and epistemic regimes of species that seek to define blackness through the prism of abject animality. By doing so, they present possibilities that point our attention to the potential of modes of worlding that are more advantageous to life writ large. I home in on the epistemic locations of science and philosophy not only because these are the sites that have continued to be privileged in a contest over meaning and truth but also because the questions pursued in Becoming Human are  prehensive approach to African diasporic perspectives on the so-called animal question, this study does not claim to be all-inclusive, but it does claim that the strategies examined here offer a set of cases that enlarge the field of being’s possibility beyond antiblack ontological plasticity. They initiate what appears impossible and create that which is to come. In Habeas Viscus, Alexander Weheliye maintains, “The greatest contribution to critical thinking of black studies—and critical ethnic studies more generally—is the transformation of the human into a heuristic model and not an ontological fait accompli” (8). Becoming Human’s contribution to this effort is its concept of plasticity, which maintains that black(ened) people are not so much as dehumanized as nonhumans or cast as liminal humans nor are black(ened) people framed as animal-like or machine-like but are cast as sub, supra, and human simultaneously and in a manner that puts being in peril because the operations of simultaneously being everything and nothing for an order—human, animal, machine, for instance—constructs black(ened) humanity as the privation and exorbitance of form. Thus the demand placed on black(ened) being is not that of serialized states nor that of the in-between nor partial states but a statelessness that collapses a distinction between the virtual and the actual, abstract potential and situated possibility, whereby the abstraction of blackness is enfleshed via an ongoing process of wresting form from matter such that raciality’s materialization is that of a dematerializing virtuality. What sets Becoming Human apart is the manner in which it takes seriously that black literary and visual culture theorizes and philosophizes.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  While certainly highlighting historical and contemporary individual black philosophical thinkers, this project is equally interested in the philosophical thought that occurs in\/as expressive culture. Given that, historically, black people have, in the main, been excluded from the more recognized domains of politics, religion, and philosophy, I maintain that black arts and letters has often been a key site for philosophy, theology, and political theory. Becoming Human acknowledges the historical and ongoing exclusions of black people from the domain of the “properly” theoretical and philosophical, but in what follows, you will not find an effort justifying or trying to convince anyone that black  and letters philosophically. Such a reading is not content with reading a novel or poem or work of visual art as mere example of the ideas of an individual “great” thinker; rather, in reading literature and visual art for theory, the approach is that of placing the theories of\/as literary and visual art in conversation with more recognizable means and forms of philosophy. It is not an attempt to be exhaustive or comprehensive rather it takes aim at assumptive logics by disrupting and reconstellating the frame through which we have come to question blackness’s relation to Man, particularly as it pertains to “the animal” and “species.” Thus, the aim is to establish new entry points into the conversation about the nature of the problem and point to other horizons rather than purport to exhaust the monumental question of race and “the human.” Subscribing to the view all is present, when it comes to modern blackness, Becoming Human—while historically situating and contextualizing “theory”—has the principal intention of depth in its critical aims rather than producing the effects of the historian. The modes of being examined in Becoming Human do not advocate a politics based on rights and entitlements under the law, precisely because their forms are undergirded by demands that are either criminalized, pathologized, or simply rendered illegible by law and the normative mode of “the human”; these demands emerge from a different way of being\/knowing\/feeling existence than the ones legible and codified in law and the dialectics of Man. Their contestation invests in speculation and expressive culture as a site of critique and creativity. They put forth transient and fleeting expressions of potentiality in the context of the incongruity between substantial freedom and legal emancipation as well as that of colonialism and decolonization.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  These gestures of potentiality are often incomplete but point to a desire and world-upending claim that is not currently recognized in the social orders that gave rise to them. Each chapter of Becoming Human engages a different aspect of what it is to problematize the category of Man from that space that has been foreclosed in order for the category to exist.30 The arc of Becoming Human starts with the grounding reference of slavery. It puts forward the theory of ontologized plasticity based on reading across Frederick Douglass’s 1845 Narrative and 1873 speech on  of Being and its racialization of the human–animal distinction. Next, it examines the concept of “the world,” by reading Nalo Hopkinson’s genre-defying and literary philosophical Brown Girl in the Ring for its upending of Heideggerian metaphysics, in particular Heidegger’s highly influential tripartite system of human, animal, and stone, through the text’s allegorical examination of the matter of black women’s being in the world. Becoming Human then turns to a reading of Octavia Butler’s “Bloodchild,” a text that deconstructs the racialized gendered and sexual imaginary of body and self, accompanying scientific debates about the origin of life itself and symbiosis, a theory of cross-species evolutionary association. Finally, Becoming Human concludes with Wangechi Mutu’s Histology of the Different Classes of Uterine Tumors and Audre Lorde’s The Cancer Journals; Mutu’s visual art and Lorde’s journals bring to the forefront the problem of antiblackness, in the mode of a discourse of species, and its role in reproductive health disparity. Becoming Human closes with a coda that initiates a black feminist theory of the necropolitical. The last two chapters and coda concern the pertinence of the biopolitics of antiblackness to historically recent and contemporary theories of biological discourse and species.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  However, all of the texts in my study underscore the recursive trajectory of discourses on black animality. Chapter 1, “Losing Manhood: Plasticity, Animality, and Opacity in the (Neo)Slave Narrative,” is introduced by Frederick Douglass’s provocation from his 1845 Narrative, “You have seen how a man was made a slave; you shall see how a slave was made a man” (389). Slavery, in particular the slave narrative, established the terms through which we commonly understand the bestialization of blackness. Douglass’s 1845 Narrative has been central to interpretations that read African American literature through the framework of a petition for human recognition. Douglass, himself, arguably the nineteenth century’s most iconic slave, grounds his critique of slavery in natural law. However, Douglass’s later speeches problematize his commitment to the natural rights tradition found in his 1845 Narrative, by disrupting its racially hierarchical conception of being and challenging the animal abjection that is foundational to its ontology. racialization and animalization as mutually constitutive modalities of domination under slavery. Chapter 1 examines how we might read Morrison as productively problematizing sentimentality as well as gendered appeals to discourses of the Self rooted in religio-scientific hierarchy, specifically the scala naturae or Chain of Being, as both discourses have historically recognized black humanity and included black people in their conceptualization of “the human,” but in the dissimulating terms of an imperial racial hierarchy.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Beloved extends Douglass’s intervention by subjecting animality’s abjection to further interrogation by foregrounding nonhuman animal perspective, destabilizing the epistemological authority of enslaving modernity, including its gendered and sexual logics. By doing so, Beloved destabilizes the very binaristic and teleological epistemic presumptions that authorize the black body as border concept. Re-constellating the slave narrative genre, Morrison opens up a new way to interpret the genre, not as one that exposes slavery’s dehumanization but rather as one that meditates on the violence of liberal humanism’s attempts at humanization. Unsettling calcified interpretations of history and literary slave narratives, Beloved identifies the violation of slavery not in an unnatural ordering of man and beast but in its transmogrification of human form and personality as an experiment in plasticity and its limits therein, while also exploring what potential opacity holds for a generative disordering of being. Chapter 2, “Sense of Things: Empiricism and World in Nalo Hopkinson’s Brown Girl in the Ring,” is a reading of Nalo Hopkinson’s 1999 Locus Award–winning near-future novel Brown Girl in the Ring. Becoming Human avers that gendered antiblack metaphysics continues to subtend scales of world among humans, animals, and objects in Heidegger’s still highly influential thought despite being imagined as a corrective to previous scales, such as the scala naturae or the Chain of Being examined in chapter 1. It explores what other sense of world becomes available in spaces of abjection and the unthought. Martin Heidegger once wrote regarding the relation between thought and being: “[1.]\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  the stone (material object) is worldless [weltlos]; [2.] the animal is poor in world [weltarm]; [3.] man is world-forming [weltbildend]” (Fundamental 177). Chapter 2 argues that the absent presence of the black female figure functions as  sequence of this system’s imperialist worldmaking and monopolization of sense, the matter of the black female body is vertiginously affected. An inquiry into onto-epistemology, this chapter explores the reciprocal production of aesthesis and empiricism, both the seemingly scientific and the perceptual knowledge that signify otherwise under conditions of imperial Western humanism. I argue that as an enabling condition of an imperial Western humanist conception of the world as such, the black mater(nal) marks the discursive-material trace effects and foreclosures of the dialectics of hegemonic common sense and that the anxieties stimulated by related signifiers, such as the black(ened) maternal image, voice, and lifeworld, allude to the latent symbolic-material capacities of black mater, as mater, as matter, to destabilize or even rupture the reigning order of representation that grounds the thought–world relation. In other words, the specter of black mater—that is, nonrepresentability—haunts the terms and operations tasked with adjudicating the thought–world correlate or the proper perception of the world as such, including hierarchical distinctions between reality and illusion, Reason and its absence, subject and object, science and fiction, speculation and realism, which turn on attendant aporias pertaining to immanence and transcendence. Exploring the mind-body-social nexus in Hopkinson’s fiction, I contend that in Brown Girl in the Ring, vertigo is evoked as both a symptom and a metaphor of inhabiting a reality discredited (a blackened reality) that is at once the experience of the carceral and the apprehension of a radically redistributed sensorium.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  I argue that black mater holds the potential to transform the terms of reality and feeling, therefore rewriting the conditions of possibility of the empirical. While remaining attentive to the role of the scientific in the philosophical and the philosophical in scientific throughout, the second half of Becoming Human turns, more centrally, to the question of “species” in scientific discourse. Having established the plastic function of blackness in the still active metaphysics of The Great Chain and the conditioning absent presence of black mater for Heideggerian scales of being, Becoming Human moves from an investigation of the philosophical production of “the animal” to the scientific production of “species.” I demonstrate  distinctions. Chapter 3, the penultimate chapter, “‘Not Our Own’: Sex, Genre, and the Insect Poetics of Octavia Butler’s ‘Bloodchild,’” begins an inquiry into the constitutive role of antiblackness for the logics of scientific taxonomical species hierarchies. The chapter identifies the agentic capaciousness of embodied somatic processes and investigates how matter’s efficacies register social inscription. Chapter 3 provides a reading of risk, sex, and embodiment in Butler’s “Bloodchild,” a text that affirms the continued importance of risk for establishing new modes of life and worlding, despite historical violence and embodied vulnerability. “Bloodchild” is instructive for situating the racial, gendered-sexual politics of the idea of evolutionary association, or symbiogenesis, in the historical discourses of evolutionary and cell biology, as well as deposing a cross-racially hegemonic conception of the autonomous, bounded body that underwrites phantasies of possessive individualism, self-ownership, and self-determination. Perhaps surprisingly, one organism in particular—lichen—has played no minor role in the idea of evolutionary association.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  As a material actor, lichen has been a source of imagination for troubling the idea of the human individual. In 1868, when Swiss botanist Simon Schwendener put forth his theory that lichen were actually an association of a fungus or algae—modified fungi, rather than one or the other—he employed vexed social imagery (Schwendener). He argued that lichens represented a master–slave relation: the master was a fungus of the order Ascomycetes, “a parasite which is accustomed to live upon the work of others; its slaves are green algals, which it has sought out or indeed caught hold of, and forced into its service” (Schwendener 4). As Jan Sapp describes, his theory was met with “bitter opposition,” considered a threat to taxonomical classification and disciplinary boundaries (4). One commentator described the theory as “the unnatural union between a captive Algal damsel and tyrant Fungal master” (4). This theory would eventually be known as symbiosis. Similarly, the term “colonialism,” Eric C. Brown explains in Insect Poetics, “replays one of the most visible ways in which humans and insects have been compared: insect colonies take their name from the Latin verb colere, meaning ‘to cultivate,’ especially agriculturally” (xiv). This poetic Latinization of the zoological world extends the by-  If, as Donna Haraway states in How Like a Leaf, “science fiction is political theory,” the penultimate chapter demonstrates that in Butler’s narratives, interspecies relations between humans and insects, parasites, viruses, protoctists, fungi, and bacteria open up the question of what it means to be (human) rather than neatly map onto intrahuman relations and histories (120).\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  This chapter aims to critically examine the stakes, possibilities, and problems of trans-species metaphors at the interface of Butler’s fiction and its criticism by examining how racial slavery and colonial ideas about gender, sexuality, and “nature,” more generally, have informed evolutionary discourses on the origin of life itself and our ideas of cellular biology by looking at the racialized history of the theory of symbiosis in relation to “Bloodchild,” Butler’s 1984 Hugo and Nebula Award–winning short story that creatively and philosophically reimagines symbiosis as well as what it means to be (human) and to have a body. Departing from the substitutional logic Sapp and Brown identify, chapter 3 explores how Butler’s fiction overturns commonly held conceptions of “the human’s” relation to the nonhuman not by analogy but by dislodging established presumptions regarding the fundaments of human subjectivity and the materiality of the body. With “Bloodchild,” Butler offers a reorientation to the subject and its related associated notions of subjectivity and subjectivation. Butler challenges conventions of literary genre and those genres of the human predicated on racial slavery and colonial narratives of possessive individualism, sovereignty, and self-determination through a literary meditation on sexuality beyond heteronormativity, sexuation beyond dimorphism, and reproduction beyond the man–woman dyad. The fourth and final chapter, in an alternate reading of Audre Lorde’s The Cancer Journals and Wangechi Mutu’s cyborg figures in Histology of the Different Classes of Uterine Tumors, identifies the manner in which the nullification of black mater as mater, as matter, continues to underwrite contemporary species hierarchies, including that of race, as race is a “discourse of species.” This chapter, “Organs of War: Measurement and Ecologies of Dematerialization in the Works of Wangechi Mutu and Audre Lorde,” identifies the contemporary reorganization of racially sexuating bio-economies by examining biotechnology, tissue econo-  shape and are shaped by an antiblack world. “Racism,” Sylvia Wynter argues, “is an effect of the biocentric conception of the human” (“Biocentric” 364, emphasis added). Biocentrism, as defined by Wynter, is a peculiar yet hegemonic logic of species; it espouses the belief that we are “biological beings who then create culture” (361). In other words, according to a biocentric logic, human cultural practices are linearly determined by groups’ respective bio-ontological composition, which are vertically arranged by nature itself.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  Wynter contrasts this belief system’s reductive investment in DNA as substratum and mechanistic causation with an alternative she terms sociogeny: “My proposal is that we are bioevolutionarily prepared by means of language to inscript and autoinstitute ourselves in this or that modality of the human, always in adaptive response to the ecological as well as to the geopolitical circumstances in which we find ourselves” (“Biocentric” 361). With sociogeny, Wynter joins other critics of nature–culture binarism, perhaps most notably Haraway’s natureculture, which has been recently extended by ecofeminist and feminist materialist conceptions such as Samantha Frost’s “bioculture,” Staci Alaimo’s “trans-corporeality,” and Karen Barad’s “entanglement” and “intra-action.”31 But Wynter raises the stakes of these critiques by arguing that affect and desire are determinant of both nature and culture as their coproduction (matter and meaning) is given dynamic expression by biocentrism’s raciality, which is to say our studied critiques of nature–culture oppositions and the phenomenon itself are inside of the economies of affect and desire generated by raciality. Departing from an exclusive focus on structure, whether it be that of the double-helix or scaled up to the symbolic order, I argue that black female sex(uality) and reproduction are better understood via a framework of emergence and within the context of iterative, intra-active multiscalar systems—biological, psychological, environmental, and cultural. Mutu’s Histology of the Different Classes of Uterine Tumors crucially reveals the stakes of this intra-activity as it pertains to the semio-material history of “the black female body,” reproductive function, and sex(uality) as linchpin and opposable limit of “the human” in scientific taxonomies and medical science, particularly that of Linnaeus’s Systema Naturae and Ernst Haeckel’s highly aesthetic approach to evolutionary theory.32 Mu-  the spectatorial encounter from that of a determinate Kantian linear teleological drama of subjects and objects to that of intra-active processes and indeterminate feedback loops. Thus, this is not a study of a reified object but of an intra-actional field that includes material objects but is not limited to them. While chapter 4 is principally concerned with the work of Mutu, I maintain that Lorde offers insights that are generative for a fuller appreciation of Mutu’s critical artistic engagement with the racialization of biological reproductive systems and its somatic effects. Lorde’s The Cancer Journals was one of the first critical analyses of female reproductive cancers to put forth an understanding of the body as an emergent and co-productive intra-actional system and to emphasize that semioaffective-psychic relations are crucial determinants of physiological processes. Lorde contends in The Cancer Journals that carcinogenesis is a feedback loop encompassing biological, psychological, environmental, and cultural agencies and, therefore, neither a matter of individualized disease nor inferior biology but rather a somaticization of politics, and, by politics, I mean war.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  The coda closes Becoming Human with a consideration of recent developments in the biological sciences and biotechnology that have turned their attention to narrating the problem of “racial health disparity” in reproductive health. I suggest that work on the epigenome, mostly housed in the regulatory sciences—epidemiology and public health— possesses contradictory potential and thus uncertain possibilities with respect to (dis)articulating the antiblack logics that have conditioned the symbiosis of teleological determinism and evolutionary thought (whereby a developmental conception of “the human” is only one of its most obvious instantiations). Bringing the epigenome in conversation with my theory of ontologized plasticity, I argue that Mutu’s aesthetic strategies, along with those of Legae, Douglass, Morrison, Hopkinson, and Lorde, featured in Becoming Human reveal a potential (with neither guarantee nor a manifest horizon of possibility—but a potential, nonetheless) for mutation beyond a mode of thought and representation that continually adheres to predefined rules and narratives that legitimate antiblack ordering and premature death. gies and horizon of meaning. This disturbance is suggestive of how we might theorize anew the paradoxes of regimes of knowledge and being that gave rise to the ongoing exigencies of enslavement and colonial modernity. Furthermore, they are highly innovative, creatively offering contrary and often counterintuitive approaches for how we might see humans and animals differently. I am less interested in finding a universal posture toward humanism in the form of a prescription on how we should be (human) or treat animals. That would run the risk of simply inverting the paradigmatic universal subject, obscuring the particular situatedness of my subject(s) by reproducing the normative logic of imperial humanism, one that equates an idealized Western subjectivity with universal law and universal law with justice.\n"}
{"prompt":"Becoming human : Matter and meaning in an antiblack world ->","completion":"  And, as we have seen, law may obscure ethics and justice because laws always point to a specific lived, historical, and embodied subjectivity—one that is not universally shared. I approach what follows without investing in any foundational authority, whether in philosophy, law, or science, because I do not believe it is necessary for ethical action; instead, this study takes as its central task the unsettling of foundational authority. It is precisely the condition of the absence of foundational authority that has commonly grounded black ethics. Historically, foundational authority has either been hostile to or denied the possibility of black intellectualism and disqualified black people from ethical consideration. The seeds planted in the pages that follow spring from the embattled epistemology of peoples living at the vanishing point between direct domination and hegemony but who nevertheless generate a centrifugal and dissident way of being, feeling, and knowing existence.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  1 Nonhuman Vision  The view from where, exactly?\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  The term “nonhuman vision” perhaps most readily furnishes readers’ imagination with images of CCTV cameras, Google Earth, satellites, and drones. And, indeed, this chapter does take as its starting point processes of perception in which the very act of seeing something, and its subsequent temporary fixing into an image, are performed by a nonhuman agent, even if their addressee is determinedly human. The term may also bring up visual acts where the human is more explicitly positioned as part of the sighting process in real time: endoscopy, microphotography, or night photography. In those latter cases, detailed images obtained via technical apparatuses such as electronic microscopes or cameras equipped with a CCD sensor featuring very high ISO sensitivity enable access to realms that normally remain hidden from human sight. The role of such apparatuses is thus to enhance limited and partial human vision. Yet it is not my aim in this chapter to celebrate uncritically any such technological enhancements to, or even replacements for, human vision, because, as Donna Haraway bluntly states with reference to examples such as magnetic resonance imaging, home and office video display terminals, and satellite surveillance systems, “Vision in this technological feast becomes unregulated gluttony: [the] eye fucks the world to make techno-monsters.”1 Technologically enhanced vision is therefore still human, and most definitely humanist, in that it reinforces the visual mastery and material dominance of the observer: it is like the eye of a slave owner glancing over his plantation or a general scanning the battlefield,2 only better. However, just as it is not my intention to gush over  struggle against technology. So, even though this chapter does start by looking at the machinic aspects of vision that challenge the limitations of the human senses and that produce images which defy human perception, it proposes the concept of “nonhuman vision” as an ethico-political response to what Haraway calls the “god trick” of infinite vision, a masculinist gaze of domination and occupation “seeing everything from nowhere.”3 Importantly, as the examples just cited demonstrate, nonhuman vision is not directly opposed to its human counterpart.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  As pointed out by John Johnston, “Among the inherited oppositions that continue to impose limits on reflection about vision and visual culture today, that which opposes the human to the technical is perhaps the most visibly widespread and invisibly pernicious.”4 Therefore, rather than counterpoise human vision with a machinic one,5 the chapter will position the human as part of a complex assemblage of perception in which various organic and machinic agents come together—and apart—for functional, political, or aesthetic reasons. In addition to being about perception and vision, this chapter is also about viewpoints—that is, about actual points and positions from which what we humans refer to as “the world,” or “the environment,” is apprehended and from which knowledge is constructed. It is thus also about scale, proclaiming as it does the need to reintroduce structure and framing to seemingly vast posthumanist vistas, if we early twenty-first-century human thinkers and observers are to make any meaningful argument about them. Writers such as Martin Jay and Jonathan Crary, as well as Haraway herself, have variously argued that vision is historically constructed. Yet the construction of vision as vision does not occur separately from other developments: it is part and parcel of the all-encompassing and indivisible process of mediation “that is simultaneously economic, social, cultural, psychological, and technical.”6 From this perspective, the chapter recognizes that something unique has occurred to human perception and the associated ways of grasping the world in the last couple of decades, with the unprecedented extrapolation of vision to apparatuses big and small—to an extent that, as Crary puts it in Techniques of the Observer, Most of the historically important functions of the human eye are being supplanted by practices in which visual images no longer have any reference to the position  Increasingly, visuality will be situated on a cybernetic and electromagnetic terrain where abstract visual and linguistic elements coincide and are consumed, circulated, and exchanged globally.7  Yet the historical specificity of data-driven images and nonhuman scales in perception aside, my position in this chapter stops short of embracing the radical discontinuity and disruption of perception as a result of the extension of visuality across various scales. Instead, I aim to develop an argument about the inherent nonhumanity of all vision, while also zooming in on some recent technological and sociopolitical developments around vision and perception to illustrate this point and consider its consequences. Nonhuman vision as an ethico-political pointer There are good reasons why we may want to adopt nonhuman vision as an ethico-political pointer. We can reference here the recent explicit recognition that the human vision and human viewpoint are too narrow and too parochial, a realization that has occurred across different disciplines, countries, social groups, and media in light of the debates on climate change, extinction, and the Anthropocene.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  The exploration of nonhuman vision as outlined in this chapter therefore needs to be seen as not just a description of events but also as a normative proposition. Embracing nonhuman vision as both a concept and a mode of being in the world will allow humans to see beyond the humanist limitations of their current philosophies and worldviews, to unsee themselves in their godlike positioning of both everywhere and nowhere, and to become reanchored and reattached again. Nonhuman vision is therefore not just about reflexivity; it is rather about introducing concern about our point of view, and an account of it, into our conceptual and visual framework, while removing from it the privileging and stability of the humanist standpoint. It is about inviting the view of another to one’s spectrum of visuality, to the point of radically disrupting this spectrum. This approach borrows from what Haraway has called a “partial standpoint,” one that allows for the production of situated knowledge—and for giving an account of this knowledge. Lessons about such partial standpoints can be learned from other beings and entities—dogs, pigeons, insects, satellites, and space probes—as demonstrated, for example, in Jana Sterbak’s video Waiting for  Figure 1.1 Bird’s-eye view from Dr. Julius Neubronner’s miniature pigeon camera, with the pigeon’s wing tips visible on the edges of the top image, ca. 1908. Public domain.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  execution and sporting slanted horizons as well as unusual camera angles, were captured by three video cameras placed on the head of Sterbak’s Jack Russell terrier, Stanley. The footage presents a unique view of the city of Venice on the brink of flooding. The low-rise embodied canine perspective deprives the human observer of the solid grounding offered by binocular human vision; it also imposes “an awareness of the physical basis of sight, which is now recognized as something deeply subjective that cannot possibly be separated from the body.”8 Sterbak’s project echoes early experiments with attempting—and inevitably failing—to see “through the eyes of the other” by Dr. Julius Neubronner, who in 1908 patented a miniature pigeon camera activated by a timing mechanism (figure 1.1). “Spectators in Dresden could watch the arrival of the camera-equipped carrier pigeons, and the photos were immediately developed and turned into postcards which could be purchased.”9 Haraway herself has learned about partial standpoints, as she admits,  sensory area for smells. It is a lesson available from photographs of how the world looks to the compound eyes of an insect or even from the camera eye of a spy satellite or the digitally transmitted signals of space probe-perceived differences “near” Jupiter that have been transformed into coffee table color photographs. The “eyes” made available in modern technological sciences shatter any idea of passive vision; these prosthetic devices show us that all eyes, including our own organic ones, are active perceptual systems, building on translations and specific ways of seeing, that is, ways of life. There is no unmediated photograph or passive camera obscura in scientific accounts of bodies and machines; there are only highly specific visual possibilities, each with a wonderfully detailed, active, partial way of organizing worlds.10  Borrowing from the intimations of posthumanist theory, my earlier statement that all vision is to some extent nonhuman should be understood as meaning that even we humans see in ways that are more than just uniquely human. Devices such as satellites or drones only foreground this inherent nonhumanity of all vision.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Drawing on feminist intimations of Haraway and others, I thus want to position “nonhuman vision” as a better way of looking, not just in an optical but also in an ethico-political sense. The liberation of the I\/eye The aim of this chapter is therefore to challenge the traditional tenets of the liberal, self-focused, masculinist “I,” who is supposedly in control of his own vision and (world)view. Importantly, the postulation of the nonhumanism of all vision needs to be differentiated from statements about vision’s potential inhumanism. The aim of the former is to explore the possibility of developing some better modes of seeing and (re)imagining both the present and the future. This vision of nonhuman vision will therefore be of use to us in posing important political questions: If a liberation of the I\/eye is to occur, what forms of subjectivity and perception does it require? And to what extent can the posthumanist framework help us develop a better vision for the human, if this human is to unsee himself in his own narcissistic parochialism and develop what we could call a truly ecological vision of selfhood? Drawing on the work of Vilém Flusser and James Gibson, I will move to outline an ecological model of perception as a more embodied, immersive, and entangled form of image and world formation. This model will open up a passageway to being-with, and thus will offer  photographic medium, at a time when photography seems to have become democratized beyond the point of banality, by looking at various image envisioners, artists as well as amateurs.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Perception and vision are vast topics, which have been addressed from various angles by both the humanities and the sciences over the course of centuries. The discussion offered here will therefore not aim to be exhaustive; instead, it will borrow insights from the interdisciplinary heritage of visual studies and media studies to say something specific about the medium that arguably organizes that which is both extremely familiar to us and uniquely abstract: photography. Given that photography converts the dynamism of vision into two-dimensional flat impressions of the flow of time, its mode of working has often been treated as secondary or even lifeless by those in visual and media studies. It is cinema that has been positioned instead as allowing special access to, or even modeling, the experience of life.11 Yet it is precisely in this moment of carving and hence abstracting time that the potential of photography will be identified as a medium that slows down time and can teach us humans to look at ourselves and our environment differently. As Rebekah Modrak puts it in Reframing Photography, photography is “about actions involving looking. It’s the act of reproducing an image an endless number of times. … It’s about pausing something that has life and movement so that we can watch it when it’s still. It’s about creating movement through fixed images.”12 This chapter will therefore sketch out a critical vitalist framework for understanding photography as a quintessential practice of life, one that exceeds its human articulations and (re)presentations.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Retracing the experiments with photography that go back nearly two centuries, I also want to take some steps toward narrating what could be described as a nonrepresentational and nonhuman history of the medium (to be developed further in chapter 3), as a challenge to its more familiar, and more dominant, humanist counterpart. Photography will thus function here as an expanded case study through which I will try to envisage some more ethical and more politically enabling ways of seeing the world, and thus also of living with\/in it. Photography beyond humanism  be producing today, as a result of which there is supposedly nothing left for us to see or know. We can hear echoes of these stories in such headlinegrabbing statements as: Every two minutes, we take more pictures than did the whole of humanity in the 1800s! Every day, 350 million photos are uploaded to Facebook! There are over twenty billion photos on Instagram! And it’s estimated that humankind has taken 3.8 trillion pictures so far!13 The accuracy of such statements should be taken with a grain of salt, not least because of the rapid changes these platforms and the practices associated with them are undergoing, as well as the relative impossibility of measuring accurately the activities they are referencing. However, numerical accuracy is not the primary concern of those who make such proclamations.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  By drawing on the rhetorical strategies of the mathematical sublime, they are first of all interested in creating a shock effect among their audiences, dazzling us with numbers that are difficult to grasp—whose role is to act as “clickbait,” to instigate the purchase of an app or a device, or perhaps even to cause a moral panic. It is not only generators of media hype, salespeople, and “life as it used to be” morality peddlers who treat us to narratives about visual excess. In a similar vein, media and visual studies scholars have interpreted the production and consumption of images in the digital age in terms of affective labor: a form of work that is seemingly limitless, yet that remains unaccounted for and hence ultimately unrewarded, even if it is temporarily satisfying on a personal level. Indeed, clicking and sharing are never-ending tasks we are all mobilized to perform if we are to keep up with the times, or at least with the timelines of our friends’ and families’ lives. Marxist critic Jonathan Beller, writing primarily about cinema but also extending his argument to social media, argues that, in the current culture of visual excess, “in accord with the principles of late capitalism, to look is to labor.”14 He goes on to suggest, “With the rise of [the] internet grows the recognition of the valueproductive dimensions of sensual labor in the visual register. Perception is increasingly bound to production.”15 Beller is rather pessimistic about the possibility of escaping from this factory of late modern visuality, set up as a narcissistic hall of mirrors. The fact that, at the time of writing, the most popular tags on Instagram include #love, #me, #cute, #follow, and #selfie seems to corroborate his thesis.16  pessimistic stories about the supposed image deluge—or, more importantly, by their humanist underpinnings. Instead, in his book The Edge of Vision: The Rise of Abstraction in Photography, Rexer attempts to reconfigure photography as a medium of nonhuman vision.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  He encourages us to engage, slowly and meticulously, with various kinds of abstract images instead, i.e., with “photographs without pictures,” also called “photographs that withhold,”17 because they invite us to practice a “way of looking that doesn’t privilege the subject of the photograph.”18 The reasons for this visual exercise are not just academic: Rexer aims to promote what he terms “novel seeing,” in which photography “is not a looking at or a looking through but a looking with.”19 For Rexer, “The photograph itself is a piece of performance art, and the performer is light—its passing through and encountering things in the world.”20 His revisionist rereading of the traditional narrative that photography is about looking at traces of light, and hence originally about the sun, rather than about decoding human-made signs and symbols, reveals his deeper ontological and ethical ambitions for the medium. He writes, “We feel throughout the history of photography a chafing at its limits, an impatience with mere visuality, and a wish for some more intimate expression of the world’s relation—but one somehow made available through the eyes.”21 Rexer’s sentiment about the photographic medium is akin to my own desire that shapes this book. It is a desire to position photography as a zoetic, life-giving, and world-making force, albeit one that entails the enactment of (at times violent) actions of the cut that need to be performed in order to still time. The ethical dimension of photography can be confronted and engaged by its human subjects when they respond to those cuts by means of looking-with (or even becoming-with) an image. If it seems to some readers like too large a philosophical claim, the proposition of photography’s zoetic ontology and relational ethics could perhaps be seen instead in terms of an artistic performance: as an articulation of a possibility, or an attempt to engender a different language about, and a new perception of, the familiar technology and practice. As mentioned before, nonhuman vision in photography is therefore not opposed to the human mode of seeing but rather forms its constitutive aspect, even if at times this is unseen or repressed. But this aspect is also one that has been present in the history of photography from its beginning. Figure 1.2 Enhanced version of Joseph Nicéphore Niépce’s View from the Window at Le Gras, 1826 or 1827.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Public domain. made, took eight hours to expose. Niépce had positioned a camera obscura on the upper floor of his country home. Within the camera he placed a polished pewter plate coated with a type of asphalt called bitumen of Judea—a light-sensitive material that hardened on being exposed to daylight. The plate was then washed in a mixture of lavender oil and petroleum, revealing a faint yet clearly traceable image of the buildings and landscape surrounding Niépce’s estate, Le Gras. As Bill Anthes explains, The required eight-hour exposure produced a visual paradox: sunlight and shadow can be seen on two sides of structures at left and right—the “pigeon house” or upper loft of Niépce’s home, and the sloped roof of a barn with a bakehouse in the rear. As such, Niépce’s landmark image presages something that will be true of all the photographs produced in the centuries following his invention: the camera has recorded a view that, for all its apparent veracity, is a scene which the human eye could never see.22  Such a nonhuman mode of seeing and doing will arguably shape the whole of subsequent photographic practice, as well as the early discourse about this practice—even though, with the increasing focus on human subjects and on the representational aspects of the image in the second half of the twentieth century, this mode will recede into the background of the narrative about the photographic medium. This is why it is important to highlight that, working within a similar time frame as Niépce, English scientist Henry William Fox Talbot—who, alongside his French contemporary, also laid claim to the coveted title of “the inventor of photography”23—described the photographs gathered in his book The Pencil of Nature (1844–1846) as having been “impressed by Nature’s hand.”24 Talbot foregrounded not only the nonhuman impressioning of paper by light as the fundamental aspect of every photographic act but also the nonhuman vision of the camera obscura’s eye.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  He associated the camera obscura with detachment and the lack of passion, and thus of moral vision, as manifest in its inability to tell the difference between human and nonhuman entities: “the instrument chronicles whatever it sees, and certainly would delineate a chimney-pot or a chimney-sweeper with the same impartiality as it would the Apollo of Belvedere.”25 Even war photography, later subsumed by the humanist aspirations of the documentary practice—which is somewhat erroneously premised on the causal link between perception, empathy, and moral action—has nonhuman antecedents. English photographer Roger Fenton traveled to the Crimea in 1854 to record the events of the ongoing military conflict. However, due to the weight and size of his equipment, as well as the limitations of the photographic technology at the time, he was constrained in the kinds of images he was able to capture. The need for long exposure times may explain why some of the most memorable photos of the conflict—such as his vast and melancholy Valley of the Shadow of Death—have a distinctly nonhuman feel. Interestingly, it is now widely suspected that Fenton had altered the vistas captured in that photograph by adding the cannonballs to the desolate landscape for effect. This constructionist approach, coupled with the vision dislodged from a singular human observer, was carried on to Fenton’s postwar photography, as Rexer comments: Take for example his work The Long Walk, Windsor (1860), whose path splits the  vanishing point that actual experience would have contradicted. Fenton reveals to us now what the connoisseurs of his century did not understand: that photography was quintessentially a conceptual art, not a quotation at all but a visual reconstruction of reality, a simulacrum with a difference. Insofar as they reconstruct reality, photographs withhold a measure of it.26  Visual experimentation of this kind increased with the development of camera technology at the end of the nineteenth century.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Attempts to slow down time and break it into singular instances, normally invisible to the human eye, drove the work of motion photographers such as Étienne-Jules Marey and Eadweard Muybridge, whose images of movement led to the overall sense that the universe itself was “expanding with machine-aided human vision” and that “there were orders of reality yet to be disclosed.”27 The attempt to find new perspectives that would further challenge established ways of seeing, literally and figuratively, was taken up by many European artists in the early twentieth century. In the images of Russian photographer Alexander Rodchenko, Modrak writes, “transmission towers soar into the sky from a worm’s-eye point of view, horns trumpet directly overhead, and we float over crowds and stairways as though seeing with a bird’s eye.”28 The insect and bird perspective was meant to allow for a displacement of fixed relations and arrangements, whether on the material or sociopolitical level. Bauhaus professor László Moholy-Nagy went so far as to label “photography’s ability to exceed human vision with radical points of view achieved by cameras, and with experimental processes using light and photographic chemistry,”29 a “New Vision.” The embracing of nonhuman perspectives in photography by central and eastern European avant-gardes was more than just an aesthetic experiment: the gesture carried an explicit revolutionary agenda. By breaking with representationalism and aiming to shock viewers with radical new angles and vistas, photographers such as Rodchenko and El Lissitzky endowed the photographic medium with the power to transform reality—or at least with their belief in that power. This belief then resurfaced in the work of media theorist Vilém Flusser, to whom I will turn later in my attempt to rethink and reimagine photography and its discourses today. It is also worth pointing out that the avant-garde experiments with photography most likely received conceptual and technical impetus from the early scientific photography of the day. In the intro-  contemporary photographic art, which was a collaboration between the National Media Museum in Bradford and the Science Museum in London, Ben Burbridge goes so far as to suggest that the nascent scientific imagining in areas such as microphotography or radiography in the early twentieth century “helped to introduce a radically abstract vocabulary into the field of fine-art photographic practice.”30 The exhibition’s co-curator Greg Hobson in turn states that, since its early days, photography has been able to “lend form to things that were not normally visible to the human eye— providing them with the appearance of something permanent and solid, or at least bound by shape and structure.”31 Hobson’s definition captures both the inherent world-making function of photography as a medium that gives form, or stabilizes, the world in motion, and the medium’s inherent nonhuman aspect.32 My brief sketch of the nonhuman side of the history of photography hopefully demonstrates that there is something rather conservative about the discourse of the photographic medium that has dominated the field of both professional practice (in its artistic and journalistic guises) and amateur pastime in the twentieth century, when photography’s transformative ambitions were overshadowed by the conviction that the medium was close to “truth.” Rexer traces back the emergence of this conviction and approach—which he terms “a broadly documentary catechism for photography”33—to the curatorial vision of North American institutions such as MoMA and the Metropolitan Museum of Art in New York City in the 1960s, when work of artists such as Diane Arbus and Robert Frank helped establish the photographic medium as art, while also curbing its experimental tendencies. The nonhuman, mechanical, and transformative vision as practiced by the followers of the avant-garde tradition never entirely disappeared from the picture, but it did recede into the background in the midtwentieth century, with the representational approaches coming to stand in for the medium itself.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Improvements in camera technology and color printing no doubt contributed to the strengthening of this link between photography and verisimilitude—and thus to the forgetting of the fact that early photographs were “translations, not transcriptions.”34 If not strictly black and white, the first photographic images were monochrome, with the image established  well as the increased affordability of the medium and its portability have obfuscated this moment of visual translation by positing an equivalence between an image and its representation. And thus, “As Alan Sekula … has pointed out, it is the most natural thing in the world for someone to open their wallet and produce a photograph saying ‘this is my dog.’”35 This broadly documentary approach to photography finds a continuation in the amateur use of images on social media. Formal experimentation with filters on Instagram and other sharing platforms only serves to highlight the relatively narrow scope of available subjects and viewpoints, which have all been preprogrammed and preseen by the camera’s and editing software’s algorithms. The images on Flickr, a platform with arguably more creative ambitions for the medium and its audience, as demonstrated by a quick look at the “recent photos” on any given day, also tend to fall into one of several preestablished and hence visually legitimated representational categories, such as portraiture, landscape, or still life. Nonhuman versus inhumane photography It can perhaps be argued that the domination of the humanist tradition in the discourses about photography as well as in its practices in recent decades springs from an attempt to offset the anxiety some feel about photography’s mobilization for all kinds of inhumane practices. Although I am using this latter term cautiously—as any theorist of posthumanism worth his or her salt would—I am seeing its value as an indicator of wider social concerns about photography’s role and function today. Inhumane practices are practices which are shaped by the cybernetic logic of performance and functionality, but from which responsibility to and for the human as a living, breathing assemblage of culturally specific values, desires, and passions remains distinctly absent. The decision not to publish images of victims in the aftermath of the Hiroshima and Nagasaki bombings out of the unwillingness to disturb the American public illustrates how inhumane values can be perpetuated in and on behalf of photography, even if on the surface such decisions are presented as signs of “humanism” and “care.” As Modrak writes: “[I]n the weeks after the bombings, U.S. newspapers and magazines reproduced aerial views of the demolished cities and photographs of the  victories of the bomb itself.”36 Yet photography’s possible complicity with inhumane practices does not apply only to wartime events.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  As demonstrated by the contributors to the collection Seeing from Above: The Aerial View in Visual Culture edited by Mark Dorrian and Frederic Pousin, the aerial view has become a “symbol of modernity” per se,37 with the aerial image, as encapsulated by Google Earth, being “the most prominent manifestation and stimulant of this voracious contemporary appetite for views from above.”38 In a separate publication—a 2008 article titled “Mindless Photography”—photography theorist John Tagg also extends this problematic of aerial perception to the highly technologized and seemingly prosperous Western world of the early twenty-first century—a world which knows no warfare within its own territories. I will discuss Tagg’s argument in more detail in the following chapter, but, for now, I would like to highlight briefly two developments involving the expansion of photography and photo imaging beyond the human visual capacity that have caused particular distress to Tagg: the regulation of urban traffic by CCTV-controlled systems and the surveillance of space by satellites equipped with cameras. Tagg claims that such practices instantiate an “inorganic machine regime,”39 as a result of which “photography loses its function as a representation of the ego and the eye.”40 It also establishes a “circuit of mindless assemblage,” whose primary role is to “capture the viewer as a function of the State.”41 Nearly a decade later, this instrumental function of image capture is not only executed by the state (although, as we now know thanks to Edward Snowden’s revelations, various modern states have become extremely efficient in executing it), but it has also been taken up by Silicon Valley–based technological corporations such as Google, Facebook, and Twitter. In this global networked setup, images arrive to us as data which is then assigned visual characteristics and converted, or rather translated, into what we humans recognize as photographs. It is in this sense that “the activities of visuality are enacted prior to, or beyond, representation.”42 Tagg laments the fact that the photograph no longer touches the body the way it did in the old punctum model, when an individual image affected the viewer beyond the semiotic meaning it conveyed. Today, even if it does travel through the body, as electricity and data, the image is “emptied of any content of palpable sensation.”43 Rob Coley adopts a similar tone in his  biologically, infiltrating bodily relations so as to cultivate an addiction to its influence.”44 It would perhaps be easy to dismiss Tagg’s concern as just a manifestation of his unreformed humanism (and, indeed, I will put this challenge to him later in the book). Yet Tagg’s turn to the age-old anxiety about technology seems to have found an unwitting resonance with many contemporary theorists of new media, including Coley, who, after Julian Assange and Snowden, have realized that the promises of a horizontal, collaborative, and truly sharing society made in the early days of the Internet have now been overshadowed by a much darker ensemble of hierarchy and enclosure, and by the monetization of subjectivity on both affective and cellular levels. Indeed, we know now, Coley writes, “that the vast majority of data intercepted from fiber-optic cables is unexamined by humans.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  It is software that sieves metadata, that conducts complex pattern analysis, that searches for ‘triggers.’ … Here, as Deleuze warned us … , the individual becomes the ‘dividual,’ the network subject, depersonalized as packets of potential.”45 This sentiment has been reflected in the emergence of what could be called “noir theory”: writing in the shadow of the double eco-eco crisis,46 when the precariousness of the human has been exposed not just economically but also existentially, as a species. What Tagg identified in 2008 was, therefore, a premonition of a new nonhuman visuality which has a definitive inhumane touch: one that reduces the human to a source of digital capital in social media or treats the human as a visual disturbance in Google Street View (GSV) imagery (see figure 1.3)—or as an accident in drone warfare. As Jon Rafman, a photographer who first came to fame after turning surreal scenes he had found in Google Street View captures into photographic objects, has commented: “I saw GSV … in some way as the ultimate conclusion of the medium of photography: the world being constantly photographed from every perspective all the time.”47 Beyond paranoid scholarship The changed setup of visuality notwithstanding, there is arguably something rather disabling about this form of “paranoid scholarship” as espoused by the likes of Beller and Tagg. This mode of writing, drawing on familiar  Figure 1.3 Joanna Zylinska, Park Road, London, 2011 (developed as part of the “Excavating Utopia” exhibition for the Look2011 Liverpool International Photography Festival). Park Road is the most common street name in the United Kingdom. There are over a dozen Park Roads in London alone: from the leafy and wealthy thoroughfare bordering Regent’s Park in NW1 through to the urban and suburban byways of E10 and SE25. Using Google Street View, I have “visited” these different Park Road locations in order to create a multilayered portrait of the mediated city, always under surveillance. The close-up photographs zoom in on the intimate moments of life as it unfolds on “Park Road, London.”  to the natural environment—glosses over the theorist’s own pleasure at wallowing in the crisis, and at drawing vital energy for his (and it is, indeed, usually his) critical activity.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Similar arguments about the alienation of the human I\/eye by the media have been put forward before, with connections being made between television watching and laziness, or computer games and violence. Can posthumanist theory offer us tools to develop a more prudent response to this anxiety about the disembodied yet all-embracing condition of the networked media, one that does not involve reinvesting value in the ever so fragile yet also singular and hence individualistic modern subject—a subject who is said to have the right to freedom, happiness, and “the look”? Could we think of a standpoint that does not see the critic’s mind as a disembodied entity, capable of rising above the networks of data and images while assessing everyone else’s entrapment in them? After all, this “god trick” of adopting a view from the top only ends up reconfirming the humanism of its subject, a primus inter pares who can elevate himself above the general malaise by the bootstraps of his critical faculties. As an alternative, I want to propose a different modality of seeing the world around us, one that does not give up on criticality but that operates in a less detached, more immersive way. Sarah Kember and I have previously termed this modality “critical attention.” It is a disposition that entails an ethical openness to the world, but also a mindful and corporeal embeddedness in it. In this mode, the view of the situation always comes from within the enfolding of matter (at hand). Critical attention “transcends human-centered intentionality by foregrounding the ‘entangled state of agencies’ at work in any event” and acknowledges that “what we are referring to as ‘human’ is only a distinct entity ‘in a relational, not an absolute, sense’ because, as Barad explains, ‘agencies are only distinct in relation to their mutual entanglements; they don’t exist as individual elements.’”48 By itself, critical attention is not a guarantee of any transformation occurring within an established material and sociopolitical setup, but it is a necessary first step in unseeing and hence unknowing those arrangements.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Naturally, there are limitations to what such an unseeing and unknowing of the human standpoint can achieve, given that it is being performed by this very human, even if in the spirit of challenging the humanist legacy. by global communication networks. Those responses do not usually posit a disembodied critical eye\/I which can rise above its material arrangements to make pronouncements about it. Instead, they put forward a tactic of “circuit-breaking,” which is to arise from within the system itself, and which involves creating noise or a glitch within that system. For example, Rob Coley argues that “Vigilant, surreptitious, or false behaviours, which impair algorithmic control, might allow some room to manoeuvre. … Any countervisuality must be immanent to the weird and noisy middle of mediation.”49 The question therefore is not whether to be inside or outside the network—whether to tweet or not to tweet, to post on Instagram or not—because such spatial differentiations do not apply in the interlinked era in which we are all becoming (social) media.50 The question, rather, is how to envision a new mode of thinking and acting in the world in which we humans are increasingly positioned as a function of images and media—as their producers, consumers, distributors, clients, corporeal apparatuses, kinesthetic machines, and reflexive surfaces. Circuit-breaking envisioners as new revolutionaries This is precisely the problem posed by Vilém Flusser in his book Into the Universe of Technical Images, a poignant analysis of how photographs, television broadcasting, and other mechanically produced images are contributing to “a mutation of our being-in-the-world.”51 The basis of Flusser’s argument is the opposition he proposes between traditional images (which are made up of “surfaces”) and technical images (which are mosaics assembled from particles). Produced by an apparatus and driven by computational logic, a technical image is a “blindly realized possibility.”52 Flusser harbors no illusions about the human ability to manage the process of producing or even perceiving such images long-term, even if the apparatus—unlike the universe, as Flusser is keen to point out—“is subject to human control.”53 But “in the longer term, the autonomy of the apparatus must be liberated from human beings” and behave the way all systems do—i.e., aim toward entropy, or heat death.54 Yet Flusser’s philosophy is not deterministic, even if he rejects any straightforward notion of “free will” and other similar humanist niceties.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Acknowledging that information logic shapes the uni-  implacable tendency of the universe toward disinformation.”55 He also outlines a role (albeit temporary) for envisioners, i.e., “people who try to turn an automatic apparatus against its own condition of being automatic.”56 The automaticity of photography is executed not only on the level of algorithm—with the majority of cameras manufactured today being able to choose the “correct” exposure, light temperature (aka white balance), and focus—but also on the level of framing. Indeed, on picking up a camera and looking through a viewfinder or at an LCD screen, we are entering the flat perspectival vision that only began to be passed off as natural in Renaissance painting. This point of view is determined by the lens, which is positioned as an extension of the human eye—although it could more accurately be described as the eye’s constriction, or “tunneling.” As Richard Whitlock, a contemporary photographic artist who has attempted to challenge the visual domination of perspectival vision in his practice, argues: Under perspective, the dominant visual mode today, we find ourselves distanced from the things around us and from each other. We become onlookers, outsiders to a world in which objects become things to be to be looked at and studied. We look at them and examine them with impunity, since they belong in a different world. Under perspective nothing returns our gaze, nothing looks us squarely in the face, unless it be positioned at the vanishing-point, in which case it will have vanished.57  Experimentation with perspective becomes for Whitlock more than an aesthetic endeavor. Just as it was for Russian constructivists such as Rodchenko, for Whitlock it is an epistemological and ethico-political task, one that challenges the mastery of the vanishing-point vision and reminds us that there are other ways of constructing the world. Whitlock’s eight-minute looped moving image The Street, composed of many photographs and videos, depicts a nondescript yet visually pleasant street in Thessaloniki, Greece (figure 1.4).\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Initially we think we are just looking at a photo of an urban corner surrounded by relatively low-rise city mansions, on a sunny day. But then our brain quickly registers visual incongruity: the whole cityscape seems located on one plane, as if it had been folded to eliminate any sense of distance or depth. We also start noticing movement occurring in selected sections of the frame: people bustling about on balconies, laundry fluttering in the wind, cars and bicycles passing in front of our eyes and receding into the background … except there is no background and the objects that  Figure 1.4  several temporalities are unfolding at the same time, inviting the viewer to travel with her eyes from one scene to another, without offering a linear trajectory between them. The flattened perspective ends up disappointing the (modern) eye that seems to know how to look at the world, and at photographic images of this world, but it also offers the viewer something else in return: an excitation resulting from the brain being pushed to unthink that it knows what it is seeing. The Street ends up generating what the artist himself has called “an extraordinary vitality,” or an enhanced sensation of life itself—rather than just a mimetic representation of life. While Whitlock is adamant that the project is not a direct commentary on the Greek financial crisis unfolding at the time of its production—which is why the collapsed perspective should not be seen as a metonymy for the foreshortening of Greece’s political and economic future by the European Union, with its rigid decisions about the management of the Greek debt—he does agree that art should challenge established viewpoints, whether they are about traditional cinematographic vision or “Greek profligacy.”58 Whitlock thus seems to have become a Flusserian envisioner: someone who has been freed by the apparatus he uses “from the pressure for depth” and who is therefore capable of devoting his “full attention to constructing images.”59 Working with the algorithm, while also being worked by it, envisioners do not step outside the world that they describe: their creations are always born in medias res, i.e., in the midst of the technical setup. The liberatory role of the artist as creator is clearly acknowledged by Flusser, but its performance does not involve rage against the machine. Only by becoming nonhuman, by letting him- or herself be ruled by the system, can the envisioner unleash “a wholly unanticipated power of invention.”60 Flusser explains: “For envisioners, those who produce technical images, stand against the world, pointing toward it to make sense of it.”61 They inform the world, or give it form.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  This conscious in-forming activity is opposed by Flusser to the sheer act of taking images: not every image maker is an in-former; not every photographer is an envisioner. Google’s “search by image” feature, introduced in 2011, which, thanks to its pattern recognition algorithm, allows users to find images across the web that bear visual similarities to the one they input into the search box, brings this fact home rather poignantly. As curator and writer Katrina Sluis provocatively teases:  Waiho church in the South Island of New Zealand is unique? Think again. The grouping, aggregating and tracking online of images “visually” made it possible to discover images that were just like yours, and escape the image-language problem of previous archival taxonomies.62  It is not that the photo of the envisioner’s cat will necessarily stand out from the Google image grid, or that his or her Instagram feed will be better curated. Rather, a true envisioner, as envisioned by Flusser, should be able to break the feedback loop between the image and the receiver that generates ever new versions of the system’s predictable outputs, while also making images themselves “fatter and fatter.”63 This act will need to involve interrupting the ceaseless flow of likes and retweets, of tags and mirror images— in other words, of all those acts of digital creation which forfeit more insubordinate forms of creativity and which thus end up colonizing their users’ attention, turning it into affective capital for the still insatiable Giant Tech Monster. Actively promoting dialogical, rewired images, envisioners have the potential to become new revolutionaries, capable of producing “new information, improbable situations.”64 Flusser is not being naïve in imagining what may sound like “a revolution by a camera phone,” albeit one used by a circuit-bending artist. Writing in 1985, he is already acutely aware that “it is possible to miss the deadline”65—hence the urgency of his vision to reenvision image making as a nonhuman practice of creation, before it becomes truly inhumane: “For the way telematics gadgets are used now, to produce empty chatter and twaddle on a global scale, a flood of banal technical images, definitively cements in place all the gaps between isolated, distracted, key-pressing human beings.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Soon there will be nothing more we can say to one another, so now is the moment to talk it over.”66 Have we not left it too late? British artist Erica Scourti seems to be starting from a similar standpoint, even if the tenor of her work is less dramatic and more playful. Her project So Like You developed for Brighton Photo Biennial 2014 responds precisely to this obesity of images today, with everyone’s photos from birthday parties, beach holidays, or London looking more or less the same. Rather than take on the role of a digital demiurge who would in-form us ex nihilo, Scourti works not only with the apparatus and its code but also with its clients, products, and outcomes. Taking as its starting point selected snap-  our computer hard drives and Facebook—as well as letters and other personal memorabilia, she runs them through the aforementioned “search by image” function provided by Google to recognize patterns and discover similarities within the web’s visual trove. In the process, she collects strangers’ images to create multiple mirror versions of her own life—which loses its singularity and becomes a replication of cultural (as well as genetic) code. Yet Scourti’s project does not entail a complete abdication of authority and decision making to the machine. The creative gesture is still very much at work here, but it lies in re-forming the perception of what counts as human uniqueness, and of the forms of freedom afforded to us by the apparatuses—cameras, servers, Google, but also the historically and biologically constructed visual apparatus, the environment in which we see and image things, and even the biological makeup of that “we.” So Like You therefore fits into a certain legacy of the modernist, and humanist, gesture of pointing to an object (a urinal, say) or a visual array and turning it into something else.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  The artist’s gesture is both informative and performative in this case, i.e., it rearranges the seen object’s established role, setup, and legacy with a view to making it look different and say something different to us. But it also serves as a premonition of a new era for images, when, as Sluis writes, “a photograph’s value might not lie in the specificity of its content but rather in its legibility to machines and the data generated around it. This reflects a paradigm shift in which there is less value to be extracted from individual images than from the relations between them. These relations tell us much about audience sentiment, patterns of consumption and potential future demand for images.”67 So much, then, for the “free” image storage offered by many online platforms today! In the era of images getting fatter and fatter, the free lunch is not being had by their makers, nor, contrary to the rhetoric of the day, is it even being shared: it is, rather, being enjoyed, in private, by the few Big Data companies who are getting more and more gluttonous. Could an envisioner make the Giant Tech Monster choke? Bonamy Devas may be just the man for the job. Working in the tradition of glitch artists who break the established circuits of communication by introducing a malfunction into the system, he has developed Photographic Tai Chi, a project whose aim is to fool the cell phone camera’s algorithm (figure 1.5).\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Figure 1.5 Bonamy Devas, from Photographic Tai Chi, 2015. Courtesy of the artist. bodies in a tai chi–like manner and then photograph each other with the panorama function of their camera switched on, while also trying to do everything one is not supposed to do when shooting panoramas: shake the camera vigorously, move it up and down as well as back and forth, wiggle. The images produced take on all sorts of shapes and sizes, depending on the individual phone’s algorithm. They are visually reminiscent of cubist experiments, with their broken lines of vision, multiple viewpoints, and surreal connections between elements. Yet they also differ from modernist masterpieces precisely because of their networked character. The artist encourages the participants to enter what Flusser imagines as a “dialogue” and share the results of their experiments, offline and online. He also participates in the game himself.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  “By tagging the images #phototaichi and sharing via Instagram, a dispersed, crowd-sourced, evolving, post-human digital entity emerges from the feed,”68 says Devas. Through this, he can perhaps be said to be taking a step toward what Flusser called “a society of artists”—players who engage in moves and countermoves in order to reprogram the apparatus. Revolutionary engagement today, according to this cybernetics-inspired critic of technology, has to begin “with the silly telematic gadgets. It is these that must be changed and changed in ways that suit their technology. Should this be successful, the centers will collapse of their own accord.”69 Just as China seems scared of Falun Gong, should Silicon Valley, “our new default provider of infrastructure for all basic services,”70 not be scared of Photographic Tai Chi? The haptic eye The projects discussed above seem to open up possibilities not only for telling a different story of photography, one that goes beyond its most conservative, representational, and naturalistic goals, but also for rethinking perception as unfixed, nonlinear, embodied, and mobile. Drawing on insights from current theories of, and narratives about, perception, I aim to take some further steps in my effort to shift the understanding of photography and vision beyond their humanist associations and affinities. Interestingly, art history, philosophy, and other humanities fields which have been concerned with vision may prove to be at least as useful in this interrogation as  thus typically limiting their analyses to the mechanics of vision and its psychophysical and physiological aspects.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  For example, the key textbook of psychology, Sensation and Perception by E. Bruce Goldstein, while providing an accessible account of perception as “conscious sensory experience” which “occurs when the electrical signals”71 representing the object we see are transformed by our brains into our experience of seeing that object, nonetheless pronounces in its opening pages that “we still don’t understand perception.”72 Goldstein offers a detailed account of the mechanics of perception by explaining: “Perception is determined by an interaction between bottom-up processing, which starts with the image on the receptors, and top-down processing, which brings the observer’s knowledge into play.”73 He also claims that recognition and action form its inherent components. Yet, when it comes to making a leap from explaining the mechanics of perception to explaining how nerve impulses, or sodium and potassium molecules flying across a membrane, become transformed into actual perceptual experience—i.e., the perception of a person’s face or the experience of the color red—Goldstein admits defeat, not just by himself but by his fellow scientists. He states, “Although researchers have been working to determine the physiological basis of perception for more than a century, the hard version of the mind-body problem is still unsolved. The first difficulty lies in figuring out how to go about studying the problem.”74 For this reason, many researchers focus instead on the physiological problem of the neural correlate of consciousness (where consciousness can be roughly seen to stand in for our experiences). It is therefore to philosophers and visual theorists that we should turn in an attempt to rethink perception, not only because such scholars are more willing to take on open-ended questions but, most importantly, because they approach perception as a cultural problem and not just a physiological one. As Crary has poignantly argued, perception and vision “have no autonomous history. … [W]hat determines vision at any given historical moment is not some deep structure, economic base, or world view, but rather the functioning of a collective assemblage of disparate parts on a single social surface. It may even be necessary to consider the observer as a distribution of events located in many different places.”75 An art historian by training, Crary does an excellent job in tracing back the changing ideas of  from God—even if it is not scientifically accurate76—has shaped our modern understanding of perception.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  He cites the camera obscura, “with its monocular aperture,” as becoming “a more perfect terminus for a cone of vision, a more perfect incarnation of a single point than the awkward binocular body of the human subject.”77 The camera obscura thus ended up stabilizing perception for centuries to come. It was only in the early to mid nineteenth century that the increased physical and conceptual mobility of the human subject in the world encouraged some new articulations of the human’s relationship to, and cognizance of, his or her environment. Yet Crary also manages to trace an alternative, even if suppressed, history of perception, which he terms the “anti-optical notion of sight,”78 with thinkers as diverse as Berkeley, Goethe, and Schopenhauer pointing to more subjective and more sensuous aspects of vision, and hence to its inherent tactility. While the stereoscope opened up the possibility of embracing the physical side of the act of perception, this possibility was overcome by that of the photographic camera, which managed to remap and subsume the phenomenological and the tactile within the optical. Yet it is important to emphasize here that it is not photography as such that led to this withdrawal and reductionism, but rather its unbroken association with the linearity and fixity of vision. Crary explains that photography “recreated and perpetuated the fiction that the ‘free’ subject of the camera obscura was still viable. Photographs seemed to be a continuation of older ‘naturalistic’ pictorial codes, but only because their dominant conventions were restricted to a narrow range of technical possibilities (that is, shutter speeds and lens openings that rendered elapsed time invisible and recorded objects in focus).”79 However, as I have tried to show throughout this chapter, photography from its beginning has developed a parallel trajectory of nonnaturalistic experiments, working against the equipment’s technical limitations or even embracing them as modes of artistic expression. When representationalism is not the main goal of image making, the camera’s technology does not have to be seen as “restricted” and “narrow” but can rather be embraced as facilitating a different way of imaging.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  But, with the technological developments in optics and electronics, the naturalistic set of visualizing conventions became the norm, thus firming up the dominant understanding of photography as a practice of representation. the history of photography. Even though the “pure perception of modernism,” as Crary puts it, was premised on “the denial of the body, its pulsings and phantasms, as the ground of vision,”80 the story of nonhuman vision I have been telling here by casting light on nonhuman and nonrepresentational photography has in fact been an attempt to reclaim vision’s embeddedness and embodiment—and thus to reinsert the human back into the picture beyond the strict subject-object dichotomy. Yet grasping vision as distributed allows us to sever the “ray of light” believed to connect the human observer in a straight line with the divine on the one hand and with the perceived object on the other. This gesture has been in step with Haraway’s intimation that “Vision can be good for avoiding binary oppositions.”81 I would thus like to insist, together with Haraway, “on the embodied nature of all vision and so reclaim the sensory system that has been used to signify a leap out of the marked body and into a conquering gaze from nowhere.”82 We could perhaps go so far as to embrace what Haraway calls, after coral and ethnography researcher Eva Hayward,83 “the haptic visual,” whereby vision is figured “as touch, not distance, as entwined with, or negatively curving in loops and frills, not surveying from above.”84 There is a clear ethical imperative in this kind of material-conceptual refiguration of visuality “as a becoming-with or being-with, as opposed to surveying-from.”85 Interestingly, architecture has been at the forefront of developing alternative theories of perception that go beyond the linear visual model, as it is an explicitly visual and sensual practice, focused on the relationship between bodies, buildings, and environments. In his tellingly titled book The Eyes of the Skin: Architecture and the Senses, Finnish architect, educator, and writer Juhani Pallasmaa argues against the denigration of the body in perception. Resisting the traditional positioning of the eye outside time and history by many philosophers, and the subsequent adoption of this model by artists and architects—a culmination of which can be found in the visual distancing of certain forms of modernism, with buildings designed to be looked at rather than dwelled in—Pallasmaa develops his theory of the eye as skin instead. His theory of vision as haptic rather than just ocular revisits the suppressed sensuous dimension of architectural history, going back all the way to ancient Greek architecture, with its “haptic sensibility.”  function as the ultimate source of knowledge and arbiter of meaning in the world.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  It is rather redefined as just one of the senses, with all of them seen as “extensions of the sense of touch—as specializations of the skin.”87 Interestingly, one of the architectural designs by Pallasmaa himself that returns most often in his book (and in its afterword by Peter MacKeith) as both a concept and an image is that of a door handle: a seemingly innocuous architectural detail that is also a literal invitation to touch the building. We could therefore conclude that Pallasmaa’s theory of the haptic eye is close to my concept of nonhuman vision because it repositions seeing as an active and dynamic process of sensuous interaction between surfaces. While stripping linear, ocular perception of its dominant role in cognition and world making, it also enriches our understanding of how perception works by pointing to the fact that we are already of the world—and that we emerge with it.88 Pallasmaa’s ideas develop from the ecological theory of perception outlined by psychologist James Gibson in the mid-1950s. Premised on the assumption that the point of observation is mobile rather than fixed, Gibson’s theory moves away from the model of perception as the transmission of an image from an object to the eye (or the brain). Instead, he understands vision as a panoramic perceptual system, with both the eye and the brain being parts of that system. This model is a direct opposite of what Haraway described as a “god trick” of infinite vision “from nowhere”: in Gibson’s ecological model of perception, “to perceive the world is to coperceive oneself.”89 According to Gibson, vision is kinesthetic, requiring a movement of the perceiving agent’s body and delivering simultaneous information about, and awareness of, “the world” and “the self in the world.”90 There is an ethical dimension to Gibson’s proposition: concerned that we modern humans “live boxed-up lives,”91 he is intent on returning us to ways of seeing that are, if not entirely nonhuman, then at least premodern-adult-human: those of our ancestors, children, and animals. Importantly, Gibson is keen to liberate us from the fixities of not just our viewpoints but also our standpoints, and to get us to look around, literally. This involves challenging the camera\/shutter model of perception because, in his understanding (supported by scientific research), our eyes are never fixed: “The eyes normally search, explore, or scan, and there are seldom  Figure 1.6 Fibonacci, Kanizsa Triangle.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Such “kanizsa figures,” named after researcher Gaetano Kanizsa, trigger “the percept of an illusory contour by aligning Pac-Man-shaped inducers in the visual field, such that the edges form a shape” (“Illusory Contours,” https:\/\/en.wikipedia.org\/wiki\/Illusory_contours), 2007, license: CC BY-SA 3.0.  in a jerky manner, and experiencing a small low-frequency tremor—our eyes are “drawn to hard edges”93 as points of stoppage on this inevitably blurry journey of perceptive movement. Rebekah Modrak explains: “The eye and brain are accustomed to using contours as a way to understand the environment.” Even though nothing in the world is actually made up of lines and edges, “the eye and brain have evolved systems that encode these differentiating signals and process the information in such a deceptively casual manner that we start to believe that edges and lines are visible components of the ‘real world.’”94 We could therefore go so far as to suggest that our visual apparatus introduces edges and cuts into the imagistic flow: it cuts up the environment so that we can see it, and then helps us stitch it back together again (figure 1.6). With this idea, we arrive at the concept of perception as active, or even world-making, rather than just secondary and responsive. The ethical force of the cut In light of the analysis above, I would like to suggest that vision itself can be understood as photographic. Similar propositions have been made before,  as a passive vehicle of image production, and photography, to cite Susan Sontag, as “an act of non-intervention.”95 The aim of this chapter has been to challenge such passive models and to position photography as a zoetic, life-giving force. It has also been to return life and movement to the very process of human perception—a process which needs to become (again) other-than-human if it is to be truly liberated from its physical and conceptual constraints. We are entering here the realm of photography understood not as a passive recording of the world but as an active process of shaping it through making cuts in the imagistic flow. Photography can play a key role in the liberation of vision from its conceptual and physical rigidity by allowing us to take stock of the imagistic flow—and of the insertions made in it by our visual and cognitive apparatus.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  So, rather than follow the “flow of images equals the flow of life” line of thinking, which has led some theorists—from Bergson and Deleuze through to Gibson—to proclaim that “Moviemakers are closer to life than picture makers,”96 I want to return to photography here as a quintessential practice of both life and the cut. The cover of Henri Cartier-Bresson’s photobook The Decisive Moment, featuring a paper gouache cutout by Henri Matisse, serves as a telling illustration of this point. Even though the humanist narrative of Cartier-Bresson’s eponymous idea, as encapsulated in his rather conventional photographs of “the Occident” and “the Orient,”97 promotes the idea of the photographer as a self-contained focused eye that can isolate chance events and grab them, Matisse’s cover returns us to the mechanical aspect of photography as the practice of cutting undertaken in alliance with various apparatuses: the eye, the brain, the camera. This is to say, cutting is not a purely human-centric process because its driving mechanism exceeds human control, but there do, of course, exist instances of cutting which the human subject can make her own, and of which she can give an account. Drawing attention to the cut is therefore also a way of reintroducing the moment of ethico-political decision into the perceptive flow. As Kember and I have argued in Life after New Media, “The process of cutting is one of the most fundamental and originary processes through which we emerge as ‘selves’ as we engage with matter and attempt to give it (and ourselves) form. Cutting reality into small pieces—with our eyes, our bodily and cognitive apparatus, our language, our memory, and our technologies—we enact separation and rela-  through displacing it from its humanist anchorings and models, we need a cut to be more than just a technique—one that we encounter not only in photography but also in film making, sculpture, writing, or, indeed, any other technical practice that involves transforming matter: it must also be seen as an ethical imperative (“Cut!”).99 Given that perception involves the insertion of edges and lines into the flow of vision, a process that is to a large extent nonconscious and not just human, we may need to introduce reflection to this process and pose the question of whether it is possible to recut the world anew, to a different size and measure, beyond the “god trick” of the straight line and the visual gluttony of the insatiable eye fuck. Nonhuman photography: A postscript The images that make up the Active Perceptual Systems project (figure 1.7) were taken over a period of two years with an automated “intelligent” wearable camera called the Autographer.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  Originally designed as a mnemonic device for people with Alzheimer’s, the Autographer was subsequently remarketed by the OMG Life company as a media gadget tool for the “always-on” generation. On selected days between 2014 and 2016, I wore the camera in various everyday situations: on a city walk, in a holiday resort, in an art gallery, in a lecture theater (when talking about nonhuman photography), at home. Inconspicuous due to its resemblance to a small necklace yet clearly visible, the camera randomly took photographs at frequent intervals. I then uploaded the photos to my computer. My decision to wear the camera on a given day, switch it on, and then select and process the images (originally taken in color) was coupled with the decision of the camera algorithm regarding what to photograph and when. The machinic behavior was nevertheless influenced by the way I moved my body, enacting a form of immersive, corporeal perception that broke with the representationalist linearity of perspectival vision while also retaining human involvement in the multiple acts of image capture. The human element was also foregrounded in the subsequent editing activities: I was faced with over 18,000 images from which I chose several dozen. The selection process was akin to making careful incisions in the image flow, with a view to setting up narrative  in city centers, on public transport, and in shopping malls, through to selfmonitoring via the constant recording of our lives with cell phones—Active Perceptual Systems is designed as a commentary on this incessant fabrication of images: of us, but also by us.\n"}
{"prompt":"Nonhuman Photography: Nonhuman Vision ->","completion":"  It also raises the question of whether, in the age of “image obesity,” the creative photographer can be seen as first and foremost an editor: a Flusserian in-former who provides structure to the imagistic flow after the images have been taken.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  The Labor of the Inhuman, Part II: The Inhuman Reza Negarestani  Issue #�� March ����  Continued from “The Labor of the Inhuman, Part I: Human” Enlightened humanism as a project of commitment to humanity, in the entangled sense of what it means to be human and what it means to make a commitment, is a rational project.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  It is rational not only because it locates the meaning of human� in the space of reasons as a speci�c horizon of practices, but also and more importantly, because the concept of commitment it adheres to cannot be thought or practiced as a voluntaristic impulse free of rami�cations and growing obligations. Instead, this is commitment as a rational system for navigating collateral commitments—their rami�cations as well as their speci�c entitlements—that result from making an initial commitment. Interaction with the rational system of commitments follows a navigational paradigm in which the rami�cations of an initial commitment must be compulsively elaborated and navigated in order for this commitment to make sense as an undertaking. It is the examination of the rational fallout of making a commitment, the unpacking of its far-reaching consequences, and the treating of these rami�cations as paths to be explored that shapes commitment to humanity as a navigational project. Here, navigation is not only a survey of a landscape whose full scope is not given; it is also an exercise in the non-monotonic procedures of steering, plotting out routes, suspending navigational preconceptions, rejecting or resolving incompatible commitments, exploring the space of possibilities, and understanding each path as a hypothesis leading to new paths or a lack thereof—transits as well as obstructions. From a rational perspective, a commitment is seen as a cascade of ramifying paths that is in the process of expanding its frontiers, developing into an evolving landscape, unmooring its �xed perspectives, deracinating any form of rootedness associated with a �xed commitment or immutable responsibilities, revising links and addresses between its old and new commitments, and �nally, erasing any image of itself as “what it was supposed to be.” To place the meaning of human in the rational system of commitments is to submit the presumed stability of this meaning to the perturbing and transformative power of a landscape undergoing comprehensive changes under the revisionary thrust of its ramifying destinations. By situating itself in the rational system of commitments, humanism posits itself as an initial condition for what already retroactively bears a minimal resemblance, if any at all, to what originally set it in motion. Su�ciently elaborated, humanism—it shall be argued—is the initial condition of inhumanism as a force that travels back from the future to alter, if not to completely discontinue, the command of its origin.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  human means being able to enter the space of reason, then a commitment to humanity must fully elaborate how the abilities of reason functionally convert sentience to sapience. But insofar as reason enjoys a functional autonomy—which enables it to prevent the collapse of sapience back into sentience—the full elaboration of the abilities of reason entails unpacking the consequences of the autonomy of reason for human. Humanism is by de�nition a project to amplify the space of reason through elaborating what the autonomy of reason entails and what demands it makes upon us. But the autonomy of reason implies its autonomy to assess and construct itself, and by extension, to renegotiate and construct that which distinguishes itself by entering the space of reason. In other words, the self-cultivation of reason, which is the emblem of its functional autonomy, materializes as staggering consequences for humanity. What reason does to itself inevitably takes e�ect as what it does to human. Since the functional autonomy of reason implies the self-determination of reason with regard to its own conduct—insofar as reason cannot be assessed or revised by anything other than itself (to avoid equivocation or superstition)—commitment to such autonomy e�ectively exposes what it means to be human to the sweeping revisionary e�ect of reason. In a sense, the autonomy of reason is the autonomy of its power to revise, and commitment to the autonomy of reason (via the project of humanism) is a commitment to the autonomy of reason’s revisionary program over which human has no hold.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  Inhumanism is exactly the activation of the revisionary program of reason against the self-portrait of humanity. Once the structure and the function of commitment are genuinely understood, we see that a commitment works its way back from the future, from the collateral commitments of one’s current commitment, like a corrosive revisionary acid that rushes backward in time. By eroding the anchoring link between present commitments and their past, and by seeing present commitments from the perspective of their rami�cations, revision forces the updating of present commitments in a cascading fashion that spreads globally over the entire system. The rational structure of a commitment, or more speci�cally, of commitment to humanity, constructs the opportunities of the present by cultivating the positive trends of the past through the revisionary forces of the future. Once you commit to human, you e�ectively start erasing its canonical portrait backward from the future. It is, as Foucault suggests, the unyielding wager on the fact that the self-portrait of man will be erased, like a face drawn in sand at the edge of the sea.�Every portrait drawn is washed away by the revisionary power of reason, permitting more subtle portraits with so few canonical traits that one should ask whether it is worthwhile or useful to call what is left behind human at all. Inhumanism is the labor of rational agency on human. But there is one caveat here: the rational agency is not personal, individual, or necessarily biological.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  The kernel of inhumanism is a commitment to humanity via the concurrent construction and revision of human as oriented and regulated by the autonomy of reason, i.e., its self-determination and responsibility for its own needs. In the space of reason, construction entails revision, and revision demands construction. The revision of the alleged portrait of human implies that the construction of human in whatever context can be exercised without recourse to a constitutive foundation, a fundamental identity, an immaculate nature, a given meaning, or a prior state. In short, revision is a license for further construction. signi�cance with human veneration, inhumanism is a project that begins by dissociating human signi�cance from human glory.� Resolving the content of con�ation and extracting signi�cance from its honori�c residues, inhumanism then takes humanism to its ultimate conclusions. It does so by constructing a revisable picture of us that functionally breaks free from our expectations and historical biases regarding what this image should be, look like, or mean. For this reason, inhumanism, as it will be argued later, prompts a new phase in the systematic project of emancipation—not as a successor to other forms of emancipation but a critically urgent and indispensable addition to the growing chain of obligations. Moreover, inhumanism disrupts a future anticipation built on descriptions and prescriptions provided by a conservative humanism.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  Conservative humanism places the consequentiality of human in an overdetermined meaning or an overparticularized set of descriptions which is �xed and must at all times be preserved by any prescription developed by and for humans. Inhumanism, on the other hand, �nds the consequentiality of commitment to humanity in its practical elaboration and in the navigation of its rami�cations. For the true consequentiality of a commitment is a matter of its power to generate other commitments, to update itself in accordance with its rami�cations, to open up spaces of possibility, and to navigate the revisionary and constructive imports such possibilities may contain. The consequentiality of commitment to humanity, accordingly, lies not in how parameters of this commitment are initially described or set. Rather, it lies in how the pragmatic meaning of this commitment (its meaning through use) and the functionalist sense of its descriptions (what must we do in order to count as human?) intertwine to e�ectuate broad consequences that are irreconcilable with what was initially the case. It is consequentiality in the latter sense that overshadows consequentially in the former sense, before it fully proves the former’s descriptive poverty and prescriptive inconsequentiality through a thoroughgoing revision. As Robert Brandom notes, every “consequence is a change in normative status” that may lead to incompatibilities between commitments.� Therefore, in order to maintain the undertaking, we are obliged to do something speci�c to resolve the incompatibilities.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  From the perspective of inhumanism, the more discontinuous the consequences of committing to humanity, the greater are the demands of doing something to rectify our undertakings (ethical, legal, economic, political, technological, and so forth). Inhumanism highlights the urgency of action according to a tide of revision that increasingly registers itself as a discontinuity, a growing rift with no possibility of restoration. Any sociopolitical endeavor or consequential project of change must �rst address this rift—or discontinuity e�ect—and then devise a necessary course of action in accordance with it. But doing something about the discontinuity e�ect—triggered by unanticipated consequences and, as a result, the exponentially growing change in normative status (that is, the demands of what ought to be done)—is not tantamount to an act of restoration. On the contrary, the task is to construct points of liaison —cognitive and practical channels—so as to enable communication between what we think of ourselves and what is becoming of us. The ability to recognize the latter is not a given right or an inherent natural aptitude; it is, in fact, a labor, a program, that is  Magni�ed grains of sand are shown in the opening sequence of Hiroshi Teshigahara's Woman in the Dunes, ����. �. The Revisionary Catastrophe The de�nition of humanity according to reason is a minimalist de�nition whose consequences are not immediately given, but whose rami�cations are staggering.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  If there was ever a real crisis, it would be our inability to cope with the consequences of committing to the real content of humanity. The trajectory of reason is that of a general catastrophe whose pointwise instances and stepwise courses have no observable e�ect or comprehensive discontinuity. Reason is therefore simultaneously a medium of stability that reinforces procedurality and a general catastrophe, a medium of radical change that administers the discontinuous identity of reason to an anticipated image of human. Elaborating humanity according to the discursive space of reason establishes a discontinuity between human’s anticipation of itself (what it expects itself to become) and the image of human modi�ed according to its active content or signi�cance. It is exactly this discontinuity that characterizes inhumanism as the general catastrophe ordained by activating the content of humanity, whose functional kernel is not just autonomous but also compulsive and transformative. The discernment of humanity requires the activation of the autonomous space of reason. But since this space—qua the content of humanity—is functionally autonomous even though its genesis is historical, its activation implies the deactivation of historical anticipations of what humanity can be or become at a descriptive level. Since antihumanism mostly draws its critical power from this descriptive level either situated in nature (allegedly immune to revision) or in a restricted scope of history (based on a particular anticipation), the realization of the autonomy of reason would restore the nontheological signi�cance of human as an initial necessary condition, thus nullifying the antihumanist critique.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  What is important to understand here is that one cannot defend or even speak of inhumanism without �rst committing to the humanist project through the front door of the Enlightenment. Rationalism as the compulsive navigation of the space of reason turns commitment to humanity into a revisionary catastrophe, by converting its initial commitment into a rami�ed cascade of collateral commitments which must be navigated in order for it  John Whitney, Permutations, ����. �. Autonomy of Reason But what exactly is the functional autonomy of reason? It is the expression of the self-actualizing propensity of reason—a scenario wherein reason liberates its own spaces despite what naturally appears to be necessary or happens to be the case. Here “necessary” refers to an alleged natural necessity and should be distinguished from a normative necessity. Whereas the given status of natural causes is de�ned by “is” (something that is purportedly the case because it has been contingently posited, such as the atmospheric condition of the planet), the normative of the rational is de�ned by “ought to.” The former communicates a supposedly necessary impulsion while the latter is not given, but instead generated by explicitly acknowledging a law or a norm implicit in a collective practice, thereby turning it into a binding status, a conceptual compulsion, an ought. It is the acknowledging, error-tolerant, revisionary dimension of ought—as opposed to the impulsive diktat of a natural law— that presents ought as a vector of construction capable of turning contingently posited natural necessities into the manipulable variables required for construction.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  In addition, the order of ought is capable of composing a functional organization, a chain or dynasty of oughts, that procedurally e�ectuates a cumulative escape from the allegedly necessary is crystalized in the order of here and now. The functional autonomy of reason consists in connecting simple oughts to complex oughts or normative necessities or abilities by way of inferential links or processes. A commitment to humanity, and, consequently, the autonomy of reason, requires not only specifying what oughts or commitment-abilities we are entitled to, but also developing new functional links and inferences that connect existing oughts to new oughts or obligations. Whether Marxist agenda, humanist creed, or future-oriented perspective, any political philosophy that boasts of commitments without working out inferential problems and without constructing inferential and functional links su�ers from an internal contradiction and an absence of connectivity between commitments. Without inferential links, there is no real updating of  Reason has its roots in social construction, in communal assessment, and in the manipulability of conditionals embedded in modes of inference. It is social partly because it is deeply connected to the origin and function of language as a de-privatizing, communal, and stabilizing space of organization. But we should be careful to extract a “robust” conception of the social, because a generic appeal to social construction risks not only relativism and equivocation but also, as Paul Boghossian points out, a fear of knowledge.� The �rst movement in the direction of extracting this robust conception of the social is making a necessary distinction between the “implicitly” normative aspect of the social (the area of the consumption and production of norms through practices) and the dimension of the social inhabited by conventions, between norms as intervening attitudes and normalizing norms as conformist dispositions. Reason begins with an intervening attitude toward norms implicit in social practices.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  It is neither separated from nature nor isolated from social construction. However, reason has irreducible needs of its own (Kant) and a constitutive selfdetermination (Hegel), and it can be assessed only by itself (Sellars). In fact, the �rst task or question of rationalism is to come up with a conception of nature and the social that allows for the autonomy of reason. This question revolves around a causal regime of nature that allows for the autonomous performance of reason in “acknowledging” laws, whether natural or social. Therefore, it is important to note that rationality is not conduct in accordance with a law, but rather the acknowledging of a law. Rationality is the “conception of law” as a portal to the realm of revisable and navigable rules. We only become rational agents once we acknowledge or develop a certain intervening attitude toward norms that renders them binding. We do not embrace the normative status of things outright.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  We do not have access to the explicit—that is, logically codi�ed—status of norms. It is through such intervening attitudes toward the revision and construction of norms through social practices that we make the status of norms explicit.� Contra Hegel, rationality is not codi�ed by explicit norms from the bottom up. To confuse implicit norms accessible through intervening practices with explicit norms is common and risks logicism or intellectualism, i.e., an account of normativity in which explicit norms constitute an initial condition with rules all the way down—a claim already debunked by Wittgenstein’s regress argument.� �. Functional Bootstrapping and Practical Decomposability The autonomy of reason is a claim about the autonomy of its normative, inferential, and revisionary function in the face of the chain of causes that condition it. Ultimately, this is a (neo)functionalist claim, in the sense of a pragmatic or rationalist functionalism. Pragmatic functionalism must be distinguished from both traditional AI-functionalism, which revolves around the symbolic nature of thought, and behavioral variants of functionalism, which rely on behaviors as sets of regularities. While the latter two risk various myths of pancomputationalism (the unconditional omnipresence of computation, the idea that every physical system can implement every computation) or behavioralism, it is important to note that a complete rejection of functionalism in its pragmatic or Kantian rationalist sense will inevitably usher in vitalism and ine�abilism, the mystical dogma according to which there is something essentially special and non-constructible about thought. Pragmatic functionalism is concerned with the pragmatic nature of human discursive practices, that is, the ability to reason, to go back and forth between saying and doing stepwise.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  Here, “stepwise” de�nes the constitution of saying and doing, claims  here amounts to practical enablement or the ability to maintain and enhance the functional autonomy or freedom. The pragmatic procedures involved in this mode of automation perpetually diversify the spaces of action and understanding insofar as the non-monotonic character of practices opens up new trajectories of practical organization and, correspondingly, expands the realm of practical freedom. Once the game of reason as a domain of rule-based practices is set in motion, reason is able to bootstrap complex abilities out of its primitive abilities. This is nothing but the self-actualization of reason. Reason liberates its own spaces and its own demands, and in the process fundamentally revises not only what we understand as thinking, but also what we recognize as “us.” Wherever there is functional autonomy, there is a possibility of self-actualization or self-realization as an epochal development in history. Wherever self-realization is underway, a closed positive feedback loop between freedom and intelligence, self-transformation and self-consciousness, has been established. The functional autonomy of reason is then a precursor to the self-realization of an intelligence that assembles itself, piece by piece, from the constellation of a discursively elaborative “us” qua an open-source self. Rationalist functionalism, therefore, delineates a nonsymbolic—that is, philosophical—project of general intelligence in which intelligence is fully apprehended as a vector of self-realization through the maintaining and enhancing of functional autonomy.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  Automation of discursive practices—the pragmatic unbinding of arti�cial general intelligence and the triggering of new modes of collectivizing practices via linking to autonomous discursive practices—exempli�es the revisionary and constructive edge of reason as sharpened against the canonical self-portrait of human. To be free one must be a slave to reason. But to be a slave to reason (the very condition of freedom) exposes one to both the revisionary power and the constructive compulsion of reason. This susceptibility is terminally ampli�ed once the commitment to the autonomy of reason and autonomous engagement with discursive practices are su�ciently elaborated. That is to say, when the autonomy of reason is understood as the automation of reason and discursive practices—the philosophical rather than classically symbolic thesis regarding arti�cial general intelligence.�  Augmented rationality is the radical exacerbation of the di�erence between ought and is. It thereby, from a certain perspective, annuls the myth of restoration and erases any hope for reconciliation between being and thinking. Augmented rationality inhabits what Howard Barker calls the “area of maximum risk”—not risk to humanity per se, but to commitments which have not yet been updated, because they conform to a portrait of human that has not been revised.�� Understood as the labor of the inhuman, augmented rationality produces a generalized catastrophe for unupdated commitments to human through the ampli�cation of the revisionary and constructive dimensions of “ought.” If reason has a functional evolution of its own, cognitive contumacy against adaptation to the space of reason (the evolution of ought rather than the natural evolution of is) ends in cataclysm. Adaptation to the evolution of reason—which is the actualization of reason according to its own functional needs—is a matter of updating commitments to the autonomy of reason by way of updating commitments to human.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  The updating of commitments is impossible without translating the revisionary and constructive dimensions of reason into systematic projects for the revision and construction of human through communal assessment and methodological collectivism. Even though rationalism represents the systematicity of revision and construction, it cannot by itself institute such systematicity. To rephrase, rationalism is not a substitute for a political project, even though it remains the necessary platform that simultaneously informs and orients any consequential political project. Stan Brakhage, Prelude: Dog Star Man, ����. �. A Cultivating Project of Construction and Revision The automation of reason and discursive practices unlocks new vistas for exercising revision and construction, which is to say,  arise from the distribution of nested structural and functional hierarchies. Sometimes, in order to make change at one level, a structural or functional change at a di�erent, seemingly unrelated level must be made. Moreover, what is important is to change functions (whether at economic, social, or political levels).\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  But not every structural change necessarily leads to a functional change, while every functional change—by virtue of functions playing the role of purpose-attainment and dynamic stabilization for the system—results in a structural change (although such an alteration in structure might not take place in the speci�c structure whose function has just changed). The signi�cance of nested hierarchies for the implementation of any form of change on any stratum of our life makes the knowledge of di�erent explanatory levels and cross-level manipulation a necessity of utmost importance. Such knowledge is yet to be fully incorporated within political projects. Without the knowledge of structural and functional hierarchies, ambition for change—whether through modi�cation, reorganization or disruption—is misguided by the con�ation between di�erent strata of structure and function on the levels of economy, society, and politics. Therefore, only explanatory di�erentiation of levels and cross-level manipulations (complex heuristics) are able to transform dreams of change into reality. In a hierarchical scenario, lower-level dimensions open upper levels to possibility spaces, which simultaneously expand the possibility of construction and bring about the possibility of revision. At the same time, descriptive plasticity and stabilized mechanisms of upper-level dimensions adjust and mobilize lower-level constructions and manipulations. Combined together, the abilities of lower-levels and upper-levels form the revisionary-constructive loop of engineering.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  The engineering loop is a perspectival schema and a map of synthesis. As a map, it distributes both across di�erent levels and as a multitude of covering maps with di�erent descriptive-prescriptive valences over individual levels. The patchwork structure ensures a form of descriptive plasticity and prescriptive versatility, it reduces incoherencies and explanatory con�ations and renders the search for problems and opportunities of construction e�ective by tailoring descriptive and prescriptive covering maps to speci�cities. As a perspectival compass, it passes through manifest and scienti�c images (stereoscopic coherence), assumes a view from above and a view from below (telescopic deepening), and integrates various mesoscales which have their own speci�c and nonextendable explanatory, descriptive, structural, and functional orders (nontrivial synthesis). The revisionary-constructive loop always institutes engineering as re-engineering, a process of remodi�cation, re-evaluation, re-orientation and re-constitution. It is the cumulative e�ect of engineering (Wimsatt) that corresponds to the functional and structural accumulation of complex systems,�� as that corrosive substance that eats away myths of foundation and catalyzes a cumulative escape from contingently posited settings. The error-tolerant and manipulable dimensions of treating the system as a hypothesis and engineering epistemology are precisely the expressions of revision and construction as the two pivotal functions of freedom. Any commitment that prevents revision and does not maintain—or more importantly, expand—the scope of construction ought to be updated.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  If it cannot be updated, then it ought to be discarded. Freedom only grows out of functional accumulation and re�nement, which are characteristics of hierarchical, nested, and therefore decentralized and complex systems. A functional organization consists of functional hierarchies and correct inferential links between them that permit nontrivial orientation, maintenance, calibration, and enhancement, thereby bringing about opportunities for procedurally turning supposed necessities and fundaments  environment for updating commitments, both through the correcting in�uence of levels over one another and the constructive propensity inherent in functional hierarchies as engines of enablement. Liberation is neither the initial spark of freedom nor su�cient as its content. To regard liberation as the source of freedom is an eventalist credulity that has been discredited over and over, insofar as it does not warrant the maintaining and enhancing of freedom. But to identify liberation as the su�cient content of freedom produces a far graver outcome: irrationalism, and as a result, the precipitation of various forms of tyranny and fascism. The su�cient content of freedom can only be found in reason. One must recognize the di�erence between a rational norm and a natural law—between the emancipation intrinsic in the explicit acknowledgement of the binding status of complying with reason, and the slavery associated with the deprivation of such a capacity to acknowledge, which is the condition of natural impulsion.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  In a strict sense, freedom is not liberation from slavery. It is the continuous unlearning of slavery. The compulsion to update commitments as well as construct cognitive and practical technologies for exercising such feats of commitment-updating are two necessary dimensions of this unlearning procedure. Seen from a constructive and revisionary perspective, freedom is intelligence. A commitment to humanity or freedom that does not practically elaborate the meaning of this dictum has already abandoned its commitment and taken humanity hostage only to trudge through history for a day or two. Liberal freedom, be it a social enterprise or an intuitive idea of being free from normative constraints (i.e. freedom without purpose and designed action), is a freedom that does not translate into intelligence, and for this reason, it is retroactively obsolete. To reconstitute a supposed constitution, to draw a functional link between identifying what is normatively good and making it true, to maintain and enhance the good and to endow the pursuit of the better with its own autonomy—such is the course of freedom.\n"}
{"prompt":"The Labor of the Inhuman, Part II: The Inhuman ->","completion":"  But this is also the de�nition of intelligence as the self-realization of practical freedom and functional autonomy that liberates itself in spite of its constitution. Adaptation to an autonomous conception of reason—that is, the updating of commitments according to the progressive selfactualization of reason—is a struggle that coincides with the revisionary and constructive project of freedom. The �rst expression of such freedom is the establishment of an orientation—a hegemonic pointer—that highlights the synthetic and constructible passage that human ought to tread. But to tread this path, we must cross the cognitive Rubicon. Indeed, the intervening attitude demanded by adaptation to a functionally autonomous reason suggests that the cognitive Rubicon has already been crossed. In order to navigate this synthetic path, there is no point in staring back at what once was, but has now been dissipated—like all illusory images—by the revisionary winds of reason.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  n & Littlefield Publishers.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  All rights reserved. Part 1  Aesthetics  n & Littlefield Publishers. All rights reserved. Chapter One  Continuity versus Discreteness  n & Littlefield Publishers. All rights reserved. AN IMPASSE Contemporary aesthetic enquiries into digital media are stuck in an impasse. On the one hand, this impasse attests to the relentless expansion of modes of thinking, acting, and perceiving that have been enabled by digital technologies and which are, in fact, specific to them. On the other hand, however, it also reflects the widespread belief that these digitally native experiences are imperfect or flawed if they are not validated by a biological substrate, a human referent, a body, or simply by ‘life’, which—in its multiform organisations and configurations—expresses and catalyses the affects and sensations that are central to aesthetic experience.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This impasse in digital aesthetics thus concerns the difficulty of attributing those perceptual and relational features that are the object of aesthetic enquiry to the strictly informational and operative character of the computer or the digital device. This is a difficulty that poses a genuine problem for present-day notions of aesthetics, given that contemporary society is in large part structured by such informational operations and machines. The deadlock that I am bringing to the fore here lies at the heart of aesthetic elaborations in the field of digital media theory and digital media  n & Littlefield Publishers. All rights reserved. 24  Chapter 1  quantitative modes of formal organisation. As a result of this impasse, the very possibility of an aesthetics of the digital becomes a contradiction in terms. While media and cultural theorists, computer scientists, and philosophers might disagree on an exact definition of ‘digitality’, they accept discreteness as its fundamental feature. The digital is, in this sense, intrinsically discrete or, in other words, characterised as a data technology that uses discontinuous values to access, represent, and manage information.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  1 Conversely, philosophical, cultural, and social accounts of aesthetic activities describe a universe of percepts and perceivers, the reciprocity of which is established by a rapport of continuity with what is given or encountered in experience. Aesthetics, in this respect, concerns the perceptual understanding of what counts as sensuous experiencing: its proprieties, features, and qualities and, subsequently, the prospect of its expression all rely equally on the continuity of perceptual and sensuous relations. In the light of these considerations, I wish to propose a model to interpret this impasse. This model frames the deadlock as an opposition between continuity and discreteness. The continuous and the discrete are antagonistic ontological registers, or two antithetical modes of being, which concern conflicting modes of grasping and recording reality. Digital technology, with its binary elaboration of reality through quantifiable mechanical operations and quantitative inputs and outputs, attends to the real by discretising it. Aesthetics, however, being predicated upon perceptual relations and sensations, would seem to require a continuous—and thus analogue—association with the world. One can see that, from the standpoint of the model of the impasse offered here, the conceptual challenge of any aesthetic investigation of the digital pertains to the problem of pinpointing what constitutes the aesthetic dimension of digitality itself.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  What are the foundational elements that concern such a dimension, and what ontology do we need in order to account for the disparity between that which is supposedly continuous (perception and sensation) and that which is not (digital technology)? It becomes evident, through taking up the challenge of thinking about these questions, that the possibility of establishing a digital aesthetics extends beyond the traditional disciplinary boundaries of a theory of art (in general), or of art made with or by computers (in the specific). The impasse between  n & Littlefield Publishers. All rights reserved. Continuity versus Discreteness  25  investigation of how we relate to things, and how these things in turn relate to other things. From this point of view, what is continuous is not only the recording of reality, but also reality itself, in its relational infinity of variations, modulations, and transformations—relations that aesthetics aims to register through the sensible. Moreover, in this sense, it should already be apparent that the impasse that I am sketching between continuity and discreteness has profound Deleuzian connotations. It is not an overstatement to say that the French philosopher Gilles Deleuze was not keen on computers.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Although Deleuze engaged, both independently and in partnership with Félix Guattari, with media such as television, radio, and—above all—cinema, he wrote little, and not fondly, about computing machines. Still, the little that he did write on the topic has influenced the critical investigation of digital technologies, the ubiquitous proliferation of which was just beginning at the time of Deleuze’s death in 1995. These sparse comments have framed, with a degree of prescience and great philosophical rigour, the limitations and dependencies of the digital medium, exposing how computing is inherently ancillary to the regimes of communication and representation, and how it relies upon the axiomatic infrastructures and informational goals that fuel contemporary society’s systems of control. 3 In a sense, it is thus somewhat paradoxical that, despite Deleuze’s overt suspicion towards the computational, his metaphysical vocabulary of rhizomes, assemblages, bodies without organs, and abstract machines abound in media theory syllabi as a means of explaining the condition of living in a networked information society. The influence that Deleuze has exerted over the cultural study of digital technology can, however, be explained by considering how a conceptual apparatus of intensities, multiplicities, and affirmations would seem particularly apt to describe a technomediated society that is, and whose media and modes of production are, without a centre and in continuous flow. In this respect, Deleuze’s theoretical language has indirectly facilitated attempts to legitimate a philosophy of digital media. These are attempts that aim to mobilise Deleuze’s famous conceptual tool kit in order to advance novel fields of engagement with the technological. We should now return to the impasse between continuity and discreteness with these concerns in mind.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In order to do so, it is crucial to stress that,  n & Littlefield Publishers. All rights reserved. 26  Chapter 1  aesthetics-as-aisthesis in the digital realm, the Deleuzian problem, according to which what is mechanical and codified is able to generate neither sensation nor thought, is brought to the fore. Of course, Deleuze is not alone in posing this problem. The disparity between the limitations of the technological (with its representational and cognitive character) on the one hand, and the irreducibility of the thinking that comes from lived experience and sensation (which both surpass cognitive representation) on the other, has been addressed frequently in contemporary philosophy and critical theory, mostly via critiques of instrumental reason or oppositions to the mechanisation of life. One might think here of the Frankfurt School as a clear example of such criticism. 6 Interestingly, one can also count Gilbert Simondon among those who share a critical stance towards the mechanisation of thought and being; obviously, one cannot omit Martin Heidegger from this list either. 7 Moreover, although they afford very different premises, aims, and outcomes, poststructuralism, postmodernism, and post-Marxism similarly emphasise particularities rather than the abstract universals that might subsume them, thus questioning the usefulness and validity of automating and systematising that which is lived.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  8 Finally, as another figure in this list, I should mention Alain Badiou, who—like Deleuze—made irreducible multiplicity the central point of his thought. Despite his aversion towards the affective and the perceptual, and despite his passionate defence of the discreteness of events that do not relate to but rather break with the quotidian, for Badiou as well thought and being ultimately remain beyond formalisation. 9 This account of philosophical suspicions of the mechanical qua the instrumental is not meant to be exhaustive. However, the heterogeneity of the voices mentioned above demonstrates that the aesthetic impasse between the continuous and the discrete should be contextualised vis-à-vis a broader intellectual aversion to the modern technological ‘enframing’ (to use a wellknown Heideggerian term) of thinking and feeling into preprogrammed structures of reasoning that can be replicated automatically. From this standpoint, aesthetics is less the ultimate citadel of the Luddite than the sharpest tool in the box of those scholars concerned with saving the singularity and specificity of the lived, whether this latter is a practice, language, art, man, or  n & Littlefield Publishers. All rights reserved. Continuity versus Discreteness  27  the association of aesthetics with a field of continuity can develop directly from Deleuze, and that this affinity between aesthetics and continuity leaves the aesthetic investigation of the digital with a difficulty that cannot be dodged or avoided, but which needs to be fully addressed. Ontological continuity is a key feature of Deleuze’s elaboration of aesthetics-as-aisthesis.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Drawing upon Bergson’s notion of duration (which is about qualitative rather than quantitative multiplicity) and upon differential calculus, 10 Deleuze’s continuity is an asymmetric synthesis of the sensible. The continuum is the ontological plane of transformation of what is prior to individuation, of what is not logically predetermined, of what instead invents and creates through difference. This differentiation, however, is never fully realised: it always demands the occurrence of tendencies, vectors, lines of flight, and infinite speeds, which remain pure differential affirmations. For Deleuze, aesthetics is exactly what offers us the opportunity to address these unactualised conditions, insofar as it concerns one’s unmediated relation with the sensuous dimension upon which these unactualised conditions find expression. Although he also addressed art and artists extensively, Deleuze did not centre his aesthetics upon notions of the art object, or upon traditional aesthetic values or definitions of spectatorship. Deleuze’s aesthetics is, primarily, a theory of sensibility. Following a post-Kantian legacy, and transversally linking Bergson with Nietzsche, Deleuze defined sensation as what strikes us before meaning is trapped into figuration and signification. Operating beyond stable or fixed subjectivity, sensation is characterised not as a merely sensory reaction triggered by the qualities of a certain object, but as constituted by differential relations in intensity, which in turn endow reality with its transcendental conditions of existence.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  From this Deleuzian perspective, the discreteness of digitality is evidently problematic, for it epitomises yet another development of the representational: in other words, a development of that which breaks the unmediated relation with the sensible and separates thinking from affect and intuition—the former to be understood in the Spinozist sense of a variation in the potentia agendi of a body, 11 and the latter in the Bergsonian sense of a method of unmediated and immediate ‘sympathy’ with things. 12 Deleuze’s reworking of the traditional notion of aisthesis presupposes instead the immanence of  n & Littlefield Publishers. All rights reserved. 28  Chapter 1  sented but only felt. 13 The impasse of digital aesthetics can thereby be phrased as a problem concerning the infinity and continuity of thought and sensation against the finitude and discreteness of those strategies that want to bind both thinking and feeling into an automated mechanism. From this standpoint, the finitude in question is not only that of the medium or of the tool, in their historical and material instantiations, but also that of the inherent limitations of formal sciences and of those disciplines that attempt to channel the continuity of thinking and feeling into a self-contained structure of reasoning. This claim can be expanded by phrasing the impasse between aesthetics-as-aisthesis and the digital as an impasse concerning the dynamism and generative power of life as opposed to the static nature of the formal, finite, and binary means through which the digital machine harnesses the living and the lived. The richness and density of sensation, at the core of aesthetics-as-aisthesis, is thus in conflict with the digital machine, understood as both product and producer of cognitive and logocentric abstractions.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In conclusion, this aesthetic deadlock is a contest that is to be fought in an ontological ring: the competition is between the indeterminacy of the lived and the determinism that the digital machine needs in order to operate and function. From this perspective, what seems more challenging is the relationship between the separateness attributed to formal abstraction (as a procedural technique or a method considered to be the norm of reasoning, and therefore also of the information processing that digitality stands for) and the viscosity of life and perceptive experience. Finally, identifying the impasse between continuity and discreteness emphasises the sense in which an attempt to describe what an aesthetics of the digital might be and might do implies a commitment to determining the ontological conditions of the real. It thus requires us to assess whether the digital can indeed be a character of these conditions, and if so, how. AESTHETIC FLUX, LOGICAL MATRIX The impasse between continuity and discreteness in digital aesthetics emerges from, but also reshapes, previous issues in the critical assessment of digital media. Stressing the occurrence of this impasse can thereby illuminate  n & Littlefield Publishers. All rights reserved. Continuity versus Discreteness  29  shadows’, 14 as well as concerns about authenticity and simulation, are subordinated to the key challenge of accounting for the ontological gap between analogue experience and digital abstraction.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This is because the crux of the contemporary conceptual debate about digitality is moving towards more structural problematisations of the digital condition. Of course, the problem of corporeality in relation to digitality is not being discarded as a whole. This and similar issues have, however, assumed more systemic nuances. It is possible, then, to return to the impasse between continuity and discreteness and to read searches for an incarnated experience of the digital from this standpoint. For example, a perceptual or experiential continuum is also envisaged by phenomenological perspectives on digitality, according to which digital phenomena cannot be explained by their subjective or objective components alone, but rather by the continuity of intentional experience. These views, which range across a variety of disciplines investigating and working with the digital, borrow from the tradition of phenomenology (i.e., the philosophical investigation of the origin and meaning of first-person experience) in order to describe digital practices in terms of their intentionality. Generally speaking, phenomenology observes and describes sensuous and intellectual experiences in order to determine the criteria of existence of abstract entities (proprieties, meanings, concepts, etc.) and to thus legitimate the objectivity of phenomena.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Such a phenomenological framework has entered science, technology, and media studies, partly via Hubert Dreyfus’s Heideggerian critique of artificial intelligence, and via the influence that Dreyfus’s critique has had on cognitive sciences and computing. 15 Phenomenologically oriented approaches to the digital thus focus on a holistic validation of what the ubiquitous computing pioneer Mark Weiser described as a ‘calm technology’ (namely, informational devices that engage with the full complexity around and within the system by digitally connecting things in the world as seamlessly as possible). 16 In the field of human-computer interaction, this phenomenological holism means that designers focus on the ways in which digital systems are manifest in the environment. In artificial intelligence research, the same phenomenological holism implies an attention to the embeddedness of mental activity, while in new media art it gives a special role to the user as  n & Littlefield Publishers. All rights reserved. 30  Chapter 1  ness, and a ground for the phenomenological disclosure of the world. 18 Such a systemic coupling is, in turn, to be performatively mirrored in the relationship between the participant\/user on the one hand and the work\/product on the other. From this phenomenological point of view, interactive and embodied digital structures (whether artistic compositions, commercial products, or industrial applications) are technologies of the context.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This is to say that they are considered as always having been constructed within an environment and are addressed in relation to the modes of presentation and of participation with their users that they entail. In this sense, these phenomenological approaches draw partly on the enactivist idea that knowledge cannot be passively absorbed but must be actively situated within the agent’s system, and that it must also be in contact with the world. The phenomenological continuum of these approaches is then the continuity of phenomenology’s notion of ‘being-in-the-world’. 19 To put this otherwise, the phenomenological continuum is the meaningful and rich continuity of an intentional relation between the perceiver and the perceived, the actor and the acted out. Phenomenological continuity describes a reflexive link among tools, those who use these tools, and the environment in which they are used. The continuity of such reflexive relations is attributed to the directness or self-presence of situations and objects to our intellectual and perceptual experiencing. Such an experiential and reflexive continuum is, to a great extent, different from Deleuze’s continuity, which is not phenomenological, hermeneutical, or psychological, but metaphysical. More precisely, Deleuze’s metaphysical continuum is a qualitative field of differentiation, requiring that the conditions and the conditioned of such dynamics of difference are not diverse in kind but in degree, thus entailing the univocity of being.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Continuity is then predicated on the variation of an infinite multiplicity of elements into the univocal plane of being. The infinite plane of transformation is, from a Deleuzian perspective, life itself. This is neither the life of the self nor any other particular life in the world. Rather, Deleuze talked of ‘a life’, 20 in the sense of a field of potential realisation that is impersonal, indefinite, and subjectless. ‘A life’ is never completely specified and never separated from its unactualised conditions. Having seen the dissimilarity between the phenomenological and the De-  n & Littlefield Publishers. All rights reserved. Continuity versus Discreteness  31  ontological level of the debate that the Deleuzian framework so importantly sets out.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  As a way of summarising what has been claimed so far, the present situation for digital aesthetics can now be rephrased in terms of a contradiction. On the one hand, we are witness to the discretisation of experiences, behaviours, perceptions, actions, and thoughts that the digital has brought forth through the softwarisation of media. 21 The pervasive use of digital technology means that there are few operations and activities today, from reading to buying and talking, that are not entangled, at least to some degree, with informational mechanisms of discretisation. On the other hand, however, we see that aesthetic investigations of the digital might have been successful in addressing the experiential appreciation of digital practices or digital phenomena, yet still arguably break down at a conceptual level when trying to cope with the discreteness of the digital itself. In my view, this is due to the fundamental disparity between ontologies of the discrete and ontologies of continuity. The impasse between continuity and discreteness is then a useful model that allows us to frame this paradoxical situation, and also to tie together different facets and nuances of contemporary digital discretisation under the rubric of the question concerning the possibility of an aesthetics of such discretising technologies. An aisthesis of the digital of Deleuzian inspiration would answer that question in a manner that would afford this possibility. Following Deleuze’s ontological characterisation of aisthesis, it is not the body or the subject uniquely but the sensible in general that rises to the role of the recorder or the ‘transducer’ (to appropriate a Simondonian vocabulary) of experience.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In an aisthesis of the digital, this central role of sensibility is also maintained and applied to the digital realm: the sensible becomes key to shaping the arrangement of human-machine relations by bringing the continuous movement of variation into what is static and finite, such as the digital machine. The sensible here might be the human user in her interaction with the machine. However, in a non-anthropocentric fashion, and in a move to surpass the phenomenology of the self, the sensible also includes the material residues of the social, the cultural, and the economic milieux as these entwine with the technological and the informational. In an aisthesis of the digital, the qualitative thus remains superior to the quantitative. The risk, in this respect, is that  n & Littlefield Publishers. All rights reserved. 32  Chapter 1  lative sense’ in which contemporary modes of calculation (such as digital technology) have acquired a qualitative dimension. 22 I wish to claim, in the light of these issues, that the impasse between continuity and discreteness, framed in its Deleuzian context, should be translated into a defeat of the relation between the aesthetic and the logical.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  As a result of this setback, it is the logico-quantitative character of digital technology that is adjusted to be more aesthetic, and this is done by loosening up what is more specific to it: discreteness. This is in part a theoretical operation that is considered to be essential for thinking the digital aesthetically. However, in this respect too, the paradox returns, and one might wonder whether an aisthesis of the digital is really an aesthetics of discreteness; in other words, the difficulty of thinking discreteness and aesthetics together, like the difficulty of thinking a sensibility of such discretisation, remains in place. In my view, we should not accept this defeat of the relation between the aesthetic and the logical. Instead, we should explore the possibility of healing this fracture. In order to understand the circumstances for this possible reconciliation between the aesthetic and the logical, we should interpret the failure of their relation in terms of the incompatibility of two divergent understandings of the structure of the real. Aesthetics, in the etymological sense of aisthesis developed by Deleuze, has to do with perception, sensation, and the thinking that originates from this metaphysical plane of sensibility. From the perspective of aisthesis, in its Deleuzian use, the real is an unstable flux of change, micro-variations, modulations, and differentiations to be felt, not cognised.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  For logic, instead, the real is a fixed matrix of discrete points, arranged in chains of premises and consequences. Here, of course, I am using the term ‘logic’ not in the Deleuzian sense of the absolute differentiation of vitalistically creative movements of thought that are able to account for the production of multiplicities. The defeat of logic is instead the setback of the more traditional rational and rationalist discipline that codifies the inferential principles of valid reasoning into preset norms for prediction and validation. I am also including, in this science of valid reasoning, the formal operativity of the digital device, geared towards problem solving and the fulfilment of specific tasks. If this logos that pushes for a discrete rationing of the world is aesthetical-  Continuity versus Discreteness  33  act of creation, is however also ‘a fundamentally material and aesthetic process’, insofar as it concerns the ‘construction of sensible aggregates that are themselves creative’. 26 Deleuze’s new is, ‘in other words, difference’, which ‘calls forth forces in thought which are not the forces of recognition’. 27 Novelty, according to a Deleuzian aisthetic framework, belongs to continuity, not to discreteness. Here is yet another problematic node that the Deleuzian setting of the impasse between continuity and discreteness brings to the fore: the digital would seem to be excluded from the production of the new on the basis of its automated repetition of the preprogrammed.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Working through possibilities and probabilities, the digital is a way of recognising through prediction. Supposedly no new thought as well as no new being can be produced, because everything is already set up; in the digital machine, there is a lot of iteration and repetition, but no differentiation. For this reason, when seen from a Deleuzian perspective, the digital has no potentiality. n & Littlefield Publishers. All rights reserved. SENSATION, THOUGHT, EXPERIENCE The claim that the digital is devoid of potentiality is part of Brian Massumi’s famous thesis about the superiority of the analogue. 28 The superiority that Massumi refers to is ontological and should be understood in relation to Deleuze’s belief in the metaphysical supremacy of the continuous over the discrete. Massumi’s argument refers directly to Deleuze’s characterisation of the notion of virtuality, so an explanation of this concept is necessary.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Objecting to the confinement of the real within the realm of actual representable things, Deleuze made the virtual the transcendental condition of experience. This means that, against Kant, Deleuze purged the transcendental of any reference to the consciousness of a subject and made it a genetic (that is, productive) field of conditions of experience. The ontological continuity upon which Deleuze’s philosophy and aesthetics are based is that same field of immanent production. The continuum is the transcendental condition of past, present, and future experience. The continuum is the virtual. Returning now to his claim concerning the superiority of the analogue, Massumi develops this argument by setting out the relationship between  n & Littlefield Publishers. All rights reserved. 34  Chapter 1  compressing, turns itself into a cup, the virtual has a continuous inside and outside, constantly invented through the affordances of the flow of its immanent action.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  According to this view, the digital, on the other hand, is always oriented towards what is already coded. It combines and systematises the possible and the probable, because only possibility and probability can be approached quantitatively and codified. Massumi explains processes of quantification and codification as operations that are unable to catch the continuity of life’s transformation and that can only approximate the virtual. The analogue is thereby superior by virtue of its capacity to be a pure potentiality in becoming and to connect the digital to the virtual of non-cognitive relationality. Since the digital is ‘a numeric way of arraying alternative states so that they can be sequenced into a set of alternative routines’, 29 it is excluded from what the neuroscientist Antonio Damasio called ‘the feeling of what happens’ 30 and removed from any experiential value. Ironically and by contrast, the promise of new experiences is an attractive attribute of digitality, and, similarly, parameters of novelty are often stressed in digital media studies. In this respect, the discussion of the impasse between continuity and discreteness helps us to bring this rhetoric of novelty to another level of discussion, pertaining to the question of whether the digital is capable of ontological production. From the aisthetic perspective, which I am characterising here as a Deleuze-inspired standpoint, novelty concerns the activity of conception-perception.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In other words, it concerns both thinking and feeling as ontogenetic activities (i.e., activities that generate being). This point has already been introduced: for Deleuze, aesthetics is not only about feeling, but about thinking too. I can add now that this thought, however, is of a particular kind: it is non-cognitive, apersonal, and irreducible to a single content, a single origin, or a single experience of it. The best way to describe it is to call it abstract thought or indeed virtual thought. Deleuze divorced the ontological conditions of the abstract from cognitive functions. For Deleuze, the separation between an ontological and an epistemological plane must be dissolved in order to leave room for ‘a new image of the act of thought, its functioning, its genesis in thought itself’. 31 Abstract thought is a type of thinking that does not belong to somebody; it is unbounded, immediate, and indeterminate; and, most importantly, it does not  n & Littlefield Publishers. All rights reserved.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Continuity versus Discreteness  35  operation that Deleuze carried out in relation to thought is thus to separate thinking from any specifically mental denotation and make it an immanent expression of the ontological inventiveness of the sensible. Deleuze took the abstract from the exclusive domain of the cognitive and plunged it into the metaphysically productive realm of sensibility. ‘Something in the world forces us to think.’ 33 This encounter, which triggers thought and which stands as thought’s starting condition, is not an encounter with a sensible being or with the result of sense experience as such. Rather, this is the encounter with ‘the being of the sensible’. 34 In other words, that which can only be sensed as an intensive difference that precedes the categorical unity of the intellect. The abstract is thereby not merely an intellectual judgement and universalising activity of generalisation or sensus communis, nor is it a metaphor or an illusion. It is a dimension of ideality or, again, of pure virtuality, which is—to use one of Deleuze’s expressions—abstract yet real. Significantly, the Deleuzian aesthetics of what Massumi called the ‘thinking-feeling’ is about intensity, 35 which is the qualitative condition of multiplicities that invent and express being, but which cannot be counted because they are not extended.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Deleuze believed that ‘it is always by means of an intensity that thought comes to us’. 36 This is the reason why aesthetics is so important for Deleuze: with its focus on sensory knowledge, aesthetics-asaisthesis can record change beyond measurement, via the intensive force of affect. Following a Spinozist conceptual lineage, affect is defined by Deleuze as ‘the continuous variation of the force of existing, insofar as this variation is determined by the ideas one has’. 37 Affect is a registration of change, a ‘lived transition’ or a ‘lived passage’. This passage is ‘determined by ideas’, yet ‘in itself it does not consist in an idea’ or in their ‘intellectual comparison’. 38 For Deleuze, aesthetics can account for thinking outside cognitive structures because affect is already a legitimate modality of what we could call sensible thought. Drawing again on Spinoza’s metaphysics, Deleuze described affects and ideas as two different modes of thought. While an idea has some defined and characteristic representational features, an affect is a bodily mode of thought that does not resemble or represent anything.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  According to this Deleuzo-Spinozist framework, affectivity constitutes the most prominent character of experiencing. Experience is addressed here not in the  n & Littlefield Publishers. All rights reserved. 36  Chapter 1  composition of real elements and eventualities that lead to the generation of a certain state of affairs. Real experience, for Deleuze, is an unmediated and subrepresentational immersion in the plane of immanence of thought and sensation. When one falls into such experience, one feels and thinks without knowing representationally or cognitively. Aesthetics is concerned with this immersion. The conditions of experience are not determined in concepts but in percepts, and aesthetics is the science of sensation that deals with these percepts.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  39 Deleuze’s aesthetics is thus an access to experience that is never subordinated to representation, but in which both thinking and feeling are operating before and outside the mesh of cognitive organisation. One feels and one thinks, and only then does one understand. Experience is always aesthetic because it is about the affective indeterminacy of thinking-feelings and calls for us to subtract ourselves from the fixed actual singularities of being until one is dispersed into the virtual becoming of the lived. Such a Deleuzian conception of experience as an access to the virtual distribution of intensities can be related interestingly, and on multiple levels, to aesthetic theories of digital technology. What is often referred to as the affective turn in contemporary cultural theory has found occasions for successful development, and much speculative vigour, in digital media theory. 40 In its Spinozist-Deleuzian lineage, the notion of affect can function as an optimal conceptual vehicle for giving ontological credit to inorganic, nonhuman realities, thus following the Deleuzian injunction to make expressivity and affectivity ‘available to things’. 41 Often, this turn to affect has coincided with the revival of metaphysical notions of matter and proposed an approach that does not aim to reduce technology to an effect of the organisation of human practices, but rather sees the technological medium as incessantly reinventing its own material conditions of existence. The affective turn in media theory has thus fruitfully engaged with digitality’s abstract modes of processing.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  The assumption is that, while the digital does not exhaust the virtuality of the real, it is nonetheless entangled with it through the sensibilities and intensities in which it partakes. Although it is definitely materialist, this affective perspective does not, however, reduce matter to a specific corporeal definition, nor does it explain a body through its organs and func-  n & Littlefield Publishers. All rights reserved. Continuity versus Discreteness  37  puter simulations, 47 new media and software art, 48 human-computer interfaces, 49 film and screen cultures, 50 sound, 51 movement and dance, 52 and the technological mediation of time. 53 These arenas and objects of enquiry, among many others, have been reconsidered through the lenses of what Timothy Murray has called a ‘Digital Deleuze’, 54 thanks to interdisciplinary scholarly debates that have both advocated and advanced the possibility of such a digital reading of Deleuze’s philosophy of affective intensities. On this view, if digital technology is radically changing the way in which we perceive and experience, then this is partly because it contributes to the production of affects and movements of thought, whenever the virtual receives and registers the information, data, and inputs\/outputs that the digital machine produces. The notion of affect has, therefore, become key to thinking the technological beyond human subjectivity and receptivity. Significantly, the turn to affect in digital studies has also helped us to think what such a ‘non-representational theory’ of computational media might be, 55 away from what media signify or communicate, and more in terms of what they do (that is, in terms of their affects\/effects).\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This affective turn in media theory streams into contextual debates about modes of control, consumption, and production in informational societies and their economies of ‘immaterial labour’. 56 These are modes that are said to exploit the affective because they invest the constitution of subjectivities and collectivities at a non-cognitive and intensive level. Moving now to a more technological level, the aesthetic-affective attention to the non-representational side of digitality can also be seen to correspond to the cross-disciplinary call to engage with the ‘material poiesis of informatics’, 57 which has enabled a vast variety of practice-based research landscapes and practical applications to establish and flourish. For instance, tangible and wearable computing, interactive architecture, physical computing, and body-area networking study computer-mediated environments, together with the use of hybrid computational-physical materials, so as to recreate states of intensity along the spectrum of the scales of sensible variations between the human body, the machine body, and all the infinitesimal steps in between. Both in respect to theory and practice, then, the affective turn can be read  n & Littlefield Publishers. All rights reserved. 38  Chapter 1  digitality with its own actual and virtual dimensions, advancing multiple efforts towards experimenting with an aisthesis of the digital. The inclination of digital aisthesis towards translating the quantitative into the qualitative can, in this respect, also be interpreted as an effort to overcome the fact that digital technologies would not seem to allow for the metaphysical dimension of potential relations in becoming proper to the virtual.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Anna Munster, for instance, talks explicitly of ‘aesthesia’ to describe her aesthetic approach to information technology. 59 It is useful to linger here on her proposition so as to give a concrete example of the way in which the affective turn in new media theory attempts to respond to Massumi’s challenge to find where the potential for creation might be within digitality. In her 2006 book Materializing New Media: Embodiment in Information Aesthetics, Munster draws largely from a vocabulary and a theoretical background borrowed from the philosophical work of Deleuze in order to propose an alternative aesthetic genealogy for digital culture. Munster focuses on the intersections between material and incorporeal forces engendered by information technologies. She understands digital code as part of a folding movement that operates through a mutual interplay of immediacies, losses, and complexities, and which lies at the juncture of the human-computer interface. Through the notion of digital embodiment, Munster proposes a modality for living and experiencing the body within the digital realm, as organic materiality comes into a relation with the speeds of information. From the perspective of our present discussion, the most attractive aspect of Munster’s argument is the fact that she acknowledges a potentiality proper to digitality. The visceral aesthetics that Munster is pursuing is not the result of direct sense-data perception but travels instead at the level of the bodycode and is thus irreducible to spatiotemporal coordinates of specific sociocultural constructions.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  For Munster, there is always a ‘something’ that exceeds experience; this surplus cannot be placed at either the level of materiality or that of coding. Such a body-code perceptual unity forms a whole that is greater than any of its parts. The special configurations between information and materiality necessary for digital embodiment aim to disrupt any pregiven formation, as they arise immanently from the outcomes of interaction itself. Having said this, Munster’s argument can, however, be used to exemplify  n & Littlefield Publishers. All rights reserved. Continuity versus Discreteness  39  related variables. 60 These sets of variables are said to find the reason for their informational existence thanks to their virtual participation in a non-cognitive status that will not be represented, for it always breaks away from rational synthesis. In effect, Munster virtualises the digital, thereby making it a negotiable continuum, the existence of which must be assumed if we are to participate in the experiential ‘approximate aesthetics’ of proximities that Munster longs for.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  61 It is thus also the case that, from this perspective, and despite a certain degree of engagement with digital information, the transcendental condition for the real experience of digitality remains in what the digital is not: namely, the continuity of immanent life. Can the digital be virtual, then? Or can the virtual be digital? In Moving without a Body: Digital Philosophy and Choreographic Thoughts, Stamatia Portanova has proposed a ‘digital philosophy’ of virtuality by focusing on what a ‘movement of thought’ is and what it could become in the days of ubiquitous digitalisation. 62 Portanova lucidly recognises the difficulty of accounting for both discrete rationalisation and continuous affects. She aims to supersede the intuitive equation between movement and continuity by exposing the former as a ‘multiplicity of potential cuts’, 63 whether these are bits, objects, or steps. Interestingly, Portanova proposes what could be seen as a discretisation of virtuality. Discreteness is reframed as a tendency inherent to virtuality itself.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Such a reconceptualisation of the virtual drifts away from Massumi’s characterisation of it as affective continuity and instead enlarges the category of the virtual to encompass ‘the unlimited potential that every numerical bit of a program, or every experiential bit of a dance (every gesture and step), has to change and be something else’. 64 From this view, ‘the creativity of digital technology derives from the abstract but very peculiar potentiality that stands behind its materiality, namely the idea to cut things (into bits, pixels, points, or dots) and recombine them, ad infinitum’. 65 Ultimately, it could be argued that abstract or virtual thought is concealed behind the actual functioning of the digital machine that lies at the centre of Portanova’s speculation. In her account, the digital has a potentiality because it is itself, as ‘a complex and visionary mathematical way to think’, 66 a modality of such abstract or virtual thought. In this respect, while Portanova’s proposition offers a concrete and serious opportunity to consider the  n & Littlefield Publishers. All rights reserved. 40  Chapter 1  will not be fully exhausted. For Deleuze, it is affect that registers this reciprocal determination: the transcendental conditions of experience are virtual forces or vectors that are recorded and lived through within sensation.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  I see both this reciprocal determination and the consequent reliance upon affect in order to transduce such determination to be a problem. This is because, in my opinion, taking up the challenge of experimenting with the specificity of digitality involves attending to its logico-quantitative nature and thus allowing the digital to have a degree of ontological autonomy from the qualitative and the affective. Digital machines, as will be discussed later in the book, organise, measure, and quantify the world by means of formal discretisation. However, when the virtual is treated as the potentiality of the digital, this logico-quantitative nature of the digital machine is considered, if not subordinate to, then at least always codetermined with the being of the sensible, because it is the logic of sensation (and not formal logic) that expresses virtuality. In this sense, whenever we think of the aesthetic potential of digitality through virtuality, reciprocal determination stops us from addressing the irreversible specificity of digitality: that of its ontological identification with discrete quantities, and with the logical structuring of these quantities through formal operations of deductive abstraction, which are not codetermined with or by sensibility. To the question of whether the digital can be virtual, or whether the virtual can be digital, I can now respond with a further question: should either be the case? I agree here with Massumi: the digital is not virtual, and vice versa. My point, however, is that this disparity does not mean that the digital is in any way ontologically inferior to the analogue.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  It simply implies that the digital is something other than virtuality and that its potential should be found elsewhere. I am not, therefore, denying that perception and sensation add an important qualitative processuality to the quantitative elements in composition in the digital machine. Of course, digital media are part of sensibility: the situations that they give rise to mesh with those intensive modes of sociability, perception, and communication that travel through the micro-scales of affective variation and, therefore, should also be accounted for on an expressive register, rather than only on a representational one. Importantly, those positions that stress the virtualisation of digitality empha-  Continuity versus Discreteness  41  My critique of the affective turn in digital studies, or of theories of the digital that are based around the Spinozist-Deleuzian notion of affect, is consequently straightforward. I do not want to discard or deny the importance of affect or its significance to aesthetics and experiencing. The problem, however, is that we should look for an experience of digitality (which, as we will see later in this book, is not just the experience of the user or programmer, but that of the digital itself) and understand that the conditions of this experience are not uniquely derived from the lived and the living, as are those of affect. For Deleuze, the virtual is a way of talking about the nonrepresentational vectorial structuring of the real. If we want to avoid virtualising the digital, the question then becomes, what kind of structuring do we need in order to engage with the conditions of experience of the digital?\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  My claim is that digitality calls for a type of structuring that is actual, discrete, and logical; however, it is also a structuring that needs to be addressed aesthetically, insofar as it is constitutive of the conditions of experience of digitality itself. This structuring pertains to the abstractive formal operations of computation. n & Littlefield Publishers. All rights reserved. \n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  The machines of Deleuze and Guattari are thus far removed from binary machines; they are instead fundamentally analogue, as they must be a little fuzzy in order to absorb and catalyse the matter-flow of the world while also probing spaces of combination and productivity. In other words, these are energetic machines, not formal ones. Moreover, the technological is just one of the many other elements that compose these machines. If ‘the machines are social before being technical’, 26 then this is because they are always somehow in relation to lived experience, although—and this is a crucial point—their subjectivity is not subordinate to the human but rather parallel to it. Of course, by introducing these considerations I am not implying that AI scientists follow the ontological principles of Deleuze’s philosophy. My point, however, is that today, ‘intelligent machines’ (if one accepts the conceptual difficulties that come with that expression) are considered to be social: the mechanised procedures of computation have entered the world and must now interact with it. According to the interactive paradigm in computing, interaction is ‘more powerful than algorithms’. 27 The cognitivist ‘closed’ model of reasoning, founded on the formal abstractions of the Turing machine, has been accused of being incapable of encompassing the complexity of the real world, which always lends itself to the behavioural richness of the living and the lived.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In technical terms, rather than algorithms that are capable of carrying out ever more difficult sequential computations, the computational structures that are sought after would be capable of transforming their preprogrammed instructions through their interaction with the real world, thus intervening in their own conditions of production by adapting them to the mutability of empirical situations. For example, in contrast to the Turing model, an interaction machine would extend and couple computation with the environment, thus creating a system that is powered by the ability of the computing device to cooperate with the external world, rather than limiting itself to carrying out ever more difficult sequential operations. The paradigmatic shift towards interaction is multifaceted. Generally, it responds to the challenges that computing confronts today, such as the vast, quick, and efficient responsiveness that computational systems are required to exhibit in order to handle the sheer volumes of data sets with which they  n & Littlefield Publishers. All rights reserved. Computation  55  software programs to inject qualitative and quantitative indeterminacy into the preprogrammed procedure. It is, then, appropriate to ask, how could the formal finitude of logico-mathematical techniques ever cope with that? Within the picture of computing that I have just outlined, although the functionality of a program is still based upon abstractive formal categorisations, formalism itself has undergone a substantial reconfiguration, resulting from the widespread criticism that has been addressed towards it.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This generalised distrust towards the formal constitutes the technoscientific context of my contention that it is possible—and, in fact, necessary—to look again at computational abstraction after the philosophical critique of representational thought. I intend to counter the tendency—a tendency that can be discerned, as I have shown, in both computing and philosophy—of responding to the crisis of formalism by either taking a certain distance from the latter, or by simply embracing that which the formal is not (i.e., the empirical). My contention, by contrast, is that computational formalisms should not be discarded but philosophically reassessed. The key to this renewed assessment is to understand computation as a method of abstraction that does not negate or refute abstractness and as a determination that does not negate indeterminacy. That computation is an abstractive method is evident. By analogy with mathematics, in computer science abstraction is understood as the conceptual practice of reducing and factoring out elements so as to address a few issues at a time. This permits the reasoning and analysis of logical systems. In computer science, abstraction is generally understood as a method that can tell what sort of information one can get from the observed system, what sort of questions are reasonable to ask in this regard, and what sort of answers one might, in principle, be able to get from it.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Language abstraction, procedural abstraction, data abstraction: they all specify content, languages, modules, procedures, variables, as well as the consequent operations that can be performed upon them. The abstractive operations of computation are multiple and operate at many scales and different speeds. Some of these abstractions are kept, others discarded; most of them are incessantly organised into sets of relations of objects and of data that are themselves already abstractions. To prove that computation does not exclude abstractness qua indetermi-  n & Littlefield Publishers. All rights reserved. 56  Chapter 2  abstract), not despite the discretisations, systematisations, and rationalisations that Deleuze criticised, but because of them. It follows that it is fundamental to my argument to advance a different understanding of what becoming, indeterminacy, and infinity might be vis-à-vis discretisation, systematisation, and rationalisation in computation. In the case of computational systems, they cannot be features of virtual life, as Deleuze understood them to be.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Instead, they are specific to the actuality of computation itself. While arguments for an aisthesis of the digital would seem to make computation something that might be abstract (and thus in becoming) by virtue of its participation in the being of the sensible, I propose that the becoming of computation corresponds to actual discretising procedures of quantitative systematisation. Computation can only generate what it has been programmed to generate. Computation, in this sense, is not ontogenetic. Computation has, nonetheless, the potential to engender new reality, insofar it has the potential to actualise itself. This is the becoming that I aim to theorise. I will do so by suggesting that the indeterminacy and infinity of computation are due to a central and constitutive characteristic of every computational processing: incomputability. The founding paradox of computer science is that it is a field that is defined by what it cannot do, rather than by what it can do.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Alan Turing’s 1936 foundational paper, ‘On Computable Numbers, with an Application to the Entscheidungsproblem’, first formalised the notion of computability and demonstrated that some functions cannot be computed. According to Turing’s model of computation, to compute is to follow an effective procedure (in other words, an algorithm) in order to solve a problem in a finite number of sequential steps. Turing discovered, however, that some problems cannot be solved via algorithmic means, because the steps involved in their processing are not finite but infinite: these problems are incomputable. Incomputability will be discussed in detail later, in chapter 6. However, in order to clarify how I intend to respond to the crisis of formalism, we can simply note here that because the incomputable is this element of undecidability, something in computation remains unknown and, ultimately, beyond representation. This unknown is a decisive element of the actual procedures of computation: it does not belong to life, the living, or the lived, but to computation itself. Although it is beyond symbolic representation, it is still  n & Littlefield Publishers. All rights reserved.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Computation  57  find, in the abstractive operations of computation themselves, a computational infinity that is not to be transduced into the qualities of sensibility, and a computational indeterminacy that does not have to simulate the indeterminacies of life. The crisis of formalism has usually been identified as evidencing that formalism must be challenged and superseded. I challenge formalism too; however, I do not wish to dispose of it. By drawing upon material that has informed the inception of the theory of computability, I aim to develop the view that formal abstraction in computation is not a mere reduction or compression of the complexities of sensibility to the simplicity of preformed representations of intelligibility. Thus, on the one hand I agree with the philosophical critique of representational thought: I too believe that the formal logic employed by computational systems cannot successfully account for the empirically real or for the virtual conditions of lived experience. On the other hand, however, my position also differs from such a critique, for I wish to prove that computation is never really only a reduction and that it never really only represents. Because of formal abstraction, computation is a procedure that is already complex—prior to any coupling with art, matter, or life—insofar as it is ingressed by a quantitative infinity that remains unrepresentable, and which is thereby impractical or useless from the perspective of cognitive computing. In this sense, by engaging with the limits of computational formalism, I challenge the conception of a calculatory preformation and depiction of the real.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  On that basis, I also refuse to endorse a computational theory of mind that is grounded in the possibility of such preformation and depiction. However, although the impossibility of enclosing procedures of counting into any final systematisation has been traditionally read as an indication of the failure of formal systems, I interpret the limits of formal reasoning not as a fault, a constraint, or a stopping point for computation, but as something that helps us to highlight the actuality of computational formalisms beyond any representational role that they might entail. I can now return to the question, is it legitimate to consider the abstractive capacities of computation in aesthetic terms, given the philosophical critique of representational thought and the crisis of formalism in science? At this point, I can expand on the positive answer that I have already anticipated and  58  Chapter 2  same attention to formal abstraction from which computationalism also proceeded. That is why drawing upon Turing’s work is pivotal to my account: I aim to challenge the cognitivist view of computation that developed from his work by proposing another reading of his logico-mathematical results. In doing so, however, I do not assume that formal abstraction can only be understood in the manner that computationalism tends to conceive it. While trying to supersede computationalism, I thus also challenge the philosophical critique of computation, despite the degree to which it accords with my intention to dispose of computationalism. This is because this critique assumes that formal abstraction is what the computational theory of mind made it to be.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  5 I agree with Latour: this is unfortunate, because Whitehead’s thinking is far from being an anti-intellectualism or a rejection of scientific knowledge. Whitehead not only engaged with the most challenging scientific theories of his day, such as quantum theory, electromagnetism, and relativity; in addition, his overall philosophy of actuality is aimed at constructing a cosmology that could prove significant to these scientific theories and contemporary mathematical concepts. We should thus welcome the fact that, in the past fifteen years or so, the study of Whitehead has been revived by attempts to rehabilitate the onto-epistemological significance of his philosophy. This Whiteheadian revival has often run parallel to a revitalised attention to Henri Bergson, as well as to fresh readings of the radical empiricism of William James, the pragmaticism of Charles Sanders Peirce, and philosophies of expression of Spinozist derivation. The thematic convergences around these directions have resulted in original connections and have offered interesting frameworks through which late capitalist society, together with its art, science, and philosophy, can be deciphered. In addition, these conjunctions have also foregrounded the unavoidable similarities between Whitehead and Deleuze. Deleuze rarely addressed Whitehead in his writings, but he did so more consistently in his teaching. 6 In the past few years, a growing body of scholarly literature has addressed Whitehead’s influence on Deleuze ever more explicitly.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  7 However, while I acknowledge this literature—and while I also recognise that it is possible to develop a reading of Deleuze and Whitehead that places them in harmony with one another—I will not attempt to propose such a view here. My aim of radicalising Deleuze’s aesthetic ontology entails looking for disparities between the two philosophers, and thus for the ways in which Whitehead’s philosophy might help us to extend Deleuze’s aesthetics of thought in such a way that it would be able to encompass computational processes. It is possible to claim that Whitehead’s metaphysics is, fundamentally, an aesthetics. In this respect, Whitehead’s philosophy is very close to that of Deleuze: aesthetics is not based upon the mere sense reception of art, as of anything else, but is instead about determining the ontological conditions for real experience. In Without Criteria: Kant, Whitehead, Deleuze, and Aesthet-  n & Littlefield Publishers. All rights reserved. Processes  63  such a basis. Nonetheless, I wish to address the ontological aesthetics of Whitehead from another perspective.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  An overlooked and yet profound difference between Deleuze and Whitehead offers the opportunity of establishing a novel ontological approach to the aesthetics of computation. This difference is as follows: Whitehead’s aesthetics is not only about the sensible, but about the intelligible too. This means that aesthetics, for Whitehead, is about sensation and thought. For Deleuze, too, aesthetics concerns thinking processes. However, in Deleuze’s work, thought is aesthetic because it involves a virtual indeterminacy that cannot be grasped intellectually and which can only be felt. For Deleuze, aesthetics is precisely what addresses this sensory knowledge. Whitehead, on the other hand, conceived a conceptual activity that would not rely on virtuality and that would instead be specific to actuality. Whereas for Deleuze thought is virtual, Whitehead described an actual conceptual capacity to make indeterminacy intelligible.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Yet, according to Whitehead, it is still aesthetics—and nothing else—that can explain this capacity, because the latter is not cognitive and does not operate through representational reductions. Instead, it is an assimilation that involves a grasping of ideas. What Whitehead’s philosophy offers, then, is an aesthetics that operates on two levels: an aesthetics in which non-representational relations are established conceptually as well as physically. In order to explain this issue further, it will prove useful to outline part of the ontological scaffolding that supports Whitehead’s philosophy. In Whitehead’s analysis, ‘this actual world spreads itself for observation in the guise of the topic of our immediate experience’. 9 The immediacy of this actual world is primarily ‘a fact of aesthetic experience’, and ‘all aesthetic experience’, in turn, ‘is feeling’. 10 If actuality is given in experience, and experience is feeling, then all actuality is ultimately felt. Shaviro is thus right to stress that a feeling relationship among actualities is, in Whitehead, more basic than any cognitive one.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Feeling has a degree of primacy in Whitehead’s main work, Process and Reality. ‘Feeling’, however, is a term that should be understood as ‘a mere technical word’. 11 Whitehead opted for the term ‘prehension’ in order to distance himself from any psychological and anthropocentric understanding of what, for him, it meant ‘to feel’. ‘To prehend’ is not ‘to cognise’, but neither is it ‘to perceive’. A prehension should instead be 12  n & Littlefield Publishers. All rights reserved. 64  Chapter 3  architecture of a mind or of a brain. A conceptual prehension is not a direct cognition, nor is it a recognition or a recollection.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Rather, a conceptual prehension is actuality’s friction with the ideal. Physical prehensions, on the other hand, are actuality’s responses to other actualities. A physical prehension feels what there is, or what there has been, and internalises this feeling into a unity that comes to constitute what there will be. Physical prehensions could be viewed, therefore, as exemplifying the affective tone of reality that Shaviro says is central to Whitehead’s aesthetic philosophy. I agree with Shaviro that physical prehensions are ‘pulses of emotion’. 13 They are a rhythm to be played out on the bodily level of Deleuzian matter-flows. If we were to remain at this bodily level of prehensive activity, it would be appropriate to view Whitehead’s aesthetics as an aisthesis or as sensory knowledge. However, Whitehead’s insistence on the concomitant existence of conceptual prehensions also makes it possible to contend that, if Whitehead’s aesthetics is an aisthesis, then it is an aisthesis of a very peculiar kind.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In Whitehead, a bodily transduction of affective forces is not enough to account for an actuality’s relation to the rest of actuality. Everything that exists is in fact ‘dipolar’. 14 All actualities in the world—not only humans, but everything that is real, concrete, and indeed actual—have a physical pole and a mental pole. This means that experience is dipolar too: while being originated by sensible relations, it is nonetheless never completed without a conceptual determination. Whitehead’s aesthetics, therefore, is not just affective. Certainly, the activity that conceptual prehensions perform falls under the category of feeling. I cannot deny that conceptual prehensions are feelings and that—insofar as these feelings are precognitive and impersonal—they exhibit many similarities with the Deleuzo-Spinozist notion of affect. In addition to this, however, it should also be stressed that a conceptual feeling is not an intensive response to change or a response proper to a body that intensively registers such change, as would be the case with Deleuzo-Spinozist affect.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  On the contrary, a conceptual feeling is the capacity of a mind (or, better, of a conceptual or mental pole) that feels because it selects, evaluates, decides, and orders—that feels, in other words, because it abstracts. Thus, while for Deleuze thinking processes and bodily affects are fundamentally the same  Processes  65  ity, it is nonetheless prehensive. This conceptual activity goes outside and beyond its cognitive and representational functions, but it is still mental, conceptual, and abstractive. In my view, if we want to establish an aesthetics of computation that would consider the aesthetic legitimacy of operations of formal abstraction, then it is precisely these Whiteheadian insights that should be investigated. Therefore, while markedly Deleuzian readings of Whitehead generally downplay the extra-affective specificity of conceptual prehensions, I want to place it centre stage and develop its significance as regards the relevance that it might hold for an aesthetic ontology (or an ontological aesthetics) of actual—not virtual—computational processes. n & Littlefield Publishers. All rights reserved. EVENTS: INDETERMINACY It is necessary to get a little more technical now, for it is only by addressing the peculiarity of Whitehead’s understanding of actuality, and how this actuality comes to being through becoming, that it is possible to appreciate the speculative opportunity that Whitehead’s philosophy offers to the aesthetic investigation of computation.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  The first thing that should be highlighted as regards Whitehead’s characterisation of actuality is that, in his philosophy, the actual is always eventual. Quite literally, this means that everything that is actual exists as an event. A parallel between Deleuze and Whitehead is often made on the basis that they are both said to be philosophers of the event. 15 According to Deleuze, events are the product of the transformations and interrelations between those intensive forces that constitute the inherent potentialities of the real. Events run through actuality and virtuality ‘in terms of changes in degrees of intensity in their relations’. 16 I have already discussed how the notion of intensity is central to Deleuze’s philosophy. A Deleuzian event can be described as a change in intensity that marks the reciprocal determination of actuality and virtuality, and thus the occurrence of ontological novelty. The concept of event is also at the heart of Whitehead’s philosophical system.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  17 Famously, Whitehead rejected the Aristotelian metaphysics of enduring substances and instead favoured an ontology of spatiotemporal atomic processes. For him,  n & Littlefield Publishers. All rights reserved. 66  Chapter 3  Of course, the concept of event is also central to other contemporary thinkers. 19 Still, what Deleuze and Whitehead have in common is that they theorised and spoke of events as immanent to, and as productive of, the real. For both writers, events are genetic: events do not happen to things, but things happen, or come to be, in events. Given these similarities, there is, however, also a major distinction between Deleuze’s events and those of Whitehead. For Deleuze, an event is virtual.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This means that it is indifferent to actualisation, ‘since its reality does not depend upon it’. 20 For Whitehead, on the other hand, events are always actual. It is true that, for both philosophers, events are functional in addressing ‘the problem of how the eternal and the actual are necessarily combined in the new and are necessary for the new’. 21 Nonetheless, whereas in Deleuze’s work an event remains partly unactualised in what he often referred to as the ‘chaosmos’ or ‘plane of consistency’ of virtuality, in Whitehead’s philosophy events are bits of actuality, or atoms of existence of this world, which must come to full determination. Deleuze’s events have no position or temporality, and, as such, they are a pure reserve of multiplicity, with no beginning and no end. By contrast, a Whiteheadian event is a spatiotemporal process that commences and then perishes. It is the result of the production of an actual structure, an actual order, and an actual unification of multiplicity. These considerations allow us to address the relation between indeterminacy and events in both Deleuze and Whitehead.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  It is my contention that the importance of the notion of the event for both philosophers is an indication of the centrality of indeterminacy to their ontologies. It is only because of indeterminacy that new actuality occurs: one can assume that Deleuze and Whitehead would have agreed with this. They would not have settled, however, on the nature of this indeterminacy, or on the relation that the latter holds with actuality. The ontological dynamic through which new actuality comes about is different in Deleuze and Whitehead, although for both this dynamic is aesthetic. This is another significant point of divergence between Deleuze and Whitehead that can be stressed in order to push Deleuze’s aesthetic proposition further than Deleuze himself would permit. In Deleuze’s philosophy, indeterminacy corresponds to pure difference— that is, to the virtual totality of unactualised conditions of the real. Indetermi-  n & Littlefield Publishers. All rights reserved.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Processes  67  affairs. The indeterminacy of Deleuzian virtual events is metaphysical and should not be confused with the empirical uncertainty of physical phenomena. Deleuze never tired of affirming a crucial distinction between the virtual and the possible. The latter lacks reality; the former does not: its reality is simply not actual. The virtual is not a reservoir of possible options waiting to be merely passed into existence; instead, the virtual is a reserve of very real energies to be exhausted, of forces to be employed, and of potentialities to be actualised. Seen in this light, ‘the virtual is change as such’. 24 Badiou is thus right to stress that Deleuze’s virtual is fully determinate, for the virtual does not lack being or existence. What should then be added to my contention is that, in my reading of Deleuze, virtuality corresponds to indeterminacy to the extent that it is the maximally unknown and the maximally unknowable.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Its abstractness means that it cannot be preformed or even only presented according to principles of identity and resemblance. In this sense, the potential for ontological production that the virtual stands for is truly contingent because it has ‘the capacity to bring forth situations which were not at all contained in precedent situations’. 25 It can thus be concluded that, in Deleuze, the indeterminacy of virtuality is an open threshold from which to jump into a lived future that cannot (and will not) be harnessed by any preformation of it. This future, for Deleuze, is expressed in the immeasurability of affective forces that traverse lived experience. One jumps into this future as one falls into ‘a life’: with a body that feels, that elongates, dislocates, and deterritorialises itself, and which loses all functional structures (and all organs), until it merges with the virtual indeterminate and the virtual unknown. It becomes possible here to fully appreciate the centrality of aesthetics to the metaphysics of events presented by Deleuze. One can, at the same time, also appreciate the opposite (i.e., the importance of the notion of event for the Deleuzian aesthetic enquiry). Both can be understood only if virtual indeterminacy is kept at the centre of Deleuze’s ontology.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Deleuzian events attest to the ontological superiority of the dynamic activity of becoming in respect to entities and states of being. A Deleuzian event is less a differentiated creature than an act of differentiating creation. It compels a step back from mediation and normalisation in order to channel the virtual, unpresentable composition that is behind everything that exists. This maxi-  n & Littlefield Publishers. All rights reserved. 68  Chapter 3  Whitehead’s self-creating events, then, are not withdrawals from determination or systematisation; they are movements towards it. Indeterminacy is thus also central to Whitehead’s ontology, albeit in a way that is quite different from that of Deleuze. In Whitehead, the indeterminacy of events has to be resolved within actuality.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This resolution, however, is not a solution but a decision that brings about a completion. This decision is the way in which an actuality ‘adds a determinate condition to the settlement for the future beyond itself’. 27 It can therefore be argued that, in Whitehead too, indeterminacy involves a threshold open towards the future. However, while Deleuze’s events prosper on the ‘drama beneath every logos’, 28 performing the dramatic dynamism of thinking-feelings ‘beneath all possible representation’, 29 for Whitehead, if there is no logos there is no event, and thus there is no drama either. To put this otherwise, the Deleuzian dynamism of thinking-feelings is characterised by an advocacy of affective indeterminacy, which translates into an argument against mental structuring. In Whitehead’s philosophy, by contrast, a systematisation is not a stopping point for thought, but the eventuation of thought itself, insofar as it is the manner in which what we could call the ‘contingency of the real’ disrupts the stubborn sequentiality of matters of fact and states of affairs. In order to gain a clearer understanding of this issue, it is useful to return to the prehensive activity that, according to Whitehead, is carried out by all actuality. As I discussed earlier in the chapter, prehensions can either be physical or conceptual.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Enough ground has now been covered to elaborate on that dual capacity and to thereby link it to the significance of indeterminacy within the Whiteheadian ontology of events. An actual occasion’s physical prehension is a prehension whose datum is another actual occasion: it is the feeling of actuality by another actuality. This is the primary way in which the community of all actual occasions relate to each other. In contrast with the early modern empiricist account of empty factuality that passively impresses itself upon human senses, Whitehead’s approach understands actuality as active, in act, and full with the generative potential for novelty and creation. The notion of real potentiality is used by Whitehead to describe such a potential for creation; the notion of creativity expresses instead the status of actuality’s ‘underlying activity’, 30 or the ‘category of the ultimate’. 31 From  n & Littlefield Publishers. All rights reserved. Processes  69  actual events to determine themselves out of the indeterminacy that they originate from.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  ‘The notion of potentiality’, Whitehead believed, ‘is fundamental for the understanding of existence, as soon as the notion of process is admitted.’ 33 An actual occasion ‘exhibits itself as a process’. 34 However, this becomingness is short-term. Every actual occasion begins, determines itself, and perishes. The perishing of an actual occasion is consequent to the full determination of the latter: for an actual occasion, ‘its birth is its end’. 35 This process from indetermination towards determination indicates how, from this point of view, Whitehead’s events are also different from those of Deleuze. Deleuze’s events are never complete, inasmuch as they are vectors that express the mutual determination of actuality and virtuality. A Whiteheadian actual occasion, however, must be understood as a drive that always reaches an end. ‘There is a becoming of continuity, but no continuity of becoming.’ 36 For Whitehead, despite real potentiality being ‘the driving force of process’, 37 the full determination of an actual occasion is achieved with the ingression into the event of another type of potentiality, which he called ‘pure’.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Pure potentiality is a general potentiality, which impinges upon actuality thanks to conceptual prehensions. The latter are the ‘primary operations amongst those belonging to the mental pole of an actual entity’; 38 they are conceptual reactions to the physical concatenation of events and prompt ‘some possibility as to how actualities may be definite’. 39 Conceptual prehensions, as I said earlier, could be described as feelings of ideas. It is crucial to emphasise again that these conceptual feelings are not conscious intellectual feelings; they are the conceptual grasping of a new opportunity. A conceptual prehension corresponds to the capacity of actuality of ‘mentally’ grasping (and thus not only of sensing) the unknown. The unknown in question is not the contingency of empirical states of affairs, but the indeterminacy that pertains to the ideality of eternal objects. For Whitehead, actual occasions are the basic particulars of what is real. ‘Any entity whose conceptual recognition does not involve a necessary reference to any definite actual entity of the temporal world’, on the other hand, ‘is called an “eternal object”.’ 40 As the name implies, eternal objects are entities, not processes.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Similarly, they are abstract and eternal, not concrete  n & Littlefield Publishers. All rights reserved. 70  Chapter 3  sion. However, ‘in its ingression into any one actual entity’, the eternal object ‘retains its potentiality of infinite diversity of modes of ingression, a potential determination rendered determinate in this instance’. 42 Eternal objects should thus be understood as modes of indetermination that are fundamental to the constitution of the actual occasion. They are the pure potentialities that inform the coming into existence of the actual occasion. ‘The definite ingression into a particular actual entity’, in this sense, ‘is not to be conceived as the sheer evocation of that eternal object from “not-being” into “being”: it is the evocation of determination out of indetermination.’ 43 Actuality needs the ideality of eternal objects: the definiteness and conclusiveness of actuality has to be informed by the indeterminacy and infinity of pure ideality. Different actual occasions can be informed by the same eternal object (e.g., the eternal object ‘blue’ can be realised in more than one actual occasion), or by different ones.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  This is because the eternal object is an abstraction: ‘blue’, for example, is one of the abstract forms determining the actuality of the sky and the ocean alike. When the process of determination is concluded, an actual occasion is fully complete. Eternal objects are disconnected between each other and unknowable in themselves. Since they are pure potentials and not actualities, their ontological status always entails what is not or what could have been otherwise, as well as what has never been. When ‘potentiality becomes reality’, it still ‘retains its message of alternatives which the actual entity has avoided’. 44 The sky is blue, yet it could have been grey or pink. From this perspective, it becomes evident that, if these eternal objects ‘involve in their own natures indecision’, 45 this indecision fundamentally pertains to their ingression into the actual occasion. In itself, an eternal object is ‘neutral as to the fact of its physical ingression in any particular actual entity of the temporal world’.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  46 The eternal object does not choose what to inform or define. Rather, it is chosen by the actual occasion that selects it in conceptual prehensions. For Whitehead, it is worth remembering, ‘“actuality” is the decision amid “potentiality”’. 47 In the context of this chapter’s comparison between Deleuze and Whitehead, this selective or decisional prerogative of actuality is particularly interesting, because it helps us to understand to what extent the ontological dy-  n & Littlefield Publishers. All rights reserved. Processes  71  tion of the virtual, while the second is the continuous flow of combination and division of the virtual field towards new directions and connections. 49 These movements are simultaneous and interdependent. In Deleuze, actuality and potentiality are two distinct fields of reality, yet one cannot exist without the other.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In Whitehead, instead, there is no such mutuality between what is actual and what is potential. It is also true that, for Whitehead, the actual is never fully realised without the ingression of pure potentiality, and that this pure potentiality is always inherent to actuality (that is: eternal objects exist in events). Many have written about the points of resonance between eternal objects and the virtual; 50 Deleuze himself favoured a parallel between the two, describing eternal objects as pure virtualities that are actualised in prehensions. 51 While I too recognise these similarities, I wish to advance an alternative view on the issue. My claim is that—although the relation between actuality and virtuality, and that between actual occasions and eternal objects, are transformative for both Deleuze and Whitehead—there is also a profound difference between what is involved in one process of determination and what is involved in the other. The relation between the virtual and actual is reciprocal; that between actual occasions and eternal objects is not. In my view, this difference makes the straightforward equivalence between Whitehead’s eternal objects and Deleuze’s virtuality difficult to sustain. James Williams has commented that reciprocal determination concerns questions about ontological permanence.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  52 He has also emphasised how, for Deleuze, identity pertains to actuality, whereas for Whitehead it is potentiality that has the property of being ‘fixed’, so to speak. I wish to draw on this line of investigation here, and to argue, by doing so, that—since in the Whiteheadian ontological schema eternal objects are static and permanent entities (indeed, eternal and objects)—the creative activity that generates the new belongs, according to this schema, to actuality and not to potentiality. Deleuzian actualisation is an irreversible ontological movement, just like the actualisation described by Whitehead. However, for Deleuze, ‘purely actual objects do not exist’. 53 Just as lived experience is always extended into the virtual field, so too is reality in general. By contrast, according to what Whitehead called the ontological principle, the concrete cannot derive from the abstract, because only the actual is fully real and fully in act. 54 Eternal  72  Chapter 3  It can then be concluded that, with the ontological significance that Deleuze and Whitehead assigned to the notion of event, both philosophers meant to highlight that there is always a potentiality inherent in actuality. While the role that they envisaged for this potentiality, as an ideal element of new existence, might be similar in both Deleuze and Whitehead, its ontological relation with actuality is not.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  n & Littlefield Publishers. All rights reserved. THE CONDITIONS OF EXPERIENCE It is a central contention of this book that computation could be addressed as a Whiteheadian actual event: computational processes should be thought of in terms of actual occasions. By investigating the physical and conceptual prehensions of these computational actual occasions, and thus by rethinking both their real and their pure potential, it becomes possible to demonstrate that aesthetics is a relevant mode of enquiry into digital computation. To address computational processes as actual occasions entails committing oneself to an aesthetics that operates on two levels. Computation can, therefore, be addressed in aesthetic terms not solely because it is a physical manipulation of data, or because its quantities could be transduced into affective qualities. Most importantly, according to the view that I am proposing, computation is aesthetic because it involves logico-quantitative operations of formal abstraction. Following Whitehead, these operations need not be considered from a cognitivist or representational perspective.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  However, they do not need to be understood as codetermined by sensibility either. Drawing on the Whiteheadian ontological schema, the intelligible is consequent to the sensible, yet not inferior to it. We saw already that any actual occasion has both a physical and a mental pole. Because experience, for Whitehead, is a process of determination of indeterminacy, it too is dipolar: actualities hold relations among each other (via physical prehensions) and with the ideality of eternal objects (via conceptual prehensions). I have also argued that, in contrast to theories of affect, conceptual activity in Whitehead’s philosophy is not codetermined by the being of the sensible, but is a genuinely conceptual operation pertaining to forms of intelligibility. Whitehead thus envisaged a conceptual activity that,  n & Littlefield Publishers. All rights reserved. Processes  73  contrast, does not locate the strictly mental and conceptual character of thought upon the plane of sensibility.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  By looking through the lenses of a Whiteheadian ontology, and by considering computation as a Whiteheadian actual event, the fracture between aisthesis and logos appears to be repairable. The two are not antithetical fields any longer. Whitehead understood aesthetics and logic as ‘the two extremes of the dilemma of the finite mentality in its partial penetration of the infinite’. Remarkably, he believed that ‘the analogy between aesthetics and logic is one of the undeveloped topics of philosophy’. This analogy lies in the fact that aesthetics and logic ‘are both concerned with the enjoyment of a composition, as derived from the interconnections of its factors’. In both aesthetics and logic, ‘importance arises from the vivid grasp of the interdependence of the one and the many’. 57 These comments are most interesting, for they attest to the relevance of a Whiteheadian framework to an authentic reconciliation between aisthesis and logos. In the context of computational practices and theories, this reconciliation is significant, because it shows that there is no need for computational formalism to be made more aesthetic via the injection of empirical variation.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Computational logos is already aesthetic: aesthetics concerns the conditions of reality (in fact, of real experience, as Deleuze would have it), and these conditions—for computation as for everything else—are not only about the sensible, but about the intelligible too. Via Whitehead, logico-quantitative operations can then be understood as crucial to the constitution of computation’s real experience. Drawing from Deleuze, I understand aesthetics as an enquiry into the conditions of real experience. With Whitehead, however, I can now enlarge this enquiry to consider what these conditions are for computational systems, inasmuch as conceptual operations, in his theory of experience, are instances of these conditions. This Whiteheadian contribution is a very helpful means of elaborating this book’s core contention that formal abstraction, in computation, is not a representational depiction of experience, but rather the manner in which the very experience of computation comes about. This, as already anticipated, should be understood not as ‘our’ experience of computation, but that of computation itself. Nevertheless, in order to develop these claims, the importance that abstraction holds in Whitehead’s philosophy should be explained further. n & Littlefield Publishers.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  All rights reserved. 74  Chapter 3  for Whitehead, guilty of reducing and diminishing experience, to say the least. Whitehead was very critical of what he called the ‘scientific materialism’ of his time. The problem with scientific materialism is that it downgrades immediate experience to a collection of empty or bare factualities in need of interpretation, as though every mental valuation of such factualities could only be external to the actual constitution of the factualities themselves. The depth of Whitehead’s ‘speculative reform or emendation of our very culture of abstraction’ is epitomised in his refusal to assign to abstractions the status of mind-dependent representations of a mind-independent world. 60 This refusal is among the reasons why Whitehead rejected the early modern British empiricist tradition that informed scientific materialism; a tradition that is epitomised by the philosopher David Hume, and according to which perceived facts are associated with the impressions and ideas that a perceiving subject, external to these facts, has elaborated from them. With his critique of the ‘brute fact’ of scientific materialism, 61 Whitehead highlighted the risk that, if we analyse experience away into nothing, we could end up mistaking ‘our abstraction for concrete realities’. 62 For Whitehead, any analysis of concrete experience must always return to this concreteness.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  As a mathematician, he understood the importance of generalisations for knowledge and understanding. However, as he was also a radical empiricist, he believed equally that ‘the true method of discovery’ takes off ‘from the ground of particular observation’, that it then ‘makes a flight in the thin air of imaginative generalization’ and eventually ‘lands for renewed observation rendered acute by rational interpretation’. 63 I am touching on Whitehead’s speculative scheme of philosophy here. Speculative philosophy, in his view, is a movement towards abstraction, which attempts to grasp the concreteness of experience. While Whitehead appreciated that one ‘cannot think without abstractions’, 64 I would claim that he also believed that one cannot experience without abstractions either. This is another striking disparity between Deleuze and Whitehead. For Deleuze, an abstractive matrix is what separates thought from lived experience; for Whitehead, by contrast, an abstractive matrix is the essential vehicle for past actuality and ideality alike to become constitutive of experience. This means that it is essential to any experience.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  From this perspective, the task of the  n & Littlefield Publishers. All rights reserved. Processes  75  ‘constructs a real that is yet to come’. 65 Like the diagram, this matrix attends to the genesis of new actuality. Nonetheless, in a manner that departs from Deleuze’s diagram, Whitehead’s matrix abstracts extensively, not intensively. In order to appreciate the strength of Whitehead’s proposition of a genetic (i.e., productive of novelty) matrix of abstraction, and the significance that this proposition holds in relation to the aesthetics (i.e., in relation to the investigation into the condition of real experience) of computation, the difference between Deleuze’s use of the notion of intensity and Whitehead’s concept of extension should be introduced briefly. This discussion is not intended to remove the notion of intensity from Whitehead’s ontology. Arguably, Whitehead envisaged a place for it in his philosophy.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  66 This is predominantly evidenced by the fact that, for Whitehead, time is as important as space. However, in contrast to the views held by Deleuze (and, before him, Bergson), for Whitehead time is not a transcendental continuity that grounds being and becoming. Time, like space, is held to be delimited by actual occasions. Time is always discretised by actuality because it exists only in discrete processes of actualisation. Time, in other words, is the outcome of actualisation, just as space is: it is not a Kantian a priori intuition, but neither is it a Deleuzo-Bergsonian transcendental field. While it is important to acknowledge Whitehead’s epochal theory of time, I will not address this aspect of Whitehead’s philosophy further here because it is not strictly pertinent to what I wish to consider. Instead, my focus is as follows: Whitehead’s abstractive matrix is not necessarily a structure of lived experience; in fact, it is a structure of experience at large. Experience, in turn, is a process of selfactualisation of discrete and finite processes that, as such, are to be understood in the quantitative terms of actual spatiotemporalities, rather than in the qualitative terms of the durational dimensions of virtual life.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Deleuze’s notion of intensity explains the importance of sensation for real experience. Yet intensity is never given in itself: it can only be grasped as resolved by the qualities to which it gives rise in actual things. ‘Intensity is simultaneously the imperceptible and that which can be only sensed.’ 67 Like Whitehead, Deleuze expanded the possibility of real experience well beyond the human. However, since in the Deleuzian framework the virtual is the transcendental condition of experience, and since this condition can only be  n & Littlefield Publishers. All rights reserved. 76  Chapter 3  of atomic yet processual entities such as the actual occasion, which dies once it is born and enters the composition of another actual occasion. While Deleuze’s intensive experience is a subtraction from determination, Whitehead’s experience is extensive, because it is an addition of ‘drops’ of reality: it is a real structure of atomic events in which a part (i.e., the actual occasion) always extends over other parts (i.e., other occasions). Whitehead, however, also envisaged a type of ontological continuity in order to explain the relatedness of events.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Still, unlike a Deleuzian flow of uninterrupted transformation, Whitehead’s extensive continuum is atomised by the actual occasions themselves. 69 This continuum is not an intensive whole but an extensive sum of part over part. The connection between things is a relation established through succession, thanks to the activity of actual occasions that extend over one another. Having clarified this, it becomes evident why Whitehead, unlike Deleuze, could not endorse Leibniz’s concept of the infinitesimal. Deleuze found that the differential point of view of Leibniz’s infinitesimal calculus was suitable to his own development of an expressionist philosophy of difference, in which the becoming of intensive forces folds and unfolds ad infinitum. Deleuze’s infinitesimal continuity of becoming increases by intensive multiplication and never ruptures. Whitehead’s extensive continuum, on the other hand, is a ‘potentiality for division’, 70 in which disjunction is a starting point, not the end product. In other words, discreteness is the only way in which continuity can exist.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  Whitehead’s dismissal of Leibniz’s infinitesimal thus also explains the rationale behind his correction of Zeno’s famous paradoxes about the illusion of motion. According to the pre-Socratic philosopher Zeno of Elea, an arrow never hits a target because its movement can be split in half, and that half can be split into two other halves, and so on. For Whitehead, the error of the Eleatic paradoxes consisted in presupposing a continuity that is then split into smaller and smaller entities. This presupposition invites infinite regression; it also assumes that becoming belongs to a continuous whole. Whitehead claimed, instead, that it is not the whole that becomes, but the part. That is to say, becoming belongs to the actual occasion. It was necessary to explain these issues at length to show that Whitehead’s ontology can afford a means of surpassing the aesthetic impasse be-  Processes  77  Drawing on Whitehead’s eventual actuality, one is ultimately exempted from virtualising the digital insofar as, in Whitehead, becoming is not a virtual movement but an actual one. This actuality, nonetheless, is not a mere succession of facts, for it is always ingressed by the ideality of eternal objects.\n"}
{"prompt":"Contingent computation : Abstraction, experience, and indeterminacy in computational aesthetics ->","completion":"  In Whitehead’s aesthetics, the discrete part does not fragment experience: instead, the discrete part is rather the sole object and subject of experience, for it is what determines indeterminacy, and is thus what truly becomes.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  � (life) ÷ � (blackness) = ∞ − ∞ or ∞ \/ ∞: On Matter Beyond the Equation of Value Denise Ferreira da Silva  Otobong Nkanga, In Pursuit of Bling—Coalition, ����.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  Lambda print. �� x �� cm. Courtesy Lumen Travo Gallery. Issue #�� February ����  things if they were read as expressions of our modern grammar and its de�ning logic of obliteration? Would this expose how the object (of exchange, appreciation, and knowledge)—that is, the economic, the artistic, and the scienti�c thing—cannot be imagined without presupposing an ethical (self-determining) thing, which is its very condition of existence and the determination of value in general?� Black Lives Matter, as both a movement and a call to respond to everyday events of racial violence (the killing of unarmed black persons by police) that rehearse the ethical syntax that works through\/as the liberal democratic state,� signals a political subject emerging in the scene of obliteration through a sentence without a (selfdetermined) subject. What I do in this text is activate blackness’s disruptive force, that is, its capacity to tear the veil of transparency (even if brie�y) and disclose what lies at the limits of justice. With a thought experiment that I call the Equation of Value, designed to help the imagination break away from the enclosures of modern thought, this speculative exercise reaches for The Thing,� which is the referent of blackness, or that which in it is exposed as the excess that justi�es otherwise untenable racial violence.� When taken not as a category but as a referent of another mode of existing in the world, blackness returns The Thing at the limits of modern thought. Or, put di�erently, when deployed as method, blackness fractures the glassy walls of universality understood as formal determination.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  The violence inherent in the illusion of that value is both an e�ect and an actualization of self-determination, or autonomy. My itinerary is simple. It begins with considerations of the role of determinacy—formal determination articulated as a kind of e�cient causation—in modern thought, and closes with a proof of the Equation of Value, intended to release that which in blackness has the capacity to disclose another horizon of existence, with its attendant accounts of existence. Installation view of Otobong Nkanga, In Pursuit of Bling, ����. Courtesy Lumen Travo Gallery. intention, I �nd that it does more than comment on power. For In Pursuit of Bling, like other works in her portfolio,� performs both as an item in the anticolonial arsenal and a site of confrontation; that is, it works for the exposure of how colonial violence remains active in the global present. In doing so, it punctures the presumed transparency of the subject of aesthetic culture, whose whole ethical framework rests on a formulation of universality held by our modern formalized syntax.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  For the most part, what I do here is try to emulate Nkanga’s artistic intervention into Western aesthetic culture with an analytic formal artifact— that is, the proof of the Equation of Value—which might implode the basis of the ethical grammar that cannot but provide a negative answer for the never-asked question for which Black Lives Matter demands a di�erent answer. Hence, I do not engage with what Sylvia Wynter claims to be the core of racial subjugation, namely, the hierarchical division of the human between rational\/irrational, or “selected\/dysselected.”�� My critical move here is not about ideological unveiling (as in exposing how European Man “overrepresents” the human, thus disavowing all other modes of being human); nor does it attempt to delineate an outside space from which to expose that “other” side of the “color line” dividing white\/European (human) from nonwhite\/non-European (nonhuman). For I am not interested in a transcultural (transcendental or physiological or symbolic) human attribute that would be both the condition of possibility for what is activated in Western European being and all other modes of being, and that which has already been mapped by anthropology, cognitive science, or neurology. My attention to Nkanga’s intention immediately takes me away from the usual analytical path. It takes me further in\/down\/through but beyond the observed divisions, beyond what the artist has already o�ered in the minerals which in her work expose the links between “places of shine”\/“spaces of obscurity,” after and against that which gives meaning to the “\/” that signals it. More particularly, I am interested in the ethical indi�erence with which racial violence is met—an indi�erence signaled by how the obvious question is never (to be) asked because everyone presumes to know why it can only have a negative answer. For this reason, I move to expose how determinacy, which along with separability and sequentiality constitutes the triad sustaining modern thought, operates in the ethical syntax in which this indi�erence makes sense as a (common and public) moral stance.�� When considering the “Subject without properties” it is always helpful to recall its genealogy, in particular how it emerged in e�orts to answer another question that very few thinkers explicitly formulated: How to describe the world in such as way as to make it possible to establish that the human mind can know the truth of things in it without the need for divine revelation? This genealogy usually opens with Francis Bacon and René Descartes as crucial players in assembling tools and scienti�c programs intended to ensure just that.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  What interests me in their attempts is the account of causality they compile through a selective appropriation of Aristotle’s famous four causes, namely, material, formal, �nal, and e�cient.��  Frontispiece of Francis Bacon's book Sylva Sylvarum: or, A natural history, in Ten Centuries (����). Bacon and Descartes emphasize e�cient causality—that is, the idea of cause and e�ect—in modern knowledge. Though each grabs onto e�cient causality for di�erent reasons—or, to put it better, in the e�ort to address di�erent issues—both do so in the preambles to knowledge programs devised to break through the mold of medieval scholasticism held together by authority, syllogism, and an image of the world governed by Aristotle’s �nal and formal causes. Like his contemporaries, Bacon postulated that scienti�c knowledge should deal with what was known as “secondary causes,” through which the divine author performs his work in\/as nature. In the New Organon (����), Bacon, advancing an ambitious knowledge program  Someone else may if he wishes imagine the “form” of �re, the “quality” of heat, and the “action” of burning to be very di�erent things in the wood. For my own part, I am afraid of going astray if I suppose there to be in the wood anything more than what I see must necessarily be there, so I am satis�ed to con�ne myself to conceiving the motion of its parts. For you can posit “�re” and “heat” in the wood and make it burn as much as you please: but if you do not suppose in addition that some of its parts move or are detached from their neighbors then I cannot imagine that it would undergo any alteration or change.��  In sum, the emergence of modern science can be described as a shift from a concern with forms of nature, which prevailed in scholastic thought, to an inquiry into the e�cient causes of changes in the things of nature. For Descartes, as for Galileo and later for Newton, change (as motion in space and alteration) results from the operation of e�cient causes, the e�ects of which can be mapped mathematically.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  Resting on the two onto-epistemological components of e�ectivity and necessity, the “Subject without properties” (i.e., the Cartesian cogito) began a trajectory that would extend beyond the con�nes of knowledge to become the ruler of modern economic, juridical, ethical, and aesthetic scenes. Detail of the installation Otobong Nkanga, In Pursuit of Bling, ����. Courtesy Lumen Travo Gallery. The Ethical Scene of Value  of knowledge as that which in things—now objects—is available to the senses (movements and alterations). Furthermore, repeating Descartes’s assertion that the mind can only know with certainty that which is akin to it—that is, the abstract or the formal—Kant consolidates modern thought when he elevates the formal (as the pure or transcendental) to that moment that is before and beyond what is accessible to the senses. Only there, as Descartes had stated about a century before, is the mind comfortable dealing with the sort of objects—numbers and geometrical forms—which it can handle without reference to space-time. For only objects exhibiting such attributes can allow for the kinds of statements Kant considers proper to knowledge, that is, statements that add to what is known about something without drawing from experience. My objective in rehearsing this argument in this context is simply to highlight how, while formalization remains central to modern thought, e�ectivity constitutes the main descriptor of the world, as knowledge becomes interested in what happens (events, movements, and alteration).\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  More importantly, e�ectivity refers both to the senses’ access to the things of the world (being a�ected or moved by them) and to the mind’s capacity to resolve the manifold into the basic tools (categories) that the understanding has available for the “higher” moments of cognition—that is, abstraction and re�ection—as well as for the task of knowledge—that is, determination. Among other things, in Kant’s account of knowledge Descartes’s formal thing (the cogito) not only knows itself (its existence and essence) without the aid of its body, but also envelops Bacon’s material and e�cient causes, and takes the lead in the task of classifying and measuring nature. For instance, in his Lectures on Logic we �nd Kant employing the categories of the understanding in a description of Bacon’s method for producing his tables; in this description, Kant subsumes Bacon’s method into his own rendering of Descartes’s “formal I” as a transcendental (a priori, pure, or formal) condition for knowledge.�� Of course, the reference to Bacon’s program is more evident in what is called Kant’s “pre-critical” work. However, determination—that is, the attribution of one, and just one, predicate to a subject—remains central in his rendering of knowledge as a matter of judgement (that is, of decision), as well as in the very de�nition of the critical task, which privileges the exposure of grounds. In any event, as noted before, determination is crucial to Kant’s notion of synthetic judgements a priori, as it is the term he uses for what Descartes called the “nexus” of consequences that the rational mind follows when attempting to establish something with certainty.�� There is no question that determination is a task of the mind.�� In sum, determinacy as deployed in Kant’s knowledge (scienti�c) program remains the core of modern thought: it is presupposed in accounts of the juridical and ethical �eld of statements (such as the human-rights framework) which (a) presume a universal that operates as an a priori (formal) determining force (e�ectivity), and which (b) produce objects for which “Truth” refers to how they relate to something else—relationships mediated by abstract determinants (laws and rules) that can only be captured by the rational things’ (including the human mind\/soul) “principles of disposition.” With the consolidation of the Kantian knowledge program starting in the nineteenth century, knowing and all other activities of the mind are reduced to determinacy: namely, the assignation of value that refers to a universal (scale or grid), while the object of knowledge becomes a unity of formal qualities (properties, variables, etc. ), that is, an e�ect of judgements that produce it through measurement (degree) and classi�cation (position). Precisely this notion of e�ectivity lies at the core of the modern ethical program and accounts for how di�erence plays into it. For there too the assignation of value results not from direct comparison—the juxtaposition of two or more things—but from the operation of a universal (formal or transcendental)  shares a key quality with universal reason (or with Hegel’s “Spirit”), namely, self-determination.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  In this way, this earlier moment of racial knowledge yielded indexes of human di�erence—i.e., the naming of racial collectives such as the Negro, the Caucasian, the Oriental, and the Australian—that transformed economic di�erences resulting from conquest, colonization, settlement, and enslavement into presentations of (Hegel’s self-actualizing) universal reason, identifying spatial and bodily con�guration that, in their turn, produced the mental (intellectual and moral) forms that caused the di�erences in social con�gurations found in the European continent and its colonies.�� My point here is that the very arsenal designed to determine and to ascertain the truth of human di�erence already assumed Europeanness\/whiteness as the universal measure, that is, as the bodily, mental, and societal actualization of universality. This has several consequences, the most relevant (to my argument here) being the occlusion of the latter as a term of comparison. More explicitly, economic di�erences resulting from hundreds of years of expropriating land and labor were attributed to racial and cultural di�erence. In racial knowledge, they become the e�ects of particular bodily arrangements, which are established as the causes for particular mental (moral and intellectual) traits, which are themselves expressed in the social con�gurations found across the globe. Put di�erently, both the anthropological and sociological versions of racial knowledge transform the consequences of hundreds years of colonial expropriation into the e�ects of e�cient causes (the laws of nature) as they operate through human forms (bodies and societies). In sum, as a category of racial di�erence, blackness occludes the total violence necessary for this expropriation, a violence that was authorized by modern juridical forms—namely, colonial domination (conquest, displacement, and settlement) and property (enslavement). Nevertheless, blackness—precisely because of how, as an object of knowledge, it occludes these juridical modalities—has the capacity to unsettle the ethical program governed by determinacy, through exposing the violence that the latter re�gures. A United Nations image used to illustrate an article on migrant deaths in ���� on the website World Maritime News.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  Let us �rst see how the �guring of opposition as contradiction would work in relation to black life. Life is the form; the positive position vis-à-vis life is �gured as “�,” and the negative position is �gured as “-�”:  i. positive life = � ii. negative life = -�  If blackness occupies the place of negative life—that is, life that has negative value, that does not matter—then  iii. blackness = -�  Let me now �gure the relationship between life (�) and blackness (-�) using basic mathematical procedures: addition, subtraction, multiplication, and division. Addition in this case becomes subtraction because of blackness’s negative value:  a) � (life) + -� (blackness) = �  When simply combined with life, blackness brings about nulli�cation (�); when added to the positive form of life, blackness obliterates it. As discussed previously, value, because it is both an e�ect of determinacy (Kant’s account of knowledge) and is equated with determinacy (Kantian and Hegelian ethical scenes), it is (a) determinate, resulting in relations marked by e�ectivity (e�cient causation), that is, relations marked by power di�erences insofar as one element e�ectively acts upon another; and it is (b) determinant insofar as it is the e�ective element—that is, it is the form which is applied to matter (content). To express the relation between blackness (�) and life (�) in terms of e�ectivity, I use multiplication (×) and division (÷):  b) � (life) × -� (blackness) = -� c) � (life) ÷ -� (blackness) = -�  When blackness multiplies or divides life, it remains in its negative expression, as blackness (-�)—that is, as lack, as a symbol of an absence (of life). Taking this a step further, it might be possible to move away from dialectics and its deployment of e�ectivity, which cannot but reproduce violence, by dividing life by blackness:  f) � (life) ÷ � (blackness) = ∞ − ∞ or ∞ \/ ∞  Instead of the sublation (d) or obliteration (e) of the form, this procedure has no result because it is impossible to divide something by zero.\n"}
{"prompt":"life ÷  blackness = ∞ − ∞ or ∞ : On Matter Beyond the Equation of Value ->","completion":"  I have chosen ∞ − ∞ (in�nity minus in�nity) or ∞ \/ ∞ (in�nity divided by in�nity) to picture the result because it is undeterminable, it has no form: it is ∞ minus itself or ∞ divided by itself. It is neither life nor nonlife; it is content without form, or materia prima—that which has no value because it exists (as ∞) without form. In equating blackness with ∞ and capturing the rare (“of which something consists”) and the obsolete (“substance without form”) meanings of matter, I claim a radical praxis of refusal to contain blackness in the dialectical form. Though Frantz Fanon’s refusal of dialectics is the most celebrated, I �nd this refusal also in Cedric Robinson’s tracing of the black radical tradition; in Hortense Spillers’s �guring of the �esh as zero degree of signi�cation; in Saidiya Hartman’s refusal to rehearse racial violence as the moment of black subjecti�cation; and in Fred Moten’s descriptions of blackness in the scene of violence which refuse a simple reconciliation with the categories and premises of modern thought.�� When blackness’s oppositional power refers to matter—or, in Fanon’s words, in the “night of the absolute”—it is possible to avoid the principle of contradiction and the accounts of self-determination it sustains; it is possible to avoid, that is, a return to Hegel (or Marx) via the shortcut of racial eschatology. What I hope this move against determinacy—the very notion presupposed in the question that Black Lives Matter sets out to challenge—makes possible is an appreciation of the urgency of bringing about its dissolution. For the work of blackness as a category of di�erence �ts the Hegelian movement but has no emancipatory power because it functions as a signi�er of violence which, when deployed successfully, justi�es the otherwise unacceptable, such as the deaths of black persons due to state violence (in the US and in Europe) and capitalist expropriation (in Africa). That is, the category of blackness serves the ordered universe of determinacy and the violence and violations it authorizes. A guide to thinking, a method for study and unbounded sociality��—blackness as matter signals ∞, another world: namely, that which exists without time and out of space, in the plenum.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Death of the Essays on Ex  Claire C  Death of the PostHuman  Critical Climate Change Series Editors: Tom Cohen and Claire Colebrook The era of climate change involves the mutation of systems beyond 20th century anthropomorphic models and has stood, until recently, outside representation or address.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Understood in a broad and critical sense, climate change concerns material agencies that impact on biomass and energy, erased borders and microbial invention, geological and nanographic time, and extinction events. The possibility of extinction has always been a latent figure in textual production and archives; but the current sense of depletion, decay, mutation and exhaustion calls for new modes of address, new styles of publishing and authoring, and new formats and speeds of distribution. As the pressures and realignments of this re-arrangement occur, so must the critical languages and conceptual templates, political premises and definitions of ‘life.’ There is a particular need to publish in timely fashion experimental monographs that redefine the boundaries of disciplinary fields, rhetorical invasions, the interface of conceptual and scientific languages, and geomorphic and geopolitical interventions. Critical Climate Change is oriented, in this general manner, toward the epistemopolitical mutations that correspond to the temporalities of terrestrial mutation. Death of the PostHuman Essays on Extinction, Vol. 1 Claire Colebrook  OPEN HUMANITIES PRESS  with Michigan Publishing – University of Michigan Library, Ann Arbor 2014  First edition published by Open Humanities Press 2014 Freely available online at http:\/\/dx.doi.org\/10.3998\/ohp.12329362.0001.001 Copyright © 2014 Claire Colebrook This is an open access book, licensed under Creative Commons By Attribution Share Alike license. Under this license, authors allow anyone to download, reuse, reprint, modify, distribute, and\/or copy their work so long as the authors and source are cited and resulting derivative works are licensed under the same or similar license. No permission is required from the authors or the publisher.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Statutory fair use and other rights are in no way affected by the above. Read more about the license at creativecommons.org\/licenses\/by-sa\/3.0 Cover Art, figures, and other media included with this book may be under different copyright restrictions. Please see the Permissions section at the back of this book for more information. ISBN-13 978-1-60785-299-5  Open Humanities Press is an international, scholar-led open access publishing collective whose mission is to make leading works of contemporary critical thought freely available worldwide. Books published under the Open Humanities Press imprint at Michigan Publishing are produced through a unique partnership between OHP’s editorial board and the University of Michigan Library, which provides a library-based managing and production support infrastructure to facilitate scholars to publish leading research in book form. OPEN HUMANITIES PRESS  www.publishing.umich.edu  www.openhumanitiespress.org  Contents Acknowledgements  7  Introduction  9  1. Extinct Theory  29  2. The Sustainability of Concepts: Knowledge and Human Interests  46  3.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A Globe of One’s Own: In Praise of the Flat Earth  59  4. Earth Felt the Wound: The Affective Divide  73  5. Destroying Cosmopolitanism for the Sake of the Cosmos  96  6. Time And Autopoiesis: The Organism has No Future  116  7. Face Race  140  8. Posthuman Humanities  158  9. Why Saying ‘No’ to Life is Unacceptable  185  10. The Joys of Atavism  208  Works Cited  230  Permissions  245  Acknowledgements I am grateful for the patience, dedication and support of Open Humanities Press, and Sigi Jöttkandt in particular.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For ongoing intellectual stimulus and friendship I thank Tom Cohen, Jami Weinstein and J. Hillis Miller. Introduction  Framing the End of the Species: Images Without Bodies Society invents a spurious convoluted logic tae absorb and change people whae’s behaviour is outside its mainstream. Suppose that ah ken all the pros and cons, know that ah’m gaunnae have a short life, am ay sound mind etcetera, etcetera, but still want tae use smack? They won’t let yae do it, because it’s seen as a sign ay thir ain failure. The fact that ye jist simply choose to reject whit thae huv to offer. Choose us. Choose life. Choose mortgage payments; choose washing machines; choose cars’ choose sitting on a couch watching mind-numbing and spirit-crushing game shows, stuffin fucking junk food intae yir mooth.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Choose rotting away, pishing and shiteing yersel in a home, a total fucking embarrassment tae the selfish, fucked-up brats ye’ve produced. Choose life. Well, ah chose no tae choose life. If the cunts cannae handle that, it’s thair fuckin problem. (Irvine Welch, Trainspotting, 187-88) There are three senses of extinction: the now widely discussed sixth great extinction event (which we have begun to imagine and witness, even if in anticipation); extinction by humans of other species (with the endangered species of the ‘red list’ evidencing our destructive power); and self-extinction, or the capacity for us to destroy what makes us human. All three senses of extinction require a nuanced conception of climate. Climate is at once an enclosing notion, imagined as the bounded milieu  a being that for all its seeming diversity is nevertheless bound into a unity of destructive power. (This is so much so that geologists are arriving at consensus regarding an ‘Anthropocene epoch’ where man’s effect on the planet will supposedly be discernible as a geological strata readable well after man ceases to be, even if there are no geologists who will be present to undertake this imagined future reading (Crutzen 2000).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Climate is not only, then, the surface or terrain upon which we find ourselves, but something that binds us to this time on the earth, with its own depletions and limits.) There is, of course, the standard meteorological notion of climate which increasingly attracts our already over-taxed attention; but this concept of climate is only possible because of a broader thought-event where humans begin to imagine a deep time in which the human species emerges and withers away, and a finite space in which ’we’ are now all joined in a tragedy of the commons. I would suggest that just as Darwinian evolution altered the very modes of scientific and imaginative thinking, such that new forms of narrative and knowledge were required to think of man as a species emerging within time (Beer 1983), so global climate change is similarly catastrophic for the human imaginary. It becomes possible to think of climate as the milieu that is necessary for our ongoing life, and as the fragile surface that holds us all together in one web of risked life, even if we cannot practically grasp or manage the dynamics of this totality (Gardiner 2006). The concept of climate is also split between knowledge and denial: on the one hand talk of climate draws all bodies (organic and otherwise) into a single complex, multiply determined and dynamic whole; on the other hand, any brief glance at climate change policy and politics evidences a near psychotic failure to acknowledge or perceive causal connections with dire consequences. In this respect we need to embark on a notion of climate change that includes the radical alteration of knowledge and affect that accompanies the very possibility of climate. It is only possible to think of climate change in the meteorological sense—with humans now bound to volatile ecologies that they are at once harming and ignoring—if some adjustment is made to the ways in which we think about the relations among time, space and species. A  we start to think about climate as a general condition that binds humans to an irreversible and destructive time means both that climate becomes an indispensable concept for thinking about the new modes of knowledge and feeling that mark the twenty-first century in terms of our growing sense of precarious attachment to a fragile planet, and that climate is an alibi.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We talk about climate, ecology, globalism and even environment (as that which environs) even though the experience of climate change reveals multiple and incongruent systems for which we do not have a point of view. We are at once thrown into a situation of urgent interconnectedness, aware that the smallest events contribute to global mutations, at the same time as we come up against a complex multiplicity of diverging forces and timelines that exceed any manageable point of view. In a recent fable that allegorized the human relation among memory, destruction and the future of life, Nick Bostrom suggests that the human species would remain complacent about its catastrophic history and future as long as it continues to forget that its situation is catastrophic. We have taken the catastrophe of human existence as natural and irredeemable: only a counter-narration in which we vanquish destruction will let us see just how death-inured we have become (Bostrom 2005). More recently, climate change scientists have started to play with new strategies for awakening public affect: perhaps the focus on hope needs to give way to mobilizations of fear, whereby we learn to ‘hug the monster,’ in order to shift from inertia and quiescence to action.1 How is it that the human species, seemingly so hungry for life and dominance, has conveniently forgotten its own self-extinguishing tendencies? We can only pose the question of human extinction—the fact that humans will become extinct, the fact that we cause other extinctions, and also that we are extinguishing what renders us human—if we locate the problem of climate change inaction in a broader terrain of ecological destruction. The very climates—cognitive, industrial, economic, affective, technological, epistemological and meteorological—that render our life possible are also self-destructive (both destructive of the self, and destructive of climate itself). There is a widespread lament regarding a trajectory of self-extinction  synthesizing power of grammar, syntax and critique we are now seduced by a culture of stimulus (Greenfield 2008).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We are not just losing one of our critical powers—our power to represent or synthesize what is not ourselves—we are losing our very selfhood. For ’we’ are—as human, as identities—just this evolved synthesizing power. Greenfield locates her diagnosis of identity within a broader argument regarding the brain and its self-forming capacities. A certain self-loss is required for stimulus and pleasure, but a certain neural extension and order is required for meaning and self. In her earlier work Greenfield had argued for a healthy or normal balance between the capacity for the joy of fleeting sensation (such as the first taste of morning coffee) and the ability to link sensations into some broader network of selfhood and significance (Greenfield 2002). If there were no capacity to enjoy the simple moment we would suffer from depression, or an extreme search for meaning that we may never be able to fulfill; drugs that treat depression enable a release from the grip of significance. But today—perhaps—it is the fleeting insignificance that is taking over twenty-first century neural architecture. The diagnostic dimension of Greenfield’s work lies in its lament regarding the new modes and temporalities of visual culture, where the transient ecstasies of video games overtake the sustained focus and pleasure of complex narrative and argument.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This lament of human self-loss achieved through the over-consumption of stimulus is not Greenfield’s alone. Her work keeps company with Carr’s The Shallows: What the Internet is Doing to Our Brain (2010), Jackson and McKibben’s Distraction (2008), Wolf ’s Proust and the Squid (2007), Winifred Gallagher’s Rapt (2008), N. Katherine Hayles’s (2007) theory of the transition from deep attention to hyper attention, and Bernard Stiegler’s (2010) lament regarding the short circuits of transindividuation (with humans having lost the orientation of care). Precisely at the moment of its own loss the human animal becomes aware of what makes it human—meaning, empathy, art, morality—but can only recognize those capacities that distinguish humanity at the moment that they are threatened with extinction. It is possible to argue, as Giorgio Agamben (1998) has done, that there has always been a sense of the human capacity for failing to be human. if humanity were a simply actuality, then there would never be the possibility of failing to realize either one’s reason, or to recognize rational humanity in others. This is why Agamben has isolated a last chance for redemption precisely at this point in our history when it becomes apparent that what we are is not something essential that will necessarily come into being: our humanity is not an actuality from which we can draw grounds for action. The fact that we forget our impotentiality—that we treat humans as factual beings with a normality that dictates action—has reached crisis point in modernity, especially as we increasingly suspend the thought of our fragility for the sake of ongoing efficiency. Both totalitarianism and democratic hedonism are, for Agamben, forms of deadening managerialism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Both act on the basis of man as an actuality. It is at this point of exhaustion, when we have become frozen spectators in a world in which images appear as ready-mades, that we can see both that there is no guarantee that we will be human and that it is human to forget oneself. For Agamben it is both the modern horrors of totalitarianism (where humans are reduced to so much manageable and disposable matter or animality) and modern democratic hedonism (where we become nothing more than the targeted consumers of dazzling spectacle) that demonstrates human impotentiality, our essential capacity not to actualize that which would distinguish as human. Most importantly, this highly human inhumanity seems to center strangely on the organ that organizes the human organism; for it is the same eye that reads and theorizes—that looks with wonder at the heavens—that is also seduced, spellbound, distracted and captivated by inanity. Immanuel Kant already drew on a tradition of philosophical wonder when he isolated man’s capacity to look into the heavens as both a source of delusion that would draw him away from grounded knowledge into enthusiasm, and as the necessary beginning of a power of thinking that would not be tied solely to sensation (Kant 1999, 269-70). The eye is geared to spectacle as much as speculation, with speculation itself being both productively expansive in its capacity to imagine virtual futures and restrictively deadening in its tendency to forget the very life from which it emerges. Indeed there is something essentially self-destructive about  before there is an eye that acts as a camera or window there must have been something like an orientation or distance, a relation without relation. I would suggest that we ought to think, today in an era of climate change, about moralizing laments regarding human reason’s self-loss alongside various posthuman theorizations that human reason is constituted by a certain self-forgetting.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The human animal or human eye is torn between spectacle (or captivation by the mere present) and speculation (ranging beyond the present at the cost of its own life). There are two directions this criticism of the embodied eye can take: one is to expand the sense of the body, to imagine a receptive or perceptive power that is not a simple snapshot of the world but a full and expansive openness. Here we might identify a pseudo-Heideggerian criticism of Descartes that was taken up by cognitive science: Heidegger had already diagnosed Western metaphysics with Descartes as a fulcrum: Descartes is able to establish man as the ’subject’ (or as that which remains present) because Western thought has always proceeded by forgetting the temporality through which all being comes into presence (Heidegger 1968). By the time Descartes establishes the subject as that which precedes and provides a foundation, ’humanism’ has definitively forgotten that there is no such thing as man as a simply existing thing with an essence. For Heidegger what is required is not a retrieval of some pre-Cartesian connectedness to the world, with man and world being co-present; rather, before there is the dyad of man and world there is something like disclosure or revealing. Contemporary cognitive science and certain philosophies of the human have drawn upon this anti-Cartesianism to insist that man is not a camera, not a computer, and the eye is not a window (Wrathall and Malpas 2000; Thompson 2007; Wheeler 2005). Where such contemporary uses of Heidegger differ from Heidegger is in their diagnosis of Cartesianism as an accidental lapse rather than as evidence of humanity’s self-forgetting ’essence.’ These pseudo-Heideggerian diagnoses suggest that Cartesianism can be overcome by returning man to the richer expansive life from which he has become detached. The subtitle of Andy Clark’s book says it all: ‘putting, brain, body, and world together again’ (Clark 1997).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Heidegger, though, there is a necessary forget-  relies upon a hiddenness or non-revealing that we must leave behind in living the world as our own. We begin in media res, always already thrown into a world that appears as so many natural and separate things. Our tendency to forget, and to live life inauthentically—not recognizing Being as the site for all clearing, as though the world were just this way naturally— is not something one can simply place behind oneself as an unfortunate philosophical error. For Heidegger in-authenticity or humanism (where we simply take ourselves to be a privileged thing among things) is not an external and unfortunate event but has to do with the very mode of being’s appearance: we see being appear, but do not attend to its coming into being. One mode of phenomenology after Heidegger has, however, taken the form of a correction or adjustment: we should overcome the deep problems of how we know or arrive at having a world and accept that the world just is that which is always already given and meaningful for living beings. Phenomenology should be naturalized and tied to a process of embodied knowledge. We are not minds who represent a world, but organisms from which the capacity and figure of knowing mind emerged. But there’s another path, another way of dealing with man’s tendency to reify himself.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This other departure from a restricted subjectivism proceeds not by broadening the self to include emotions, dynamism and the non-cognitive, but by tearing the eye from the body. Rather than restore the human to some unified and expansive vision it might be possible to think of the eye as a machine. This machine would not be a computer, for a genuine machine does not have a central organizing program but is put to work through connections; one could consider synthesizers as computers receiving inputs and turning out data, or as machines in their creation and recreation of connections. For Deleuze and Guattari, the reference to synthesizers is not another metaphor for thinking, where we substitute one machine for another. Thought is a synthesizer: just as musical synthesizers take the sounds of the world and repeat, create and mutate various differences, so thought can maximize rather than diminish the complexity of sensations: A synthesizer places all of the parameters in continuous  is only at this point that one reaches the abstract machine, or the diagram of the assemblage. The synthesizer has replaced judgment, and matter has replaced the figure or formed substance. It is no longer even appropriate to group biological, physico-chemical and energetic intensities on the one hand, and mathematical, aesthetic, linguistic, informational, semiotic intensities, etc., on the other. The multiplicity of systems of intensities conjugates or forms a rhizome throughout the entire assemblage the moment the assemblage is swept up by these vectors or tensors of flight (Deleuze and Guattari 2004, 121) Before exploring the ‘multiplicity of systems of intensities’ in detail, we can go back over the relation between the eye and human self-extinction, between the eye that views the world in order to enable survival, and the eye that then becomes frozen or seduced by its own imaging power—to the point where the eye takes in a frozen image of its self.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Bergson has argued for an economy of the eye and creative difference: in order to release itself from merely surviving in the world, the human eye organizes the world into conceptualized units, mastering the world by reducing difference. This intellectual process allows for increasing technologies and the furtherance of systems of order: the intellect is at home with technology and matter, or that which remains the same through time and can be mastered though repetition. What is abandoned is intensity—the infinitesimally small differences and fluxes that the eye edits out. For Bergson the problem with this difference-reducing mode of the intellect is when mind turns back upon itself, and fixes upon a static image: thought is no longer intuited (as it should be) as a dynamic creative force, but appears as a brain, representing self, thinking substance or ‘man’ (Bergson 1913, 196). This argument for the self as not being a substance but, rather, the condition for the organized perception of substance, has a long philosophical and moral history. If Aristotle argued that what distinguished us as humans was not merely perception of the world, nor consump-  be perceived, this moral distinction becomes formal in modernity. That is, Plato and Aristotle concede that man is a biological being but with a capacity for reason, a capacity that distinguishes humans from other beings. But the modern theory of the subject, with Descartes positing a different substance—or res cogitans—makes a difference of kind and modality with regard to humans and their relation to images.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘Man’ is the being to whom the world is given for representation; what man himself is can never be known in itself, but only after the event of perception of the world. For Foucault, it was this shift from a world that possessed its own order and hierarchies to some distinction between ordered world and man as representing being that marked a historical a priori: what shifted was not an event within time but the modality of time itself. In modernity historical time is that through which ‘man’ both recognizes that he emerges from material conditions, at the same time as the very logic of life that requires him to labor, speak and form social wholes can only be known after the event (Foucault 1970). If pre-moderns sought to elevate humans among other animals, modernity increasingly rejects human superiority and refuses to see man as rational animal; for man is pure reason. Kant does not argue that we have to be more than merely biological or animal beings, he insists that we are not beings at all. Rather, there are only beings because there is something like an organizing or synthesizing power. There is a world because there is a subject to whom a world is given. It makes no sense to strive to perceive or know the self, to try and capture the self as something that might be viewed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In the beginning is a potentiality for viewing from which we constitute a viewed world. We then imagine—ex post facto—that there must be selves who would be there to be viewed. Whereas Kant argued that there must be something like the subject who existed as this condition for all intuition (even if this subject cannot be known), Bergson (1913) argued that there was no subject who intuited images, just images or perceptions from which we posit some thing—the brain—that provides the illusory image that would cause all images. But if pre-modern philosophy from at least Plato onwards argues that we ought not think of ourselves only as appetites, for we are responsible  are perceptions, from which something like a self is constituted. We cannot explain the self ’s relation to images because of the interests and appetites that are its natural base. Desires and appetites are possible only because there is imaging: in the beginning is the relation. We can think of Freud here for whom pleasures are possible because of a prior genesis of a relation between desire and desired; the libido is a force that forms a relatively stable or ‘cathected’ pool of ongoing equilibrium, relating to the outside world in terms of its own tendency towards quiescence (Freud 2011). The desiring self is possible only because of a prior distribution that emerges from perception; a relation between self and other is formed through perception and does not precede perception Something quite distinct structures modern claims for the relation between mind and image.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is not only the case that the self emerges from organizing perception, but also that perception can destroy the self. In Beyond the Pleasure Principle Freud observes his grandson throwing a cotton reel in and out of his cradle, while intoning ‘Fort\/Da’ (away\/here) and it is from this observation that Freud argues that in addition to the self ’s formation of a stable border between itself and the world, there is also a tendency to want to destroy or annihilate that distance. If pleasure is managing the relation between perceiver and the manageable influx of stimulus, then beyond pleasure there lies a tendency towards annihilation of distance, a dissolution of the bounded and perceiving organism. What if the brain that is supposedly properly (in its human mode) oriented towards synthesis were at risk of falling back, of devolution? For some time it has been noted that there is an anxiety regarding mere images: the society of the spectacle (Debord 1973), a world of simulation (Baudrillard 1994), a world of passive consumption (Adorno 2001) or mere exhibition without aura (Benjamin 2008), a world of hyper attention rather than deep attention (Hayles 2007), at once seems to destroy the brain’s evolved powers, and yet also give the lie to a certain destructive illusion regarding the brain as image. If we have lamented for so long—since Kant at least—that man tends to forget that he is a subject and tends to take himself to be just substance, then why are we so alarmed today by the brain’s tendency to destroy any image or sense  anti-self-consciousness or pure immediacy (Hartman 1970). Have we arrived, perhaps unwillingly, at Emerson’s transformation of the self into a transparent eyeball (Emerson 1982, 39)? And yet this achievement of what was once a Romantic and existential imperative for consciousness to be nothing other than its perceptual relation to the world, a pure process without reifying ground, is being met with mourning and alarm.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  First, consider all the ways in which ’we’ are now reacting with horror to our own capacity not to be ourselves. This ranges from neo-Kantian claims that without the commitment to some idea of who I am—without some ongoing identification of what I would do if I were to remain true to the idea I have of myself—then ’I’ am not a self at all (Korsgaard 2008, 86). There are also neurological claims regarding the importance of ongoing synthesis, ranging from Greenfield’s moral anxiety over a culture of mere stimulus, to Antonio Damasio’s claim that the self is not, as Descartes would have it, a thing that feels, but a receptive and creative structure of feeling from which it might then be possible to have a snapshot attitude to reality. If we lose sight of that feeling self, of the emotional brain, or of the naturally affective, connected and world-oriented self then we risk mistaking mind for mere machine or computer (Damasio 2000). When today—with horror—we look at young minds, we ask how they have become nothing more than cameras or computational devices. The young brains of today are not affected or world-oriented; they manipulate Facebook numbers with ruthless algorithmic force, and ingest images without digestion or rumination. We watch, with horror, as the human brain reverts to being not so much a reader of Proust as akin to a squid, or mere life (Wolf 2007). This tendency to be nothing more than a screen for images is observed as at once the brain’s horrific tendency towards self-extinction (an internal and ever-present threat) and as accidental or extrinsic (something that has assaulted us from without, by way of technology and modernity).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The diagnoses of the brain’s and humanity’s capacity to destroy itself are persistent and manifold, ranging from a supposed neural devolution caused by spectacle-stimulus culture to various anxieties about over-  yet, at the same time, this release of the intuition of images from the organizing self of Cartesian subjectivism is hailed as redemption from the rigidity of man: no longer do we enslave ourselves to the notion of the autonomous, disembodied, affectless and world-divorced subject. One of the many and varied modes of posthumanism hails an end to human exceptionalism and cognition-oriented models, and instead begins from one already integrated, dynamic and connected world. There is no ‘really hard problem’ about the relation between mind and world, for the mind is an effect of relations, not something that has to act in order to represent a world to which it must subsequently relate (Flanagan 2007). It is not the case that we begin life as observing, representing beings who then become through receptivity. Rather, in the beginning is a dynamic and world-oriented receptivity from which organized cognition, and the sense of the self as subject or man emerges. It is from a primary openness to the world, a primarily sensed world, that there emerges the sense of one who sees. This ambivalent observation of the self-extinguishing tendency of the brain’s capacity for imaging does not pertain only to philosophy, theory or recent theses of the brain. There are also popular accounts of our selfattrition, with our over-consumption of everything from the internet and Facebook to empty fats and calories, indicating that the very mechanisms that led to out expansion are the same that will lead to our demise.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Beyond all the laments and moral proclamations regarding our falling away from the activity of human reason, and beyond all the posthuman celebrations that there is no such thing as ‘man’ and that we are really always already at one with one web of life, we might ask how it is possible for humans to have this panicked (or joyous) apprehension of self-loss. If humans really are at one with the world of which they are nothing more than living and creative perceivers, why have we felt for so long that we are disengaged and rational minds? How did ‘Descartes’s error’ take hold? Or, if mind and reason are our proper self-creating potentialities, how is it that the spectacle of the world has lured us into destroying ourselves? Why are our own creations, technologies and desires the very mechanisms that preclude us from being most properly ourselves? It is as though our  fragility to be nothing more than itself, a mere screen rather than a properly self-organizing whole. The thousands of years of evolved complexity can fall away through overconsumption. Just as the very desire for fats and sugars that propelled the body to hunt and develop technologies for metabolic stability and survival will drive the modern body into obesity, hypertension and an early grave, so the darting eye that stimulated the brain into becoming a reading and interpreting animal, may also be at the forefront of the human species’ cognitive atrophy.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  And does this not say something profound about climate: that the human species’ damaging of its own milieu is not an accident that we might otherwise have avoided, precisely because climate—as our milieu—is something that our very dependence upon will preclude us from ever really seeing? Both of these questions—of self-destruction and milieu-destruction— are economic problems. (Both Freud and Bergson argued that the self was an effect of investment, by postponing the discharge of energy and allowing a pool of force that would be relatively stable through time.) The human animal delayed consumption of immediate resources, developed hunting and farming techniques in order to store energy, and so then freed energy and resources for further technical-intellectual-moral development (Ayala 2010). The viewing eye also delayed immediate response, developing concepts and perceptive technologies that enabled greater representational sophistication. V.S. Ramachandran speculates that the self and the notion of mind emerged in a survival tendency to anticipate the actions of others (Ramachandran 2003). The viewing eye becomes a reading and organizing apparatus, allowing ’man’ to become a subject.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  These same replicating technologies, and life-propelling investments— allowing us to fashion cinematic, computational, virtual reality and televisual technologies—would eventually sacrifice the reading brain to the merely stimulated eye. Apart from the general interest of observing a widespread anxiety regarding the brain’s own capacity to destroy itself through the very perceptive power that generated its supposedly proper potentiality in the first place, it is possible to orient this discussion towards the perception of futurity. that we are really, properly, nothing more than a dynamic power to perceive—that there is still (for all the talk of loss) a reliance on a normative notion of the human, whereas what is required today is an inhuman perception? For all the talk of climate change we assume that the climate is what environs us, and that change—or the danger of change—needs to be calculated according to the degree to which it enables or precludes ongoing existence of humans (Mann 2009). If biodiversity is a prima facie good then surely any ecosystem—even one that emerged after human extinction—would answer the requirement for ongoing life? And if biodiversity is not a prima facie good, and is only good insofar as it offers ecosystem services for humans, then the very reasons why we might finally act in order to maintain biodiversity—in order to continue to live—seem to be hampered by our drive for life. The very eye that has opened up a world to the human species, has also allowed the human species to fold the world around its own, increasingly myopic, point of view. Today, we might start to question the appropriate point of view from which we might observe and evaluate the human viewing eye: from our own greater will to survive, or would it not be better to start to look at the world and ourselves without assuming our unquestioned right to life?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Our very narration of the brain and its emergence as the properly synthesizing milieu from which all other imaging milieus need to be considered, shelters us from the thought of the inhuman images that confront us at the limits of the embodied eye. We can recall, here, Deleuze’s criticism of Bergson, which is technical and counter-vital. Bergson, like so many other early modernists mourned the living and dynamic eye that had been sacrificed to technological expediency. For Bergson the intellect cuts up the world in order to achieve managerial efficiency and then subjects itself to that same technical calculus. The mind starts to operate with an image of itself as some type of viewing machine. Redemption, for Bergson, lies in retracing the path, regaining a vitality that would no longer be that of the bounded organism. Intuition would pass beyond its enclosed self-interests to arrive at the perception of life’s duration or élan vital. For Deleuze, by contrast, the problem is that the eye remains too close to the lived.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (So, today, when we demand ‘reality’ of television and  thing as life and reality to which vision ought to be subordinate.) Rather than asking the eye to become organic once more, and to re-find its place in life, Deleuze asks for an inhuman perception: can we imagine the world without us, not as our environment or climate? Drawing on Bergsonism, rather than Bergson’s concrete example of the fallen nature of cinematic perception, Deleuze calls on philosophy to ‘open us up to the inhuman and the superhuman durations (durations which are inferior or superior to our own), to go beyond the human condition’ (Deleuze 1988, 28). It is the cutting power of the eye that needs to be thought: the eye would be approached as a form of synthesizer, but as an analog rather than digital synthesizer. That is: the eye does not need to free itself from imposed distinctions to return to the flow of life, but should pursue ever finer cuts and distinctions, beyond its organic thresholds. How might we imagine a world without organic perception, without the centerd points of view of sensing and world-oriented beings? Is there such a thing as perception without a world? (Think, here, of Heidegger’s remark that a stone ‘has’ no world, which is a way of saying that a stone has no climate, for a stone has no concern for ‘its’ world or environment.)\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This would not be a world without reading, as though abandoning the eye of grammar would return us to an inhuman lifelessness. Instead, the reading would take a radically different form. After humans have ceased to be present on the planet, their history will remain readable in a quasi-human sense: the earth’s strata will be inscribed with scars of the human capacity to create radical and volatile climactic changes. But one might consider a form of reading beyond this quasi-human and discerning mode: if, following Heidegger, the stone has no world, how do we account for the fossil records or archives borne by the stone? What might be thought is the extinction of the climactic eye: can we imagine a mode of reading the world, and its anthropogenic scars, that frees itself from folding the earth’s surface around human survival? How might we read or perceive other timelines, other points of view and other rhythms? The fossil record opens a world for us, insofar as it allows us to read back from the brain’s present to a time before reading; strata will continue beyond human reading, but if inscription continues is it too much of a stretch  that a certain film offers ‘a reading’ of a certain event: we do not simply mean that the author is reading an event, for that may not have happened. The earth, after humans, will offer ‘a reading’ of a species’ history, just as we might say that Robinson Crusoe offers ‘a reading’ of race, empire and capitalism, even if neither Defoe nor his readers actually actualized the sense of the reading.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Why have we assumed that reading and readability should take syntactical forms? Here I want to refer to what geologists have posed as the new anthropocene era, where it is imagined—after humans—that our scar on the earth would be readable for something like a future geologist. Not only do we imagine what would be readable for a world without readers, we also have to deploy and imagine (from within geology) a different mode of stratigraphic imaging. Stratigraphy, at present, is a mode of reading past layers, but the positing of the anthropocene era relies on looking at our own world and imagining it as it will be when it has become the past. In imagining this world after humans we are reading what is not yet written or inscribed. We can see, now, from changes in the earth’s composition that there will be a discernible strata that—in a manner akin to our dating of the earth’s already layered geological epochs—will be readable. This strata or text of the earth does not yet exist; we abstract from the human eye and its reading of the inhuman past, to imagine what would be readable, after humans, in a mode analogous to the human eye. One can only open up to this post-Anthropocene point of view if we start to view this world beyond the bounds of climate, and see climate as one expression—among many—of a broader time and broader (inhuman) life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Perhaps, then, the moral outrage about the death of active and synthesizing vision, or the premature hailing of the world as already posthuman, needs to be tempered by the thought of the seeing brain that looks beyond itself. What we should not do is try to retrieve or repair a proper human vision; nor should we think, too easily, that we have abandoned human myopia once and for all. This allows for a new thought of the brain’s self-extinguishing tendency. If there is an anxiety regarding the eye-brain’s seduction by images to the  questioning the worth of the imaging brain? There is a strange torsion operating between the shrill cries lamenting the brain’s captivation by spectacle, and the supposedly opposing counter-image of the good flourishing mind-brain. In response we might ask seriously what all these diagnoses of the reading brain and its atrophy amount to for a thought of art and climate change. First, if the reading eye did have a proper mode—if the human brain had as its proper potentiality the mode of syntactical, synthesizing and world-ordering vision—how would we evaluate the last centuries of aesthetic judgment, which have relied on destroying the brain’s capacity for comprehensive consumption? One doesn’t have to be a fan of Duchamp and the avant-garde to note that there is something interesting, at the very least, in visual productions that short-circuit recognition.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Indeed, one might say that climate change should not require us to return to modes of reading, comprehension and narrative communication but should awake us from our human-all-too-human narrative slumbers. In Danny Boyle’s 127 Hours (2010), in the film’s revelatory final quarter, the central character’s voice provides a voiceover declaring that all moments in his life have been leading up to this point. The screen is split into three panels, with one of the panels depicting the depleting battery indicator on his camcorder. At this stage, and for all the character knows, his self-made film and testimony will never be viewed, and yet—even so—he proclaims a moment of destined union between the end of his own life and the earth’s history: from the first comet that struck the earth to create life to this final point of self-narration, all this was destined to converge on this filmed present (or so he believes). This temporal point— one of the film’s peaks—is at once one of human heroism, confirmed by the final scene where the protagonist and his family are seated on a suburban sofa viewing the cinematic audience the way we have just viewed his triumph. And yet at the very moment that this central character’s destiny is related, the film’s visual field explodes into a geological vision—the camera eye being taken over by the dazzling sun, which in turn dissolves into layers of rock and water beyond human time and perception. This cinematic seduction is quite different in kind from our tendency to be  This geological eye operates alongside the lulling eye of the forming human power; it is not the simply destructive eye of the visual avant garde. It is not just the willful assertion of the desire for the human to assert its mastery by freeing itself from instrumental and comforting images.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is a positively geological vision, a seduction not by the light that warms and illuminates but a radiation that moves beyond organicism. This light appears through the cracks of our own survival mechanisms: in Danny Boyle’s cinema alone we can see it in Sunshine of 2007 (where the sun of light towards which the space mission travels is figured as that which must be viewed but which remains as not viewable), and in the sublime scene of the Sydney opera house as a frozen wasteland in 28 Weeks Later (2007). The very titles of these films—hours, weeks, days— are intensive lived periods in which something like the unlived and unlivable takes hold. Jacques Rancière has commented on a certain double nature of the image that defines art: commenting on Roland Barthes’s Camera Lucida, Rancière notes that Barthes (who had begun his career by aiming to strip images of their myth or lure and did so by reading what appeared to be enigmatically frozen as actually the outcome of human history and labor) reversed this in Camera Lucida by affirming a dazzling power of the image as such that occurs when photography becomes an art (Rancière 2009). For Rancière this is not noteworthy because of some interest in Barthes’s biography, but because it discloses art’s double relation to the image, a doubleness inherent not only in photography but also in the novel. For Rancière, the novel as art at once describes and images, and draws attention to (while also destroying) any simple notion that the image is secondary and effaces itself before that which it indexes. Rancière is not as indebted to the French avant-garde as Barthes, or Deleuze, for whom art is the release of affects and precepts beyond the lived, or Derrida, for whom literature is an absolute precariousness that has no referential outside other than that which it traces from itself. But there is a sense in Rancière’s notion of art as a release of image from anything other than its own dazzling materiality without reference or relation, of a surmounting of a certain anthropocentrism of the aesthetic image.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It as though a  To this extent all art leading up to the avant-garde would be art and image only to the degree to which it was anti-mimetic, or other than any form of reference, as though art somehow were god-like, freed from any necessity to be anything at all, liberated from all constituting relations. This, for Rancière, is the two-sided nature of the image. I would suggest that something like a third side of the image is prompted by the thought experiment of extinction. By referring to extinction as a thought experiment I want to move in two directions. If we think of the experimental passage to extinction as thought—if we imagine thinking as a variation that takes place from function but essentially risks all function—then thinking of life as mindful requires thinking of mind as intrinsically destructive. Thought occurs when relations between terms are destructive, when there is a not knowing or misprision. Life occurs not with ongoing self-sameness but with an experimental variation that could be construed as risk, except that risk implies betting, strategy or even the venturing of some being, whereas it is only after variation that one might refer ex post facto to a mutation that is interpreted as good for some being or some environmental fit. And this is also why environment (like climate in its narrow meteorological sense) is not such a helpful term, given the notion of surrounding or environing—as though beings varied to fit a world.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Extinction—as thought experiment—destroys such notions; there is just variation that is not variation of any being. So if extinction is thought experiment, it is because the process of extinction is a variation without a given end determined in advance; thinking possesses an annihilating power. A certain thought of delimited extinction, the extinction of humans, opens up a variability or intrusion of a different side of the image. This is a geological, post-anthropocene or disembodied image, where there is some experimental grasping at a world that would not be the world for a body, nor the world as body. This mode of impersonal imaging differs from an avant-garde immanence of aesthetic matters or sensations, for such notions tend towards a god-like self-sufficiency. The avant-garde sought to think of the liberation of the image from man, but in doing so it created a heightened subjectivism where ‘we’ might liberate ourselves  consciousness destroys itself to leave nothing but its own pure nonbeing; we can begin to imagine imaging for other inhuman worlds. That is to say: rather than thinking of the posthuman, where we destroy all our own self-fixities and become pure process, we can look positively to the inhuman and other imaging or reading processes. What happens if one thinks of the vision of no one, of the human world without humans that is still there to be seen?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What remains might still take the form of ‘a’ vision or referring eye—the scene of a human world as if viewed without any body. The positing of an anthropocene era (or the idea that the human species will have marked the planet to such a degree that we will be discernible as a geological strata) deploys the idea of human imaging—the way we have already read an inhuman past in the earth’s layers—but does this by imagining a world in which humans will be extinct. The anthropocene thought experiment also alters the modality of geological reading, not just to refer to the past as it is for us, but also to our present as it will be without us. We imagine a viewing or reading in the absence of viewers or readers, and we do this through images in the present that extinguish the dominance of the present. The figure of a frozen Sydney opera house, a London where Trafalgar Square is desolate, layers of rock distorted through a camera lens that is not the point of view of any body, an underwater Manhattan, or a sunlight so bright it would destroy the eye—all these experiments strive to image a world as image (as referential) but not referential for any body. These images cannot be sustained, and are unsustainable; they—like the thought of extinction itself—will always be for us, and are always co-opted by the narrative lures they fragment. They nevertheless indicate an era or epoch that has begun to sense, if not have a sense of, a world without bodies.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What we call a catastrophe will be, for it, a contingency. Microbes will survive, as well as insects, whatever we let loose. In other words, it is only because of the global ecological transformations we can provoke, which are potentially capable of putting in question the regimes of terrestrial existence we depend on, that we can invoke the Earth as having been put in play by our histories. From the viewpoint of the long history of the Earth itself, this will be one more ‘contingent event’ in a long series. (Stengers 2000: 144) To the shame of philosophy, it is not uncommonly alleged of such theory that whatever may be correct in it is in fact invalid in practice. We usually hear this said in an arrogant, disdainful tone, which comes of presuming to use experience to reform reason itself in the very attributes which do it most credit. Such illusory wisdom imagines it can see further and more clearly with its mole-like gaze fixed on experience than with the eyes which were bestowed on a being designed to stand upright to scan the heavens. (Kant 1991: 62-63) If we were serious about considering what theory after theory might mean then perhaps we should push this notion to its limit: not simply theory after the 1980s indulgence or heyday of high theory—those days  thoroughly assimilated and because what is left remains a toothless tiger, legitimating all sorts of positivisms and moralisms.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (Evidence for assimilation is everywhere: no monograph in literary studies appears without some cursory footnote to a theoretical concept; no undergraduate education proceeds without some basic overview of ‘feminism,’ ‘post-colonialism,’ and ‘post-structuralism’; and no graduate student would be advised to avoid theory altogether.) More often than not, being ‘after theory’ signals nothing more than that one is aware of some textual mediating condition: there is no sex in itself, race in itself, history in itself. This contemporary theoretical astuteness, consisting of acknowledging the provisional status of one’s position, then allows for local attention to minute particulars without any consideration of the problems, possibilities and impossibilities of reading as such. The new historicism that supposedly emerged after theory allows for a mode of positivism justified by an avoidance of grand narratives (Gallagher and Greenblatt 2001: 6). Other modes of theory—queer theory, race studies, gender studies, disability studies, digital media studies—seem to be theoretical not so much by a distinct mode of reading but because of a choice of a marginal object. If anything ‘theory’ as it is now practiced—with its emphasis on the lived, bodies, multitudes, emotions, affects, the political, the ethical turn—is indeed practiced; it avoids the problem of theory—what we can say there is, or the limits of existence—by grounding itself in what one ought to do. Recently, and in line with the ebb and flow of critical trends, there has been an anti-anti-theory reaction, ranging from a general contestation of historical and cultural locatedness (or, in Felski’s words, ‘context stinks’) to a profound and wholesale rejection of the Kantian Copernican turn, or the idea that we can only know and legitimately theorize the world as it is given (Felski 2011; Bryant, Srnicek and Harman 2011). Quentin Meillassoux argues that it is the Kantian turn, or refusal to know that which cannot be experienced by us, that closes philosophy off from the truth of contingency—and crucial to that thought of contingency would be the imperative to think of the world not as it is given to us, including geological statements about deep time and logico-philosophical claims about contingency (Meillassoux 2008).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Increasingly the general  jar with broader cultural imperatives. On the one hand, there is an efflorescence of cultural production devoted to imagining a world without humans, beyond human viewing (broadly evidenced in post-apocalyptic film and literature); and on the other, and often from within philosophy or ‘theory after theory,’ there is a retrieval of the world only as it appears and only insofar as it is a lived world for some being (what one might refer to as the ‘naturalist’ turn [Petitot et. al. 1999]). The Kantian conception of theory and its project of self-limitation, despite recent refusals of Kantian finitude, help us make sense of this twin tendency to leap beyond human limits and yet remain restricted to the lived. Although Kant does insist that we can only have scientific knowledge about that which can be experienced as given this does allow for a mode of scientific realism, for it also encompasses that there are also—beyond the given—the forces from which the given is given to us. What has occurred, since Kant, is an increasing rejection of an ‘in itself ’ beyond the given, and yet such a gap should perhaps be thought today—not in order to repair or close the distance that separates us from the world, but to heighten both our nonknowledge and the imperative to think (but not experience) that which cannot be known. Theory, if it is critical in the Kantian sense, would need to begin from Kant’s distinction between theoretical knowledge, concerning objects about which we can speak because they are given to us, and practice, which follows from the absence of knowledge about ourselves.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Lacking anything objective or experienced that might give us a moral law we are left without foundation. It is because we only know what is given—even if ‘the given’ can go beyond the human eye to include all the apparatuses through which humans image and project a world—that a strong scientific realism also creates a unique gap between theory and practice (Langton 1998). Theory is an acceptance of a distinction between a strong sense of the inhuman (that which exists beyond, beyond all givennness and imaging, and beyond all relations) and an unfounded imperative that we must therefore give ourselves a law. We act in the absence of knowledge of the world beyond us, and yet knowing that there is a beyond means that practice cannot be reduced to what we know or  made for us because we do not and cannot know any ultimate ground) to the burden of having to make a decision. Human feeling, or ‘the lived,’ does not exhaust what there is. Theory follows from being exposed to a world that is not ourselves; theoretical knowledge is directed to something that is only given through relations but is also not exhausted by the relations through which it is given. In many respects theory, far from being an academic enterprise that we can no longer afford to indulge, is the condition and challenge of the twenty-first century or age of extinction: ‘we’ are finally sensing both our finitude as a world-forming and world-destroying species, and sensing that whatever we must do or think cannot be confined or dictated by our finitude. Theory reminds us both of the givenness of the world, or that what we know is given to us in some specific way, at the same time as this knowledge and relation exceed us.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Theory is at once necessary and impossible, just as its ‘relation’ to practice is necessary and impossible. Theory, or distance from the real, is necessary: ‘we’ are faced with an existing world that, precisely because it exists, is not ourselves; without that ‘outside’ world there could be no inner subject, no ‘we,’ no agent of practice. But this existing world to which we are definitively bound is therefore impossible: the given world is given to us, never known absolutely. We are not paralyzed by this distance from the world, for it is the distance that provokes both knowledge and practice (Stengers 2011); but the distance nevertheless entails that practice cannot form the ground for our knowledge (‘do what works’) nor can knowledge ground practice (‘act according to your nature’). To avoid theory and pass directly to practice would require forgetting that the self of practice is only a self insofar as it is placed in a position of necessary not-knowing. Recent forms of Kantianism that conclude from this separation that there is an inevitable ideal of humanity and human normativity (Korsgaard 2009; Korsgaard and Cohen 1996) focus all too easily on the practical side of reasoning—whereby the absence of knowledge forces us to be self-governing—and forget too happily the theoretical problem. This self that gives the law to itself is necessarily exposed to a domain which it must theorize but can never grasp as such. To remain with the theoretical challenge, or accepting the distance from the world  provides us with a challenge both to think beyond the world as it is for us, and yet remain mindful that the imagining of the inhuman world always proceeds from a positive human failure.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  There would be two senses in which theory would fail. The first sense of failure is necessary and critical: one must at one and the same time be placed in relation to an existence that is never given as such, and it is this world of necessarily given but distanced existence within which we act. (In an era of encroaching extinction this failing theoretical condition becomes a forceful practical problem precisely because we are obliged, practically, to think not only about the unknowable but also the unimaginable. The world we inhabit is becoming increasingly impossible to know and imagine.) The second sense in which theory fails occurs with its seeming triumph; today, if theory has taken institutional hold it has done so by failing to be theoretical; in various modes of theory after theory, where we have returned to life, affect or ‘the lived,’ theory feels no qualms about the limits of imagination. Indeed, theory as imagination allows ‘us’ to affirm humanity, the lived, meaning, community, the future and life—precisely when the incoherence of these terms should block any easy praxis. Symptomatic of this failure of theory (via institutionalization) is theory’s complete success, and this can be gauged by considering what is now no longer possible: anti-theory. In the early days of theory to be opposed to theory was to be opposed to textualism; it was to insist that ‘everyone knows’ that for all intents and practical purposes texts mean what we want them to mean.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Theory, by contrast, detached texts from a ‘wanting to mean.’ Such a distinction is evident in the grand debates of the 1980s, including Derrida’s skirmish with John Searle, the latter insisting that context would ground utterances (Derrida 1988). But that Searlean attention to context and practice—the position that was once anti-theory—is today the hallmark of theory, both the theory that still remains of historicism and the newer waves of anti-textualism that affirm life, things, history, intent and bodies. In 1982 Stephen Knapp and Walter Benn Michaels published ‘Against Theory’ in Critical Inquiry and posed the following thought experiment. Imagine encountering the marks ‘a slumber did my spirit steal,’  leaves the rest of Wordsworth’s poem. This, the authors argue, at first seems to present intention-less meaning, but this is not so. Once we read we attribute intention; any of those supposedly detached, non-referential objects of theory—texts without context, readers or authors—are proven (Michaels and Knapp claim) to be impossible. If something can be read then it has meaning, and therefore intention. What such an insistence precludes is that something might be read, and not be actively or meaningfully inscribed: a geologist ‘reading’ the earth’s layers would not be reading in Knapp and Michaels’s sense, and it follows that it would be a mistake to ‘read’ texts in the way that one might read scars on the earth’s surface or fMRI images.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One would, supposedly, need to distinguish between reading—seeing the lines waves leave on the shore and discerning some pattern—and reading, where one posits someone who meant to leave marks in just this way in order to say something to someone. It seems such a distinction is easy, but is it? Imagine we find, some hundreds of years from now, remnants of a wall with spray-painted tagging left behind, and then next to the remnant tags would be some paint that fell onto the wall accidentally, and then next to that would be a city-funded community artist’s mural. Cities today are made up of such human-inhuman couplings, where graffiti mixes with staining, with randomly posted notices as well as scars from wreckage, damage and animal and technical marking. Knapp and Michaels would claim that our capacity to read marks such as a mural follows from author’s meaning: if there were not an author who had painted the work there would be nothing to be read. Other marks, like ‘tagging,’ one assumes, could also be read—as forms of signature. Random paint stains might indicate that someone or something had existed but—like the natural marks and wear on a wall— could not be read. And yet it is just this hybrid assemblage of marks, stains, signs, tears, human-animal-technical inscriptions that comprises any archive: how does one look back and decide to read what was left by a hand, and not read or avoid reading what occurred through inhuman and random processes?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Knapp and Michaels one can distinguish clearly between the rogue methods of theory, that willfully detaches texts from intent-meaning, and reading that relies on texts having a sense which is  Benn Michaels felt this point still had relevance in 2001 in his ‘The Shape of the Signifier,’ which was, again symptomatically, an appeal to the political. Reading and texts go together to yield intentions and contexts; there are not just signs as such, mere markers of ostensive identity, but historically sedimented and meaningful intentions. In a recent review in The London Review of Books Benn Michaels insists again that identity itself cannot bear significance; it makes no sense to say—for example— that race means something or anything, for one reads such markers only because of socio-economic and historical semantic horizons. One would not ‘read’ a body as being of a certain identity, unless that body were located in a broader network of human and meaningful sense. The very markers that allow us to read identity presuppose some understanding of a common humanity that is unfairly differentiated (Benn Michaels 2009). Whereas Knapp and Michaels could articulate this insistence on the necessarily contextual and political production of meaning as an argument ‘against’ theory in the 1980s, Benn Michaels’s position is now exemplary of what counts as theory. That is, theory is just this attention to the human, intentional and interested ground of the emergence of texts. This is what theory is and ought to be.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What was once anti-theory—a reaction against the detachment of texts from any supposition of humanity or meaning—is now so mainstream, that the same argument can be rehearsed and become central to a defense of theory ‘after theory.’ Theory ‘today’ is not an acceptance—as it once was, or might have been—that we do not know the political or the practical and that what we are given as objects of theory are both inhuman and can be considered rigorously only with something like an extinction hypothesis. But theory, if it takes on the impossibility that is its twenty-first century potential, might be imagined as a radical de-contextualization. Let us not fall too readily into assuming the human, or assuming ‘our’ intentional presence behind texts; let us short-circuit ‘man’s’ continuing readability of himself in the context of texts and his reflexive mode of judgment whereby he sees marks drawn in the sand and immediately recognizes his own inescapable will. Theory after theory might take a more robust form whereby we con-  towards the world? An absence of the look or point of view of theory could take two forms, one of which (I would suggest) is dominant in whatever remains of theory today, and another that represses theory. The first mode was articulated by Hannah Arendt in The Promise of Politics. Politics—being in common, speaking in common, living as a multitude—has always been repressed, Arendt argues, since Plato at least, and has been subjected to the ideal of bios theoritikos (Arendt 2005: 85). The contempt for labor and for the multitude has meant that political philosophy has always been oriented towards contemplation rather than action, a privileging of theoria over praxis.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  [S]ince Socrates, no man of action, that is, nobody whose original experience was political, as for instance Cicero’s was, could ever hope to be taken seriously by the philosophers […] Political philosophy never recovered from this blow dealt by philosophy to politics at the very beginning of our tradition. The contempt for politics, the conviction that political activity is a necessary evil, due partly to the necessities of life that force men to live as labourers or rule over slaves who provide for them, and partly to the evils that come from living together itself, that is, to the fact that the multitude, which the Greeks called hoi polloi, threatens the security and even the existence of every individual person, runs like a thread throughout the centuries that separate Plato from the modern age. (Arendt 2005: 83-84) Since Arendt that targeting of theoria for the sake of life and praxis has intensified, particularly in the work of those whose redemptive political theory has seemed to save theory from the cartoon characterizations that consigned the irresponsibly formalist and textualist modes of ‘French’ thought to a past that was not yet properly attuned to the politics of life. I will consider this retrieval or saving of theory later. For now I want to suggest that there might be another, diametrically opposed, sense of theory after theory. This would not be a return of theory to life, and certainly not a return of theory to the body, to affects, to living systems, living labor  the ways in which a radical consideration of force without center, without life, without intention or sense is continually relocated in practical life, in doing. One diagnostic point, for example, would concern the migration of certain terms, such as ‘performativity,’ or ‘difference,’ which harbor the potential to think an act without an actor, but which have actually operated to reinforce the practices of self-formation. Although Judith Butler insists on there being ‘no doer behind the deed’ in her theory of performativity (Butler 1993: 142) one might observe that performance was nevertheless for Butler that which, ex post facto, produced a body who would recognize itself as human (Butler 2005).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This aspect of human recognition, with a specific focus on the face, comes to the fore in her later work (2006). Whereas theory might be approached beginning from estrangement and distance, considering a world that is not ourselves and a force that cannot be returned to the human, theory is moving precisely in the opposite direction to being nothing more than the expression of praxis, nothing more than relations of recognition. Antonio Negri insists that ‘living labour’ and the self-producing body of ‘homo homo humanity squared’ opens up a world liberated both from the centralizing exploitation of capitalism and freed from any position of knowledge and cognition outside the collective body, and he appeals to the master thinkers of theory (Derrida and Lacan) in order to generate this ‘genealogy of vital elements.’ How, we might ask, is a Lacan whose corpus was devoted to the necessarily alien and inhuman fact that there is system, and a Derrida who began by considering genesis as ‘anarchic,’ read as modes of vital living expression? [T]he living expressions of our culture are not born in the form of synthetic figures but, on the contrary, in the form of events; they are untimely. Their becoming is within a genealogy of vital elements that constitute a radical innovation and the very form of the lack of measure. Some contemporary philosophers have set off in pursuit of this new expressive force of postmodernity, and they have attempted to characterize it. Already Lacan had pointed to the absence of measure in the  we find them picking the flowers that grow in these extreme fields. (Negri 2008: 66-67) This joyous affirmation of the living, of the multitude, of productivity, of the other, or of pure potentiality and futurity is but one way of reading theory.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But is this the best mode of thinking and reading when we are at a moment when there is no shortage of information about life and its temporality—no shortage of data bombarding us daily with the inevitable end of the human organism—and yet are all the more insistent that whatever else it is thinking and theory are primarily organic? Does not one of theory’s earliest gestures towards a force without production, or a potentiality without actuality or presence, at least suggest that one might consider relations beyond life and creation? How would theory confront the absence of theoria: ‘life’ without the human look? Life without praxis, life without meaningful action, life without production or labour: such would be theory after theory, or theory that opened itself to the thought of extinction. Hints of such a theory were articulated at theory’s very genesis: not only explicitly in texts such as Derrida’s ‘No Apocalypse, Not Now: Seven Missiles, Seven Missives’ (1984) or Gilles Deleuze and Félix Guattari’s suggestion that one might need to think of the world beyond or before the gaze of the organism (‘becoming-imperceptible’), but also in theory’s most scandalously ‘apolitical’ moments, such as Paul De Man’s suggestion that theory begins when one reads a text as if there were no readers, no contextual life that would be its site of emergence, and no living horizon that might maintain or animate its sense (De Man 1972). More recently, hints of a surviving or nascent theory occur in extensions of Alain Badiou’s promising ‘theoretical antihumanism’ that push theory beyond Badiou’s own decision of the subject (Badiou 2001: 5). Ray Brassier (2008) takes up Badiou’s antihumanism, along with Quentin Meillassoux’s insistence that it is possible to think beyond human knowledge (Meillassoux 2008), to move further into a world without cognition. Graham Harman has also taken up phenomenology, not to insist that the world as given is always given to some subject or body, but to demand that we think of relations of givenness beyond self-present think-  might say that these gestures are theoretical insofar as they begin from what is not immediately present to a subject of action.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One might want to go further than these suggestions from within philosophy to consider what literary theory might offer to a present that is dominated by information calculating the end of time, alongside a range of cultural productions striving to witness such an end—however paradoxical such an end might be. That is: how would theory approach the influx of data regarding irreversible threats to the human species—an onslaught of evidence that is met at one and the same time by increasing climate change denial, a resurgence in ‘theories’ of human praxis, and a widespread cultural production that intimates the end of human life? How would a theory that was literary—or that considered the remnants of the letter—‘read’ the spate of films of the last decade or more that have been witnessing the possible end of all human life? Such films include, especially, redemption narratives where the potential extinction of the species is averted by a popular or ecological victory over techno-science: James Cameron’s Avatar (2009) would be the most recent example. But for all their redemptive and re-humanizing work, post-apocalyptic films and novels also open up the thought of literary theory, where the ‘literary’ would signal something like Benn and Michaels’s enigmatically inhuman traces. One can think here of texts as remaining, unread, dead objects without authors or audience. Would readers fifty or one hundred years from now who found random copies of Glamorama or Finnegans Wake be secure in attributing intent and meaning, or would not such texts be more likely encountered as marks or traces without animating hand? A literary theory would not assume that texts or letters were the work of a living body, and yet would be theoretical as well as literary in asking what sort of reading, viewing or look such texts or marks might open.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Imagine a species, after humans, ‘reading’ our planet and its archive: if they encounter human texts (ranging from books, to machines to fossil records) how might new views or theories open up? Such a literary theory would not, as Derrida suggested concerning literature, be an opening to democracy insofar as literature is a right to ‘say anything’ (Derrida 1997: 58). Rather the ‘text’ would operate as an ‘anarchic genesis’ or ‘mal d’archive’: a force  Leaving those suggestions aside for now, I want to begin by addressing the question of why such a strong sense of theory after theory ought to be entertained. First: one might consider the current terrain of theory as a reaction formation. In response to a world in which ‘the political’ is increasingly divorced from meaningful practice (whatever that would be) theory has insisted in ever more shrill tones on the grounding of theoria in meaningful, practical, productive and human-organic life. Second: our context or life is one in which a radical sense of ‘after theory’—the non-existence of thinking beings—is all too obvious, despite the fact that the one area theory has failed to address is what it might mean in this (literally posthuman, or after-human) sense to be ‘after theory.’ That is, one might ask why it is just as the world faces its annihilation, or at least the annihilation of something like the organic life that was capable of bios theoretikos, that ‘theory’ turns back towards productive embodied and affective life? Third: if popular culture is dominated by a genuinely post-theoretical meditation—by a constant, obsessive and fraught imagination of a life or non-life beyond the gaze of the organism, and by the literal image of extinction—why is this the one mode of post-theory that ‘theory’ has failed to consider? The twentieth century witnessed several waves of extinction threat or catastrophic risks coming in various modes with various temporal intensities: the sudden nuclear annihilation of the cold war was perhaps the only potential extinction threat that has abated.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Sudden nuclear catastrophe is perhaps the only event that would produce apocalyptic annihilation; all other possible extinctions would be gradual, allowing for a minimal ‘human’ presence to witness the slow and violent departure of the human. Indeed, two of the senses of post-apocalyptic lie in this indication that there will not be complete annihilation but a gradual witnessing of a slow end, and that we are already at that moment of witness, living on after the end. Indeed, this is what an ethics of extinction requires: not an apocalyptic thought of the ‘beyond the human’ as a radical break or dissolution, but a slow, dim, barely discerned and yet violently effective destruction. Since the cold war, other threats to human species survival have succeeded each other with the public imagination being turned  we can imagine as other and as ‘our’ end only one threat at a time. If post9\/11 culture seemed gripped by the threat of terror, then more recent fears of systemic economic collapse have overtaken the focus on the war on terror. One might note that although the threat of AIDS—the initial figuration of which was highly apocalyptic—has hardly gone away, little mention was made of viral disaster once other concerns such as climate change began to attract attention. After 9\/11 and the shift from a war on drugs to a war on terror, various viral disasters have deflected ‘attention’ from bio-weapons, nuclear arsenals and suicide bombers, ‘focusing’ instead on SARS, bird flu and the H1N1 virus. Interspersed among those surges of panic have been waves of other threats (including the threat of panic itself, for it may be the case that it is the fear and chaos of terrorism and viral pandemic that pushes the system into annihilating disorder).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Before the financial meltdown of late 2008 the ‘era of cheap food’ came to an end (due partly to the shift in production towards bio-fuels), with food riots in Haiti presaging intense global aggression from the hungry. This was eclipsed by waves of lawlessness and violence that followed the stringencies caused by economic chaos, which in turn would lead to a fear of disorder that would be both precipitated by diminishing resources while also exacerbating the increasing fragility and incompetence of systems of social order that would suffer from widespread uncertainty and confusion. These terrors—viral, political, economic, climactic and affective— have not failed to dent the cultural imaginary. In addition to quite explicit texts about viral disaster, from Outbreak (1995) to the more recent The Invasion (2007), 28 Days Later (2002), 28 Weeks Later (2007) and Contagion (2011), other disaster epics have focused on spectacular catastrophes prompted by global warming (including Danny Boyle’s Sunshine in which a space mission to reignite the dying sun is thwarted when the space travelers fail to resist the desire to stare directly at the source of the light that would have saved the earth, so drawn are they to light’s blinding intensity). Like The Invasion in which humans are infected by a virus that robs them of all affect and thus annuls their capacity for violence and emotion, fiction and documentary culture have repeatedly  saving? (Exceptions to this investigation of species-worthiness would be David Benatar’s Better Never to Have Been (2006), Thomas Ligotti’s The Conspiracy Against the Human Race (2010), and Ray Brassier’s far more questioning Nihil Unbound (2009).) But beyond asking the worth of the species, we might ask why and how such questions are both possible (given that they are implied in so much contemporary fiction) and yet impossible, given that the human species seems to have defined itself as a will to survive? How might the human race imagine its non-existence, and how would we humans of the present adopt a relation to those whose miserable future will be ‘our’ legacy?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (In The Day After Tomorrow (2004) survivors taking refuge in the frozen-over New York Public Library decide not to burn the works of Nietzsche, choosing an economics text book for some final warmth.) Other texts have passed judgment on a self-extinguishing humanity, with the recent remake of The Day the Earth Stood Still (2008) featuring a dead-pan Keanu Reeves informing humanity that it has no right to live given the waste and violence of its history. Such worlds are after theory in a quite banal and literal sense. There are no theorists. This era of theory after theory has been considered by ‘theory,’ if at all, either in the mode of mournful despair (by an Agamben who wishes to retrieve the political in the face of the hedonism of spectacle) or rehumanizing emancipation, (by a Hardt and Negri who regard liberation from any external point of judgment as the consequence of living labor no longer subjected to spatial fragmentation or material production). These new trends in theory are accompanied by a series of returns or relocations of the previous generation of thinkers to their less threatening philosophical fathers. Derrida is returned to Husserl in order to avoid the radically disembodied and inhuman forces of writing; Deleuze and Guattari are returned to Bergson in order to re-affirm the boundaries of the organism; the machinic potentials of digital media are located in the bodies of meaning-generating audiences (Hansen 2000; Hansen 2003; Hansen 2004). A Merleau-Ponty whose concept of ‘flesh’ bore the possibility of taking the body and even ‘life’ beyond the sense of the lived has, for theorists of biopolitics, become a way of positing vital norms  More specifically still: if theory after theory has any meaning, should it not refer to a hyperbolic and minimal theoretical condition in which we consider not simply the formal absence of a population but an actual disappearance?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Theory is constitutively distinct from practice precisely because theory relates to that which is not ourselves; theory is the consideration of that which is given to us (while practice is the law one gives to oneself in the absence of knowledge). Hyperbolically, then, theory ought to relate to cultural production not in terms of bodies, affects, multitudes and identities, unless these too were also considered not as self-evidently familiar and living but as strangely dead to us. This would also give us a minimal approach to an ethics of extinction, which would also be a counter-ethics. We would not assume an ethos, a proper way of being, community, ‘we’ or humanity that would be the ground and value of literary or other objects. Just as Foucault’s counter-memory sought to consider all those forces that had some power in the present but were not present to living history (Foucault 1977), a counter-ethics would be theoretical in beginning from the condition of the present—looming extinction— without assuming the ethos of the present. That is, one would—as the world after theory ought to compel us to do—consider what is worthy of concern or survival, what of the human, the multitude, or the living would enable an ethos that was not the ethos of the present. We can return again to the question of theory after theory, today, and ask why it has so focused on an empty tomorrow—a future of open creativity, and unbounded possibility—that it has not considered the tomorrow of its own non-existence. Given even the minimal assumption that reading theoretically requires some necessary distance from any actual audience, and given the now-literal threat of the absence of the human species, why has theory survived, after theory, in a mode of increasing humanization and organicism?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Why, when events and timelines would seem to demand just the contrary, does theory takes its current self-englobing form? As an example of the ways in which theory has, just as Arendt suggested it ought to do, retrieved a politics of living in common (a polity of the multitude with no outside), we might consider three dominants. First, a deconstruction that now mourns Derrida  radical openness defies all calculation (saving justice and democracy to come) (Naas 2008: 67-68). Such a mode of deconstruction would survive at the expense of a Derrida who suggested an ‘untamed genesis’ that would be neither living nor dead, neither before nor after the human but nevertheless disruptive of any mode of good conscience. Second, a turn to life or naturalism insists that the world is always the world for this or that living system, always embedded in a milieu given as a range of affordances: this ranges from the retrieval of phenomenology and the embedding of mind in life (Petito, Varela, Pachoud and Roy 1999) against an anti-organicism or textualism that would draw attention to forces beyond the lived, to the celebration of bio-political production and the multitude against a bio-power that is seen as extrinsic and opposed to life (Hardt and Negri 2000). Finally, one might cite a return to the aesthetic, whether that be an aesthetics of language that separates man as a speaking being who gives himself his world from animality (Agamben 2004), to a reaffirmation of literature ( Joughin and Malpas 2003; Attridge 2004) or art in general as grounded in the human organism’s sense-making capacities of its world. It would be far too obvious to add to this list the affirmations of identity politics or, worse, subjectivity, that would posit a self that is nothing more than the negation of a world in itself (knowable, measurable and presentable) precisely because the subject is that which gives a world, law and norm to itself. Theory might have both interest and worth—if we accept the thorough contingency of such worth—only if it is as destructive of the imagination as our milieu of possible extinction allows.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We might need to abandon the grounding of ecology on nature (Morton 2007) or consider modes of deconstruction in which the future were not radically open, hospitable and affirmative (Clark 2010). There is no shortage of data regarding the possible or inevitable absence of humans: terror threats are calculated meticulously by government think tanks; climate change protocols and negotiations require detailed prediction and scenario plotting, and popular news is dominated by economic, climactic, viral and political ‘updates’ regarding a range of intruding violences (Grusin 2010). Such information, far from indicating the location of texts in a polity, suggests  lines drawn without any preceding or ideal community. Let us also, more importantly, be aware (insofar as we can) that the text of the current ‘multitude’ includes information regarding climate change, terror, destruction and extinction expressed in a vocabulary of mitigation, adaptation, viability policy and sustainability, none of which can figure the non-existence of the human. If theory were to operate as it might then it would be destructive of such an imaginary; it would be theory after theory. Chapter 2  The Sustainability of Concepts: Knowledge and Human Interests Climate change studies—a burgeoning field prompted by government research initiatives and academic opportunism as much as by the impending crises associated with global warming and resource depletion—is, in general, formed by combining the ‘hard’ sciences (geography, geology, physics, biochemistry, biology and genetics) with the social sciences (geography again, psychology, political science, demographics, sociology and economics). As a consequence of most major research institutions having produced some type of climate change research network the humanities, too, are beginning to contribute to understandings of the problems presented by climate change. Before considering why any simple inclusion of the humanities in climate change studies needs to be questioned, I would like to open a series of considerations.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  First, the combinations of the hard sciences and human sciences that make up climate change studies—even though interdisciplinary research networks bring these sciences together—keep the disciplinary borders of various fields in place. There are, of course, some sciences—geography, psychology—that are in part both hard and social sciences, but even this division within the subject presupposes something like the idea of a human science. That disciplinary distinction, as Michel Foucault argued in The Order of Things, is not simply a division of labour that takes a single subject such as nineteenth-century natural history and then divides the same practices of gathering information into different disciplines: what counts as true or false alters dramatically, with the very idea of a distinc-  example, that we cannot see natural history as simply preceding biology or the science of life. Nor can we read Adam Smith’s theory of wealth as leading seamlessly to economics; nor can we see theories of grammar as similar in type to the social science of linguistics. To understand how these new disciplinary distinctions create a curious new object of knowledge—man—we can take our lead from the present. Even popular economic theories, such as Freakanomics (Levitt and Dubner 2005), or the Chicago school theories that directly influence government policy (Overtveldt 2007) presuppose a certain concept of man. Either—as Freakanomics theories posit—we constantly miscalculate the effects that our ‘choices’ will have on our well-being (by being lured into paying more for our daily coffee if only we can be seduced by a special offer that will create a habit); or, we are naturally competitive and self-interested animals who, if left to themselves, will allow the most efficient players to rise to the top while the muddling remainder of the population can benefit from economic prosperity in general. What economics as a social science assumes is a ‘subject of interests’ (Montag 2009): it is not sufficient just to look at relations among goods and prices but also to have some notion of human behavior, especially if the operations of human behavior are not immediately apparent to humans themselves.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Questioning the extent to which capitalism presupposes normative concepts of the self is hardly new. C.B. Macpherson’s 1962 classic theory of possessive individualism is perhaps now widely accepted, with the concepts of the free individual or the level playing field now recognized as being barely veiled assertions of liberal market norms. What is slightly more nuanced, and not so widely acknowledged, is not the critique of liberal normativity but the shift from the normative to the normal. If behavior is based not so much on (even implicit) regulatory ideals regarding the proper life that one ought to live, but more on some preceding and determining life, then the mode of decision or axiology shifts from selfdetermination to alignment—bringing human existence into accord with the life of which it is an expression. We tend to explain human actions by appealing to some prior logic of life from which they emerge. There is a shift from assessing human action according to its manifest sense to  man is also able to read and interpret the life of which he is an effect. In this respect certain historical theses—ranging from MacPherson’s claim that the supposed neutral individual of capitalism is in fact the outcome of a specific politico-economic historical period, or Louis Dumont’s argument that modern homo economicus needs to be explained anthropologically—rely on some ultimate horizon (history, anthropology) that would gather and explain human positivity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Foucault (1970) agued that Adam Smith’s Wealth of Nations of 1776 explained how human interaction produced commodities, how these could be exchanged, and how a system of circulating goods produced an overall stability and system that benefited all concerned (Smith 1976). When Karl Marx forms a theory of labor the life or species being of the human animal is added to the way questions are posed: why, we might ask, do human beings labor and enter into exchange? For Marx the answer presupposed man’s species being: we must labor, collectively and with the help of technology, in order to meet our needs. This, in turn, explains the existence of ideology for there are forces that determine the relations we establish to each other—forces of production that place some bodies in greater servitude to production than others. The very concept of ideology in its Marxist sense—not what we believe but belief as grounded in a preceding and hidden life—relies upon situating the human species in a collective history that originates from an initially life-serving aim. These initial forces determine our social being, even if they are not directly experienced, and are capable of being interpreted only after the fact. Marx’s theory of ideology, in a manner shared by social or human sciences more generally, relies upon interpreting the way in which we live our social relations: what we experience as natural—that I go to work for an employer who pays me for my time— needs to be understood as the outcome of a historical process whereby those in command of the means of production that will ultimately reduce human effort (factory owners, for example) are capable of buying the labor of other individuals from whom they profit (Foucault 1970, 257). The human sciences, such as economics, do not just chart the circulation of goods (as did Adam Smith’s theory of wealth) they presuppose something like human interests that can explain systems of exchange.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  looking at the mechanisms of ‘life, labour and language’ (Foucault 1970, 345) through which social systems are effected, we can also have humanities disciplines that would be interpretive in their examination of human cultural production, and would also presuppose ‘man’ as an historical, social and productive animal. Anyone working in a literature department today may well recognize that Foucault’s notion of literature—a mode of human production not grounded in purposiveness or a theory of human function—has well and truly been overtaken by logics grounded on a normalizing theory of man, whether that be a theory of literature as ideology (allowing for smooth social functioning and the reproduction of capitalist social relations) or a theory of narrative and story-telling as a human survival mechanism (or so literary Darwinism would claim). Foucault, referring to the knowledge practices of his own day, was critical of some of the key discourses that made up the humanities, such as phenomenology, structuralism and psychoanalysis (Foucault 1970, 355). These approaches would examine cultural production while presupposing what Foucault referred to as man as an ‘empirical-transcendental’ double. Man is empirical—a being whose language, social relations and bodily habits are determined by the material relations he must take up in relation to his environment and others; but man is also a being who can analyze those material forces and thereby ‘read’ the ways in which he has come to be the specific social being that he is. Psychoanalysis, for example, will argue that we can only exist and live if our desires take on some acceptable, socially-sanctioned form; we can, however, always read these socialized forms to discern something like desire as such. (Other less humanizing or organic forms of psychoanalysis would not ground desire in the function of man as a social animal, but Foucault’s target was a psychological form of psychoanalysis, one grounded on a desire that would be explicable according to the human animal as a self-furthering and survival-oriented being). Phenomenology, also, insists that we exist only insofar as we make sense of ourselves and our world; we need to see all that we do—from daily habits to great artworks—as a mode of worldproduction.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Structuralism, too, regards language, culture and social relations as a product of a transcendental need for ordering: the specific  some mode of ordering is necessary or transcendental—characterizing any and every culture. We can pause and look at how these first two considerations—both involving normalizing theories of man—open up questions for climate change studies. For it is not just that we address questions of climate on the basis of certain values, including assumptions regarding market viability and social fairness; it is also the case that we adopt normalizing forms of reasoning and calculation, both assuming that individuals may act more benevolently towards the climate (and future others) if narratives can be formed that are sympathetic and coherent, and that the values of survival and the future are shared by all humans here and now. There is also division of labor between the predictive hard sciences concerned with climate change research and data, and the interpretive projects of the humanities. How does the distinction between the physical sciences and moral sciences not only alter the way we approach climate change (as something with a physical base that may affect different humans differently) but produce the very concepts through which we think about ways of tackling climate change? First, as long as we assume something like the possibility of a social science, in its distinction from hard sciences, we will not only have a bifurcation between data (such as the evidence yielded by the earth sciences for global warming) and social impact (such as the work done by social geographers who gauge how gender, class and race produce disproportionate and unequal impacts of climate change); we also presuppose a subject of interests. That is, it is assumed that there is a physical world of material forces and constraints and that this physical world is the milieu, environment or climate within which we are located. The concept of climate may be the most telling of all, deriving from concepts of surface and habitation, when in fact what ‘climate change’ indicates is that there is not a distinct milieu that we can observe and manage but a mesh of overlapping, divergent, interconnected and dispersed systems with certain factors such as clouds and even human hope itself, operating in two directions at once: too much hope and we don’t act, not enough hope and we don’t act; clouds may both increase and lessen  (where economics, politics, technology, knowledge and industry operate by divergent timelines and logics) the concept of climate reinforces the sense of ‘a’ milieu or habitus.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Climate change would therefore refer to a material and physical locale that may be treated as material resource for goods and data (by the physical sciences) or as a restraining and determining condition that will alter how we produce our world and our polity (by the human sciences). The word ‘climate’ originally refers to a specific region, indicating different modes of human life, but once we refer to ‘climate change’ and have something like the climate, we also generate the concept of something like humanity in general. That is, if we now have something that is not a specific ‘clime’ or territory but a single condition for all living beings then there is also something like a general concept of life that comes to be threatened. Second, this leads to the specific possibility of the humanities. This possibility might seem, at first glance, to produce something quite distinct from either the physical being of the hard sciences or the social systems of the human sciences. If political theory, economics and sociology can examine the impacts of climate change and climate change policy on different nations, social groups, ethnicities and gender—and if these social sciences can also explain non-physical aspects of climate change, such as the needs of developing nations and peoples to maximize production without being able to afford strategies of mitigation— what they cannot do is examine the meaning of climate change: how it is lived by ‘us’ and what modes of understanding and cultural production led to climate catastrophe and disdain for the environment upon which we depend and which also produces us as the beings that we are. This is where the humanities may, and has, entered climate change studies. One might even argue that the humanities has always taken the form of climate change studies: has always asked what humanity or ‘the human’ is such that it may have come to treat its own milieu as so much raw material for profit, consumption and energy maximization and not as a body worthy of care.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The humanities, we might say, has always considered the earth as climate or environment—the home of our being, or our unavoidable terrain and surround—and never as mere stuff, matter  variability of humanity across time and space. In a humanizing mission, reacting to the disenchantment of the world by the supposed ‘hard’ sciences, the humanities open a space for human variability. This humanizing motif occurs as early as the first formulations of English Studies in the late nineteenth and early twentieth centuries, concerned to develop a moral framework in an increasingly secularized and disenchanted world, and is reiterated—today—in various calls for the humanities to be led by life and praxis against the mechanizations of globalization and capitalism (Baldick 1983; Bérubé and Nelson 1995). By the time the humanities explicitly take up these concerns of eco-criticism or environmental philosophy it has a wealth of material to draw upon that would demonstrate that we are, primarily, ecological beings. The humanities could not do without the ecological motif, or the commitment to historical cultural variation across a comparative and meaningful plane. By the time universities form explicit networks for climate change studies there is already a demarcated niche for the humanities: neither assuming the brute facts of the world, nor dealing with humans statistically in the manner of the human sciences, the humanities nevertheless presupposes a ground of life that expresses itself in human self-creation. On the one hand environmental philosophy—even though generalizing this area covers over many complexities—reacts critically to the fundamental concepts that are deemed to constitute Western metaphysics. The idea that we are self-determining ‘subjects’ whose relation to the world is one of representation (knowledge) or use (with the world as mere raw material) needs to be supplanted by a relation of care, concern or respect.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The humanism and anthropocentrism that have marked Western thought need to give way to a new relation to the environment. This would not be a shift in the value we attribute to the planet and atmosphere that is our home; it would not be a question of valuing the environment more, or of granting it greater worth, importance or significance. We would require what Nietzsche referred to as a transvaluation of values (Nietzsche 1968). Rather than generating values on the basis of instrumental reason or utility—rather, that is, than assuming that the worth of an object or action is gauged by how much it furthers our  humanity in its current mode. We would, at the very least, consider values as if from a point of view different from that of ‘man.’ This would occur if, for example, we granted non-humans (animals, trees, ecosystems) rights, or if we questioned the concepts of rights and entitlement and instead developed values of mutual care, concern and deep ecological connectedness. On the other hand, while insisting upon the need to alter the very structure of our thought away from instrumental (or use-oriented) and cognitive relations to the world in which we live, eco-criticism has already uncovered an implicit and long-running awareness of a complex relation to nature that might be unearthed in canonical literature (Bate 1991; Bate 2000). Despite a manifest assumption that humans are given the world as so much available property, eco-critical readings can show the ways in which there has always been an awareness that the earth is not mere matter, but an environing and meaningful place that is as much constitutive of our sense of self as we are of the significance it has for us. Again, like environmental philosophy, eco-criticism cannot be reduced to a common set of principles.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What can unify both these ways in which the humanities disciplines have anticipated current attempts to approach our climate differently is both their target and some of their key concepts. What is targeted is the notion of human beings as self-sufficient and primarily rational agents whose relation to the world is ideally one of disinterested or disenchanted knowledge; the use of key concepts, ranging from environment and ecology, to the privileging of place over space, along with concepts of care, concern, indebtedness and most importantly life also serve to move from a philosophy based on individuals and matter to a mode of thought that is more relational, more sympathetic and ultimately more concerned with meaning. That is to say, there is never a world as such, in itself, that we then have to manage and quantify, for ‘we’ exist and have a sense of ourselves only insofar as we have a specific place that is always embedded in, and generative of, an entire world of possible futures (which involve other timelines and potentials beyond ourselves). Perhaps the strongest mode of this critical relation to Western knowledge takes the form of James Lovelock’s Gaia hypothesis, where he insists that not only is it not a question of taking up a different attitude to nature,  presents the world as a single organism, so that human life would not be placed within the world, or in relation to the world, for human life would be just one aspect of an intricate, complex, dynamic, interacting and homeostatic system (Lovelock 1979). The Gaia hypothesis was formulated to challenge conventional ways of thinking about humans and their relation to the environment. It suggests that any adequate response to climate change would require a radical reassessment of our conceptual terrain. We might, then, consider some of the key terms that orient climate change policy, ranging from ‘cap and trade,’ adaptation and mitigation to sustainability and viability. These terms remain managerial and instrumental.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Cap and trade is, of course, an explicit adoption of a calculative framework. Policy and negotiations focus on a single variable (carbon emissions) despite the volatility and complexity of factors that the physical sciences have consistently demonstrated to make up the problems of climate change. The very notion of trading carbon emissions—that as long as a payoff is made somewhere or by someone then further destruction can be sanctioned—not only (again) places human response in the mode of homo economicus, it also precludes any genuine thought of the future. If carbon emissions can be managed, traded, and held at ‘acceptable’ levels then we fail to confront the scientific evidence that indicates that even a halt in current carbon emissions would leave a tailing effect that would continue to wreak havoc; continued trade in emissions presupposes that the future will be different in degree, or a continuation of the present, and not different in kind. There is something anaesthetizing in the idea of trading carbon emissions and allowances: as though something like an economy were at work, an enclosed system of more and less, and not—as is becoming apparent—a future that will be unmanageable and have entirely different terms. One might make a similar remark about the concepts of sustainability, adaptation, mitigation and viability. Sustainability assumes the value of continuity: if one changes it is only insofar as is required in order for human life to continue, an implication that is less subtly contained in the strategy of mitigation. Not only do all these terms accept that humanity exists as something that has the  the calculations are arithmetical, concerning more and less, rather than differential).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Climate change is perceived as a problem of disturbance, precluding us from continuing life in the same manner; and it is only for that reason that changes need to be made. Such changes will not be global in the full sense of the word; they will not alter the fundamental or entire system within which we are imbricated. They will rather occur as responses to a predicament. Life may have continued unperturbed—had we been wiser and more cautious, perhaps less profligate and wasteful— but unfortunately we plundered nature excessively and with short-term thinking. Our response is therefore to extend our calculative approach to the future to include not only our maximal efficiency here and now but our ongoing existence, our sustained existence. All these terms are aligned with what Gilles Deleuze referred to as extensive multiplicities: certain multiples have their units determined in advance, and are composed of equivalents (Deleuze 1994). In general we might say that the very possibility of the social sciences is built on calculations of extensive multiplicities: in relation to climate change studies one can look at how different members of populations respond to, or are affected by, policies or climatic disasters. More importantly, the timelines take the mode of more or less: what practices do we need to adopt to live longer?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  How might ‘we’ adapt? Can we use less? Can we be more like developing nations? How much suffering and sacrifice will be demanded from our future generations? All such questions assume that the future would be a continuing time of more or less. Such extensive calculations also presuppose a general underlying substrate—human life—that may vary culturally and historically, that may have to adapt, but will have nevertheless have some mode of continuity. Rather, then, than continue a late Romantic project of re-enchanting the world, following a science of calculation that disenchanted the world, I would suggest that what is required is a more intensified disenchantment and evacuation of meaning, or what Timothy Morton has referred to as an ecology without nature. As long as we regard the world as our lived world, as an organic and meaningful whole that is the milieu of our being then our approach to the future will be bifurcated: split between an increasingly  englobing environment.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In intensive quantities it is not a question of equivalent units of more or less, but of speeds and thresholds that have the capacity to produce differences in kind. Climate change calculations, models and scenarios have long been characterized by quantities that are not those of a single unit (beneficial or detrimental) but will alter in kind and relation depending on speed and quantity; not only are there tipping points (or thresholds where one more degree of heat will alter the entire system) there are also unpredictable feedback effects and incalculable productions of disequilibrium. Had the social sciences taken on a similar complexity they would have to consider the possibility that the units with which they work—humans, societies—would alter in kind, beyond recognition, at certain speeds and thresholds. This could be seen positively, whereby one might say that climate change will not simply disturb human life, requiring it to sustain itself in a more viable manner, but will alter the very unit of ‘the human.’ Here, one would have to rethink the very being of ‘man’ that was produced by the division between hard and social sciences: there could no longer be this animal blessed with language and history, who produces himself socially and technologically, but who can also study and read himself as an object of historical and cultural production. For there would no longer be man (historically and socially determined and determining) but a species tied to rhythms that were geological and beyond the historical and familial imagination. This would require us to consider that the question of the humanities and the human is not something that might be added to the problem of climate change, as though the environmental and policy problems could benefit from an examination of some concepts. Here is where we might return to how theories of ecology, environment and—of course—climate as terrain or habitation have already been considered by the humanities. For perhaps what may need to be rethought is the very concept of the human as it subtends the humanities.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Returning to Foucault’s genealogy of the emergence of the human sciences in modernity, we can recall that ‘man’ becomes possible as an object of knowledge only with the strict distinction between the hard sciences of matter, and the social sciences that chart man as a socio-his-  the hard sciences of matter, and then the temporal-cultural expression of man in the social sciences, then it follows that the discipline of the humanities forms both an enabling condition and presupposed axiology: for discipline is both a set of conditions of knowledge and an art of formation. In the disciplines of the humanities ‘man’ not only studies himself as determined, in part, by his climate, for he can also reconfigure his intellectual climate, rewrite his concepts and vocabularies. He can alter himself from within his own history, sustaining himself, and rendering himself more viable by becoming more attuned, more sympathetic, less instrumental in relation to what will always be his climate and his environment. Indeed, in theories such as the Gaia hypothesis, man can project his organic being onto life as a whole. No longer would he be fragmented from a climate that is unfortunately not bending to his will and knowledge; he would, rather, be part of a living form that in its dynamically self-sustaining manner would guide him away from self-seeking politics to a naturally forming politics of the whole. Ethics and politics— what ‘we’ ought to do—would follow directly from the natural and vital norms of the one living earth. Lovelock’s Gaia hypothesis, like any theory that assumes a natural or proper connectedness (however occluded), reinforces what Foucault referred to as the specifically modern nature of bio-power (Foucault 1978), and maintains an extensive and bourgeois approach to values. That is, despite the recognitions of ecology, environment, climate and biosphere, it is man who will read the conditions of this system, discern its proper order, break free from merely instrumental attitudes and arrive at a proper mode of self-regulation.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The alternative to this privileging of climate, environment, ecology and biosphere as continuations of self-sustaining life was already prefigured when Foucault spoke about the possible erasure of man. Here, one would not assume that the future would only need to be altered in degree in order for life to continue: one would ask whether the future would be one of life. That is, would all those disciplinary norms, including a distinction among hard sciences of data, human sciences of self-management, and the humanities as self-interpretive, not be fragmented following their dissolution and failure in the face of impending catastrophe? If we did not  managing the human, via the humanities, but would be asking how we might think in the absence of sustained human life. This would lead, in turn, to thinking climate intensively—and this, in turn, would require not only adjusting concepts but creating new concepts, or even thinking beyond concepts. At its simplest, climate change ‘policy’ would have to shift from being political—the coming together of bodies in common via a common language of sustaining and adapting—to become impolitic. What ways of speaking would fragment, disturb and destroy the logics of self-maintenance that have always sustained humanity as an animal that cannot question its existence? (Humanity has, of course, always questioned the essence of its existence—who is man?—but it has rarely questioned the actuality of its existence: that it may not be.)\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  To consider the future intensively we would at least begin with the possibility that an event might occur to ‘us’ that would create a mutation of such a force that ‘we’ would no longer exist. What we have known as human life, supposedly marked by instrumental reason, self-maintenance, risk-assessment, management of resources and exchange with a view to relatively short-term futures, would give way to a being that does not have a future. As long as we calculate the future as one of sustaining, maintaining, adapting and rendering ourselves viable, the future will differ only in degree; this would mean of course that there would be no future for us other than an eventual, barely lived petering out. If, however, we entertained the erasure of the human (especially as defined through the discipline of the humanities, whereby humanity is that fragment of a selfmaintaining nature that can sustain itself through reading itself) then there might be a future. This would not be a future of the climate, of a terrain or habitation, and certainly not of an environment—as that which environs or encloses. For if the experience of climate change were to be experienced it would disclose that there is no climate, biosphere or environment. There is not ‘a’ world, existing in the manner of an organism, that maintains and sustains itself. Chapter 3  A Globe of One’s Own: In Praise of the Flat Earth Questions, today, of climate and climate ethics—and even concerns regarding the sustainability and viability of this life of ours on earth— appear to present a new imaginary for political questions.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One might say that it was only in the late twentieth century, with events such as the picturing of the earth from space, the possibility of nuclear annihilation of earthly life or the increasing speeds of new media allowing for the possibility of global audiences (such as the entire world viewing 9\/11), that something like the problem of a global ethos would emerge. If there had always been a silent presupposed ‘we’1 in any ethical theory, then this virtual universalism would always struggle alongside moral valorizations of specified communities.2 How do we, from the particular world we inhabit, begin to think of life as such? It is the present sense of the planet as a whole, as a fragile bounded globe that might present us, finally, with the opportunity and imperative to think a genuine ethos. Now that we have a notion of climate that seems to break with the etymology of this specific inclination or latitude of the earth , and does so by gesturing to something like a sense of the earth as a region or inclination in itself, this might open a new imaginary of the globe. We might think of ethos as no longer bound to a territory within the planet; instead there might be the ethos of this globe of our own, that has no other region against which we might define ourselves or towards which we might direct our fantasies of another future. If there is something like climate change, perhaps it takes this form: not only a mutation of this climate (warming, deplet-  traditional sense—as our specific milieu—we will perhaps lose sight of climate change, or the degree to which human life is now implicated in timelines and rhythms beyond that of its own borders. The figure of the globe appears to offer two ethical trajectories: on the one hand an attention to global interconnections and networks would expand responsibility and awareness beyond the figure of the isolated moral subject. Ethics may have to be considered beyond discursive, human and political modes (especially if one defines politics as the practice of a polity).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  On the other hand, the figure of the globe—considered as a figure—is intertwined with a tropology of interconnectedness, renewal, cyclic causality and organicism. This traditionally theological series of motifs, with the globe’s circularity reflecting a divine intentionality, is maintained today in many of the most profound and seemingly secular ecological theses, including the Gaia hypothesis and the global brain. It is the possibility of extinction or the end of human time that forces us to confront a new sense of the globe: far from being an unfortunate event that accidentally befalls the earth and humanity, the thought of the end of the anthropocene era is both at the heart of all the motifs of ecological ethics and the one idea that cannot be thought as long as the globe is considered in terms of its traditional and anthropocentric metaphors. The word ‘globalism’ along with the word ‘biopolitics’ suffers from a curious double valence. As a descriptive term globalism can refer to the lost autonomy and destroyed difference among worlds: the formation of global media, markets and communications eliminated what was once a panorama of difference. Once upon a time the globe enjoyed divergent timelines and worldviews. Even if it was central to the colonialist imagination to romanticize the extent to which ‘other’ worlds were exotically untranslatable, mystical and embedded in a non-linear time, there is nevertheless a very real sense in which globalism has created an earth of a single time, single market and single polity. Globalism would be a mode of homogenization, disenchantment or rendering quantifiable that one could lament as having displaced an earlier world of distinct places for the sake of one quantifiable space.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This reduction of distinction has significant material consequences; today, any particular country’s envi-  trigger a series of imaginary ramifications. In positive terms this has been described by Michael Hardt and Antonio Negri in terms of a new multitude. Liberated from nation states and physical locales there can now be a humanity as such, a self-creating living labor that has no body other than that which it gives itself through its own immaterial productive powers (Hardt and Negri 2004). Thought less optimistically, one might say that the physical ability to occupy converging and synchronized worlds and times is coupled with a cognitive paralysis to think of any future that would not be one more chapter in a familiar collective narrative. This is evident in the terms that are used to describe the predicament of the globe. It is not only the case that events are materially and systemically linked, so that the volatile economies of even the smallest countries may precipitate global crises; it is also typical today to see all of financial history as similarly continuous and interconnected. This occurs both in short-term and long-term thinking; recent events have prompted the publication of a series of histories and genealogies, including the histories of debt, of money, of corporations, bonds and markets: all suggesting that the present is an expression and extension of a single history of something like ‘the’ globe (Ferguson 2008; Cashill 2010; Graeber 2011; Coggan 2012; Bakan 2005). Economic events are considered in relation to a past that we have been unable to think as anything other than differing by degree.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Despite the new global conditions and linkages the 2008 cascade of economic crises were gauged to be either as bad as or worse than the great depression, while terms such as ‘recovery,’ ‘recession,’ ‘depression,’ and ‘crisis’ place the current state of play as a continuation of a past, a past that varies and recovers always in terms of one easily comprehended cycle. The lexicon deployed to assess and gauge the environment is similarly comforting in terms of its linear temporality and delimitation: Australia still refers to its condition as one of ‘drought,’ even when the period of insufficient rain and increasing desertification exceeds a decade; climate change policy refers to ‘mitigation,’ ‘adaptation,’ ‘sustainability’ and ‘viability’—all of which enable one to think of management (however difficult) rather than cessation, rupture or incomprehension. One might say that the imagi-  forced to yield ever more to the human desire for life—is coupled with an incompatible global figuration. Things will cycle back to recovery. The globe can be taken and assessed as an object and managed, saved, revived or given the respect and care that it deserves. If where we are is a globe, then it can be imagined as delimited, bounded, organically self-referring and unified. Perhaps—given the advent of globalism as a concrete event where there can now be no time, place or body that can live outside a certain destructive force field of events (such as the possibility of viral, political, economic and climactic terrors)—now is the time to think non-globally. The usual figures of the bounded earth, the ideally-self-balancing cosmos, the interconnectedness of this great organic home of ‘ours’ are modes of narrative self-enclosure that have shielded us from confronting the forces of the present.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is not surprising that ‘globalism’ is at once a term of mourning, signaling a world economy and politics that has taken every space and timeline into its calculative, cynical and rigid systematic maw at the same time as it signals a redemptive potential. We are, so various environmental and ecological imperatives remind us, always interconnected across and through this one living globe, this living world that environs us. The maxim, ‘act locally, think globally,’ should be reversed: there can be no encompassing global thought, for insofar as we think we are fragmented by various locales, figures, lexicons, disciplines and desire, but we nevertheless are caught up in a globe of action where no intent or prediction will be enough to secure or predict the outcome of any action. It was the great contribution of Lacanian psychoanalysis to point out that the visual figural unity of the human body—the bounded organism we see in the mirror—serves as a captivating lure that precludes us from confronting that ex-centric predicament of the speaking subject whose desire is never given in a living present but is articulated and dispersed in a time that is never that of a self-comprehending and self-affecting whole. Just as the spatial unity of the human body covers over the temporal dispersion of the speaking and desiring subject, so the delimited material object of the planet enables a misrecognition of the multiple systems, forces, timelines, planes and feedback loops that traverse what  interconnectedness and hyper-volatility—should, if anything, have prompted a destruction of the figure of the globe. And yet the opposite appears to be the case: even in the genre that is apparently most devoted to global catastrophe—the disaster movie—the globe is strangely reinforced and consolidated. A typical instance is Independence Day of 1996, in which an invasion of earth is initially viewed from the contained space of a US government control room, as though we will be able to have advance vision of ‘our’ end and limit from the point of view of a single screen and panel of experts. Perhaps today we might note that it is the physical image of the globe that serves as a reaction formation, precluding a thought of the consequences of globalism (if globalism remains the correct term for the increasingly evident and non-human complexities that are precluding any possibility of a global or comprehensive vision).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If capitalism could once have been thought of as ‘a’ power imposed upon the globe then this is no longer the case. As the recent economic crises demonstrated capitalism is not a system, cannot be attributed to a body of interests, and is less a transcendent structure imposed upon organic life than it is just one of the many ways in which local, ill-considered, barely intentional forces of consumption and acquisition exceed the comprehension of any body (be that a physical, political, national or economic body). Marxist theory’s attempt to locate capitalism within history and within a theory of interests can be compared to a whole series of localizations and narrative therapies. Popular culture has for decades been giving a face and\/or body to a series of diffuse and essentially ‘unglobable’ threats. Despite a series of calls for thinking in terms of distributed, de-centered and dispersed cognition, where we acknowledge that institutions, cultures and even organisms are not governed by a central organizing brain, the political imaginary remains wedded to organic figures. Popular culture has presented viral invasion more often than not in terms of an isolable and intruding body: conquering such threats can then be placed in a standard narrative of good and evil, self and other. Terrorism, too, is given a specific face in media culture (either the named Osama Bin Laden or an ethnically specified other). But it is not only popular culture that has  Lamenting the fall of modernity into a bio-politics that manages populations according to a general and quantifiable ‘life,’ Giorgio Agamben argues that it will be possible to arrive again at a genuine politics only by considering what Foucault failed to confront: the problem of sovereignty in modernity (Agamben 1998).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  That is, whereas Foucault was critical of the sovereign model of power, or power as an external and imposed body, Agamben’s critical concept of bio-politics wants to resist a modernity of diffused or capillary power, focusing again on how power establishes itself as a body. Agamben refuses the notion of the political and the polity as a universal or a given; the polity is constituted in and through human potentiality’s realization that it lacks any determined end. For Agamben, what needs to be recalled is the genesis or emergence of the political fold, the opening of something like a political space that then enables a distinction between that which is interior and that which is exterior to the polity. What counts as political is, for Agamben, itself not a political decision, and this is because ‘the polity’ or the opening of a space of what will become ‘our’ concern is an event, and one to which genuine thinking ought to (constantly) return. Today’s losses of commonality, or the absence of something like a global community, should prompt us to address that the global community or horizon is neither given nor guaranteed, but is nevertheless urgently required if we are not to lose sight altogether of our potentiality to be political, to open a political space. What bio-politics and its terrors force us to acknowledge is that our defining potentiality—for speaking together and opening up a political space— discloses itself most fully when it is not actualized. For bio-politics, too, bears the same double valence as globalism. It is precisely in the era of the bio-political, when all decisions regarding what we ought to do are grounded on maximizations of life that the passage from life to polity, and the political constitution of what counts as political life is forgotten.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is Auschwitz, modern hedonism, and the bio-political absence of a genuine political space of speech and decision that evidences the true nature of politics. Politics occurs not when bodies located in a world then decide to speak together, for politics is—through the event of speaking—the opening out of a world. Here, then, in this confrontation with a mod-  political space—Agamben gives the contemporary term ‘bio-politics’ a force that relates directly to the imaginary hyper-investment in the globe. Agamben, unlike the Foucault whom he criticizes for not confronting the relation between bare life and sovereignty, regards bio-politics in its various forms—both totalitarian managements of populations and democratic aims to increase a society’s happiness—as a loss of the political. As long as politics is focused on bare life, or the calculation of a living substance we will have retreated from the question of the potentiality of the political: man is not born as a political animal but becomes one, and he does so by creating a political space through speaking, opening up a world that is always his world. The Greek distinction between bios (or a life that is formed, bounded and oriented to what man might make of himself) and zoe (or mere bare life that, in modernity, becomes so much disposable waste and that increasingly becomes the subject of politics) is, for Agamben a difference that needs to be re-thought and re-inscribed. It is bios—created, formed, bounded, delimited life—that has been lost and that entails a loss of the political. How does this relate to globalism?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Both Agamben’s critique of biopolitics and the reaction against globalism express a traditional and theological mourning for a loss of form. Globalism’s evils follow from its ravaging disrespect for limits and difference, its tendency to consume all previously distinct and specified nations and cultures into one vast calculative system without definition or limit. Not surprisingly the response to both globalism (seen as an inhuman, mindless and unbounded system) and to biopolitics (seen as a loss of the self-defining polity) has been the reaffirmation of the figure of the globe or bounded form. Agamben, for example, posits a series of positive manoeuvres that would ameliorate the biopolitical ravaging of the man of poiesis; these include a return to the active creation of man as a political living form as bios rather than zoe, as a being whose political nature has little or nothing to do with his mere life but requires creation. Not surprisingly, then, Agamben also wishes to retrieve a more authentic aesthetic encounter, where art is not passive spectatorship of an artist’s private invention but an opening out or disclosure of a created world. Here, art as poiesis or putting into distinct form  Hardt and Negri, reacting more explicitly to a globalism that has precluded any active and intentional formation of a polity, call for the creation of a single, self-producing, self-aware and self-referring open whole of humanity: a single, continually re-productive body of man: In addition to envisioning revolution in ethical and political terms, we also conceive of it in terms of deep anthropological modification: of metissage and continuous hybridization of populations, of biopolitical metamorphosis. The first terrain of struggle is, from this point of view, the universal right to move, work and learn over the entire surface of the globe. Thus revolution, as we see it, is not only within Empire but also through Empire.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is not something which is fought against some implausible Winter Palace, but something which extends against all the central and peripheral structures of power, in order to empty them and subtract the capacity of production from capital. (Negri, Hardt and Zolo 27) We can pause here to note that what underpins Agamben’s call for a new politics and Hardt and Negri’s manifesto for a self-productive multitude is a figural globalism that is a variant of a traditional and theological organicism. That is, the figure of the globe—the ideally bounded sphere in which each point is in accord with the whole, and in which the whole is a dynamic and self-maintaining unity—harbours an axiology that privileges bios over zoe. What must be asserted as dominant and proper is a whole or bounded form that has no external or transcendent principle, no ordering that is given from without or that would elevate one point or term above another. Literal globalism, perceived as humanity’s alienation from itself and its earth through dead technical systems (such as the market, mechanization, computerization and speculation), is to be cured by figural globalism. Life as zoe, the mere life that lives on without a sense of itself, without a world and without form, is to be combated by life as bios: a properly political life of self-formation and speaking in common. Politics ought to be of, by and for the polity: thus, the call to immanence, whereby a body  power. Recall that for Agamben Foucault failed to consider the relationship between biopolitics and sovereign power, between power as instituted law that creates the border between law and non-law, or between governable life and the merely living.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Agamben the problem with biopolitics is that it is insufficiently directed towards bios: both totalitarian governments and democracies focus on well-being and happiness rather than confronting the problem that mere life does not proceed without some sort of gap or decision towards its proper world and end. If one were to recall the Greek attention to bios, or formed life, one might be able to retrieve something of the proper political potentiality that is covered over in modernity. Foucault, however, suggests an opposite path. The problem with biopolitics is not its inattention to bios or self-making but, rather, its maintenance of organic—or what I will refer to here as ‘global’—thinking. One could be misled by reading Foucault’s corpus backwards, concluding that his final thoughts on Greek and Hellenistic arts of the self would be the natural consequence of a theorization of biopolitics, leading to a retrieval of a poetics of the subject. But there are other possibilities indicated in his earliest criticisms of the concept of life. The problem with this concept, or more accurately this problem, is that its manner of folding an inside from an outside, or of producing a relation through which something like knowledge is possible, is—to use a Deleuzian term—its reactive reterritorializing quality. It is the concept of life as such, the life from which bounded beings emerge and against which they maintain themselves, that leads to a certain structure of ethics.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Man becomes that being who is nothing more than a reflective structure, a being whose only law is that of giving a law to himself. The three concepts analyzed by Foucault that constitute the modern empirical-transcendental episteme are life, labour and language. It is because there is something in general called ‘life’ as a process of striving, self-production and self-maintenance that language and labor become the means through which man creates himself as an historical being. On the one hand Foucault suggests that this is in quite a specific sense the consequence of a refigured globe: the pre-modern space of knowl-  of nature, or experience of the earth as possessing its own sense that could be unfolded in various ways in each living form, gives way to an order that appears in representation and tabulation. Man, in classical thought, is not yet that being produced through the act of speech and labour that forms him in relation to a life in general that is only known after the event of its formation. In modernity the globe is no longer the book of nature or scene of readable order, becoming a site of ‘life’ that is now known as the enigmatic progression through which organisms and systems emerge: life is a process that can be read after the event of its ongoing acts of formation. Critically, then, this would suggest that with the politics of life itself something of the globe is lost or occluded. And this, indeed, is how ecological and anti-globalist theory understands both biopolitics and globalism more generally.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What is lost is any sense of the earth as a living whole, as bearing a life and temporality of its own, within which human beings are located and towards which they ought to pay due respect and care. Yet despite the sense that globalism as a political event has erased all traditional and enchanted senses of the globe as a living whole that harbors its own order, the appeals to the figure and normativity of englobed life have become more intense than ever. If Agamben seeks to retrieve a sense of the world as that which man gives himself through speaking in common, and if Hardt and Negri aim to catalyze the self-expressing multitude, then they do so in thorough accord with a tradition and spirit of the self-evident beauty and worth of the organic globe. First, we can note the theological nature of this figure of the self-referring, self-creating living form that has no end or determination outside its own existence.3 Not only is this how the Christian God of monotheism was defined (as a potentiality that has no essence other being in pure act, never deflected from pure self-forming), it is also the case that theological poetics used the figure of the bounded sphere to express a divine intentionality of perfect accord, balance and (most importantly) self-reference. Such a form has its own temporality which is at once linear, organic and circular; it is a time of increasing creation and fruition, in which beings arrive at their proper form and in which the end concludes and discloses the reason of the whole. As an example we can think  divine meets the human in John Donne’s frequent references to globes, circles, circumference and recovery, as though the earth’s form is that of the soul: Then, soul, to thy first pitch work up again; Know that all lines which circles do contain. For once that they the centre touch, do touch Twice the circumference, and be thou such (Donne 2000, 229). Second, this divine, organic and perfectly bounded form of immanent self reference can take the form of philosophy itself: that activity through which human reason refers back to, and redeems, itself by circling back and recognizing its own constitutive conditions.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One could include here Heidegger’s hermeneutic circle, Hegel’s philosophy of absolute self-reference, and more recent and supposedly scientific claims for ‘human’ understanding, such as Robert Wright’s recent claim that the monotheistic figure of God will, organically, evolve to become nothing more than that of human nature understanding itself as the origin of all the figures to which it was once enslaved (2010). Third, and finally, when current ecological theorists continue to refer to the environment—as that which environs or encloses—or call for a due reverence to an earth that bears its own balance and self-ordering, it is once again a figure of bounded form or bios that is maintained against a life that would be a force without sense of itself, a time without disclosure of fruition. The problem with this anti-globalization global tropology is twofold. First, it is inefficacious when one considers the nature of modern power. The twenty-first century is marked by an intensification of diffuse and destructive forces. The cold war and its threat of nuclear annihilation had already troubled the motif of life as a war of interests among bodies, for it was clearly possible that the trajectory of man for survival and dominance was the same path that would lead to his disappearance. The subsequent wave of annihilation threats, from the AIDS awareness of  that no longer concerned themselves with a worldly survival, and then economic crises that exposed an absence of any centered or commanding viewpoint: all these serve to show that the image of the globe, of an interconnected whole, is a lure and an alibi. We have perhaps always lived in a time of divergent, disrupted and diffuse systems of forces, in which the role of human decisions and perceptions is a contributing factor at best.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Far from being resolved by returning to the figure of the bounded globe or subject of bios rather than zoe, all those features that one might wish to criticize in the bio-political global era can only be confronted by a nonglobal temporality and counter-ethics. Second, it follows that far from being an ecological figure that will save us from the ravages of globalism, subjectivism and bio-politics, it is the image of the globe that lies at the center of an anthropocentric imaginary that is intrinsically suicidal. Of course, extinction and annihilation lie at the heart of all life. But accelerated and self-witnessing extinction can only be achieved by a global animal, a ‘man’ whose desire for survival and mastery is so frenzied that he consumes his own milieu. And he does so because his milieu is a globe. If, as recent ‘returns’ to phenomenology insist, the thinking and living being always has a world, and if that world is always a world of meaning—defined in terms of potentialities and the organism’s timeline—then we are truly global. We are bounded by our own living form, with a world of our own folded around our sensory-motor apparatus (Thomson 2007). But does not the phenomenon of a violent, life-annihilating and globe-destroying globalism present us with another possibility?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Perhaps what we need is a zoopolitics: not a lament for the ways in which politics has taken hold of human populations as mere life, but a critique of the ways in which political thinking remains human all too human—repressing the utter contingency of life by insisting on the meaning and form of bios. Rather than criticize biopolitical modernity for rendering mere life as formless, calculative, and void of meaning and mindful creativity, we should cast both bios and zoe on the side of figural lures, and strive to think beyond all forms of life. Neither the mere life of animality nor the formed life of political man, our attention would be better directed to a multiple and divergent net-  power that enables politics, not for regarding man as bios rather than zoe. Rather, the biopolitics that is hysterically and morally regarded as destructive of well-bounded life would still be captured by bios, by the good form of self-producing man and would be better directed towards forces beyond the human, beyond the organism and beyond the globe. The globe or earth as the planet that was blessed with the contingency of life, including the human species whose global imagination has done so much to create destructive systems beyond its own power and comprehension, cannot be saved. Insofar as it is imagined as a globe or living whole with its own order and proper potentiality that might be restored, the earth will continue to be sacrificed to the blindness of an organic thinking that can only insist upon its own self-evident value. One final feature of globalism that needs to be noted, and that might suggest a new counter-global temporality is that of information. There is no public sphere, no bordered polis in which circulating data may be reflected upon, and incorporated; there is no transcendental and procedural ideal of consensus that would emerge as an aspect of an all encompassing life-world.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  According to Habermas, and other theorists of discourse theory, insofar as one speaks or even insofar as one claims to know, an intersubjective claim is presupposed (Habermas 1991, 378); it would be a performative contradiction to say something that one did not also claim to be true (Apel 2001, 47). Insofar as one speaks one is already with an ideal domain of recognition that is procedurally, if not actually, intersubjective and global. But the actual fact of globalism destroys global inclusion, consensus and recognition. There is a glut of speech and a deficit of both recognition and the demand for recognition. The more global citizens seek and demand inclusion the less attention and media space becomes available: every tweet, blog, Facebook post and text message places more and more pressure on the bloated domain of available consumable information. Individual speech acts are not fragments of one grand communicating globe; rather, the excess of production is utterly destructive of any possibility of (even ideal) reception. Indeed, it is the surfeit of information, especially information regarding the limits of the globe (such as data about global warming, resource depletion, new speeds  polis) and demands some mode of schizo-analysis. The latter would refer to a tracking of splits in forces, of divergent systems and incongruous fields.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One may never free oneself from the figure of the globe, or even the globe as the notion of figure—the notion that ‘we’ give a world to ourselves through our own recuperating imagination. But if the present has the capacity to teach us anything it may be this: only a shattering of the globe, with an attention to forces that resist recuperation, incorporation and comprehension—forces that operate beyond intentionality and synthesis—only this radical destruction can save us from ourselves. Notes 1. In his commentary on Husserl’s vision of the task of phenomenology, Derrida notes that any consideration of universal truth, or truth in general, must presuppose a subjectivity that would transcend any specific or determined cultural norm; this would yield humanity as a horizon within which located norms would function, a ‘silent presupposed we.’ Derrida notes, though, that this freeing of humanity from any determined and concrete image of ‘man’ occurs with Husserl’s modernity and the vision of phenomenology as uncovering the transcendental presuppositions of Western thought (Derrida 1978, 61). 2. Michel Foucault argues that in modernity only ethics is possible, only a negotiation of the forms of arguments, and that morality—or the practical judgment of specific forms of life—is no longer possible (Foucault 2002, 357). 3. ‘…this amounts to thinking time and movement on the basis of the telos of the gramme that is completed, in act, fully present, that keeps its tracing close to itself, that is, erases its tracing in a circle.’ (Derrida 1982, 60).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Chapter 4  Earth Felt the Wound: The Affective Divide We are suffering, today—here and now—from hyper-hypo-affective disorder. We appear to be consuming nothing other than affects; even the supposed material needs of life—food, sex, sociality—are now marketed affectively. Branding relies on irrational attachments or ‘lovemarks,’1 while politics trades in terror and resentment. Affects themselves are marketed: one can purchase games of horror or disgust, and even the purchase of a cup of coffee is perhaps undertaken less for the sake of the caffeine stimulant and more for the Starbucks affect.2 This is what led Michael Hardt to theorize a new era of affective labor.3 But this over-consumption and boom of marketable affects is accompanied by affect fatigue, as though there were an inverse relation between the wider and wider extension of affective influx and the ever-diminishing intensity of affect. It is not surprising then that cultural diagnoses of the present observe two seemingly incompatible catastrophic tendencies: a loss of cognitive or analytic apparatuses in the face of a culture of affective immediacy, and yet a certain deadening of the human organism (ranging from Walter Benjamin’s observation of an absence of experience in an information age to Fredric Jameson’s claim for a ‘waning of affect’ in a world of over-stimulation, in which there is no longer a distinction between experiencing subject and external object, no other person, for whom one might feel empathy4 ). On the one hand there is a widespread consensus and diagnosis that the human sensory motor apparatus has departed from an informationalcognitive or even image-based mode of immaterial consumption to one  calculative modes of reason.) N. Katherine Hayles has referred to a shift from deep attention to hyper attention (2007). Bernard Stiegler, working critically from Hayles, has diagnosed a widespread cultural attention deficit disorder.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  He rejects Hayles’s suggestion that this shift or loss might be ameliorated by different pedagogic strategies; more is required than—as Hayles proposes—simply intertwining Faulkner with computer games. Stiegler places the turn to mere stimulus within a broader fault or potential deficit of the human brain, which has always required (and yet been threatened by) inscriptive technologies that extend its range beyond its organic boundaries. For Stiegler, the loss of deep attention is also an atrophy of trans-individual networks: the script technologies that had always supplemented the brain’s power and had also always threatened to weaken that power through externalization and alienation reach new levels of risk. Without extended circuits connecting the reading-writing brain to logics not its own we face the perils of a new infantilism (Stiegler 2009). Techne, for Stiegler, no longer opens the brain onto broader circuits but produces short-circuits. Flickering screens now leave the eyebrain within itself. In a more popular mode, closer to the more panicked tones of Nicholas Carr’s In the Shallows: What the Internet is Doing to Our Brains (2010), Susan Greenfield (2008) argues that we are no longer developing the neural networks or habits that allow us to read with a connecting grammar. We are more oriented to the flashing stimuli of detached intensities, not so much meaning as sensation.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In a contrasting celebratory mode Mark Hansen, whose signature maneuver has been one of returning texts to lived bodies (‘correcting’ Deleuze by way of Bergson, ‘correcting’ Stiegler by way of Husserl), argues that digital media’s simulation of faces has the direct affect of re-engaging the viewer—consumer’s emotive responses thereby redeeming art history and ‘high theory’ from the errors of its inhuman ways: Insofar as the confrontation with the DFI functions by triggering affectivity as, precisely, a faculty of embodied heterogenesis, it operates a transfer of affective power from the image to the body. Instead of a static dimension or element intrinsic  virtualizes the body: the crucial element is neither image nor body alone, but the dynamical interaction between them. As the digital artworks discussed at the end of this article propose, if we can allow the computer to impact our embodied affectivity directly, our communication and our coevolution with the computer—and along with it visual culture more generally—will enter a truly new, ‘post-imagistic’ phase.5 Before we launch into too simplistic a notion of a historical break or fall into a myopic culture of affect we need to note that there has always been an affective component of cultural production, and that this has always been acknowledged and theorized (going back to the ‘doctrine of affects’ [Lenneberg 1958]). It would be more accurate to say that we are witnessing a shift in the cultural dominant. Just as the affective component of cultural production has always been present, so has a suspicion or denigration of the merely felt. The anxiety regarding a dominance of the merely affective or visually captivating in the face of a weakening of cognition has often been tied to a concern regarding the externality of technological and mnemonic devices that supposedly deflect the brain from its proper potentiality. There have always been fears regarding the capacity for technology to weaken cognition, reducing the brain to mere automaton of stimulus interface. This is why Stiegler’s reading of the history of techne as pharmacological is so important: he neither simply adopts Derrida’s history of metaphysics in which writing technologies have always been unjustifiably purged as parasitic, nor celebrates a posthuman digital culture in which illusions of the brain’s autonomy would have been overcome.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Stiegler, any brain-extending system, including the brain’s own mnemic networks, at once enables more complex relations and precludes the brain from ever having a law or propriety of its own. What Stiegler laments is not alienation, technology and loss of internal integrity per se, but the historical loss of individuation where systems would not be general and mechanistic but would enable ‘a’ singular time to be read for all time. It is not technology’s takeover Stiegler laments so much as its reduction to localized stimuli at the expense of  that enables a sense to be intuited that is not that of my present world, and that also allows something like ‘a’ Plato to be reactivated by future generations (generations who can nevertheless read a past time for the present). What the present threatens to do is break those very individuating modes of reading that have created the circuits that have taken individuals beyond the range of their own isolated psyches. This is why, perhaps, Stiegler attributes an individuating potential to social networking sites, such as Facebook (Stiegler 2010, 134). Here, the screen I encounter is not a simply stimulating prompt for rule-bound response but an opening to other speeds and networks. So while it would be too simplistic to create a pure divide between cognition and affect, and similarly inadequate to posit a straightforward historical break between an early era of slow reading and a present of immediate reactions, it is possible to notice within any artwork two tendencies or temporal economies: the connective delays of cognition versus the immediacy of affective stimulus. There is nevertheless, today, a contraction or weakening of grammars and syntaxes of cognition in the face of the instant gratification of affects.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Computer games, and the cinematic and tele-visual cultural products that are inflected by game culture may have narrative and teleological components, but the dominant experience is that of intensities. A culture of shock and awe allows us to sit before a screen and enjoy the affects of horror, terror, mourning, desire, disgust, fear and excitement without sense. This has been one of the long running criticisms of the visual temporality of pornography, in which bodies and movements are displayed without any narrative framing, and certainly without the individuating temporal circuits of care that Stiegler regards as crucial for modes of becoming that would not weaken the human psychic apparatus. The distinction between cognitive-semantic and affective-stimulant aesthetic modes is not purely historical and operates in any recognition of an artwork as art or any text as true. Approaching a text as art requires that it become detached from its functional or communicational mode, at the very least allowed to survive in part as some sort of material monument. The Prelude, while perfectly capable of being translated can nevertheless never be fully translated without remainder. were to offer itself as ‘pure’ truth then its affective dimension, though possibly present, would (or should) be immaterial; by contrast, if one grants an object the status of art then one attributes some monumental quality to its materiality, some sense of an affective component that is that of the art object itself. This dependence of artworks on an autonomous materiality that is essential to the work (whereas pure cognition or logic would aim to be ‘substrate neutral’) would still apply to digital or mass-produced media, for it is digital culture that manages to create an infinitely divisible matter.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The digital codes that enable the continual repetition of a materiality, such as a sound, color or text generated by codes, may be purely formal and substrate neutral, but the outcome of digitalization is the capacity to reproduce matters without any loss or division of the original. It is the clarity of color, sound or resolution that gives digital culture its force, intensifying the capacity to experience sensible qualities in the way that it was once able to transfer semantic content alone. Digital culture could therefore be either purely formal and cognitive, with the manipulation of digits and empty variables, or predominantly affective with digital technologies enabling the simulation of stimulating matters. What is significant is digital culture’s tendency towards a far more strict retraction to the digit or the circulating unit: even when visual culture is not digital in the sense of being digitally rendered into codes for computer replication, there can be a restriction of attention to the already established digits or units of communication. If one laments the waning of a culture of reading and the loss of deep attention in favor of hyper-attention then this may also count as a mourning for analog modes of reading, whereby there was not a direct passage or translation between stimulus and response but a delay in assessing what counted as a unit of information or input. The very history and possibility of reading relies on a complex relation between digital and analog. All reading operates by way of digitalization, or—as Bergson noted—a capacity to reduce differential complexity to already established units of recognition; without that reduction of differential complexity perception would be paralyzed precisely because the influx of intensity would be too complex to master or recognize (Bergson  the speed, and therefore the greater the efficiency. What appears to be operating today is a high degree of digital distinction and accuracy, precluding the need for interpretive delays.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Digital culture would include not only computer digitalization in the narrow sense, but a culture of speeds whereby stimulus circulates without translation or transfer, where there is a single circuit of relay. This would begin to explain why attention deficit is actually the need for more stimulus—precisely because there is increasingly less delay or depth that requires decoding. We are at one and the same time constantly bombarded with new intensities, and yet the simplicity of the codings enables quick consumption, and then the demand for more. The various diagnoses of attention deficit, which descry an over-consumption of affect, often rely upon a historical narrative regarding the dialectic between cognition (or reading as) and affective pleasure (or stimulant vision). The eye-brain is abandoning or self-extinguishing one of its evolved powers, and one sees this exhaustion of the power of sense and the hypertrophy of sensation not just in the proliferation of new media but in the invasion of new media speeds into traditional media. Non-digital forms of production are altered, now, by digital speeds; ‘high-brow’ novels (such as David Mitchell’s Cloud Atlas) are composed from bite-sized chunks assembled to yield multiple and dispersed viewpoints. Even seemingly slow and manifestly human-centered cultural productions, such as the unstructured reality television events of Big Brother or Jersey Shore, rely not on plotting and character development so much as the capacity to pick up or leave the screen at any point. Such works are unsigned or devoid of sense precisely insofar as they are less events of production, created to stand alone or possess a certain force, as events of consumptive immediacy: the camera simply takes up whatever is there to be passed on and viewed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It would be too easy and inaccurate to align cinema and television with immediacy and stimulus, and reading with grammar and deep attention. Cinema and visual culture can be both narrative-semantic and stimulant-affective, just as literary forms can start to emphasize episodic affects rather than narrative coherence. Perhaps the success of Fifty Shades of Grey lies both in its claim to be erotica,  distinction between stimulus and affect: the former is neutral and presemantic, and could either be read as information or merely felt. But affect is often associated with the merely, solely or simply felt as though it were only stimulus; this conflation is at the heart of hyper-hypo affective disorder. For if affect could be distinguished from cognition and yet still have a non-informational or non-semantic sense then one might find a way of overcoming the deep mourning for a culture of meaning and deep attention without celebrating the brain’s self-extinction. That is, there might be something like affect that would not be feeling, and that would not be reducible to the organism’s stimulation. Something of this isolation of affect is being sought, I would suggest, in Deleuze and Guattari’s (1994) idea of art as the production of affects that stand alone.) Any historical divide or paradigm break can be intuited only by distinguishing tendencies within mixtures; there are no hard and fast lines, but there are dominants and distinct inflections.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The capacity to reflect upon the relation between felt stimulus and conceptual order was long ago placed within the artwork in Kant’s aesthetic: one feels the influx of sensation but not as bodily pathos. Rather, it is because the sensations are not yet conceptualized, and yet conducive to conceptualization or thinking, that the subject feels her own forming power. This feeling is not pathological—not a bodily sensation, and not emotion—but the feeling of the relation between the world that is given in sensations, and the subject’s capacity to synthesize sensations. Lyotard, writing on Kant, referred to this process as tautegorical: it is not the imposition of the subject’s categories, but the subject feeling itself feeling: ‘Tautegorical: this is judged absolutely great because the thought that judges this feels itself to be great absolutely’ (Lyotard 1994, 81). The feeling is not individual, but individuating, for it gives me a sense of myself as a forming power, as capable of being a subject. The experience of beauty is the experience of that which ought to find its way to some communicable sense, not the sense of what this object is, but a sense of how this sensation would feel—sensus communis. The Kantian concept of sensus communis anticipates what Stiegler (following Simondon) refers to as trans-individuation: technologies create networks that allow the reading-viewing brain  circuits of thought beyond any individual brain and body, even though those very same technologies that inscribe a supra-individual circuit of thinking and reflecting may—as in the case of modern media technologies—become short-circuited, reducing the cognitive and affective range of the embodied brain. What is important in Stiegler’s critique of current media technologies is that he regards media in all its sense not so much as mediation, or the means through which thought is communicated, but as constitution: selves thing, live, feel and remember through the inscriptive and affective networks of their time and milieu.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Stiegler affective force and range is diminished the more bodies are turned back and inward upon sensation and stimulus. Closer to the Kantian legacy there has been an art-critical tradition of considering affect not as bodily feeling but as the sense of a work, where sense is an orientation prompted by perceived relations. What this implies is that viewed objects, or relations of viewing, have distinct promissory temporalities: reflective judgment, enabled by art, offers the sense of a feeling of humanity in general, what ‘one’ would feel. It is in this tradition that Deleuze draws upon Worringer’s (1953) art-historical work to place the relation between cognition and affect within art history: early art is geometrically abstract, giving order to the world; but this is superseded by empathy or the depiction of organic forms that one might perceive and feel. Deleuze then places this historical problem within the work of Francis Bacon: how can one paint the body not as an organism one feels but as a figure emerging from forces not its own? Deleuze and Guattari also write a pre-history of the reading eye that is directly political: the eye moves from being a collective organ, feeling the pain as it sees knife enter flesh, to being a privatized reading machine, viewing the cut of the knife as a sign of a punishment for a transgression committed and a retribution to be paid. The eye becomes organized as a reading and memory machine: the voice no longer sings but dictates, decrees; the graphy no longer dances, it ceases to animate bodies, but is set into writing on tablets, stones, and books; the eye sets itself to read-  This formation of the reading eye occurs also as the organization of the body, which becomes an organism in which seeing, hearing, speaking and touching all fold in on the private body who can now view the world as a single matter determined from ‘a’ point of order. (This organization is an event of deterritorialization, for a term outside the system of relations now determines relations from some privileged point).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  With that Deleuzo-Guattarian work in the background it is not surprising that there has been a celebration of affect, as though affect would release us from the ‘despotism of the signifier’ (or, more broadly, the tyranny of Cartesian and computational paradigms). And yet it is the event of privatization, with forces or pure predicates being referred back to the single organizing living body that is celebrated by the ‘affective turn.’ Much of what passes as Deleuzian inflected theory champions precisely what Deleuze and Guattari’s projected future would go beyond. While Deleuze and Guattari chart the genesis of the organized body from affects, and then describe the organization of those affects (now as lived) by way of the unified organism of the man of reason, this does not imply that they want to return to the site of genesis, return to the embodied lived affect that has been alienated by the axiomatics of the single system of capital. On the contrary, the problem of affect—the truth of affect, which would be something like force as such—cannot be retrieved by a return to the body. Rather, for Deleuze and Guattari, capitalism is not axiomatic enough, not inhuman enough. It suffers from an anthropomorphism that can also be tied to contemporary hyper-hypo-affective disorder. Capitalism, if pushed to its maximum potential or ‘nth’ power, would open the relations among forces to produce multiple differential quantities. As long as everything is organized according to consumption and production (in terms of the digits of the private organism) the potential for forces to be produced—such as affects—will always be grounded upon affections.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The visual production of the affect of horror or terror will be oriented to horrifying or terrorizing (as in many horror films or political campaigns). As long as affects are confused with affections, or feelings of the lived body, then nothing will ever be felt; the body will only re-live itself. consumption and production but also of criticism and ‘theory.’ The ‘affective turn’ accounts for the emergence of language, music, morality and art in general by referring to the lived body’s desire for self-maintenance. (In a similar manner the ethical turn was also a turn back to social relations, feelings and duties: and we might ask why this turn back occurs just as humanity is facing a world where there may be an un-lived?) Deleuze and Guattari offer a complex history of the relation between brain, body, intellect and affect, and follow Bergson in arguing for a history of thought’s different powers, with technologies of concepts and artistic methods allowing at once for organic unity (the sensory motor apparatus that reduced all to efficiency) and for another tendency to think time as such or difference as such. Concepts, for example, reduce complex differences to generalities so that thinking can proceed efficiently, in the service of action. But there could also be concepts that destroyed expediency and action—such as the concepts of justice, democracy, humanity—but that opened thinking to a future. What might justice be?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The same might be said of affects: it would only be by destroying affections— the ready and easy responses craved by our habituated bodies—that one might enable affects. If Deleuze’s work has seemed to license a return to lived and bodily affections this should alert us to the constant tendency for relapse and re-territorialization in the brain’s relation to its world. Deleuze and Guattari were critical of a historical tendency of paranoid capitalism: the tendency to read all events through the scheme of the individual set over and against of world of differences that can be felt and lived as his own. Any supposed private affection, they argued—including parental love—opens up to all of history, and ultimately the ‘intense germinal influx.’ We need to turn back from organized units and feelings, not to the lived body, but to the quantities and relations of forces from which identifiable bodies and sentiments emerge. The mother arrives as already organized, racialized and historicized, and (similarly) the love between any couple carries all of history and politics with it. In the beginning, Deleuze and Guattari argue, is not the body and its affections, but the affect. There is the force of knife and flesh, or the dazzling light of the screen; bodies become organisms through the affections composed from  So what can we say about both the ‘affective turn’ in theory, and the addiction to affections at the expense of affect, especially if we do not want to fall too easily into a joyful historical break or mournful nostalgia? It is not new to diagnose an epoch.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Freud placed modernity at the neurotic end of the spectrum, suggesting that an over-fixation on symptomatic displacements needed some release. Our desires, he suggested, did require some form of social organization for the sake of civilization, but with the stringent requirement to love all of humanity it would not be surprising if aggression would then be unleashed in the form of total war. For Freud, culture had become overly neurotic, investing unreasonably in what (for Freud at least) was a dispassionate (inhuman or overly ideal) figure of humanity. Today, we might think the pathology of collective desire differently. Perhaps we have swung towards psychosis—not so much tied to libidinal containment and repression as lacking all sense of order, generality, universality or transcendence. If Deleuze and Guattari appealed to schizophrenia they did so against what they saw as the paranoia of modern capitalism—the over-attachment to a single system in which any event or affect would be the sign of one single system of life, a life that becomes nothing other than the interaction and exchange of quantifiable force (a simple digitalism of a single axiomatic). Deleuze and Guattari’s schizoanalysis would split or de-synthesize forces, not reducing all flows to a single system of exchange. And this splitting would give force a ‘stand-alone’ quantity, creating it neither as felt-stimulus nor recognized generality.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It would short-circuit hyper-hypo affective disorder: the over-stimulated appetite for consuming affects alongside the hypertrophy of the capacity to think affectively. Whereas affect-empathy and abstraction-cognition have been noted as opposing historical and formal tendencies, the present’s diagnosed retreat into affect-sensation evidences not a tipping into one of these modes or the other but their indistinction; it is as though there can be no abstract conceptual thinking that is not confused by ’feelings,’ and no experiencing of affects that is not already generalized or pre-marketed and ’branded.’ So we need to note first that there is a growing market in pre-packaged, already-consumedconsumable affections. And yet it is for this reason that there is no affect. some orientation or sense of affect this was never that of a simple bodily response or lived feeling; what was attended to was not an affection but a force that would yield an affection. Affects would be ‘stand alone’ powers, possessing a certain autonomy. One would need to distinguish affect— such as the terror of tragedy—from the affection of being terrified, and these tendencies would have different temporalities. Affect would have to do with the artwork’s capacity to create circuits of force beyond the viewer’s own organic networks. The notion of the autonomy of affect—or affect being corporeal but non-cognitive—was theorized by Brian Massumi, who argued for a range of bodily responses that bypassed conceptual or emotional sense (Massumi 1995).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Antonio Damasio (2000) also argues that there is, in addition to the feeling of what happens in the body, another dimension of the organism’s response that is not attended to. For Damasio this unattended proto-self is the ground and condition for the more conscious self, while for Massumi this non-cognitive dimension has a political force that needs to be considered today precisely because it is barely registered. But we might, given the contradictory celebratory turn to affect, alongside the mourning of the human loss of more sophisticated responses, want to ask about the contemporary specificity of this range of the non-cognitive affective body. If we are suffering from hyper-affective disorder this is because a potentiality of the body for undergoing stimulus but without conceptuality and attention is now no longer a background condition but accounts for the desiring structures of contemporary culture tout court. The social and political organization of bodies does not occur by way of ideas or beliefs—the imposition of semantic content or structure—but by way of affective addiction, either to the diverting stimuli of personal screens and headphones, or to the bodily stimulants of caffeine, sugar, tobacco or other widely ingested and publicly legitimated substances. If the constitutive human condition was once deemed to be Angst—a sense that there might be some event, without any fleshing out of just what that event would be—or if the dominant mode of politico-economic affect was once that of speculation (a paranoid control of all events into a single system [Colebrook 2012B]), then we can observe a new and possibly  have perhaps become psychotically detached from any object domain, ‘experiencing’ the immediacy of affects without any sense that we are being affected by a world of which sensations would be signs. We may well be in an era of a new self-enclosed narcissism, each ‘individual’ being nothing more than a privatized bubble of instantaneous intensities. Or, more accurately, rather than lamenting a narcissistic enclosure, what might be wanting would be narcissism: we are no longer entranced or motivated by a better image of ourselves.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  There is an absence of selfimage, a supposed liberation from the figure of myself as a beautiful or worthy ‘member of humanity;’ yet it is just such an image that would release me from being driven by the immediacy of sensations. (Is not the popular refusal of stereotypes, along with a certain academic critique of normativity as repressively normalizing, indicative of a refusal of anything other than the self as pure performance, an affirmation of active immediacy and a horror of any element that would not be included in the dynamism of life that is always already the self ’s own?) Many of the celebrations of affect today, directed as they are against the linguistic paradigm or intellectualist or Cartesian accounts of the self, valorize a model of life in which the self is not really a self at all. There is not an enclosed individual who then represents the world; in the beginning is the relation or affect, from which some relatively stable responsive center emerges. Jeremy Rivkin argues not only that we are presently driven by affect and that affective bonds precede the formation of individuals and competitive aggression but that empathy is the human civilizing drive tout court (2009). Antonio Damasio, along with Joseph LeDoux (1996) and Maturana and Varela (1987)—and many supposed Deleuzians continuing their emphasis on embodiment and living systems—have turned theory and analysis away from the cognitive, conceptual or reflective dimensions of experience towards embodied, distributed and autopoietic selves. Damasio argues that the background self is largely unnoticed, and that ’Descartes’ error’ consisted in taking the fragment of the responsive self that came to attention as some sort of center or representing ‘theatre.’ Maturana and Varela, insisting on the embodied nature of the mind, reject the notion of ‘a’ world that would then be pictured or known  horizon of possible affects to which bodies would respond. The Cartesian subject is not only a philosophical error; it is embedded in a tradition of Western individualism in which minds are set over against a world that they quantify and master.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A more mindful tradition, closer to Buddhist models of selflessness, would not only be more correct, but may help us in domains as diverse as artificial intelligence and management studies (Flanagan 2007). All these turns in theory are, I would suggest, both expressive of and reactions against hyper-hypo affective disorder. That is, it is precisely at the point at which we have become glutted with affect—so consuming of affects in a blind and frenzied manner—that theory insists upon the intelligence and profundity of affect. This complex reaction formation is similar to the three sides of the obesity epidemic: we stuff ourselves full of food at indiscriminate speeds, cannot taste or discern anything outside its pre-branding (for we have to be alerted to a food being ’chicken-flavored’) and yet all this is accompanied by a new genre of food porn: master chef competitions, the spectacle of celebrity chefs, restaurant menus that require literary criticism and the migration of artful food depictions from the genre of still life to advertising. Similarly, we gorge on affections yet cannot get the sense of any affect, and all the while live in an age of theory that wallows in the autonomy of affect. Whether we regard the predominantly affective self as a loss of a subject whose identity would yield greater social responsibility and awareness (mourning cognition and grammar in the widespread loss of attention), or whether we see the Cartesian tradition as something better left behind, there seems to be agreement that there has been some affective turn (Gregg and Seigworth 2010; Clough and Halley 2007). This occurs not only at the level of theory, where we recognize the error of the linguistic paradigm or the cognitive or computational models of the self; it also occurs in a widespread shift in perceptual mechanisms and relations. It is possible to say that that we are indulging in affective over-consumption and that cinematic and marketing devices have responded by remaining constantly innovative: the genre of ‘torture porn’ both reflects and reflects upon this hyper-affective addiction trend.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  On the  or novelistic imagination of a life lived as a trajectory towards wholeness, recognition and social meaning—whereby I consider myself from the point of view of the better self I would like others to see me as being—it is also possible to note a contrary tendency towards waning of affect. I would, though, want to give this notion of affective hypertrophy a different inflection from Fredric Jameson’s criticism of a postmodern subject who, deprived of historical connectedness and any broad political sense, becomes nothing more than a schizoid field of intensities, caring little about social trajectories or class consciousness ( Jameson 1991). In many respects hypo-affective disorder occurs alongside a strongly informational, if not narrative, attentiveness. There is no shortage of information about the dire threats posed not only to the future of the human species, but also to the current financial, ecological, political and bureaucratic systems upon which present generations rely in order to survive. Predictions regarding catastrophic economic disorder, imminent resource depletion, viral devastation, chemical warfare, bio-terrorism, rogue states in possession of nuclear weapons or unforeseen disasters brought about by various genetic technologies seem to have had little effect on behavior and decision making despite their widespread narration and imaginative rehearsal. In addition to explicit thought experiments such as Alan Weisman’s World Without Us or the television series Life Without Humans, or one-off documentaries such as Aftermath, cinema of the last decade has intensified and multiplied a long-standing tradition of disaster epics entertaining the possibility of the annihilation of the species. Whereas these were once imagined as exogenous events (usually the invasion of alien species), climate change and viral threats now dominate the cinematic imaginary. Novels such as McCarthy’s The Road or Atwood’s Oryx and Crake begin in a world in which devastation has occurred; just what event led to such a situation can quite easily remain unstated precisely because the idea of a near-posthuman world is today utterly plausible.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  To call such novels or films post-apocalyptic misses their significance, for there is not only no apocalyptic revelation or dramatic disclosure, there is also no real sense that there need be a radical intrusion or disturbance for such worlds of depletion and posthumanity to appear. Yet, despite all  that would indicate that anyone really feels or fears the sense of the end. Climate change denial is one thing, and possibly more rational than climate change awareness coupled with minor delusory negotiations (such as cap and trade, mitigation, adaptation or any of the other bargaining strategies). The affective turn is not then a solely academic or theoretical correction to the supposed linguistic paradigm of high theory; it is also a pathology of the populace (which is certainly not a polity, for it has nothing to do with bodies assembling to speak, deliberate and communicate in common). There is a passion for affective consumption that is extensive—more affective input please!! !—but inversely devoid of intensity. There is nothing effective or affective about affections; and this includes the fact that we constantly remind ourselves of the primacy of the affective and insist that in the beginning is the emotive attachment, and then proceed to act as if the same old cognitive rules applied. We recognize our affective core, repair our theory and then proceed with argument as usual.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Our response tends to be pharmaceutical rather than pharmakological: that is, just as we deal with ADD by providing the brain with chemical stimulus (because ADD sufferers fail to focus because nothing is stimulating enough) so we have dealt with our affective hypertrophy (our inability to sense) by over-consuming and over-producing affects. How then might we assess the seeming dominance of or addiction to the intensities of affect—including the direct marketing of affects in ‘feel good’ experiences or the horrors of torture porn—alongside the no less apparent atrophy of affective response to an overload of information regarding genuine threats to organic life? Perhaps the way in which affect itself has been theorized might indicate a peculiar structure that would go some way to accounting for this divide. What if the concept of affect were potentially a formation that would shatter the organism’s emotive enclosure? It is possible to see affect as a concept in Deleuze and Guattari’s sense: it would not be extensive—referring to an already lived and actualized set of phenomena—but would be intensive, creating new relations and lines of thought, opening different mappings or potentials among what  is in the not acting, or in the receptivity without responsiveness or relation that affect occurs. Affect becomes a genuine concept when it poses the possibility of thinking the delay or interval between the organism as a sensory-motor apparatus and the world that is (at least intellectually) mapped according to its own measure. If we do tend to conflate affect with emotion—if we do not mark a distinction between the feeling of what happens and a whole domain of pulsations and fluxes beyond the perceptions of the organism—then this is symptomatic of the tendency to reduce the force of concepts to the lived. And is it surprising that the concept of affect with its potential for thinking of forces detached from the lived, from the organism’s responses, from feeling and from emotion would be reduced to an association with thoroughly humanized notions of meaning?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Such problems are particularly important today when the distinction between affect and emotion may go some way to allowing us to envisage life beyond the organism. For it is life beyond the organism—both an actual world in which organic life has been extinguished and a virtual world of potentialities that are not lived—that has become increasingly unthinkable. Such a world may exist (dimly) at the level of affect but not at the level of feeling and the lived. On the contrary, what is presented as potential affect (a world without us) is reduced to affections—feelings of horror that are resolved ultimately as redemption narratives. That is, there is an industry today built on the affective lure of humanity’s and possibly life’s non-existence: this would include high culture installation pieces that feature machines, mechanized robotic humanoids, lost objects and automated sound productions (something like Thomas Mann’s camera without person at the end of Death in Venice) to popular visions of a life without humans, such as the sublime opening scene of Danny Boyle’s 28 Days Later of 2002 (or the conclusion of Matt Reeve’s Cloverfield (2008) (where a supposed department of defense filming of the last humans to have suffered from a violent viral intrusion plays out to the film’s end). There is a widespread circulation of the image of life without life, of witnessing without vision. Or, at least, one might begin to note that there is a disjunction between affect and the lived and that what might at first  eventually become a difference in kind, such that there would be affects that ‘stand alone.’ Now might be the time to begin considering affect not as the base or ground from which cognition has been abstracted, nor as a primarily embodied and barely lived near phenomenon, differing in its intensity from fully fledged and conceptualized experience, but as a power or force with a tendency to persist or endure. When Brian Massumi wrote about the autonomy of affect he was referring to somatic responses that not only exceeded the cognitive but also the level of feeling and emotion.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (His examples included a melting snowman and President Reagan. Images of both produced bodily responses that could not be mapped onto cognitive values of affirmation or negation, and were not felt as emotions that would then prompt action or belief. In the case of the melting snowman, the children who reported on their felt responses were at odds with their bodily responses; what they described as memorable and pleasant was—when measured physiologically by heart-rate and galvanic skin activity—of a certain intensity rather than to do with content). [T]he primacy of the affective is marked by a gap between content and effect: it would appear that the strength or duration of an image’s effect is not logically connected to the content in any straightforward way. This is not to say that there is no connection and no logic. What is meant here by the content of the image is its indexing to conventional meanings in an intersubjective context, its socio-linguistic qualification. This indexing fixes the quality of the image; the strength or duration of the image’s effect could be called its intensity. What comes out here is that there is no correspondence or conformity between quality and intensity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If there is a relation, it is of another nature. (Massumi 1995, 84-85) The disjunction between quality and intensity may, in the case I would like to conclude by considering, be one of disjunction or reaction formation. That is, the higher the degree of threat to the organism, the more the quality of affect is that of terror or sublime annihilation, the more disen-  posthuman existence, and yet have no intensity: it does not prompt us either to action or to any sense of what a posthuman world would be. On the contrary, the more evidence, imagery, feeling and ‘experience’ of a world without humans is displayed, the less affect or intensity occurs. In fact, both theory and experience become increasingly organic: with thinkers ranging from Maturana and Varela, to philosophers such as Evan Thompson and Andy Clark insisting that the world we are given is exhausted by the world as felt or lived (Clark 2003; Thompson 2007). ‘We’ are now living a world of popular, academic and ‘high’ culture in which scenes of human and organic annihilation are repeatedly and obsessively lived, and yet at the cognitive level we continue to affirm the primacy of the world for the embodied, emotional and living organism. Man is no longer homo economicus or homo faber, defined by enterprising activity or production, but by feeling. What is occluded is the unlived, that which occurs both at the level of somatic responses that fail to be registered (other than by their negation at the level of reaction formation, with the shrill affirmation of emotion).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What is also occluded is what Deleuze and Guattari theorized in What is Philosophy? as the definitive capacity of art—an art that occurs outside the human and beyond the organism: affects stand alone, exist in themselves and cannot be reduced to the lived. On the one hand this appears to be an example of a privilege accorded to high modernist aesthetics, in the assumption of an art object that breaks with the bourgeois banalities of consumption and enjoyment. On the other hand, though, there is a sense in which Deleuze and Guattari’s distinction among art, philosophy and science—and, in turn, their geneses of these potentialities outside the organism—also breaks with the high modernist aesthetic of art as cultural revivification. That is, if modernism separated the art object from feeling and emotion in order to break with social codes and conventions of consumption, it nevertheless re-humanized or re-vitalized affect: that is, art restored thinking to life and returned life to thinking. There was a sense that critical art might return thinking to the sense of its own emergence. A debased form of this aesthetic occurs today with many of the wars on the banality of images  dehumanizing—for such denunciations seek to restore individual perception, autonomy and feeling). What Deleuze and Guattari suggest in all three of their potentialities for thinking—creation of concepts in philosophy, of functions in science, and affects and percepts in art—is a locus of production outside the organism and outside the lived.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Brian Massumi, separating intensity from quality, nevertheless located affect entirely within the living system: Both levels, qualification and intensity, are immediately embodied. Intensity is embodied in purely autonomic reactions most directly manifested in the skin-at the surface of the body, at its interface with things. Depth reactions belong more to the form\/content (qualification) level, even though they also involve autonomic functions such as heartbeat and breathing. The reason may be that they are associated with expectation, which depends on consciously positioning oneself in a line of narrative continuity.’ (Massumi 1995, 85) For Massumi affect occurs as the event or disruption into social coding of the newness of a (not-yet narrated or linear) disturbance. Deleuze and Guattari, in their chapter on affects and percepts, give a relatively clear instance of the autonomy of percepts—prior not only to human, but also to animal life. They describe the stagemaker bird, organizing coloured leaves to assemble a territory. The bird is only able to move and self-organize because there are expressive matters that enable processes of assembling: in the beginning is neither the doer nor the deed but the matters to be dealt with (Deleuze and Guattari 1994, 184). The coloured matters precede and are followed by the bird, with the bird becoming a functional and defined organism through this assemblage of autonomous sensory qualities.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  When art captures sensations that stand alone—as though the perceptions of organisms would only be possible because of these autonomous potentialities of percepts—then this is relatively easy to understand, as though a Mondrian or Cezanne drew upon, rather than produced, the vibrations of colour. But how could we say the same of affects, render them autonomous, inhuman and inorganic, in a  There is some indication in Deleuze’s book on Francis Bacon of how art might capture affect in its autonomy—not simply its distinction from symbolic orders and cognition (as in Massumi) but in its inorganic or incorporeal moment. Deleuze refers to Bacon’s painting of the scream— not the feeling of horror, felt by the body, but a depiction through the body of the forces that seize it:. Unlike a viewing of A Nightmare on Elm Street, the viewer is not horrified—the work does not cause horror—but we are capable, supposedly, of witnessing affect, not as felt or lived but as force beyond the organism and its meaningful responsiveness: If we scream, it is always as victims of invisible and insensible forces that scramble every spectacle, and that even lie beyond pain and feeling. … Bacon creates the painting of the scream because he establishes a relationship between the visibility of the scream (the open mouth as a shadowy abyss) and invisible forces, which are nothing other than the forces of the future (Deleuze 2005: 43) But are these forces really affects, or the forces from which affects are composed? And is their depiction by Bacon, via the screaming body, really akin to the pure sensory qualities that we can think of in the use of colours or expressive matters? Some provocation is given by Deleuze’s phrase, ‘forces of the future,’ for it is here that we might think affects beyond the era of humanity, both in traditional modes of literary expression and in recent genre shifts. How are affects created by art if they are not expressions of some artist’s or character’s psycho-physical organism?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  How could affects possess that stand-alone inhuman inorganic quality that percepts seem to do when they provide potentials for assemblages (rather than being derived from them)? There would be no easy answers to this problem; it should not be easy to distinguish between art that makes us feel joyous—tapping into our sensory motor apparatus—and art that is joyous, that intimates a joy outside humanity and organisms. (What, for example, is trance music: a drugging sound that detaches us from meaning and the traditional temporal lines of chord progression and development, or a physical pulsation that operates directly at the  Canonical literature gives us some indication of an autonomy of created affects that are not those of the organism, as though art could give body to that which exceeds the lived. Adjectives such as Kafka-esque, Dickensian or Lawrentian and Orwellian refer to affective assemblages that are not those of characters. Nor do such affective complexes prompt us to feel absurd bureaucratic torpor, oppressive urban paternalism, phallic atavistic passion or nightmarish social surveillance: it as though these worlds offered affects as such, there to be lived, as if they existed as potentialities for all time, even if captured through the depiction of a certain time. Such expressions pass into common parlance and refer not to a style of writing so much as the potentiality of that writing to seize on forces that it manages to assemble. If we travel through middle America we might view certain scenes as if captured by a David Lynch or Raymond Carver. Beyond canonized art there are today many attempts to capture affects beyond the lived and humanity: books (and television series) such as Alan Weisman’s The World Without Us or cinematic scenes such as the opening of 28 Days Later, along with a vast range of unremarkable nature documentaries do not only depict worlds and life beyond humans, but can also suggest (perhaps) a melancholy or joy of a world without living witness.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It would be telling, then, in the face of this tendency to imagine or contemplate joys, depressions, horrors and screams outside the lived—and right at the moment of possible human self-annihilation—if theory were unable to think affects beyond the lived world of the bounded organism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  5. Mark B.N. Hansen, ‘Affect as Medium, or the `Digital-Facial-Image’’ Journal of Visual Culture 2.2 (2003): 205-228, 208. Chapter 5  Destroying Cosmopolitanism for the Sake of the Cosmos What would the value of cosmopolitanism as a concept be? How might it work and what problems might it resolve or transform? Today the term intersects with globalism, offering itself as a mode of connection or collective resistance that would enable a thought of some political totality or ‘open whole’ irreducible to the forces of the market. The problem appears to be posed, from Kant to the present, as a way of thinking beyond human to human conflict—seeking a higher order beyond interests of individuals and polities. Cosmopolitanism appears to be a self-evident good: is not the very concept of the good oriented towards that which would be or could be a good for all?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Insofar as we rationally will anything at all we seem not only to be claiming something for ourselves as particular persons, but also to be appealing to some ideal or idea as such that could be agreed to by any subject whatever. Cosmopolitanism is at once in line with a purely formal or procedural liberalism, but also has the benefit of appealing not only to that which ‘we’ here and now agree to be good, but beyond that to some virtual humanity not yet present: ‘Cosmopolitanism … starts with what is human in humanity’ (Appiah 2006,134). If cosmopolitanism is a universalism that is also not the assertion of one’s actual goals as the goals of all, but indicates an ideal of maximal inclusion and self-critique, who would assert the contrary? And what would the contrary thesis be? That we are all, inevitably, bound up with local attachments incapable of truly transcending the particular? No, even that suggestion is already incorpo-  uniform humanity. Cosmopolitanism is not the reduction of all difference to a single model of citizenship; it is, rather, an Idea of a polity— a gathering of bodies for discussion, decision and determination—that would not be that of this or that nation but of the cosmos. We might say that the cosmos is an Idea in the Kantian sense: we require the notion of the cosmos in order to think the relations among different localities, and this Idea generates a task for future thinking, but such an Idea can never be fully actualized or presented.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Perhaps, today, this cosmopolitan idea is more urgent and more possible than ever. Surely it is the advent of (increasingly evident) threats to this cosmos—resource depletion, rising sea levels, global heating, desertification, species extinction, viral apocalypse, violent fundamentalisms, bio-weapons—that impel us to free the polis from the nation state and imagine a greater cosmos. For is it possible to say any more that politics occurs at the level of the state or nation? If decisions are made in the name of national polities, such as recent decisions to put environmental policy on hold in the face of economic imperatives, or of the compromise of claims for rights to life and universal health care because of a need to sustain fiscal responsibility and corporate structures, then what one appears to lose is not only the space of the cosmos but also a certain modality of the future. Decisions based on polities of the nation state are enslaved to a temporality of competing interests, whether that be the political terms of opposed parties or—if one is dealing with nation to nation negotiations—calculations regarding markets, future flows of capital and investment and Realpolitik. A cosmopolitical imperative would not only expand horizons spatially— to think beyond the geographical boundaries that create political, cultural and imaginary borders—it would also necessarily alter temporal limits. Globalism as an economic phenomenon in which territories once external to the nation state are included in ever-expanding and mutating markets would need to be supplemented or transcended by a cosmopolitanism1 that imagined modes of sympathy, recognition and respect beyond the terms of the market.2 If cosmopolitanism were truly to distinguish itself from globalism then it must not do so merely in a spatial and extensive manner (being more inclusive) but would need to differ inten-  organizations and geographical borders (all included in the systems and networks of globalism); the cosmos would, in its new mode, include a virtuality. Traditionally the cosmos signifies an orderliness, suggesting that the actual globe as material entity is placed within, or expressive of, a broader harmony (a cosmos of the planets and heavens).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In contemporary forms of cosmopolitanism such appeals to divine or eternal harmony give way to an imaginative supplement: whatever the world is here and now, with all its global networks, markets and power structures, there can also be the figuration of ethical territories. Above and beyond physical and political borders there might be affective or immaterial communities, such as Michael Hardt and Antonio Negri’s redemptive positing of a humanity united by ties of immaterial labor (Hardt and Negri 2000). The political times and the mode of production have changed. We have to construct the figure of a new David, the multitude as champion of asymmetrical combat, immaterial workers who become a new kind of combatants, cosmopolitan bricoleurs of resistance and cooperation. These are the ones who can throw the surplus of their knowledge’s and skills into the construction of a common struggle against imperial power. This is the real patriotism, the patriotism of those with no nation. (Hardt and Negri 2005, 69) These territories would not be extensively spatial (a portion of the globe) but intensive—a space of infinite hospitality without limit, a city of refuge that occupies a virtual space, a community that is not grounded upon a common soil or even a normative notion of the citizen (Derrida 2001, 8). Such a virtual or spiritual humanity (that could no longer be reduced to man as an organism) was already imagined by Bergson in his Two Sources of Morality and Religion.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Bergson’s work on the distinction between morality and religion was part of a broader project that aimed to intuit, from the actual world’s present state of complex phenomena, the tendencies that had enabled the emergence of the current state of things and that would indicate possible futures. If we have, today, a complex mixture of  (yet coupled) forces in the groupings of human bodies. Morality is an extension of the organic and material need for survival; it makes sense at the level of our merely biological or instinctual existence to gather into localized units, establish basic order, defend ourselves from others and imagine others to be rather like ourselves. If instinct is the tendency that enables organisms to act for the sake of their own preservation, then basic morality is instinctual. If intellect is another tendency—this time allowing for generalization and abstraction beyond individual survival—then this, too, would account for more complex social groupings—such as the nation state, or even ‘man’: such groupings would be based on a calculation of the present for the sake of a future that is akin to the present. I might die for my country, my children, or even act somewhat selflessly by consuming fewer resources for the sake of future generations that I imagine to be an extension of the present. Morality, Bergson argued, would proceed from social groupings and recognition: the intellect would not be limited to animal self-interest and immediate gratification of needs but would imagine a life beyond the present, and bear sympathy towards individuals beyond itself and immediate family. Morality sacrifices the demands of present pleasure for the sake of future security and the formation of a public good.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But Bergson posited another tendency that was also a different mode of temporality: spirit, unlike intellect, was not generalizing and extensive (creating categories that would reduce minor differences for the sake of inclusiveness and efficiency). Spirit would slow down the speedy and manageable reduction of complexity and instead begin to intuit differences, rhythms and perceptions beyond its own purview—beyond the range of ready-made concepts. Religion is different in kind, not degree, from morality. It would be a mistake to see something like Pauline universalism as the extension of sympathy to include all of mankind, creating a ‘family of man.’ It would similarly be mistaken to see an evolution of monotheism as a movement of increasing abstraction and universality (Wright 2009). It is Bergson’s claim that a truly spiritual religion is not more and more inclusive, but moves beyond inclusiveness and single groupings of ‘man’ and instead imagines that one might act and feel for what is not yet present, represented or imagined. For Bergson the  for the sake of those other organisms that I imagine to be like myself and towards whom I feel some (however distant) sympathy. Bergson’s examples of Christ and Socrates, by contrast, do not extend sympathy to yield a greater inclusiveness or broader definition of the human. Their actions and teachings are not directed to some normative or general figure of the human.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The intellect that will sacrifice the present of pleasures for the sake of long-term gain, efficiency and stability is surpassed by a spirit that can liberate the temporalizing and creative power from any body. Whereas the intellect uses the imagination of a future to calculate more efficient self-interests, expending more energy in the present for the sake of a greater deferred good, spirit can embark upon deferred action as such. This would not be for the sake of any already imagined, figured or felt good—it would be a saintly, Christ-like, Socratic and dynamic spiritualism that did not rest with any object. Bergson is explicit that for the most part the forces of matter tend towards inertia: the intellect may break with immediate organic selfinterest but will then be seduced by the moral image of man or humanity as a stable object with properties. It takes an anti-social and anti-moral impulse to break with norms, pleasures and habits of communication: ‘Shaken to its depths by the current which is about to sweep it forward, the soul ceases to revolve around itself and escapes for a moment from the law which demand that the species and the individual should condition one another’ (Bergson 1977, 230). Nature (by way of moral obligation) builds ‘man’ for stable and closed societies—akin to the ant in the ant-hill—but there is another impulse that is distinct from man’s organic being and distinct from moral humanity. This creative dynamism is destructive of the closed figures of man, tearing the intellect from its forms and figures; spirit bears a supra-rational force, especially if we think of moving beyond rationality as the surpassing of any single ratio. There is something essentially malevolent in Bergson’s passage beyond moral humanity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Bergson notes that such an individual reaction against collective moralism not only tends to close back on its own figures and myths; the creative impulse always works in conflict with the tendency towards inertia. There must have been a time, Bergson suggests, when there was  over, and moral man—global man with all his delusions of existing as a being with a closed nature—can never be fully surpassed by the dynamism of spirit. All one can aim for practically is some ever-expanding and ever-creative figure of humanity that would be relatively open. Bergson’s thought therefore anticipates the current predicament of cosmopolitical desire in an age of globalism. On the one hand political relations, geographical distributions, market forces and the residues of imperialism already include and anticipate all human organisms as a unified whole. On the other hand, a new cosmopolitics would allow every event of inclusion to have a destructive force on the very humanity that appropriates all others in its name. Bergson makes a distinction between static and dynamic religions, the former creating stabilizing myths and figures, projecting its own organic image of itself onto life as a whole; the latter draw upon already given figures but do so in order to recreate and open the image of what counts as ethical life. The former tend towards self-satisfaction and the rewards of pleasure, the latter towards a selfless and mystical joy.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Both are results of the creative or differential force of life, which works against the closed and fixed forms of matter—destroying the actual for the sake of a not-yet present end. Following Bergson, though, we can mark a difference in kind, and not just degree, between globalism and cosmopolitanism. The former tends towards measuring its own movements according to the actual world: striving to achieve greater profits or even human rights for more individuals, improved conditions for more individuals, inclusion of more individuals (all the while maintaining the standard figure of the moral individual as rational consumer blessed with rights and moral judgment). Cosmopolitanism, by contrast would be oriented to the virtual: hospitable (as Derrida suggests) to an other who is totally other, who does not answer to or accord with already given notions of human dignity and whose possibility (rather than presence) is destructive of any supposed good conscience (Derrida 2001). We are left, then, with a politics of the virtual that seems remarkably similar to a politics of the Idea. Kant had also, in one of the key texts on cosmopolitanism, argued that as a being of nature man could only regard himself as bound up with physical causes and passions. But natural being  by pure animal instinct nor a rational law. Kant assumes that if we could separate man as he is in himself from the manner in which he appears then humanity would follow a prearranged plan in the manner of ‘rational cosmopolitans’ (Kant 1991, 41).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Why would the ‘rational cosmopolitan’ be the figure that Kant opposes both to an animal nature that is instinctual and man as he appears historically? A preliminary answer would draw upon what Kant says elsewhere about the pure forms of moral law that we are capable of thinking but not knowing. If I were to act as if I were a rational cosmopolitan then my individual and worldly being (with all its pleasures, calculated interests, possible pay-offs from good actions and other motivations) would be surpassed by the imagination of myself as a member of humanity in general. I would not be a specific historically located and culturally defined self, but a pure will who could act as if my actions and desires were those of all wills for all time. Cosmopolitanism, then, is for Kant an idea that we cannot avoid; it is the duty to think of how one might act for all and for all time. If we can think such a will (despite the impossibility of knowing or actually becoming a ‘rational cosmopolitan’) then we ought to act in accord with such a possibility: ‘Nature only requires that we should approximate to this idea’ (Kant 1991, 46-7). The first manoeuvre of Kant’s essay is, then, to place cosmopolitanism out of this world. It is an Idea, something that we can not see evidenced in history other than afterwards, via reflection, when we can look back on collective past actions that seem to tend towards increasing order.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Because we only know human actions, and ourselves, in terms of natural consequences of cause and effect, and within a nature of physical laws, any seeming ‘rational cosmopolitan’ may, for all we know, be acting from local interests. As in personal morality, one never knows whether one has acted from duty. One can know that one has acted according to duty. Similarly at a global level, one can never witness benevolent humanity as such—one is presented with antagonisms, violent usurpations, wars, disputes over honor and recognition—and this because man is a divided being. Unable to remain in a state of animal inertia and security he struggles to conquer those others without whom he would not receive recognition but with whom he cannot live peacefully. Even so, something  brutish self-interest) but through a nature that we assume, on reflection, after the event, opens to a human concord beyond that of our merely animal natures. Kant’s idea of cosmopolitanism is not the result of calculation within this world, but intimates another ordering power liberated from the finite point of view of man whose world is only known as it is given to him, not as it is in itself: Wars, tense and unremitting military preparations, and the resultant distress which every state must eventually feel within itself, even in the midst of peace—these are the means by which nature drives nations to make imperfect attempts, but finally, after many devastations, upheavals and even complete inner exhaustion of their powers, to take the step which reason could have suggested to them even without so many sad experiences—that of abandoning a lawless state of savagery and entering a federation of peoples in which every state, even the smallest, could expect to derive its security and rights not from its own power or its own legal judgement, but solely from this great federation (Foedus Amphictyonum), from a united power and the law-governed decisions of a united will. (Kant 1991, 47) Where Bergson’s dynamic religious or mystical impulse differs from Kant is in its suggestion of the positive power of the virtual, and this may well mark its distinction from anything cosmopolitical.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  That is to say: Kant, like contemporary cosmopolitical approaches, distinguishes between a calculative, conflict-based, self-interested and antagonistic global warfare (even if that global war is one of market competition and political expediency) and the idea, beyond that, of a humanity that can imagine itself beyond any of the natural figures that have grounded its specific communities. The problem—despite the distinction in kind between a managerial globalism and an open ethical cosmopolitanism—is whether one can ever do more than think this potentiality as a negation of the actual. This, indeed, seems to be the issue that exercises writing on cosmopolitanism: is not the aim for a plural world inclusiveness just one more way  I may appear to have effaced self-interest, nationalism, global capitalist assimilation and predation and yet who knows whether this benevolent outcome is not the consequence of a will oriented to particular calculations? For Kant, one cannot know such a thing, but that is beside the point. We can, at least, aim to act as if we were rational cosmopolitans; we can imagine what such willed maxims would be. Whether any of the actual decisions we make would actually be executed solely with the view of ‘humanity in general’ (liberated from any determination of locality or history) would not alter our attitude towards how we think about what a good principle would be. Cosmopolitanism of this nature—as an Idea or infinitely receding horizon—characterizes the post-Kantian tradition that ranges, however diversely, from Habermas’s ideals of ongoing critique to Derrida’s infinite hospitality (even though Derrida distinguishes his city of refuge from Kantian Ideas precisely in its lack of a human normative dimension and its orientation to the wholly other). Positive approaches tend to locate the cosmopolitan intention not in a necessarily impossible ‘beyond’ but in the real, in the bringing into actuality of an already given potentiality.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In the case of Hardt and Negri’s Empire, it is humanity itself, in its laboring activity that yields a multitude that is no longer delimited by a normative image of humanity but creates from itself, for itself, nothing other than its own collective being. But it is just the language used by Hardt and Negri—‘homohomo humanity squared,’ the Christian love of St Francis or agape (therefore not confined to bourgeois normality)— that ought to give us pause (Hardt and Negri 2000, 204). Such an appeal to immanent potentiality avoids the crippling effects of what Deleuze (1994) referred to as the ‘thermodynamic’ nature of bourgeois ideology, whereby one recognizes the force of a moral ideal and yet also resigns oneself to knowing it only in its diminished and finite mode. One recognizes a call for justice, democracy, hospitality and cosmopolitanism but always in the deferred form of a ‘not yet.’ On the one hand I know that cosmopolitanism requires the surpassing of any given or particular norm, and yet I know that such an ideal will always be marked by a particularity from which it emerges. Life is deemed to be nothing more than the compromised actuality that we are already given. Negri discern a potentiality not just for more justice, or even the intrusion of an Idea of justice, but of a revolutionary rupture from the present and within the present. The conditions of the present, such as immaterial labor and the networks of globalism, are precisely those that can inaugurate a new commonwealth that transcends localities, nations and state forms. Hardt and Negri’s debt to Deleuze is by no means direct, nor straightforward.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One of the clearest distinctions between Hardt and Negri’s approach and some of the philosophical sources upon whom they draw is their sustained commitment to figures of humanity. Their call for an immanent politics remains wedded to the anthropomorphic tendencies of global, commonwealth or cosmopolitical figures and the residual archaisms of man that such figures bring in train. First, for Hardt and Negri the bringing into actuality of the new commonwealth is liberated from static and transcendent ideas of the state that would impose order and justice from without; but the image of a man who makes himself from himself and who exists, not as an isolated being, but as a creative component of a multitude that has no being other than its ongoing dynamic creativity transposes theological axiology into a supposed secular immanence. It is now not God who expresses his being through a creation capable of returning and recognizing itself in its divine and immanent origin; it is the human creative spirit. This much, also, was suggested in Bergson’s dynamic religion that, like Hardt and Negri’s multitude, tended to figure the future in Christian terms. Bergson defines mysticism as the creative spirit liberated from practical affairs and inertia, and it is because of its mystical component that Christianity had the potential to remain active, not simply resting with a negation of the world but proceeding to bring forth a new world of life’s own creativity, a creativity feeling itself in its own creative joy. For Bergson such a power of creative life partaking in its own creativity—no longer stalled by meeting the needs and pleasures of the organism or society—found its end in man, and especially in the Christian man of dynamic religion: the ultimate end of mysticism is the establishment of a contact, consequently of partial coincidence, with the creative  thus continuing and extending the divine action. (Bergson 1977, 220-221) So, here, we arrive at a problem that is not at all extrinsic to cosmopolitanism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  How do we conceive the virtual or futural domain that is irreducible to the ties of global capital and interest? Must it take the form of humanity imagining itself, of a city of refuge, of the divine? Bergson, via a thought of the divine, at least raises the idea of a life that cannot be identified with the organic or global, even if he then falls back upon an already given notion of the divine. As long as we think the surpassing of competing self-interests and organic expediency as being transcended by the cosmopolitical we still remain at the level of difference in degree. First, the cosmos, even if it is not a spiritually ordered or harmonious whole is nevertheless distinguished (by Kant) from the wars of competing social bodies or (by Hardt and Negri) from the globalism of merely material forces that do not yet bring to full potential the immaterial lines of affection, labor and communication. Kant will argue that the cosmopolitical order is the result of a reflective equilibrium: we do not positively engineer political harmony but can discern the tendency towards cosmopolitical peace after the event. This discloses a certain reason in nature, suggesting that human discord, war and aggression ultimately tend towards a higher stability above and beyond human-to-human conflict. This is truly, then, a cosmopolitics: human historical life takes on a cosmological dimension irreducible to the forces of the polity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This cosmpolitical reason does not emerge from political relations directly, but opens out onto another plane. Even so, while distinct in order, Kant—like those after him—nevertheless sees the potential for a passage from polity to cosmopolitanism. The former achieves order among bodies (as a polity) but is then placed in warring relations with other bodies. The cosmopolitical is therefore a version of the polity—equilibrium achieved among bodies—that layers over the political: no longer sympathy, affinity and legitimation at the political level, but the same concord from discord manoeuvre taken one level higher. Order from disorder, equilibrium from disequilibrium,  abstraction of the cosmopolitical order becomes a way of extending the forces of globalism: either one argues that global economic, marketing and communicative lines can yield to a new commonwealth by being freed from strictly economic codes (Hardt and Negri) or one posits a critical cosmopolitanism where the economic violence of globalism is reflected upon by a cosmopolitical perspective that never frees itself from, but is also irreducible to, the economic. Despite Bergson’s reliance upon (Christian) humanity as the means through which the creative force of life might create a new potentiality of dynamic spirit, he nevertheless suggests a different way of approaching the cosmopolitical problem. Consider, first, how the problem is posed, invariably passing from relative order to greater order: man as an animal creates polities—relations among similar bodies striving for ongoing stability of their kind or species—but these polities become warring bodies in turn. The problem is posed as one of passing from the political man to man in general, from the generalized and grouped to the higher groupings of a higher generality, from radical difference to increasing indifference.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  And this passage to the indifferent is disclosed in the ultimate formulae of a new cosmopolitanism in which I need not recognize any traits in the other apart from pure and formal otherness. This is at once an extension and fulfillment of liberalism, from Kant’s imperative to act as a member of the kingdom of ends and Rawls’s ‘veil of ignorance’ to Derrida’s hospitality towards the wholly other and perhaps even notions of a ‘community without community’ that would signal the pure form of relation without being governed by any normative term. As long as the problem is posed as one of cosmopolitanism it seems that the passage towards greater abstraction, formalism or generalized humanity—Hardt and Negri’s ‘homohomo humanity squared’—would be the only option. But is cosmopolitanism a genuine concept of the future that might help us to think twenty-first century horizons? I would suggest that it is not, and this for several reasons. First, for all the laments today regarding the loss of ‘the political’ (supposedly vanquished by managerialism or biopolitical bureaucratic calculations of mere life), is the polity the best way to think about relations of force? Beyond the political—the gathering of  cosmopolitical, after all, is an extrapolation of the polity: a mode of harmony, order, humanity or citizenship that transcends, extends or emerges as the pure (or purer) form of the polity. The problems we encounter today, ranging from a global financial system without center, accountability, rationality or future to a planetary destructiveness that has resulted directly from the inflation of human sustainability at the expense of other rhythms cannot be achieved by granting a greater ideality and range to the political, and certainly not by positing a cosmic (or higher order) harmony that would supplement or override human conflict.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Second, if we accept that the cosmopolitical imperatives of hospitality, community, humanity or refuge occur as a passage from necessary conflict—what Kant refers to as ‘childish malice and destructiveness’ or what Bergson describes as the enclosure within the organism—towards a higher order equilibrium, then the cosmopolitical would always have as its basic terms the already formed and bounded units of the aggressive individual. Politics and order, even when stretched to its highest ideals, would be a question of negotiating the degree to which the forces of these individuals could be combined to form some higher order individual. In Kant war is defined as a consequence of the human species’ strange threshold condition: neither governed by animal instinct nor capable of intuiting the rational cosmopolitanism that would be their pure ideal, humans live with each other for the sake of recognition, yet cannot abide each other because of their competing desires. For Bergson, however, the situation is slightly different: there is a conflict or warring power in the impulse of life as such. Creativity is at once explosive—pulverizing inert and closed forms—and yet always coming up against its past created forms. It is intellect, after all, that frees the human organism from the self-interests of animal instinct (by calculating on a more efficient expenditure of deferred energy), and yet this same intellect maps the future according to already determined units. Perhaps this is one way of understanding contemporary globalism, at once extending itself to all territories in an all inclusive manner but—in reaching the limits of its coherence—failing to adjust its measurements of profit, efficiency, expansion and enterprise. One might say the same about any form of cosmopoli-  in kind.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But if life itself in its creative dynamism is, on Bergson’s suggestion, already at war with itself, creating the very obstacles to its own forward movement, obstacles that in turn require a greater creative ‘thrust,’ is there another way to think the passage beyond global war? This leads to the third, and final, objection to cosmopolitanism already hinted at earlier. The very nature of the politics of cosmopolitanism is bourgeois and thermodynamic: calculating the relation among forces in terms of management of degrees, or more or less, and of compromise. Yes, we want an all inclusive humanity, but not one of the market. Yes we want equality, but not the reduction of all human cultures to one standard. Yes, we want multiculturalism but not the narcissism of small differences. Yes, we want the rights and freedoms of the enlightenment but should be wary of universalizing specifically modern Western values. In criticizing bourgeois ideology as thermodynamic Deleuze was drawing attention to the crippling and self-important nature of notions of political compromise: on the one hand I maintain certain norms and values—this gives me the individual identity that allows me to be a moral individual.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Yet, on the other hand I am aware that those values are provisional, culturally and historically specific and never fully universalizable. Deleuze signals an alternative mode for thinking ‘political’ concepts (although it needs to be borne in mind that all his and Guattari’s political terms—including micropolitical and schizoanalysis—decompose psyches and individuals into forces and relations). If one began, not from models of mediation, more and less, or greater and expanded models of hospitality, but from differential calculus then forces would not be forces of bodies and the cosmos would need to be considered beyond the polity. In the plateau of A Thousand Plateaus that deals, however fleetingly, with the cosmos, Deleuze and Guattari achieve two conceptual manoeuvres. Before one can think of the cosmos as a deterritorialization of the earth or territory, one also needs to see earth and territory as themselves assembled from forces of chaos (with their attendant autonomous qualities): ‘The forces to be captured are no longer those of the earth, which still constitute a great expressive Form, but the forces of an immaterial, nonformal, and energetic Cosmos’ (Deleuze and Guattari 1987, 342-  On the contrary, it is from the assembling of expressive qualities that something like an individuated body can emerge. Deleuze and Guattari here (and in What is Philosophy?) cite the stagemaker bird, whose turning over of leaves to display their lighter side creates a territory of found qualities; it is this formation of assembled qualities that creates individuation. There is a selection from chaos of materials that are not indifferent but that possess various potentials for relations and distinctions.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Thus any earth or territory has already resulted from the assembling of qualities. Today’s figure of the globe, for example, is not arbitrary and relies on the selection of qualities—such as the spherical planet, the generic image of the human being as a communicative, universalizing, enterprising and communal animal—from which something like the concept of globalism is formed. When these qualities are ‘deterritorialized’ or extended beyond their already actual form to consider virtual variations we get the cosmopolitical citizen: a man blessed with speech (but no language in particular), a sexually differentiated and culturally specified individual (but with no culture or gender in particular). We might look both at the ways in which a supposedly generic humanity draws upon a range of expressive qualities—from the figure of face and voice to the motifs of family, sexual difference and skin color—and at how the composed ‘family of man’ then allows for extension (or deterritorialization) to a cosmos that is always cosmopolitical. That is, the cosmos is always an extension of the composed polity, an abstraction or idealization of man englobed in his world of human others. If the first feature of Deleuze and Guattari’s concept of the cosmos is that it is not cosmopolitical—for the cosmos can occur as the deterritorialization of non-human forces—the second is that (at least in this plateau) it bears a direct relation to music. But this is the case only if music is defined as the relations of qualities and differences, the power to form inflections and rhythms from which something like the human practice and culture of music emerged: The T factor, the territorializing factor, must be sought elsewhere: precisely in the becoming-expressive of rhythm or  Can this becoming, this emergence, be called Art? That would make the territory the result of art.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The artist: the first person to set out a boundary stone, or to make a mark. Property, collective or individual, is derived from that even when it is in the service of war and oppression. … The expressive is primary in relation to the possessive; expressive qualities, or matters of expression, are necessarily appropriative and constitute a having more profound than being. (Deleuze and Guattari 1987, 316) There is a pre-human and pre-organic music that is generated from the differential relations among expressive qualities: the beating out of a rhythm establishes a pulse or band of time from which something like a meter might be organized. There is an articulation of sounds into tonal inflections that provides the condition for something like a scale or melody (or phonemes). Before there is something like a language— a repeatable and formalized set of relations—there must be the formation of qualities and the creation of differences. (One can think here of Freud’s example of his grandson establishing a pulsation of Fort-Da, opposing two sounds across space and time, securing a territory that then enables the forming of a body and its world.) And it is here that we can tie Deleuze and Guattari’s plateau on the refrain (where cosmos is conceptualized) with Deleuze’s idea of a differential mode of thinking.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Deleuze and Guattari insist that there is an autonomy or differential power in expressive qualities. Relatively stable terms or beings are formed from pure predicates or qualities. One might say that ‘man’ as a rational animal who is defined through the speaking-seeing-eating figure of the face and voice has a political composition (for it determines relations among human bodies) but this occurs after the entering-into-relation of certain qualities. Man is an animal assembled through the speaking-seeing face (itself composed racially of skin colors), the commanding voice (again enabled through the composition of a phonematic spectrum) and the organized body (effected by bringing the hand-eye-brain complex into relation.) There is, in this respect, nothing political about the cosmos as long as we  be composed from the forces of chaos? Such a determination would have been enabled by certain expressive qualities—the potentialities of sound in the voice, of light in the seeing eye, of conceptual configurations in the reasoning brain. Such qualities are synthesized and coordinated to produce the man of politics. To define the proper destiny of man to be that of a cosmo-political animal is to contain thinking within the already formed bounds of the organism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A differential politics, by contrast, approaches the cosmos as a radical deterritorialization, freeing expressive qualities from a human-all-too-human composition: For there is no imagination outside of technique. The modern figure is not the child or the lunatic, still less the artist, but the cosmic artisan: a homemade atomic bomb—it’s very simple really, it’s been proven, it’s been done. To be an artisan and no longer an artist, creator, or founder, is the only way to become cosmic, to leave the milieus and the earth behind. The invocation to the Cosmos does not at all operate as a metaphor; on the contrary, the operation is an effective one, from the moment the artist connects a material with forces of consistency or consolidation. (Deleuze and Guattari 1987, 345) How might we think this meditation on the limits of cosmopolitanism in concrete terms? What would Deleuze and Guattari’s suggested cosmic release of matters mean, or—more accurately, since it is no longer a question of meaning or symbols—how might such deterritorialization work? Consider one of the problems of the twenty-first century: water. At once crucial to life, water is also one of the elements whose relations to human organisms and polities exposes crucial fragilities, including water borne infections, floods, drought, rising sea levels and melting ice caps.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Water has, of course, been politicized. In the 2008 documentary Trouble the Water Hurricane Katrina was an event that could not simply be referred to as a natural disaster but exposed political distributions: the absence of decisions, intentions, attention and sympathy that affected a certain geographical region of America that was also, of course, a racial and sexual region. More broadly, and also in 2008, Flow: For Love of Water  most basic of human elements into a key political weapon and structuring cause. Such cinematic events gesture towards a traditional cosmopolitanism, both in presenting the local plight of Katrina to a world audience as an indictment of America and in exposing certain globalizing markets (of water) to a population of general human concern. The response to such demonstrations of political mapping would be some form of cosmopolitical activism: such concerns would—as in twenty-first climate change rhetoric more generally—be those of viability, sustainability and the maintenance of humanity. How will we live on, into the future, if this most basic of elements becomes politicized, becomes a weapon or resource that is subject to plays of power among humans? Another politics of water is also possible, one that would be musical in Deleuze and Guattari’s sense (if music refers to the relations established among expressive qualities and their capacity to create forms, territories, identities and to open to the cosmos). We can begin by thinking about water’s elemental or musical qualities (its semi-autonomous power to enter into relations beyond human polities) through Roman Polanski’s Chinatown of 1974.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Ostensibly a detective drama about the theft and re-channeling of water that is political in the most traditional of senses—to do with local contests and human interests—the film also allows water to become a visual quality. This is not when water is seen or made visible but when its absence or inhuman power takes over the screen: set in a heat-wave, the drama is shot through a heat haze in which the flows of human perspiration are matched with a barely discernible visual fluidity that takes the form of a slightly out of focus point of view. It is as though beyond the political plays of power something of the cosmic force of water—its resistance to human manipulation, its brutal and inhuman potentiality— threatens the person-to-person drama of the plot. Chinatown is at once about a cosmopolitics of water—about the ways in which corporate powers can take over local management and resources—at the same time as it is counter-political in its presentation of water as expressive or sensuous matter; water is not just represented as a human commodity but also takes over the formal elements of the screen, becoming an element from which the visual field is composed. A more specifically musical mode of  water (which have been electronically synthesized, becoming almost melodic) are interspersed with sounds from the string quartet, which take on the quality of ‘becoming-water.’ At once the most formed and mannered of genres, the string quartet enters into relation not with the forces of the earth as territory (where water, say, is a humanized, nationalized quality) but with the cosmic force of water—its capacity to enter into variation and bear a sonic power beyond that of the polity. One might refer to such uses of the sounds of the cosmos as deterritorializing in a higher sense: the form of the work—its relations of varying sounds in dialogue—is also its matter, the work is the synthesis and forming—deforming of the elemental sound of water. Why would such an opening to the cosmos be worth anything today? Is not the urgency of twenty-first century climate change a condition of such intensity that one must manage, now, as efficiently and bureaucratically as possible the sustainability of human life?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Perhaps climate change calls for the most cosmopolitical of responses: the taking hold of the world’s resources away from nation states and local polities for the sake of the viability of ongoing life. Such an imperative would, though, be in the name of the sustaining of human life, and of human life as it is already formed, already politicized and already organized. If we were to think otherwise, and if the crises of the twenty-first century were to prompt us to think at all it may be in a cosmic and inhuman mode, asking—at least beginning to ask—what the elements of this earth are, what force they bear, how we are composed in relation to those forces. If climate change politics has taught us anything to date—if it has, and if there is an ‘us’ or ‘we’ who might learn from, or be destroyed by, such events—it is that information and data directed to the maintenance of the polity has not yielded any affective response. Climate change skepticism is increasing, and this possibly because the cosmic force of destruction is now pushing beyond the political imagination, beyond our capacity to imagine ourselves and others like us in a future that will not be an extension of the present. Perhaps something other than a discursive politics among communicating individuals needs to open up to forces that are not our own, to consider the elemental and inhuman, so that it might be possible  be destructive of the polity, that would not return all elements and forces into what they mean for ‘us.’  Notes 1. Brennan (2001) argues that globalism is the economic ground upon which cosmopolitanism as a cultural and (putatively) critical phenomenon is based. He criticizes writers such as Mignolo (2000) who argue for a disjunction between a managerial cosmopolitanism that retraces market forces and an emancipatory cosmopolitanism that would be liberated from economic imperatives.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2. Hardt and Negri (2000) argue that the economic conditions of immaterial labour in globalism allow for the creation of a commonwealth irreducible to any modes of connectivity and affect other than those of humanity’s own selfconstituting striving. 3. On the nature of intensive versus extensive differences see De Landa 2002. 4.  http:\/\/www.boosey.com\/cr\/music\/Next-Atlantis\/54870  Chapter 6  Time And Autopoiesis: The Organism has No Future There was a critical scene that was narrated frequently in the theory-frenzied years of the 1980s, operating as an often-invoked tableau that would awaken us from our literalist slumbers. The child faces the mirror, jubilantly rejoicing in the image of his unity : The jubilant assumption of his secular image by the kind of being—still trapped in his motor impotence and nursling dependence—the little man is at the infans stage thus seems to me to manifest in an exemplary situation the symbolic matrix in which the I is precipitated in a primordial form, prior to being identified in the dialectic of identification with the other, and before language restores to it, in the universal, its function as subject. (Lacan 1977, 76) This scene captured the predicament of misrecognition: the self is not the naturally bounded organism (a thing within the world), but a site of desires, relations, drives, fantasies and projections that cannot possess the coherence of a body. There is a radical disjunction between the subject, who is nothing more than an effect of its relation to an other whom it cannot read, and the self, ego or individual that we imagine ourselves to be.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is the body as bounded organism, centerd on a looking face whose gaze can be returned by the mirror, that not only represses the chaotically dispersed and relational manner of our existence; it also operates as a figure of reading. We read other bodies as though they harboured  become apparent (Felman 1987). In this respect the Lacanian notion of Imaginary meconnaissance—where we live the decenterd and dispersed incoherence of the symbolic order as some illusory whole—repeats a criticism of the organism that goes back as far (at least) as Husserlian phenomenology. For Husserl it was quite natural to regard oneself as a thing among things, but that ‘natural attitude’ concealed the true nature of the subject: a subject who is not a thing but the condition through which things are given (Husserl 1965). Husserl, here, radicalized Kant’s distinction between subject and body. For Kant, I know and experience myself as a body within the world, but I can only do so only because of the transcendental subjectivity that is not itself spatial or temporal. Kantian ethics, and the liberal tradition that follows from it, relies on this distinction between the natural self, that may be an object of calculation and science, and the subject that can neither be known nor predicated. In the absence of any knowledge or experience of the subject, selves can be given only through the procedures and decisions that they inaugurate.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Husserl, Kant did not go far enough in his distinction between subject and body, for it is not only the case that the subject in itself cannot be known or experienced as a thing within this world; the subject is the very origin of the world (Fink 1970). There can be no sense, givenness, time or being outside the event of transcendental synthesis. Although Heidegger would place more emphasis on Being’s disclosure, regarding the subject as a clearing for the event of revealing, he also was highly critical of mistaking Dasein (a disclosing relation) for das Man (a psycho-physical body) (Heidegger 1996). This, indeed, was Heidegger’s criticism of humanism. In a typically Heideggerian manner, Heidegger locates a moment of philosophical opacity and forgetting in a transition from Greek to Latin, from legein and logos or ‘speaking about’ to logic, or some preceding system through which the world would be ordered. Since the Roman understanding of humanitas, man has been understood as an organism with an additional capacity of reason (Heidegger 1998). The problem with humanism, for Heidegger, is not that it defines ‘man’ as a special or privileged being, but that it still defines man as a being. Man is not a being or thing, and he is certainly not a foundational being that  phenomenology at all; for it would merely have placed one more being— man—as the ground of all other beings, without asking how man himself appears.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Taking up phenomenology in France, Sartre insisted on the radical transcendence of the ego: there is being on the one hand, which simply is ‘in itself,’ and then the relation of difference to that being which can never (authentically) be experienced or lived other than as nothingness, as the negation of what simply is (Sartre 1957). Bergson, despite his difference from phenomenology, also criticized the ways in which the efficient intellect would reduce all its complex experiences into stable objects; this reifying process was perfectly appropriate for non-living beings but a disaster when turned back upon the human knower himself who then experienced himself as just one more thing among things (Bergson 1931). Whereas Husserl, Bergson, Sartre and Heidegger lamented (and aimed to correct) a history of philosophy that had mistaken the subject who was not a thing for the human body, psychoanalysis acknowledged that the condition of misrecognition is irreducible. There is a tendency towards ‘organic thinking’ captured in Lacan’s notion of the Imaginary; we are Oedipal insofar as we consider ourselves as self-bounded bodies lamentably subjected to condition of difference. We imagine a form of bodily integrity that has been subjected to some prohibiting system or law; what we fail to recognize is that the bounded unity of the body is a figural lure that precludes us from recognizing that we are nothing more than an ongoing, dispersed and ex-centric condition of speaking being that can neither be localized nor experienced beyond law and language. (Deleuze and Guattari will not challenge Lacan’s reading of the tendency of the human organism towards privatization, or to regarding the world of difference and relations as a nightmarish beyond. They will however write a genealogy of that lure of the bounded body, arguing that what Lacan deems to be transcendental is a historically specific condition of the modern speaking ‘subject.’) For Lacan, the yearning to retrieve the lost child who was once complete (before its submission to unreadable relations) follows from our organic dependence. The child appears to himself, in the mirror, as a unified whole—an identity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What that delight-  as always situated within a system of symbolic relations of which we are only ever effects. These effects are never given as such, but always relayed through relations of enigma, misrecognition, anticipation, projection and unattainable desire (Butler 1997; Butler 2004; Butler 2005; Laplanche 1999; Mitchell 1975; Wright 1984). In the beginning is the bodily image as lure or alibi that covers over temporal dispersion; from that initial imaginary unity we imagine that there must have been some other who robbed us of our pure plenitude, unboundedness and connectedness; we read this other as holding the key or power to our enjoyment. This notion of the subject as formed through relation to an unreadable other has been reinforced recently by Judith Butler who has placed less emphasis on her earlier notion of the self as effected through performance of social norms, and has turned instead towards Laplanche and his insistence that our ex-trinsic condition of existence is one in which we are always placed in a relation of reading an other who is essentially unreadable (Butler 2005). The reasons for returning to, while adapting, Lacan are manifold. The Lacanian ego is at once formed through body image, even though the imagined body does not exhaust the subject’s being; subjectivity is always other than itself, always split between the speaking\/seeing self and the self spoken and viewed. Perhaps the most difficult aspect of this intertwining of subject and ego was the emphasis Lacan placed on the phallus, the body part that is not a body part. For Lacan it is the condition of subjection, prohibition and loss (the condition of speaking through a system that is not one’s own) that creates the fantasy that there must once have been, or will be, mastery.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  There must be a phallic power of possession, even if it is one that I as a speaking (subjected) being do not have. Laplanche was explicitly critical of Lacan’s centering of the Oedipal predicament on the phallus: yes, we are all constituted through a reading of the other, but we do not read that other as the one or other who possesses the phallic law, the power of castration. This liberation of the imaginary from the phallus would, at first glance, be an improvement: why should a body part be privileged when we think about the ways in which we fantasize our existence? For Laplanche there is a structural truth to the Oedipal complex, for every  were once perfectly bounded organisms who underwent subjection to an alien order. Whereas Lacan figured alienation in linguistic-phallic terms, with the imposition of speech being fantasized as submission to the law of the father who holds the phallus, Laplanche’s ‘enigmatic signifier’ was not language in the symbolic sense but the look or gesture of the other who forces us to read their desire. Now it might seem, today, that it is Laplanche’s emphasis on the look of the other and each specific body’s relation to the law that might be a more fruitful understanding of our body’s relation to language and that this would accord, too, with Deleuze and Guattari’s criticism of the tyranny of Oedipus and the ‘despotism’ of the signifier. But this is not so: for Deleuze and Guattari write a genealogy and diagnosis of the Oedipus complex and the privileging of the phallus. The virtue of the Lacanian critique is its ideality and inhumanity: before there is a human-human look or relation, something like the human organism has to be formed as an image.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The body and its organs are historical and political phenomena. The modern man of capital does indeed live the relation among his body parts as Oedipalized: he is the man of speech who must articulate his desires through language as a symbolic order, and who will also live in fear of the loss of that order. In Anti-Oedipus Deleuze and Guattari maintain the importance of the virtual body part (Deleuze and Guattari 1977). The body has been increasingly ‘privatized:’ no longer living its forces collectively or intensively. Instead of the phallus being a collective totem, capable of generating the powerful spectacle of a tribal body moving in rhythmic pulsations, ears all responding to the beating tempo, eyes all feeling the intensity of the common spectacle, flinching as knife meets skin in rituals of castration, the body has become folded in on itself. Modern man is a speaking animal, subject to no law other than that of articulating his desires in speech. The organs are now private: the eyes that look out on a world as so much calculable matter to be mastered by the hand that will labour to transform the world into exchangeable commodities. This privatization of the organs means that desire can only be experienced as secret and personal, lost in its passage through collective speech, and never capable of reaching that full masterful voice of the  Thinking about Deleuze’s philosophy in relation to the body requires stepping back from a too easy dismissal of Lacan and the virtual body part.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A social machine occurs when flows of desire are given relative stability: all the dancing bodies of the tribe gazing wondrously on the phallic symbol that allows for the creation of a territory. Body parts are always virtual before they are actual; the organized organism—where the eyes sees the same world heard by the ear and narrated by the voice—is the result of a history of co-ordinations and stabilized relations. Lacan was aware that the gaze of the infant was never a virgin glance: to look at a world of speaking subjects was to take on the history of the organism. For Deleuze and Guattari politics could only begin with this organized and Oedipal body, a body centered on the speaking voice submitted to the law of the signifier, always articulating a desire for a mastery and phallic dominance that is possessed by no-one. Only if one acknowledges the crucial role of the body in politics can one begin to think the body without organs. In this respect if one thinks of the body as, say, gendered, then one buys into the phallic order. If we see bodies as receiving their identity through the imposition of social norms, then we assume a body as a whole that is then given identity and selfhood through normativity. Deleuze and Guattari take up the Lacanian challenge and ask how this dispersed collection of organs—the eye, ear, voice, brain, skin—comes to be organized as a speaking animal.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Should we not ask how bodies that once existed through collectively intense organs—all eyes gazing on the cut into flesh, all ears feeling the stamping of feet, all voices screaming with the cry of a totem animal—became this point in space submitted to the laws of normativity? This means stepping back from the body to think the composition of organic powers, powers of organs rather than parts of the organism. Is not this what philosophy aims to do: to free the brain from the sensory motor apparatus of survival (Deleuze and Guattari 1994)? And is this not what visual arts aim to do: freeing the eye from reading, coding and recognition (Deleuze 2004)? Let us pause, then, and look back to the theorizations of ‘the body’ that reinforce our sense, today, that we have overcome 80s textualism and theory and no longer assume the primacy of language. Judith Butler’s Bodies  the organism before language, so much as a recognition that the linguistic paradigm itself entailed at least some minimal image of embodiment. To say that the ‘I’ is an effect of language, an effect of the act or performance of speech, implies that one will at least imagine or construct some image or figure of the speaking body. Even if the subject is deemed to be effected through language, language can still create a body as constructed through a series of norms and figures.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It was the status of the body as image that perhaps allowed for a confidence that one was no longer dealing with a literal pre-critical body; one could write about embodiment without appearing to be a vulgar materialist. Both in feminist criticism, and beyond, the body was primarily a literary and rhetorical problem. Although a great deal of literary and cultural criticism turned to ‘the body,’ this was always a consideration of how the body had been written, figured, problematized or constructed through various discourses (Kirby 1997; Wilson 1998). Even fiction (such as Jeanette Winterson’s Written on the Body of 1993) responded to this trend of coupling writing and the body: to write or speak is to imagine oneself as a subject, but that imagined subject is always embodied, and the body is always constituted through tropes. (This idea of the body as being a ‘lived schema’ through which the world is mediated is sustained today across a range of disciplines including neuropsychology, linguistics and political theory [Gallagher 2005; Gibbs 2006]). However, it was just this sophisticated post-Butler attitude of thinking of the body as other than representation and yet constituted through representation that precluded one from really thinking what the body might do. Butler published Bodies That Matter at least partly in response to the putative linguisticism of Gender Trouble. If we accept the argument of the massively influential Gender Trouble that the ‘sex’ that would supposedly be represented, mediated or imagined through cultural figures of gender is actually always figured as other than gender, then we also acknowledge that any appeal to ‘the’ body is a negative critical manoeuvre against received images and figures but is enabled only in its distance and difference from those figures.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The body that matters, then, is not some brute ‘in itself ’ that would precede cultural imagination, with cultural imagina-  matter is just that which appears in the splitting of a seemingly prior ‘before’ from a no less illusory after: To ‘concede’ the undeniability of ‘sex’ or its ‘materiality’ is always to concede some version of ‘sex,’ some formation of ‘materiality.’ Is the discourse in and through which that concession occurs—and, yes, that concession invariably does occur—not itself formative of the very phenomenon that it concedes? […] to refer naively or directly to such an extra-discursive object will always require the prior delimitation of the extradiscursive. (Butler 1993, 10-11) There ‘is’ no matter as such, no body as such, only a body that matters— a body known only insofar as it is recognized—and only a matter that is given as there for this body in its potentiality. Matter is given only as lost, as having been there for the work of culture and speech. Temporality is at once that which gives matter; for matter is that which must have been. At the same time, temporality is that which is the other of matter: we live and endure as the same bodies through time only in the re-iteration of an identity; this iteration that produces the subject as the same through time is also that which, through failure, can disturb and disrupt identity. There is always, in the subjection to identity, that which remains other than the normative matrix that recognizes identity. Matter in itself would be imagined, mourned or figured as that strange non-identity beyond all relations of inside and outside, before and after.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Grosz’s Volatile Bodies was avowedly less linguistically or—if we are not to have a narrow view of language—less performatively oriented. Butler took up the notion of the performative as the linguistic act that constitutes its referent. But this is an act that is not grounded upon a static body: quoting Nietzsche, Butler insists that there is ‘no doer behind the deed.’ One should not imagine that there are speaking subjects who then come to make statements about material bodies. On the contrary, there is the act or event of speaking from which one is effected as a subject  that something like an ‘I’ can be recognized. For Grosz, in contrast with Butler and a series of other approaches to embodiment that were even more constructivist than Butler’s careful negotiation of performance, the body was not achieved through the act of performance, even if that act was taken to be that which effected the ‘I,’ rather than being the act of some ‘I.’ Nor was Grosz simply turning back to the motility of the phenomenological ‘lived’ body. (Recently there has been a widespread return and resurgence of interest in the lived body of phenomenology against the theories of language and cognition that paid too little attention to the organism’s relation to the world. Such a return is premised upon correcting a supposedly disembodied subject that underpins Western reason and cognition [Thompson 2007]. Grosz’s corporeality is neither the lived nor the constructed body; in fact, her body is closer to something like an inhuman embodiment that gives itself through humans, but is also expressed in animal bodies, and the bodies of things.)\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Recognizing that the very notion of the act, force, performance or utterance would require some minimal relation, Grosz’s volatile bodies were poised membranes or borders, ongoing productions of an interior in relation to an exterior. Drawing on (but also surpassing) the lived body of phenomenology— insisting that one could only act or orient oneself in a world if there were some space that would always be the space for this body with its potentialities—Grosz also noted that this underlying lived body that enabled spatiality would in turn have its prior and not necessarily bodily (and certainly not organic) conditions. These conditions were explained by Grosz through the frequently used example of a moebius band: the relation between interior and exterior, the establishment of a bounded body from which potentiality and motility might be thought, could not be taken for granted and was itself effected from a whole series of relations. The most important relation, both for Grosz at this stage and for many writers working on embodiment, was the image. It is with the look towards another bounded body, taken as the sign of an impossible interior, that I might also live my own skin and physique as similarly blessed with its interiority. To live my physical being and its potentialities both as mine, and as the ongoing subject of action, requires the experience of  a self has therefore always been intertwined with what it means to be a body, and both these terms—self and body—have, in turn, been defined through a capacity of trauma, where trauma is imagined as the rupture of a border. What I want to do in the pages that follow is consider a series of possibilities: is it possible to think beyond that image of the bounded body? Such a possibility would be salutary today precisely because all those seeming gains in theoretical maturity that were won by posing the question of the body after the linguistic turn appear to be threatened, and threatened precisely because we can only imagine threat, trauma and non-life as other than the bounded body.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  That is, once it was accepted that bodies were not passive matters to be inscribed by culture, it was also acknowledged that the body’s borders were the result of relations, encounters and—as Grosz so aptly demonstrated—morphologies: one can be a bounded body only with a sense, figure or image of one’s limits. But this raises a problem: is life necessarily bounded and embodied life, a body of inside and outside? If we accept systems theory, body theory and the once-dominant idea of the self as constituted in relation to an other, then the answer is ‘yes.’ There are, though, other forms of life beyond that of the organism, and beyond that of the autonomous living being. (Such a consideration can be read in Grosz’s more recent work on Darwin concerning itself with a force of sexual selection that cannot be grounded in a body’s or gene’s survival: although sexual selection has a visual field and power as its milieu, it is no longer a visuality of the bounded image of recognition [Grosz 2011].) The departure from the lived body would need to be at least twofold, considering life beyond bodies and bodies beyond life. First, one might question the decision to consider viruses as other than life, a decision that is based on the virus as parasitic and non-selfmaintaining (Ansell-Pearson 1997). Second, one might question the exclusion of techne from life: if one were to distinguish between life and techne, then a living organism would be bounded and self-maintaining and distinct from various inorganic or created supplements. But life presents us with a series of movements and mutations, such as computer viruses, technical evolutionary imperatives and the ways in which organs  at this point in human history to consider life primarily from the point of view of the organism: are we not being forced to encounter the ruptures of organic timelines as we become aware of the depletion of the cosmos and the decay of our milieu, even if such erosions are never experienced or lived as localisable events?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Before moving on I would like to look back at the classic meditation on the image of the bounded body, Freud’s Beyond the Pleasure Principle, where Freud posits that pleasure—the maintenance of a constant energy or equilibrium—may have some ‘beyond’ that would take the form of a dissipation of all energy (Freud 1975). The first principle of equilibrium and pleasure is still recognisable today in a series of post-Freudian observations regarding an organism’s relation to life. A completely closed body that had no world would be deprived of the means of ongoing life; an absolutely open body without borders would not be a body at all, would have no ongoing identity. What is required then is a border or membrane that enables communion with an outside, but an outside that is always an outside for this bounded body, and that is managed so as to produce only the alteration or perturbation required for ongoing self-maintenance. The now widely cited and philosophically consecrated systems theory of Maturana and Varela (1987) deploys a series of terms to describe this necessity: coupling (where a body’s autonomous or self-maintaining movements are established in relation to outside variables); autopoeisis (where the body does not interact mechanically with its outside but does so in a way to maintain its own balance and sameness); relative closure (so that a body at once maintains itself but also adapts to changing external perturbations); and meaning (for the outside of a body is always its own outside or world, experienced or lived in terms of a range of possible responses rather than an objective representation). The ideal body must therefore balance two contrary requirements: completeness and self-sufficiency. A body detached from all that was other than itself would be hopelessly incomplete, divorced from the means of its own sustainability. A body must complete itself in order to maintain itself; it must not remain as some detached fragment but must be united or coupled with a world, open to what is not merely itself.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (This  object to which the organism is subjected [Freud 1961]. The erotic drive to connection and completion, depicted by Freud’s as two halves of a body seeking to be re-united, harboured an aggressive potential [Freud 1975]. The organism desires a plenitude or non-separation that requires it to go beyond itself, abandoning its original and mythic self-enclosure of primary narcissism; but it is just this overcoming of the violent selfcontainment of original closure that may in turn lead to a destructive drive to destroy the object that lures the organism from its quiescence. That destruction could even be turned back upon the self, after losing the object, if mourning is not completed in a life-serving manner). Many writing after Freud have not regarded the organism’s condition of coupling as anything other than benign, insisting on the originally world-oriented, meaning-making and other-directed dynamics of bodily life. The very logic of today’s insistence on the ‘embodied mind,’ the ‘extended mind,’ the ‘synaptic self,’ the ‘global brain’ and even the ‘mind in life’ blithely sail over the deep and essential contradiction of the living body (Varela, Thompson and Rosch 1991; LeDoux 2002; Bloom 2000; Clark 2008). All the criticisms of the detached and disembodied Cartesian subject that insist upon the self ’s primary and dynamic connectedness ignore what Freud and Lacan recognized as the imaginary lure of the body: for all the self ’s world-orientation and openness there is also a primary blindness and enclosure that is necessary for the very experience of oneself as embodied, bounded and located in a milieu. As alive the body must be oriented or related to what is not itself, must desire a completion.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  However, because such completion is always sought on the organism’s own terms, always for the sake of the organism, a body is necessarily blind to those forces that lie beyond its range. The very desire for completeness that drives the organism to couple with its world will also preclude it from seeing the world in any terms other than its own. Whereas philosophers have happily celebrated this necessity of the world always being meaningful, or the world always being a world for me, we might suggest that such blissful enclosure in meaning precludes the very striving for completeness it is supposed to serve. The desire for completeness comes into conflict with self-sufficiency or the desire not  One might say then that pleasure—today’s celebrated processes of equilibrium, homeostasis and autopoeisis, or processes deemed to be synonymous with the life of the organism—are necessarily destructive of life that cannot be experienced in terms of the bounded body. Freud’s second principle of a ‘beyond’ to pleasure or self-maintenance would not be in opposition to life; it would not simply be the death of the organism. Nor would it be a force regarded as traumatic, as that which is initially unassimilable but that could, through working and representation, be brought to coherence and sense. A genuine beyond of pleasure and a genuine beyond of the organism and its closed world of meaning would also be beyond trauma, for it could not be regarded as an infraction of the body from outside. This is precisely why Deleuze and Guattari suggest that one moves beyond death as a model—death as defined in relation to the bounded organism—to the experience of death.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The experience of death is the most common of occurrences in the unconscious, precisely because it occurs in life and for life, in every passage or becoming, in every intensity as passage or becoming. It is in the very nature of every intensity to invest within itself the zero intensity starting from which it is produced, in one moment, as that which grows or diminishes according to an infinity of degrees … insofar as death is what is felt in every feeling, what never ceases and never finishes happening in every becoming—in the becoming-another-sex, the becoming-god, the becoming-a-race, etc., forming zones of intensity on the body without organs. Every intensity controls within its own life the experience of death and envelops it. (Deleuze and Guattari 1977, 330) Such an experience would shatter the bounded body, and occur not as the body’s other or limit but as a pure predicate, potentiality or intensity taken away from the coordinates of the organism. If we do not begin the question of life from the point of view of the bounded organism and its world, then we are compelled to think life beyond the opposition between pleasure and trauma, between boundary and infraction. Instead,  note, if not comprehend? A species can only survive by mutation and by not being itself; any species also—through that very survival—takes a toll on its milieu that might lead (as in the case of man) to the destruction of life in general. How could one define this dissolution as tragic or traumatic or, more simply, undesirable if one were not to assume already the primacy of bounded self-maintaining life?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This raises two questions for the future of this body we recognize as human, a body that is facing—today—two possible traumas. Has this body so oriented itself to its own sustainability—seeing the world clearly only in terms of its own perturbation—that it has no sense of the distinct perceptions and souls that are destroying it from within, and no perception of the folds and series that are traumatizing the milieu itself? Is it possible to speak of, or object to, the dissolution of the organism that we know as human? How might we use these two notions of life—one that is bounded, embodied and open to trauma, and another that is post-traumatic—to assess what we mean by theory and thinking today? I would suggest that a certain notion of the theoretical, where theory is the look that we direct to our own acts of perception, has always been intertwined with a vital and normative account of life, and that it would be worthwhile to consider a theory that might entertain a thought of viral or radically malevolent life. In order to pursue this counter-possibility of a life that is not defined in relation to trauma, I want to conclude by looking at the ways in which a certain image of the body has underpinned theory and its temporality. Consider a certain diagnosis of disembodied life that is dominant, possibly necessary, in contemporary thought. In a series of disciplines, ranging from neuroscience, cognitive science, philosophy, evolutionary psychology, sociology, future studies and cultural studies, it is now common to begin with the criticism of the Cartesian intellect.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (The historical thesis is that there was, once upon a time, a unified human existence, where the self was defined socially and collectively, and where nature was not yet disenchanted or seen to be brute matter opposed to mind.) Various disciplines have taken up distinct criticisms of the Cartesian concept of  for the fall into the abstractions of Cartesian intellectualism. In contrast with a disembodied mind, and a matter deemed to be passive, mindless, inert and without relation, theories of living systems have sought to see any supposedly distinct beings as emerging from relations. The words ‘autopoiesis,’ along with ‘homeostasis’ and ‘equilibrium,’ operate across all these disciplines with their inter-related diagnoses of the present inertia of thinking life. First, neuroscience: this mode of enquiry has benefited greatly from the decade of the brain declared by President Bush in 1990, and from the accompanying technological developments enabling new means of imaging. Although neuroscience is a diverse field, its very potentiality is marked by a single critical shift; the neuroscientist is not concerned with finding the ‘bit’ of the brain responsible for a certain thought or idea, but can now look at systems of relations. A perception does not occur in some simple one-to-one correspondence between object in the world and picture in the brain, but through complex and distributed patterns of relation. We respond to the world, not as blank slates being imprinted with data, but as dynamic and self-regulating systems.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Life strives to maintain itself, and does so not by ‘picturing’ an outside world, but through an ongoing, interactive, and non-linear system of responses and adjustments. The non-linearity is crucial, even in the most simple of perceptions. There is not a self who captures the image of an object, but a body orienting itself toward (and anticipating) the world that is always given in a certain way. This dynamic engagement will enable the synthesis and relation to data, which in turn produces certain bodily relations, and these in turn allow further interaction with the world. If we want to understand thinking, according to Antonio Damasio, then we should not begin with cognition or representation—some mind housed in a body— but begin with the body as a self-regulating system, a system that does all it can to maintain its own state of equilibrium, and that will ultimately experience any bodily emotions or ongoing adjustments as ‘the feeling of what happens.’ More importantly, that process of interaction can only be between organism and world if there is some boundary that distinguishes between surviving life and milieu:  simple to complex, most living organisms exhibit it. What does vary is the degree to which organisms know about that urge. Few do. But the urge is still there whether organisms know of it or not.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Thanks to consciousness, humans are keenly aware of it. Life is carried out inside a boundary that defines a body. Life and the life urge exist inside a boundary, the selectively permeable wall that separates the internal environment from the external environment. The idea of the organism revolves around the existence of that boundary. (Damasio 137) What we must remove is ‘Descartes’s error,’ or the idea of mind as something distinct from life, for life just is an ongoing dynamic process of response, interaction, adjustment, orientation and—most importantly— sense. There is no possibility of a brute event, a body encountering a force that is not always already meaningful. This insistence on meaning need not be an anthropomorphic notion. And to see this we can turn to the broader and highly influential theory of life as necessarily autopoetic, particularly as adopted by the cognitive science of Maturana and Varela.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One of the crucial features of Maturana and Varela’s work is their definition of life that requires some form of boundary or membrane. Their definition allows, then, for autopoesis and meaning. Life is autopoetic because a living being maintains its own internal relations; a living system must be able—through interaction with its milieu—to sustain itself. Living systems are coupled to environments that are always defined as being what they are for that specific system; and this is how autopoiesis is tied to meaning. The environment of an organism is constituted in terms of that body’s possible responses: This basic uniformity of organization can best be expressed by saying: all that is accessible to the nervous system at any point are states of relative activity holding between nerve cells, and all that to which any given state of relative activity can give rise are further states of relative activity in other nerve cells  Further, life—unlike other living systems—has a certain self-productivity that is crucially defined in relation to that system’s border. If a cell can live on, and even reproduce, simply by existing in its milieu then we can call that cell a living system. Its living-on requires no intervention of any process or force other than relation to milieu. A clear contrast, of course, would be a machine or mechanism; a typewriter can produce text if connected to a human body, an ink ribbon and paper, but a typewriter placed in its milieu—sitting on a desk among papers—does nothing more than decay through time (even if that decay is considerably slow).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Maturana and Varela, tellingly, draw upon the philosophical tradition of phenomenology and its criticism of Cartesian notions of disengaged mind. As long as we define mind as a closed being that may or may not encounter some external world, and as long as we see that world as being encountered through knowledge, or perception as a mode of ‘picturing,’ then we will never understand the life of thought. This brings us to the next discipline that draws on notions of distributed and embodied cognition, linear systems and self-production: artificial intelligence. There had been a criticism, early in the rapprochement between philosophy and artificial intelligence, that had insisted that—following Heidegger—it was the very embodied, active, worldly and practical nature of thinking life that precluded anything like an ‘intelligence’ that might be replicated in a computer (Dreyfus, Dreyfus and Athanasiou 1986). But those very Heideggerian insights regarding the necessarily embodied and temporally complex nature of thinking have now enabled new developments in artificial intelligence. If we want to create thinking we should abandon the Cartesian model of an information center that would direct parts of a body-machine; instead we should begin with the response. In the beginning is the action in relation to an environment, and this action always occurs in an ongoing process of adjustments and responses. Creating a robot could be successful, not by building an information-loaded brain-like center, but by creating parts that were capable of adjusting and allowing feedback responses with an encountered environment.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  At the simplest level, for example, we would have more success in creating a walking machine if we were to begin with leg-like parts that  or representing minds who happen to be placed in bodies that then have to encounter some world. On the contrary, we are originally responsive and action-oriented and also—more importantly—naturally prosthetic, taking whatever we can from the world as an extension of our already world-oriented and can-do openness to life: The old puzzle, the mind-body problem, really involves a hidden third party. It is the mind-body-scaffolding problem. It is the problem of understanding how human thought and reason is born out of looping interactions with material brains, material bodies and complex cultural and technological environments. We create these supportive environments but they create us too. We exist as the thinking beings we are, only thanks to a baffling dance of brains, bodies, and cultural and technological scaffolding (Clark 2003, 10) We therefore need to rid ourselves of the idea of a mind that would be pure and would then use its body or supplement its body with alien materials. For matter, like the body, is always already familiar, already potentially available for the extension of our being as we make our way through life. In the ongoing striving to maintain ourselves all that we encounter may be incorporated, taken up as part of our ever-extending and constantly relational being: Autopoiesis in the physical space is necessary and sufficient to characterize a system as a living system.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Reproduction and evolution as they occur in the known living systems, and all the phenomena derived from them, arise as secondary processes subordinated to heir existence and operation as autopoietic unities. Hence, the biological phenomenology is the phenomenology of autopoietic systems in the physical space, and a phenomenon is a biological phenomenon only to the extent that it depends in one way or another on the autopoeisis of one or more physical autopoietic unities. (Maturana and Varela 1980, 113)  in relations that are always already affective, sensually attuned, emotionally responsive and autopoetic or homeostatic (on an individual and on a ‘social’ level). Steven Mithen has argued that before we have language as some system for conveying information, or before we have a grammar that would synthesize and organize a perceived world, there is an originally and communally-affective enjoyment of sound, that both gives each body a sense of its self in relation, and produces the social system of constitutive relations (Mithen 2006). Robin Dunbar has argued for the originality of gossip (Dunbar 1996). Against the idea that language begins as one body relaying content to another, Dunbar suggests that sound begins as a purely relational and communal phenomenon, allowing bodies to exist in community, through the feeling of sound and responsiveness. These developments in the sciences and social sciences have led to the emergence of a narrative regarding theory and the time of theory. There was a time when, suffering from the disease of intellectualism or mindcentered (or simply centered) approaches, we examined social systems in terms of conscious agents.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In so doing we adopted linear notions of causality, rather than looking at the complex, dynamic, interactive and materially distributed systems that contribute to any event (De Landa 2006). We also, no less disastrously, suffered from the linguistic paradigm, where ‘a’ system was seen as the ground through which we might interpret the world, when in fact the world is a dynamic network of interacting, affectively-attuned, responsive and self-maintaining bodies. Often this diagnosis of our misguided commitment to Cartesian notions of disembodied mind has been coupled with a moral program for cultural reinvention. Recent work in philosophy has suggested that if we turn to non-Western understandings of ‘mindfulness,’ where selves are not command centers but properly attuned to the world, existing as nothing more than a series of ongoing adjustments and mutual encounters, then we will be able to think more ecologically, less instrumentally and—most importantly— with far greater managerial success (Flanagan 2007). The three concepts of autopoeisis, equilibrium and homeostasis function in all these domains, of neuroscience, cognitive science, philosophy of mind, social theory and future studies. These concepts all presuppose  from its own responses and potentialities; any properly futural future would be a break with the self-constitution of the organism’s always immanent time, and yet all theories of relational organic life posit that without some departure from its sphere of ownnness the organism would have no life. In itself, or if it remains in itself, the organism has no future. There can only be a time to come if we open out from our embodied, relational, world-attuned being.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The world within which we are situated—if we accept that ‘we’ are nothing other than the situated and responsive beings that we are—is always a world encountered in terms of possible responses. We exist in meaningful milieus. Our condition as embodied, as relating to the world as the beings that we are, is that the world is given as this world for us. To a certain extent, then, we are protoecological, originally attuned to our milieu. If we have a future, so it is argued, it cannot be one of calculation, instrumental reason and the mere continuance or ourselves in isolation. Our future could occur only if we remind ourselves of embodiment, if we recall what we really are and once again live our attunement to our milieu not as accidental but as intrinsic to our very being. But there is another sense in which the organism has no future, and it is here that I want to turn back to the exclusion of non-bounded life from the definition of life in general. As long as we think of life as autopoietic, as that which strives to maintain itself, and as that which is necessarily attuned to a milieu, we will regard disembodied life as that which ought not to have occurred, or as a simple error: a certain living being— man—mistook himself for mind, but can always correct that error and recognize himself as properly embodied.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In defining Cartesian ‘mind’ as nothing more than a falsehood we will fail to account for its force, its persistence and the possible futures it presents to the organism that can only have a world of its own. Consider what needs to be excluded as long as we insist on life as that which is defined by self-maintenance: the virus, malevolent thinking, and inhuman futures. I want to conclude by placing these three excluded lives in contrast with three too-frequently cited normative bodies: the child, the Buddhist and the animal. In the current literature the Cartesian horror of the disembodied intellect—that is, the  cured by reference to animal, infant or non-Western life. The animal is nothing more than orientation or potential action for the sake of ongoing life, not yet burdened by the life-stultifying questions of the intellect. Animals also provide the norm for an originally affective and praxis-oriented language; birds and monkeys use sounds as ways of creating bonds or affective relations, not as the representation of some idea in general. The same applies to infants, whose perceptions are originally less cognitive than affective—seeing the world in terms of what enhances or harms the self, and experiencing sound as a sonorous caress (not as the vehicle of information). Finally, the Buddhist: if we suffer in the West from centered, disembodied, linear and instrumental notions of mind, then we would do well to pay attention to the eastern tradition of mindfulness.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Stephen Mithen has appealed to both infants and animals as indicating an origin of speech in non-semantic but embodied-relational modes of sound, while a series of texts on mindfulness, including the work of Owen Flanagan, has criticized Western instrumental consciousness and appealed to the more attuned modes of Buddhist awareness (Mithen 2006; Flanagan 2007). As I have already suggested, these ideals of a body that is at once identifiable through time yet also nothing other than its ongoing attuned responses must exclude other lines of life and time that are defined less through the maintenance of a border in relation, and more in a form of rampant and unbounded mutation. A virus cannot be defined as a form of life on the Maturana and Varela model; its lack of a border or membrane means that it cannot be considered in relation to its milieu. It does not maintain itself, and is not a living system precisely because it is only in its parasitic capacity to open other life forms to variations that would not be definitive of an autopoetic relation. What might the future or temporality of viral life be? It could not suffer trauma, could not be subject to an excess of influx that would destroy its living balance precisely because a virus is nothing other than a process of invasion, influx and (to a great extent) non-relation. A virus does not have a world: it is not defined according to its potential responses that would enable its ongoing being. In one respect then, it is only viral life that has a future: both in the sense  bounded and delicate attunement, is not really a future so much as the maintenance of the same through the constant warding off of a future that would be other than our own.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This brings me to the next non-bounded life, malevolence. If we are autopoeietic, embodied, attuned, responsive, dynamic and systemdependent beings, how is it that we have acted in such a way that we have created a future that will no longer be a milieu for the organisms that we are? If humans are so organically attached to a world that is itself a living self-maintaining and organic whole, how did the destruction of this symbiotic domain of life take hold? Can we say that the Cartesian figure of disembodied life as really a mistake, or is it not a more accurate picture of ‘man’ in the anthropocene era? This, I think, suggests that we need to consider the future that this non-organic, non-relational, rigidly disembodied life has allowed to occur. If life in its bounded form is relational, mindful, attuned, responsive and dynamic (and if this life has no future that is not always already its own) then what of the life that did not act to maintain itself, that did not respond to its milieu, that did not live with the sense of its trauma-sensitive membrane? As long as we fail to consider this life we fail to address the future. In recent attempts to deal with our future, and the malevolent damage or willful destruction we have enacted upon ourselves, it is often implied that once we recognize our truly relational and embodied condition we will indeed have a future.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If we could only see that we are not Cartesian minds contingently placed in a world that is of no concern to us, then we will recognize our originally ecological condition and once again live with a sense of the world (where sense is mindful orientation). One concrete example of an ethic of the future, based on a recognition of our proper embodiment, is the turn to mindfulness. From philosophy to business management, it is argued that if we recall to ourselves our intrinsically embodied and in-the-world being, then we will act with respect and care (rather than destructive dominance) to what is not the self (but yet is always already constitutive of the self). Do we not, with this faith in the malleability, adaptability and possible future of this human body that could overcome its Western violence and rigidity, sim-  active and mutational. What any ethic of mindful responsiveness must do is dismiss as non-existent, or non-living, those forces of viral malevolence which have, until now, quite happily proceeded to make their way through the world without a thought of sustainability, and without a sense of the human as necessarily relational, embodied and affectively sensitive. How might we act if we acknowledged or even entertained the possibility of this viral and malevolent life, and if we considered the human not as a body coupled to a milieu, but as a series of potentialities that could branch out into territories beyond its own self-maintenance. How would we act if we recognized that insofar as the organism’s future is always the organism’s own then the organism has no future? Its time will always be determined in advance as the time of its own relations; and without the recognition of that other life that destroys such relations the organism’s time will come to an end.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A molecular or viral politics that did not assume the benevolence or trauma-resisting membranes of a self-defining body would have the following features. First, an attention to mindlessness: how do unbounded, non-self-maintaining processes—processes with no sense of relation— create a political territory that is not that of the polis or mutually recognizing bodies? And how do those bodies that we are, with only a sense of processes in relation to our own living systems—resist all recognition and interaction with the mindless? Why do we not have the strength or force to think of a world that is not our milieu? Second, a politics of viral futures: if we accept life-potentials that are not self-maintaining but that operate as nothing more than mutant encounters, then we move beyond a politics of negotiation among bodies to a politics devoid of survival. Perhaps it is only in our abandonment of ownness, meaning, mindfulness and the world of the body that life, for whatever it is worth, has a chance. This, indeed, is the direction offered by Deleuze and Deleuze and Guattari’s thought: a capacity to take intuition beyond the organism’s own duration to imagine qualities as such, a desire to overcome the brain of the organized body and approach thought as such opening to the eternal, and a relation between art and philosophy that does not assimilate sensation (the sensible) to what can be thought (the sensed) but approaches  forward to the ‘superman’—to the inorganic potentialities that exist now only in confused and all too human composites (Deleuze 1988B). Chapter 7  Face Race Defacing and Facing Humanity The human race is facing extinction.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One might even say that there is a race towards extinction, precisely because humanity has constituted itself as a race. The idea of a single species, manifestly different but ultimately grounded on a single human race of right and reason, has enabled human exceptionalism, and this (in turn) has precluded any questioning of humanity’s right to life. In actuality humanity is not a race; it becomes a racial unity only via the virtual, or what Deleuze and Guattari describe as a process of territorialization, deterritorialization and reterritorialization. In the beginning is what Deleuze and Guattari refer to as the ‘intense germinal influx,’ from which individuated bodies (both organic and social) emerge. Race or racism are not the results of discrimination; on the contrary, it is only by repressing the highly complex differential forces and fields that compose any being that something like the notion of ‘a’ race can occur. This is why Deleuze and Guattari argue for a highly intimate relation between sex and race: all life is sexual, for living bodies are composed of relations among differential powers that produce new events; encounters of potentialities intertwine to form stabilities. Such encounters are desiring or sexual because they occur among different forces that create new and dissimilar outcomes. If sex and desire refer to the relations among different quantities of force, race and races occur when those productions of differences are taken to be differences of some relative sameness.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In the beginning is sex-race or race-sex: the encounter of different potentials to form new emergent (relative) identities. Race  of territorialization: so that race (or kinds) unfold from sex, at the same time that sexes (male or female) unfold from encounters of genetic differences. All couplings are of mixed race. It is through the formation of a relatively stable set of relations that bodies are effected in common. A body becomes an individual through gathering or assembling (enabling the formation of a territory). A social body, tribe or collective begins with the formation of a common space or territory but is deterritorialized when the group is individuated by an external body—when a chieftain appears as the law or eminent individual whose divine power comes from ‘on high.’ This marks the socius as this or that specified group. Race occurs through reterritorialization, when the social body is not organized from without (or via some transcendent, external term) but appears to be the expression of the ground; the people are an expression of a common ground or Volk. The most racially determined group of all is that of ‘man’ for no other body affirms its unity with such shrill insistence.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘Humanity’ presents itself as a natural unified species, with man as biological ground from which racism might then be seen as a differentiation. The problem with racism is neither that it discriminates, nor that it takes one natural humanity and then perverts it into separate groups. On the contrary, racism does not discriminate enough; it does not recognize that ‘humanity,’ ‘Caucasian,’ or ‘Asian’ are insufficiently distinguished. Humanity is a generality or the creation of a majority of a monstrous and racial sort. One body—the white man of reason—is taken as the figure for life in general. A production of desire—the image of ‘man’ that was the effect of history and social groupings—is now seen as the ground of desire. Ultimately, a metalepsis takes place: despite surface differences it is imagined that deep down we are all the same. And because of this generalizing production of ‘man in general’ who is then placed before difference as the unified human ground from which different races appear, a trajectory of extinction appears to be relentless.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Man imagines himself as exemplary of life, so much so that when he aims to think in a posthuman manner he grants rights, lifeworlds, language and emotions to nonhumans. (And when ‘man’ imagines animal art or lan-  not as an expressive extension of the body, but as an expressive matter in its own right.) Man’s self-evident unity, along with the belief in a historical unfolding that occurs as a greater and greater recognition of identity (the supposed overcoming of tribalism towards the recognition of one giant body of human reason) precludes any question of humanity’s composition, its emergence from difference and any further possibility of its un-becoming. Humanity has been fabricated as the proper ground of all life—so much so that threats to all life on earth are being dealt with today by focusing on how man may adapt, mitigate and survive. Humanity has become so enamored of the image it has painted of its illusory beautiful life that it has not only come close to vanquishing all other life forms, and has not only imagined itself as a single and self-evidently valuable being with a right to life, it can also only a imagine a future of living on rather than face the threat of living otherwise. Part of the problem of humanity as a race lies in the ambivalent status of art, for art is the figure that separates white man par excellence: humanity has no essence other than that of free self-creation, all seemingly different peoples or others must come to recognize their differences as merely cultural, as the effect of one great history of self-distinction. However, if art were to be placed outside the human, as the persistence of sensations and matters that cannot be reduced to human intentionality, then ‘we’ might begin to discern the pulsation of differences in a time other than that of self-defining humanity. Art would not be an extension of the human, a way in which man lives on and creates himself through time.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Art would be bound up with extinction, signaling the capacity of matters to insist and persist beyond any animating intent. Far from extinction or human annihilation being solely a twenty-first century event (although it is that too), art is tied essentially to the nonexistence of man. Art has often quite explicitly considered the relation between humanity and extinction. For it is the nature of the art object to exist beyond its originating intention, both intimating a people not yet present (Deleuze and Guattari 1994, 180), and yet also often presupposing a unified humanity or common ‘lived.’ Wordsworth—yes, Wordsworth!—was at once aware that the sense of a poem or work could  Oh! why hath not the Mind Some element to stamp her image on In nature somewhat nearer to her own? Why, gifted with such powers to send abroad Her spirit, must it lodge in shrines so frail? (Wordsworth 1991; The Prelude V 45-49). If the archive were to be destroyed, would anything of ‘man’ remain?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Art gives man the ability to imagine himself as eternally present, beyond any particular epoch or text, and yet also places this eternity in the fragile tomb of a material object: ‘Even if the material lasts only for a few seconds it will give sensation the power to exist and be preserved in itself in the eternity that coexists with this short duration’ (Deleuze and Guattari 1994, 166). ‘Man’ as a race (as a unified body imagining himself as a natural kind) is essentially tied to extinction: for man is at once an ex post facto or metaleptic positing of that which must have been there all along, awaiting eternal expression. At the same time ‘man’ is also that being who hastens extinction in general by imagining himself as a single tradition solely worthy of eternal life, stamping the world with his own image. This unified humanity that has become intoxicated with its sense of self-positing privilege can only exist through the delirium of Race, through the imagination of itself as a unified and eternal natural body: All delirium is racial, which does not necessarily mean racist. It is not a matter of the regions of the body without organs ‘representing’ races and cultures. The full body does not represent anything at all. On the contrary, the races and cultures designate regions on this body—that is, zones of intensities, fields of potentials. Phenomena of individualization and sexualization are produced within these fields.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We pass from one field to another by crossing thresholds: we never stop migrating, we become other individuals as well as other sexes, and departing becomes as easy as being born or dying. Along the way we struggle against other races, we destroy civilizations,  Racial delirium is not only a passage through differential flux from which identity emerges; it also entails that ‘we destroy civilizations’— affirming the potentiality of reducing any produced culture or tradition to ruins. Man exists above and beyond any particularity; as one grand racial unity, he is that through which cultural distinction emerges. If racial delirium occurs as an affirmation of the possibility of anything becoming extinct, racism is a neurotic grip on survival. Racism—including, and especially, the affirmation of ‘man’—is a repression of racial delirium; racial delirium would open up to all the differences and intensities beyond any unified or generic ‘man.’ By contrast, racism affirms one great unity—the properly human—in which various kinds might be seen to differ by degree, being more or less human. Humanity is always a virtual production or fabrication that posits itself as ultimate actuality, occluding the differentials from which it emerges. The fabrication of man as a race that at once enables the lure of essential unity, and yet places that unity in the fragile monuments of art today (in the twenty-first century) faces the actual threat of extinction. Given that threat, how might art adjust to a milieu of imminent, probably certain, disappearance?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  How might this race that has for so long surrounded itself with art, and mirrored itself in art, open out to the world upon which it depends but which it has nevertheless almost annihilated? How does the human race turn from mirroring itself, enclosing itself in the cave of its own images, to thinking its inextricable intertwining with fragile life? These questions are not new. All art has the problem of extinction and race at its core. Any sentence that begins with ‘All art…’ needs to be treated with extreme suspicion. The logic of racism, after all, has always defined the properly human from a single moment—deep down they are all (or should be) just like ‘us.’ And, as already mentioned, the figure of art is crucial to this unifying lure: deep down we are all human, all the same, and express ourselves differently in the grand tradition of human art. Such claims are less often made by art historians than they are by philosophers, who are fond of speaking of art as such, or art in general, or the essence of art, and who usually deploy such concepts to smuggle in  when philosophy seemingly detaches itself from the assumptions of normativity, when philosophy speaks for man in general. Kant’s insistence on aesthetic judgment as reflective, presupposes Western art practices of framed and detached art objects: man realizes that he is not just a physical body, but a subject who can feel himself as a creative being responsible for the reason of the world.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  When Jacques Derrida affirms that ‘literature is democracy’ (Thomson 2005, 33; Kronick 1999, 166) he includes all literary practice under a high modernist norm of framed voice (art is not what is said, but a presentation that there is ‘saying’); when Theodor Adorno (2004), more explicitly, shows the aesthetic as properly disclosed in modernist formalism he allows art in general to be oriented towards the disjunction between concept and reality; various Marxisms or historicisms will begin an account of art in general from this or that exemplary object (the social novel, Greek tragedy, postmodern reflexivity). Deleuze and Guattari seem both to fall into this (possibly unavoidable) universalizing tendency with their distinction between an art of affects and percepts and a philosophy of concepts. And yet their insistence that art emerges from a pre- or counter-human animality and that this ‘art’ lies in the capacity of sensations to persist in themselves, opens the thought of an inhuman time, and an eternity outside man (Deleuze and Guattari 1994, 182). This is why, also, they pay so much attention to the twinned concepts of race and face: for it is art that at once forms the figure of a common humanity (man as homo faber), at the same time as the resistance and decay of art objects opens life and creation to temporalities beyond those of a self-legislating humanity. It is most often philosophers, determined to secure a domain of life that is not yet submitted to convention, instrumentality, recognition, opinion, or assumptions of human nature, who will find in art as such that which precedes, exceeds or disturbs given systems. Art either offers us the capacity to reflect upon the worlds ‘we’ have formed (Habermas 1987), or, art brings ‘us’ back once again to humanity’s eternal capacity to be nothing other than the image it creates from itself (Agamben 1999, 68). But there are two ways this eternity might be thought: as humanity’s destiny—man as the capacity to create the thought of the universal—or  is necessarily always concerned with annihilation and specification (or the production of species, and the persistence of sensations beyond the life of the creator) then any claim that art is essentially or eternally of a certain mode belies art’s distinct fragility. That is, the claim to something like art in general reinforces the sense of man or humanity in general, and occludes what Deleuze and Guattari have presented as the animality of art, its existence in pure matters of sensation.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  When Deleuze and Guattari [1994, 165] argue for art as the preservation of sensations that exist before man—sensations that persist in themselves—they go a long way to destroying the race of man. [P]henomenology must become the phenomenology of art because the immanence of the lived to a transcendental subject must be expressed in transcendent functions that not only determine experience in general but traverse the lived here and now, and are embodied in it by constituting living sensations. (Deleuze and Guattari 1994, 178) Art is not the expression of humanity, in general, but the destruction of any such generality through the preservation and temporality of the ‘nonorganic life of things’ (Deleuze and Guattari 1994, 180). Art, traditionally conceived, has been racial in a double sense: it offers figures of man in general (always—in Western art—the white face of the subject); and is then archived as the expression of a humanity that comes to know and feel itself through the creation of its own pure images. Art, Face, Race Art is always the preserving of a sensation that is of its time, but that is submitted to existence for all time. If art is to figure something like ‘the human’—and if the human is, philosophically, an openness to world that is given best in the face—then it must always do so through the material figure of some specified head. Emmanuel Levinas’s argument that the face is singular, and that the singular relation to any face disrupts a logic of calculation and specification, is an extreme philosophic argument; it  Figure 1: Joanna Kane, William Blake deathmask, from The Somnambulists, 2008. Dewi Lewis Publishing 2008.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Photo courtesy of Joanna Kane. not of this world of beings—and yet returns that transcendence to the privileged body of man: The same and the other can not enter into a cognition that would encompass them; the relations that the separated being maintains with what transcends it are not produced on the ground of totality, do not crystallize into a system. Yet do we not name them together? The formal synthesis of the word that names them together is already part of a discourse, that is, of a conjuncture of transcendence, breaking the totality. The conjuncture of the same and the other, in which even their verbal proximity is maintained, is the direct and full face welcome of the other by me. This conjuncture is irreducible to  with the conjunction ‘and’ the Other continues to face me, to reveal his face. (Levinas 1979, 80-81) Levinas’s elevation of the face relies on an experience of a singularity that would be liberated from all generality, that would not be a specification of this or that universal type. Levinas’s appeal to the face is at once non-semantic, for the face disrupts generality and communication or shared notions of what counts in advance as human; the face appears in its singularity as this face, before me, here and now.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If, however, such a face were to be figured in art it would need to take on some specification, where specification is always of the species or race. A face ‘as such’ without species might be thought but it could only be figured through this or that concrete head. Even when it does not figure human bodies, persons or faces, art is always about face and always about the extinction of species. It is always a presentation of this earth of ‘ours’ witnessed from our race: ‘All faces envelop an unknown, unexplored landscape; all landscapes are populated by a loved or dreamed-of face, develop a face to come or already past’ (Deleuze and Guattari 2004b, 191). So there are two twinned (yet necessary) impossibilities. First, a work of art can live on, as eternal and monumental, only if it takes on a material support: my thoughts can be read after my life only if I inscribe them in matter. And yet, second, that matter is also essentially fragile, corruptible and subject to decay. A face—or the witnessing of the subject in general—can only occur through some racialized head: I can only imagine humanity in general, as spirit, through the species.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The eternal—the sense of art, the subject of the face—is always constituted through this object, this head. The logic that intertwines face, race and art is the logic of life: a unified body or species can only occur through persisting beyond individual bodies— a race is like an artwork or monument, surviving beyond individual life—and yet, such persisting unities also only survive through variation. A race or species varies and opens to other differences in order to live on, just as the individual human subject can persist through time, beyond himself, only by supplementing himself through the matters of art. A work of art is only a work if it has taken on some separable and repeat-  term) and be exposed to inevitable decay, so the bounds of a race are possible only because of a specification that requires an ultimately annihilating variability; a race or species is possible only because of something like an art in life, a variability that both enables the formation of living borders but that also entails the annihilation of bounds. A race is at once the gathering of sameness, a certain genetic continuity, and an openness to difference—for a race continues through time via sexual variation. In the remaining sections of this chapter I want to explore two ideas about extinction and race in relation to art works that will allow us to look at the ways in which all life is oriented to an oscillation between extinction and specification (or ‘raciation’), and that this leads to an impure border between the faces of philosophy—or the idea of a humanity as such—and the heads of art, or the material figures through which that humanity is given. As a preliminary opening to these two ideas of race and extinction I want to consider three visual images, the first of which is the smiley face that came to stand for acid house culture, while the second is William Blake’s death mask refigured first by Francis Bacon’s 1955 ‘Study for Portrait II (after the Life Mask of William Blake),’ and second by the contemporary Edinburgh photographer Joanna Kane (Kane 2008). All of these images, in different ways, problematize the distinctions between the face and the head, between philosophy and art, or between species-survival and extinction.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If we want to consider something like a pure form of the face (theorized philosophically) then we could turn to Levinas’s detachment of the face from all generality, calculation, mediation and specification: for Levinas a face is not a head. The latter is a body part, and might also figure something like the biological human species to which ‘we’ would owe certain allegiances and contracts. On a bodily, psycho-physical or (for Levinas) non-ethical level, it is because others have bodies like mine that I enter into certain sympathies, and this would allow ‘us’ to maintain ourselves in relation to external threats and a milieu of risk (so the head would also signal something like Bergson’s ‘morality,’ which is a bonding formed through relative likeness [Bergson 1935]). For Levinas, all philosophy that has been grounded on being, or that has  singularity of the face. It is the encounter with this face, here and now, that disrupts convention, sign systems, repeatability and doxa; it is this singular face that prevents the reduction of otherness to an event within the world. The face enables us to pass from (or through) the heads that we recognize as part of a common species, to the other whom we can encounter but never know. Or, in Bergson’s terms: from something like a common morality of humanity premised on a specified kind, one would pass to the thought of a virtual, not yet present and singular other. The face would give us something like pure life: not the form or matter that one recognizes as the same through time and that is subject to decay and exposure to risk, but the animating spirit of which matter is a sign.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The face for Levinas is, after all, not a sign or mediation of humanity so much as an experience or rupture with all mediation and sense. (The same applies for those who invoke his work today, amid conflicts among peoples [Butler 2006, 133].) Life, however, is never pure and its processes of variation and creativity are known only through the relative stability of bounded forms. These forms and bounded beings are perceived as the beings that they are only by reducing the intense fluctuations and differences into ongoing and recognizable figures. At the other end of the spectrum from the pure life of a perception that is not yet frozen or determined into any relatively inert figure is the mere head. If the head for Deleuze and Guattari occurs with a pre-modern tribal individuation that is not yet that of humanity, it is possible to see this head again today in the post- or counter-human head of the smiley face. So lacking in distinction that it has neither race, nor humanity, nor artfulness, the smiley face signals loss of life (having become a punctuation mark in emails and text messages: ‘:)’). It is the retreat from specification and the removal of any definitive body—anything that would allow for engaged sympathy—that makes the smiley face at once the most vulgar of heads, as though even the primitive animal totem heads (or portraits commissioned through patronage) were still too singular to really enable the joys of a loss of face.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In two recent books the neuroscientist Susan Greenfield has commented on the contemporary problem of meaning, sensation and identity. Drugs that work to overcome depression may operate by relieving  cannot, Greenfield argues, simply enjoy a sip of espresso, the feel of sunshine on the skin or the sound of a flowing stream (Greenfield 2000). The depressive is focused on meaning or connection, tying sensations into a resonant whole, and cannot therefore experience the senseless ecstasy of sensation as such. An experience is meaningful if it is placed in the context of past encounters and future projects, but a certain joy is possible only if that neural network of sense is also open to sensation. One must be a self—having a certain face and singularity that defines one as who one is in terms of one’s projects—but one must sometimes also be just a head: a capacity to feel or be affected without asking why, or without placing that sense in relation to one’s own being and its ends. Greenfield’s more recent book, ID, has—despite her earlier recognition that we sometimes need to let go of identity and meaning—lamented what she sees to be an attrition of our neural architecture (Greenfield 2008). While the current drug and computer-fuelled retreat from syntax and recognition—and its accompanying sense of self—has its place, contemporary culture’s focus on flashing screens, disconnected sensations and immediate intensities is hurtling in an alarming manner to a total loss of face. There is a widespread loss of being someone, and a disturbing tendency towards being ‘anyone.’ That such a process of neural extinction accompanies species extinction is not a mere coincidence, and that such a movement towards not being someone is symbolized by the smiling head of ecstasy use should give us pause for thought.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  As the species comes closer to the extinction that marked its very possibility as species, it has retreated more and more into its own self-identity, becoming more and more convinced of the unity of race (the humanity of man in general). One could only become this or that marked race—especially the race of man—by closing off absolute difference and englobing oneself into a determined and self-recognizing kind: ‘When the faciality machine translates formed contents of whatever kind into a single substance of expression, it already subjugates them to the exclusive form of signifying and subjective expression’ (Deleuze and Guattari 2004b, 199). Is it any surprise that today, confronted with actual species extinction, ‘man’ ingests drugs that relieve him of meaning, buys  something that is accidentally destructive, or could we not say that the face of man emerges from such self-enclosure? Is not the grand scene of Levinas’s ethics—one face to another without intrusion of a third or any other world—not the mode of coupling that has led to the earth’s defacement? Today’s culture of self-annihilation—an overcoming of face, sense and bounded recognition—may not be as lamentable as Greenfield and others suggest. It may be a perfectly inhuman (and therefore wonderful) response to a world in which the value and art of one’s species is no longer unquestionable. Is face, human face in its radical distinction and immateriality, really what one wants to save? Acid house visual and aural culture, apart from being signaled by the smiley face, rely on an elimination of a time of development and figuration in favor of a time of pulsation.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Music of this style, along with trance and later forms of dubstep and brostep, destroy the man of speech and reason for the sake of sensations liberated from humanity. Not only do the drugs that accompany trance and house music allow for the experience of sensation without a framing of sense, the music is characterized by instrumental—usually digitally synthesized—repeated chord sequences, with infrequent and non-complex modulations, pulsing rhythms and uses of language that are sonorous rather than semantic. Visuals that accompany this music are not so much abstract as minimal, not geometric forms and figures but intensities of light and color. That this movement of acid house is part of a broader tendency towards loss of face is signaled by the smiley head it takes as its totem, by the general culture of counter-syntax described by Greenfield, and by the strange neural tie between the face and specification. What such late capitalist events disclose is what Deleuze and Guattari refer to as a ‘higher deterritorialistion;’ there is not a movement back to the one single ground of humanity, but a creative release that opens out towards a cosmos of forces beyond humanity. More specifically one might note, then, that it is not by inclusion or extension of the categories of rights and humanity that one might overcome the intrinsic racism (which is also a species-ism) that regulates the concept of man. Rather, it is by intensifying sensations that one is liberated from the face of the signifying subject, opening forces to the inhu-  The face is not animal, but neither is it human in general; there is even something absolutely inhuman about the face. To the point that if human beings have a destiny, it is rather to escape the face, to dismantle the face and facializations, to become imperceptible, to become clandestine, not by returning to animality, nor even by returning to the head, but by quite spiritual and special becomings-animal, by strange true becomings that get past the wall and get out of the black holes, that make faciality traits themselves finally elude the organization of the face….\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (Deleuze and Guattari 2004b, 189) One of the most commonly cited neural disorders in much of the current popular literature regarding the brain is Capgras syndrome, where a patient without any delusion or loss of cognitive function, sees a close relative but then claims that this relative is an alien or imposter (Feinberg and Keenan 2005, 93). (This would be the opposite tendency of ecstasy culture where every stranger appears as a beloved.) What is missing is not any visual or cognitive input but affective response: if the emotional intensity or affect is not experienced then I claim—despite all evidence to the contrary—that this is not my mother, or child or partner. This syndrome has been widely cited in order to claim that we are not solely or primarily cognitive beings, and that our relation to others requires an affective response to their visual singularity—not simply the knowledge or recognition of who they are. This might seem both to support and refute the Levinasian face. On the one hand it seems that—despite Levinas’s claims that the face of the other makes an impelling claim on me—it is really only certain faces with a specific visceral genealogy pertinent to our own being that are truly experienced as faces; everyone else is a mere head. On the other hand, it also appears that the face is not one object in the world among others, not reducible to a knowable and identikit type, for faces are radically singular. Faces engage affective registers that cannot be overridden by cognitive or simply visual inputs.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A face at once has no race, for if I see this other as a face then I am devoted to an affective response that has nothing to do with general (or genetic) speci-  face that is bound up with my own organic and specified becoming. The face is at once that which is radically exposed to extinction, given that I experience as face only those heads bound up with my world, time and life. At the same time, the face appears to be quite distinct from organic survival; the body of the other person is before me, and yet something is missing. The affect, which is not a part of their body but is bound up with their capacity to be perceived in a certain manner, is what marks their singularity: The human head implies a deterritorialization in relation to the animal and has as its correlate the organization of a world, in other words, a milieu that has itself been deterritorialized (the steppe is the first ‘world,’ in contrast to the forest milieu). But the face represents a far more intense, if slower, deterritorialization. We could say that it is an absolute deterritorialization: it is no longer relative because it removes the head from the stratum of the organism, human or animal, and connects it to other strata, such as significance and subjectification. (Deleuze and Guattari 2004, 191) One response to the border of the face—to this strange body part that is at once an organic head and also a marked out, fragile and exposed singularity—is a form of willed extinction. If there has been a tradition of art dominated by portraits, signatures, leitmotifs and claims to radical distinction and living on, there is also a counter-tradition of the head rather than the face, concerned with annihilation, indistinction and becoming no one.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Faced with the all too fragile bounds of one’s specified being one could either cling more and more desperately to one’s englobed humanity—asserting something like Levinas’s pure face as such—or one could confront the head head-on. Both Francis Bacon’s portrait of Blake and the contemporary Scottish photographer Joanna Kane’s photograph are taken from William Blake’s death-mask. Blake, perhaps more than any other artist, exposed the impure logics of extinction, specification and art. Resisting an increasing culture of commodification and the annihilation of the artist’s hand,  himself in the morass of markets, mass production and already given systems, Blake engraved every word of his poetry on hand-crafted plates, colored every page with his own hand, invented his own mythic lexicon and gave each aspect of every one of his ‘characters’ a distinct embodied form. As a consequence of seizing the act of production from the death of general systems, and directly following the assertion of his own singularity against any general humanism, Blake’s work is more subject to decay, extinction and annihilation than any other corpus. Because Blake resisted the formal and repeatable modes of typeface, and because he took in hand his own creation of pigments and techniques of illuminated printing, it is not possible to detach the pure sense or signature of Blake’s work from its technical medium. The more Blake took command of technicity or matter—the more he rendered all aspects of the work artful—the more exposed his work was to the possibility of annihilation. It was because Blake’s work was so specific, so distinct, so committed to the living on and survival of the singular, that it was also doomed to a faster rate of extinction.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (Blake’s work can never be fully reproduced or anthologized.) Similarly, one can note that it is because it was so masterful at survival, at securing the sense of itself and its worth as a species, that humanity as a race faces accelerated destruction. Both Bacon and Kane depict Blake not through the surviving portrait, but through the death-mask. If the portrait is one of the ways in which the head is framed, signed, attributed and placed within a narrative of artist as author, creator and subject of a world of intentionality that can be entered by reading and intuition, this is because the face of the portrait is tied to an aesthetics of empathy, in which the hand of the artist is led by the idea of a world that is not materially presented but that can be indicated or thought through matter. In this respect the portrait can be aligned with what Deleuze refers to as a history of digital aesthetics, in which the hand becomes a series of ‘digits’ that in turn allows the world to be visualized, not as recalcitrant matter, but as a quantifiable mass in accord with the eye’s expectations (Deleuze 2005, 79). The digital—as universalizing and generalizing of the world—therefore presupposed what Derrida referred  (Derrida 1989, 84). For all its supposed resistance to mediation, representation and a history of Western being that has reduced the event of encounter to a general ‘being,’ Levinas’s ‘face’ is insistent on an immediate relation to otherness that is not diverted, corrupted or rendered opaque by the decay-prone flesh of the head. What sets the aesthetics of empathy, which would discern a spirit in the bodily figure, apart from the aesthetics of abstraction is just this positing of an immateriality that transcends matter.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is the other, given through the face, whose presence is not arrived at by way of analogy or concepts. This is possible only if all those matters that tie a subject to specification and therefore certain extinction are deemed to be transparent or external to some pure otherness as such, to some pure face that is not corrupted by the head. The portraits of Blake, like the sense of Blake’s work in general, do indeed survive and circulate beyond the author’s living body. Even so, that face of Blake and the sense of the work that survives beyond decaying matter are possible and released into the world only through a matter that is intrinsically self-annihilating. An aesthetics of abstraction, in contrast with empathy, is possible through a production, from matter, of pure forms; abstraction constitutes formal relations distinct from the singular, localized and subjective experiences of living organisms. One might therefore say that it is only through racial delirium—passing through and annihilating all the species of man—that one finds something other than racism, or man as he properly is. This might effect an ‘about-face.’ Blake’s work already confronted this relation between, on the one hand, discerning the world as possessed of spirit (a world of innocence in accord with an ultimately human face), and, on the other hand, a world of matter devoid of any life other than its reduction to pure forms of digits (the world of ‘single vision and Newton’s sleep,’ where experience knows in advance all that it will encounter). In his illuminated printing and engraving techniques Blake’s works confronted the resistance of the hand in relation to a matter that was neither pure form, nor living spirit, but yielded something like an analogical aesthetics—the genesis of forms and life from the chaos of materiality.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One could refer to this as a radically haptic aesthetic in which the eye can see the resistance of form emerging from  Bacon’s paint adds its own flesh of color to the form of the mask, while Kane’s highly finished photography renders the material object spiritual, not by gesturing to the face but by granting the matter itself its own luminosity. The visual surface of the photgraph, rather than the gazing face of the portrait, seems to posses at once its own spirit and its own temporality, specification and line of duration. It is matter itself, and not the living form it figures, that seems to endure opening its own line of survival, extinction and specification. Kane’s faces-heads are higher deterritorializations in two senses. The face that enables empathy and alterity becomes a head again, but not a head of the living organism so much as a material artifact of matters that are themselves expressive. The art object that would seem to signal the human organism’s potentiality to free itself from mere biological life, to create that which endures beyond its own being, itself shows all the signs of material fragility, exposure and annihilation. Philosophy finds faces in art; art is that creation of a signification of a sense beyond any body, of an endurance liberated from the instrumentality of the human organism. But there is always something of the crumbling, decaying, unspecified head in the faces of art.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Chapter 8  Posthuman Humanities Suddenly a local object, nature, on which a merely partial subject could act, becomes a global objective, Planet Earth, on which a new, total subject, humanity, is toiling away (Serres 1995, 5). There was something odd about Stanley Fish’s speedy intervention in the ‘debate’ about the closure of certain humanities departments: But keeping something you value alive by artificial, and even coercive, means (and distribution requirements are a form of coercion) is better than allowing them to die, if only because you may now die (get fired) with them, a fate that some visionary faculty members may now be suffering. I have always had trouble believing in the high-minded case for a core curriculum—that it preserves and transmits the best that has been thought and said—but I believe fully in the core curriculum as a device of employment for me and my fellow humanists. But the point seems to be moot. It’s too late to turn back the clock. (Fish 2010) In the general milieu of non-debate that pitched economic rationalism against an unquestioning right for the humanities to continue existing in its current form, Fish admitted that certain nineteenth-century ‘pieties’ would, today, not be believed. Fish himself did not disclose whether he believed these pieties or whether they ought to be believed; he went on to admit that keeping the valued humanities alive would require possibly coercive means. These means would not be a justification of the humani-  not.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Now, such a paean is odd given that one might have thought that if one really valued and wanted to sustain what ‘we’ learned from the French in their high theory heyday it might have been that education as a ‘core enterprise’ might be worth questioning (both for reasons of politics in Foucault’s sense, or the way disciplines constitute illusions of ‘the’ polity, and for reasons of good thinking, such that ‘keeping something you value alive’ might best be achieved not by clinging to survival but by a joyously destructive and active nihilism). Fish already suggests in his title—‘The Crisis of the Humanities Officially Arrives’—that the crisis was implicit up until now. Indeed the humanities have been in crisis, and for good reason. If, as Husserl already noted very early in the last century, the ‘sciences’ were in crisis because of a certain notion of ‘man’ as a natural animal blessed with technical reasoning capacities, then such a crisis could not but affect the humanities. Even Husserl accepted the impossibility of grounding any new knowledge or future-oriented discipline on man as he actually is and suggested that dealing with the crisis would entail opening a new line of thought beyond natural ‘man.’ Today, in a century that can begin to sense, if not articulate, humanity’s capacity to destroy its own species-being, along with the milieu that it has constitutively polluted to the point of annihilation, what sort of defense might one make for the future of humanities disciplines? Should one not, rather, say ‘no’ to everything that has defended and saved man and his future, especially to the concept of life and potentiality of which man would be the utmost expression? Do we not require a new discipline? This would need to take the form not of the humanities, especially if the humanities were to take on a certain motif of the posthuman.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  That is, if the humanities were to live on by consuming, appropriating and claiming as its own the life of animals, digital technologies, inter-disciplinarity (or the rendering of science as human) then there would merely be a continuation of a reactive nihilism. Posthumanism, as I will define it here, is not an overcoming of the human but takes a similar form to the structure of nihilism. Here is Nietzsche’s diagnostic account if nihilism: a ‘higher’ world of truth is positied behind appearances, so that this actual world is given lesser  belief in a transcendent redemption negated the force of this world for a higher world, then a reactive nihilism responded to the loss of transcendence with despair, the horror that there might be nothing more than this world. Similarly, humanism affirms all value and being on the basis of the human logos: what is true and right is that which can be rendered rational. When that belief in a rational and grounding humanity falls away, what we are left with is a world minus man, a world in which there is no longer a truth or being, only observation. We subtract man’s logical supremacy from the world and are left with the contingency of observation (Wolfe 1995). In this respect, the retreat to a world in which there is only man, not God, remains theological—for God has been subtracted but the world as God-less (abandoned to man) remains. The posthuman, similarly, renounces human privilege or species-ism but then fetishizes the posthuman world as man-less; ‘we’ are no longer elevated, separated, enclosed, detached from a man-less world, for there is a direct interface and interconnection—a mesh or network, a living system—that allows for one world of computers, digital media, animals, things and systems.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  There is a continuation of the humanities, which had always refused that man had any end other than that which he gave to himself, in the posthuman notion that man is nothing but a point of relative stability, connected to one living system that he can feel affectively and read. Not only have motifs such as ‘affect,’ ‘posthuman,’ living systems and digital media been explicit topics—giving the impression that ‘the’ humanities can survive criticisms of the illusions of a once-dominant (supposedly) Cartesian rationalism, these motifs have intensified and entrenched the strategies that have always marked the humanities. They allow for business as usual—in the same manner that nihilism allowed for a continued theologism; we have abandoned God and man, but now live this world as what is left after the subtraction of God and man. What we have are living interconnecting systems, with no point of exception, privilege or transcendence. If a world devoid of God and man continues a certain myopia of insisting that what is is that which can be observed, this ultrahuman posthumanism is conducted in a reactive and resentful mode. For what have ‘the posthuman,’ ‘affective’ or ‘ethical’ turns licensed? There  language is dead, and we no longer believe that this world of ours is given order from without by ‘a’ system of language or structure which it would be the job of literary critics or cultural studies to decode. There has been a return to life, bodies, animals, ecology and the inhuman in general, as though we are once again liberated from the prison of our humanity, no longer distanced from the world and now able to find a truly post-theory, posthuman world of life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We turn back to history, contexts, things, bodies, life and nature. The humanities would, through all its demarcation disputes, attacks, defenses and mutations be defined not by a normative notion of the human but by an anti-normative insistence that man is not, for he has no positive being other than that which is given to him by virtue of his historical and living becoming. The humanities would be primarily critical and interpretive, and would be entwined with a logic of negation and refusal. The sciences would be procedural, operating from within paradigms (however sophisticated, reflected upon or provisional) while the humanities would occur through self-distancing or reading: whatever life or system is given, it is the task of the humanities—because there is no such thing as the human—to open a space of conversation, legitimation, questioning or critique. Without such a space one would be reduced to the ruthless actuality of metrics or utilitarianism. ‘Man’ as given in the humanities is not the man of science (subjecting the world to so many repeatable, efficient and quantifiable functions). Nor is the humanity of the humanities the ‘man’ of the human sciences (whereby man’s social and political being can be read as an expression of what Foucault refers to as his ‘empirical density’: man speaks and labors because of the needs of life, and it is this emergence from life that allows man to read himself in today’s anthropology, social linguistics, evolutionary psychology and cognitive archaeology). The man of the humanities was already posthuman, possessing no being other than his reflexive capacity to read his own ungrounded and utterly flexible becoming.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘At the very moment that we are acting physically for the first time on the global Earth, and when it in turn is doubtless reacting on global humanity, we are tragically neglecting it’ (Serres 1995, 29). comprise the humanities. Rather, ‘humanity’ is a meteorological imperative, a concept that needs to be created today in order to confront the change in techno-geological climates. Serres’s work, despite its manifest humanism in The Natural Contract, does not take the form of a resistance to the technical reduction of man to systems. (What his work demands, in a manner similar to Deleuze’s affirmation of differential calculus, is not an overcoming of calculation but a more subtle differential calculation: a reckoning of the quantities and systems produced by the relations among the bodies of the human species and the other forces upon which it is parasitic.) Serres’s theorization of the human is not a posthumanism that would happily conflate human existence with life in general. Such posthumanisms are, as I have already suggested, ultimately ultra-humanisms insofar as they attribute all the qualities once assigned to man—qualities such as mindfulness, connectedness, self-organizing dynamism—to some supposedly benevolent life in general that needs to be saved from the death of merely calculative systems. Against this Rosalyn Diprose has re-asserted the role of human meaning, perception and value in providing an opening of the event in an otherwise leveled world: Formulating an ethics for the posthuman world requires a more considered ontology to supplement that which is assumed in biopolitical analysis.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The challenge is to better understand what kind of collective practices allow the emergence of the ‘event’ within assemblages of human, nonhuman, meaning, and technical elements without ignoring the mediating role of (historically conditioned) human perception, receptivity and responsiveness. (Diprose 2009, 13) That is, supposedly, the value of the humanities today, lies both in its ideal resistance to a culture of economic rationalism and narrow utilitarianism and its less pious claim to educate students with transferable skills or critical reasoning or rhetorical flexibility. The humanities of posthumanism has happily abandoned species-ism and exceptionalism—man is no longer adjudicator or hermeneutic arbiter outside the web of life—for there is one de-centered, mutually imbricated, constantly creative mesh,  The ecological thought imagines interconnectedness, which I call the mesh. Who or what is interconnected with what or whom? The mesh of interconnected things is vast, perhaps immeasurably so. Each entity in the mesh looks strange. Nothing exists all by itself, and so nothing is fully ‘itself. ’ There is curiously ‘less’ of the Universe at the same time, and for the same reasons, as we see ‘more’ of it.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Our encounter with other beings becomes profound. They are strange, even intrinsically strange. Getting to know them makes them stranger. When we talk about life forms, we’re talking about strange strangers. The ecological thought imagines a multitude of strange strangers. (Morton 2010, 15) Morton’s project differs both from the simple ecological affirmations that would reunite humans with a lost nature (for he aims to think ecology without grounding and unifying nature), and also from the strands of ‘object oriented ontology’ that would insist that not everything is connected (Harman 2012, 132). And it is this latter possibility of disconnection or detachment that is, I would suggest, productively inhuman. Yes, most avowed posthumanisms have celebrated the destruction of man as the ground of all reason, but what they have brought back is one grand whole of interconnected systems of observation (often readable in terms of some grander system of class, power or life).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But it is the sacrifice of man as Cartesian subject in favor of a posthuman ecology of systems that allows the humanities to live on. If the human is assumed to be nothing more than an interface, already at one with a world that is one living system, then posthumanism is nothing more than the negation of a humanism that never was. It is an ultrahumanism precisely because once man is abandoned as a distinct system or inflection he returns to characterize nature or life in general, just as the death of God left an implicit and widespread theologism that no longer had a distinct or explicit logic. Posthumanism is an ultrahumanism and partakes of the same metaleptic logic of reactive nihilism. In nihilism, a higher world is posited to justify or grant worth to this world. This higher world is posited from a reaction  ‘man’ to grant sense to existence, then when ‘man’ is negated or removed what is left is the human all too human tendency to see the world as one giant anthropomorphic self-organizing living body. Not surprisingly, there become increasingly shrill calls for human meaning (including a pragmatic or humanized religion, and a certain substitution of literature for God as the ground of human sense-making). ‘Man’ is effected as that animal who would be especially poised to read the logic of life, and this because of his capacities for speech and sociality; it is the creation of man that enables a certain concept of life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  When man is destroyed to yield a posthuman world it is the same world minus humans, a world of meaning, sociality and readability yet without any sense of the disjunction, gap or limits of the human. Like nihilism, the logic is metaleptic: the figure of man is originally posited in order to yield a sense or meaning of life, and yet when man is done away with as an external power what is left is an anthropomorphic life of meaning and readability. A certain idea of man—Foucault notes—was intertwined with the possibility of the human sciences and of a concomitant notion of life. If, for Foucault, both ‘man’ and ‘life’ emerge in the eighteenth century this is because there is a new distribution in the table of knowledge, a new fold between inside and outside. Rather than examining the forms of living being in a world of analogies—with humanity being an expression of a broader cosmology, there is now something like life as such with its specific temporality and imperatives. Whereas humans had been privileged beings (blessed with reason) it is now man who is at once empirically constituted by life (required to speak, labor and constitute polities because of the needs of his species being) and yet also capable of reading that logic of life as transcendental: psychoanalysis, Marxism, ethnography, structuralism and (today’s) evolutionary psychology or cognitive archaeology all account for the modus of the human organism according to a certain logic of life. [T]he end of metaphysics is only the negative side of a much more complex event in Western thought. This event is the appearance of man.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  However, it must not be supposed that he suddenly appeared on our horizon, imposing the brutal fact  so violently. No doubt, on the level of appearances, modernity begins when the human being begins to exist within his organism, inside the shell of his head, inside the armature of his limbs, and in the whole structure of his physiology; when he begins to exist at the center of labour by whose principles he is governed and whose logic eludes him; when he lodges his thought in the folds of a language so much older than himself that he cannot master its significations, even though they have been called back to life by the insistence of his words. But, more fundamentally, our culture crossed the threshold beyond which we recognize our modernity when finitude was conceived with an interminable cross-reference with itself. Though it is true, at the level of the various branches of knowledge, that finitude is always designated on the basis of man as a concrete being and on the basis of the empirical forms that can be tied to his existence, nevertheless, at the archaeological level, which reveals the general, historical a priori of each of these branches of knowledge, modern man—that man assignable in his corporeal, labouring, speaking existence is possible only as a figuration of finitude. Modern culture can conceive of man because it conceives of the finite on the basis of itself. (Foucault 2003, 346) Today, even though man as a privileged being has been incorporated into a posthuman plane of interacting living systems what remains is the reactive and ultrahuman logic of finitude: it is because there is life (or a being’s relation to an ecology) that one can only know the world as it is given through organic conditions. A being is alive insofar as it maintains itself and does so in relation to a milieu that it perceives according to its own capacities; humans and animals have worlds, and the world is not so much data to be represented by an imposed order nor a book of life but an interactive and dynamic mesh of living systems. One can account for language, labor and life according to a single logic of man: a being emerges from the needs of self-maintenance (which in the case of man  If the humanities—for Foucault—had any value it would not be as an extension of this logic—such that we might see literature as emerging from evolving and self-furthering life, or as somehow the means by which the empirical being of man might be awakened to his proto-transcendental powers of critique.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Rather what Foucault referred to as literature would evidence something like a force beyond life, a machinic power that could not be referred back to the self-furthering human organism (Deleuze 2006, 110). Language would not be the system through which we could read man’s emergence from a general order of life as self-maintenance; it would not be world-disclosive, nor an extension of organic and organizing imperatives of life. Now if it is this man (of finitude) that has been removed from exceptionalism in the posthuman landscape, and if the humanities disciplines have abandoned poetic assumptions of human speech as a special or privileged domain for revelation, what remains is a negative or reactive continuation of anthropomorphic projection by other means. Selfmaintaining organicism and auto-poeisis are everywhere. In terms of theory this has led to a posthuman landscape in which there is one general dynamic system with animals, machines and digital codes all woven to constitute a single ecology; the knowledge procedures are generally extensive, subsuming more and more events within the domain of one evolving and efficient life. It is for this reason that Rosi Braidotti has marked out two distinct modes of posthumanism, one of which would draw attention to the ways in which lines of life and thought are ‘topologically bound’—not considered to be one expressive aspect of one single system of life. The posthumanism of which Braidotti is critical is of a single-system where all observations can be grounded on a single selfexpressive living whole (Braidotti 2006, 199). What is not considered in the posthumanisms of living systems are radically differing intensities, or intensive multiplicities, in which different speeds and economies open different and incompossible systems.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  I would suggest that it is no surprise, then, that certain Luddite modes of literary Darwinism have gained literary vogue. Despite the sophisticated achievements of Darwinism in philosophy and science (from thinkers as diverse as Elizabeth Grosz and  literary studies to purposive and meaningful life. Not only have explicit versions of literary Darwinism led to a rejection of high theory (a high theory that had supposedly imprisoned thought in language [Carroll 2004,29]); there has also been a more general proclaimed posthumanism that considers the absence of man to be a license for a new literalism, with direct talk of life, affect, bodies and ethics\/politics. The ethical turn, like the affective turn, is a turn back away from a supposed human imprisonment within language to the real and collective conditions of existence. One might cite, as an example, Eva Ziarek’s critique of Agamben. Agamben had already attacked the deconstructive attention to limits in order to retrieve the event of saying or opening of the political (Agamben 1999, 209). Ziarek, in turn, wants to take Agamben’s general concept of potentiality, from which the polity would open, and locate this force in intersubjective communality: ‘potentiality cannot be understood, as Agamben seems to suggest, in terms of the isolated subject and what ‘he can or can not do,’ because it is fundamentally a relational concept, emerging from the encounter with another ‘you.’’ (Ziarek 2010). In a similar manner Hardt and Negri also want to turn away from the locatedness of centering points of view, and therefore from language and other constituting, inhuman and transcendent (to human life) systems, to the commons, the multitude—immanent political bodies that would have nothing outside or beyond themselves (and certainly not any imposed norm of humanity): The primary decision made by the multitude is really the decision to create a new race or, rather, a new humanity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  When love is conceived politically, then, this creation of a new humanity is the ultimate act of love. (Hardt and Negri 2005, 26) In addition to these general affirmations that would now return man to the one common life of which he is a political and benevolent, and ultimately productive, expression, new ‘posthuman’ objects of interest also return differential structures to purposive, self-maintaining, fruitful and generative life. human comprehension. There has emerged in addition to a posthumanism that affirms a simple, continuous interface a critical posthumanism that affirms embodiment. In reaction to those who feel that humanity may extend or overcome itself through technology, there have been those who stress the resistance and significance of the embodied substrate, directly rejecting the ‘substrate neutral’ claims of those who stress computation (Dougherty 2001). Critical posthumanism reacts against the idea that the body is nothing more than contingent hardware or a vehicle for an intelligence or humanity that is primarily informational; this counter-technophilia is more critical of the residual humanist (or Cartesian, or rationalist) assumption that ‘we’ have now arrived at a point in history where technology might overcome the body. Critical posthumanism is nevertheless—like other affective, ethical, corporeal or postlinguistic ‘turns’—a retrieval of the lived body that follows the same logic of reactive nihilism. That is, whether one uncritically affirms the capacity for humans and life to evolve to a point of posthuman freedom from all grounded biology, or whether one maintains an insistence on bodies and interests, one nevertheless grants the human (and the humanities) a continued critical role of reading and meaning.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What is left out of play is the rigid separation or malevolence of the human that can neither be willed away in a mode of techno-vital euphoria, nor retrieved as some point of re-creating invention. By contrast, both Serres and Deleuze focus on the inhuman multiplicities of systems: Serres’s concepts of parasitism and pollution allow for an examination of what Deleuze and Guattari refer to as stratification (Deleuze and Guattari 2004, 176). While systems are relational, it is also the case that appropriations, overcodings and disturbances produce distinct registers. The human, as a concept, would be one way of thinking technological, meteorological or disciplinary thresholds that create intense ruptures. Humanity would be a disturbing outcome of systemic events, not an origin. Given that both Serres and Deleuze’s concepts of humanity or ‘the people’ are futural—gestures towards how we might think the ways in which the human-sensory motor apparatus has intersected with and created new speeds for other systems—it is not surpris-  occurs is cross-contamination or discursive germinal warfare rather than communication and a common life world. It was the genius of Foucault to take the modern logic of life and show its direct consequences for human disciplines. It is the turn to life—the idea that social historical man can be explained by a more general process of species being (or man as a laboring political animal)—that enables social sciences.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  These disciplines are reactive because they no longer present norms as direct imperatives but as following on from the needs of life; there can only be biopolitical management of populations if there are human sciences that enable an ethics of knowledge, an organization of the human species according to broader requirements of existence. The humanities, if they react against this reduction of man to a material body and affirm either the capacity of man as a speaking, laboring being not to speak or work (Agamben’s impotentiality) or more standard humanist affirmations of that which is not quantifiable because embodied, affective and lived, do nothing more than maintain the normative logic of life that would entail their redundancy. That is: let us say that the human sciences and bio-politics reduce ‘man’ to bare life, to being manipulable and manageable data. It follows that either the humanities becomes a supplement to this model—business ethics, bio-ethics, the production of transferable skills or critical reasoning—or, it argues that ‘humanity’ is never simply data, information, animality or bare life but has an excess of potentiality that remains unactualized. This would allow certain versions of posthumanism—those that argue for the ways in which animals or digital media complicate any simple Cartesian or rationalist model of the human—to keep the humanities alive. Man would not be mere biological mass, nor an information machine, and for this reason his ‘rights’ could neither be saved in themselves nor extended to animals and humans: on the contrary, the embodied interactions of humans, machines and animals would evidence a richness of the lived, of the affective, or suffering or lived body. So if man as a particular and exceptional being has been vanquished, what is saved is nevertheless a highly normative (theological-organic) logic of life in which the bounded and self-separating body with a world of its own is affirmed against various calculative reductivisms. never makes quite clear just what mode of humanities he wishes to save, or why such survival would truly be worthy.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  He does refer to the horror of closing French departments when it was precisely French culture that was the breath of life for humanities departments in the 1980s. One might note as an aside the odd objection to losing French (French!!!! ); Jean-Luc Nancy even protested, ironically, that it would of course be more efficient to learn ‘Java’ or Chinese (as the language of business). Was he really, in leaping to the defense of the humanities, suggesting that saving French was properly open and futural, while emphasizing Chinese was mercantile—akin to reduced ‘languages’ to ‘Java’? Peut-être serait-il judicieux d’introduire à la place, et de manière obligatoire, quelques langages informatiques (comme java) et aussi le chinois commercial et le hindi technologique, du moins avant que ces langues soient complètement transcrites en anglais. (Nancy 2010) Leaving aside what French might contribute to the twenty-first century, one needs to ask what aspect or consumed fragment of this mourned French theory yields a properly viable mode of humanities study. A certain strand of French thought—one highly suspicious not only of ‘man’ but of certain structures of knowledge in which the emergence of systems and idealities might always be returned to the lived—is precisely what has been occluded in so called posthumanism today. Indeed, the humanism that has been rejected is Cartesian computational or cognitive rationalism in favor of embodied, affective, distributed, emotional or subjective life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The humanities would somehow return disengaged logics and structures to the properly living or embodied plane of life from which they emerge. It is not only Habermas (1987), then, with his insistence that sciences always emerge from a lifeworld who domesticates and anthropomorphizes knowledge systems. It is what currently passes for French-inflected theory that celebrates the primacy of the lived. N. Katherine Hayles, one of the key figures of contemporary posthumanism, proclaims her distinction and theoretical sophistication from a naïve computationalism in a return to embodiment, and the lived. For Hayles:  privileges information over everything else. As we have seen, information is a socially constructed concept; in addition to its currently accepted definition, it could have been, and was, given different definitions. Just because information has lost its body does not mean that humans and the world have lost theirs. Fortunately, not all theorists agree that it makes sense to think about information as an entity apart from the medium that embodies it.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Let us revisit some of the sites of the computational universe, this time to locate those places where the resistance of materiality does useful work within the theories. From this perspective, fracture lines appear that demystify the program(s) and make it possible to envision other futures, futures in which human beings feel at home in the universe because they are embodied creatures living in an embodied world. (Hayles 1999, 244) This ‘critical’ posthumanism is reactive in two inextricable senses, morally\/politically and epistemologically. As Nietzsche described the logic of ressentiment: the lesser value of my life, the suffering or weakness I feel, is caused by some evil other—an other whose power and mastery proves their evil and my valued innocence. Like nihilism, which posits a higher world, diminishes the worth of actuality, and then falls into despair when the higher world is lost and there is nothing other than the actual, so ressentiment attributes all the world’s ills and evils to the Cartesian man of rationalism and instrumental reason, and finds enchanted life and unified nature to be worthy because innocent and other than human. One posits a value outside life (humanity) that would render life meaningful or worthy, and when that value is no longer affirmed or believed in one lives on in a state of weak, mournful and enslaved subjection. Only the humanities can grant meaning to the world: in the absence of both God and man all we are left with is meaning. Various calls to save the humanities rely upon an asserted ‘something’ that must be irreducible to the quantitative materialism of economic rationalism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Methodologically or epistemologi-  witnessed in its impotentiality (Agamben), the affective or lived experience that is manifest precisely in its alienation, or just a general weak affirmation of meaning (Cottingham 2003, Wolf 2010; Eagleton 2007). Just as Foucault (1978) argued that man would be maintained by a process of enquiring into his hidden sexuality that must be the cause of his being, so the human and humanities survive by continually searching for that ultimate cause from which calculative and scientific reasoning must have emerged. One reacts against theory and disenchantment by a return to the lived. Mark Hansen, self-proclaimed new philosopher of new media, insists that it is precisely when digital media produces images with which I strive (but fail) to identify or empathize that ‘my’ lived and affective embodiment is, by default, re-affirmed: the shift of affective power here explored—from image to body—goes hand-in-hand, and indeed exemplifies, a larger shift currently underway in our incipient digital culture: from the preformed technical image to the embodied process of framing information that produces images. What this means, ultimately, is that we can no longer be content with the notion that we live in a culture of already articulated images, as philosophers and cultural theorists from at least Bergson to Baudrillard have maintained. … Bluntly put, the processes governing embodied life in the contemporary infosphere are disjunctive from those governing digital information. Accordingly, in our effort to reconfigure visual culture for the information age, we must take stock of the supplementary sensorimotor dimension of embodied life that this heterogeneity makes necessary. Since there is no preformed analogy between embodiment and information, the bodily response to information—that is to say, affectivity—must step in to forge a supplementary one.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In order for us to experience digital information, we must filter it through our embodied being, in the process transforming it from heterogeneous data flux into information units—images—that have mean-  That is, the more inhuman, dehumanizing, replicating, alienating or simulating the image—the more the human appears as nothing more than appearance susceptible to inauthentic doubling—the more my alienated and impossible human feeling persists. It is as though the intensity of the despair I feel at your claims that God does not exist simply proves—through my very sense of loss and sadness—that really there must be a God or spirituality after all, known in His retreat or in my mourning. I feel a loss of meaning, ergo it is. The second example of subjective recuperation comes from Žižek, who draws upon Rancière and Badiou to criticize a postmodern politics of a single domain of circulating opinions and tolerated identities in order to affirm the event of the subject. In a mode akin to St. Paul’s universal Christianity in opposition to Greek sophistry or ‘the Jewish discourse of obscurantist prophetism,’ the subject is not an affirmed substance within the world, nor a messianic visitation from another world, but is given only in its act of break or disorder—again known only in its not being known: the way to counteract this remerging ultra-politics is not more tolerance, more compassion and multicultural understanding but the return of the political proper, that is, the reassertion of the dimension of antagonism that, far from denying universality, is consubstantial with it. Therein lies the key component of the proper leftist stance, as opposed to the rightest assertion of particular identity: in the equation of universalism with the militant, divisive position of engagement in struggle. True universalists are not those who preach global tolerances of differences and all-encompassing unity but those who engage in a passionate fight for the assertion of truth that engages them. (Žižek 1998, 1002) The problem with humanism, so it seems, is that it is deemed to be rather inhuman.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Cartesian subject of calculative reason, along with computational theories of mind or representation, including both older humanisms of man as supreme moral animal and posthumanisms envisioning a disembodied world of absolute mastery, cannot cope with the  man—the being who represents a world to be known—would give way to one single domain of life as living system. There would no longer be a privileged center of knowing, nor ‘a’ world in general, just a web, network or mesh of multiple worlds. This would either yield a macro-organicism of Gaia and deep ecology along with a humanities oriented towards care, concern and eco-criticism or deep ecology, or—and these two paths are not mutually exclusive—a highly interdisciplinary mode of humanities in which words and texts are part of the same circulating web of things, bodies, technologies, images or any other event. It is not surprising then that philosophy has argued for connecting the mind back to the world (Clark 1997) or putting mind into life (Thompson 1997), and for thinking of societies and living bodies, as well as political systems and languages as assemblages of interconnected and immanent, but always realist and material, registers (De Landa 2006; Protevi 2009; Latour 2005). But if systems theory, assemblages and living systems approaches allow the humanities to live on, no longer as privileged decoders of culture but just as readers of systems alongside other (possibly more scientific) readers, then perhaps the most valiant posthuman ultra-humanist modes of humanities have been those that appeal to science for a grounding of their modes of reading; no longer are they seduced by the specialness of literary objects. It is in this manner that Brian Boyd neatly points out Derrida’s ignorance of the scientific findings for language’s emergence from life, a point that then allows Boyd to pursue a science-based literary Darwinism that, like the work of Joseph Carroll, corrects the ‘high theory’ notion of linguistic construction: If they had been less parochial, the literary scholars awed by Derrida’s assault on the whole edifice of Western thought would have seen beyond the provincialism of this claim. They would have known that science, the most successful branch of human knowledge, had for decades accepted antifoundationalism, after Karl Popper’s Logik der Forschung (The Logic of Scientific Discovery, 1934) and especially after Popper’s 1945 move to England, where he was influential among lead-  anti-foundationalism almost an inevitable consequence. I say ‘parochial’ because Derrida and his disciples think only in terms of humans, of language, and of a small pantheon of French philosophers and their approved forebears, especially the linguist Ferdinand de Saussure.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  There was some excuse for Derrida in 1966, but there is none for the disciples in 2006, after decades of scientific work on infant and animal cognition. (Boyd 2006) Like many other turns, returns or reassemblings Boyd’s argument takes the form of a redemption narrative: we used to be Cartesian, computational, humanist, linguistically enclosed, but now we have discovered life. The humanities now takes everything in and in abandoning the closure of the literary object regains the world—the living, dynamic and interdisciplinary world. Manual De Landa also writes about materialism’s capacity to save us from linguistic narcissism or idealism (De Landa 2006, 12-13), while Andy Clark specifically refers to putting the world back together again (although his culprit, as with Evan Thompson, is not French theory but Cartesianism and computationalism) (Clark 1998 xi-xii). Mind is a leaky organ, forever escaping its ‘natural’ confines and mingling shamlessly with body and with world. What kind of brain needs such external support, and how should we characterize its environmental interactions? What emerges, as we shall see, is a vision of the brain as a kind of associative engine, and of its environmental interactions as an iterated series of simple pattern-completing computations. (Clark 1998, 53) Would the humanities be worth saving in such a world?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Would not humanities scholars be better replaced by journalists—reporting and disseminating findings from the sciences—or by scientists themselves? If, as Boyd claims, understanding literature really requires understanding evolution would you not rather trust someone with a rigorous training in that area? And if the body and its neural responses were really the basis for what goes on in digital media, who would you save, a critic who  There is a definite historical sense and teleology here: language, literature and the objects of the humanities—including ‘man’—emerge from life. Man, unfortunately, made the mistake of regarding himself as distinct from life, leading to Cartesianism and linguisticism, but science has redeemed us. Neuroscience has returned the brain to affective emotional life, and evolutionary theory has returned that living affective life to a broader narrative of the organism’s efficiency. Interdisciplinarity will save the humanities as will a sense of historical emergence or genesis. We will become posthuman via consumption—absorbing information and methods from the sciences—and extension: no longer limiting human predicates such as thought, affect, pathos and signification to humans. It might seem to follow, then, that a combination of the work of Gilles Deleuze and Michel Serres would finally be in order.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Consider the key motifs of their works: an inter-weaving of different disciplinary registers (mathematics and poetry), a refusal to isolate the human animal from life, a sense of life as a multiplicity, a complex historical sense that would destroy the history of man in favor of a history of bodies (where bodies would include technological objects, words, languages, animals, polities, cities and images) and an emphasis on sense. The latter term would not be meaning or the way in which the world is for ‘us’ but would open out onto a broader domain of interaction and relations (as well as that which is devoid of relation and connection). What I would suggest, though, is that there is an inhuman (rather than posthuman) approach to knowledge offered by the ways in which Deleuze and Serres approach the problems of history and sense, and that such an approach would not extend the life of the humanities by melding it with a single interdisciplinary domain of which the sciences would also be a part, but would intensify certain dimensions of the humanities only by destroying certain majoritarian, anthropomorphic or dominant components. It is true that Deleuze and Guattari weave together insights from science linguistics, art, philosophy and the social sciences, not only in A Thousand Plateaus but also in What is Philosophy? The latter volume poses the question of philosophy as a genuine problem; it does not so much define philosophy extensively (generalizing from what has already actu-  that make these lines of thought possible? On the one hand, philosophy art and science emerge from virtual powers (such as the capacity, in art, for sensations to be presented as such); on the other hand, Deleuze and Guattari also specify the economic, imaginary, geographical and historical conditions for something like the philosophical practice for creating concepts. They also locate art, not in human practice, but in animal life. However, it is precisely through the expansion of a disciplinary tendency beyond its human form that Deleuze and Guattari destroy a certain model of inter-disciplinarity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If one could think of concepts, affects and functions not as practices grounded in a self-maintaining human life, then one would not only have to rethink the supposed self-evident good of inter-disciplinarity and the unity of the humanities, but also the future and survival of disciplines and the dominant image of the (now highly humanized) humanities. Such a future would not assume the value of living on in its current form, either of humanity or the humanities, and it would abandon such assumed values precisely because of what we might refer to—after Serres—as climate change. If we could imagine the radical sense of climate, from clima and inclination, or the inflection that yields a certain patterning of what surrounds us, then we might say that now is the time to question the human and posthuman basis of thinking, especially when the posthuman has been a return of the human into one single life with one single inclination, that of ongoing self-maintenance. To conclude with a more positive—which is to say, destructive—approach to thinking beyond the interdisciplinarity of the humanities I will conclude with drawing upon two concepts from Serres—parasitism and pollution—and two concepts from Deleuze and Guattari: concepts\/affects and higher deterritorialization. Assembled together these concepts can yield a new sense of sense and a new sense of history. At its broadest the concept of parasitism would at first seem to place Serres’s approach within a single and unified field of knowledge, as it yields a model not just for relations among living bodies, but for information systems and—one might say—life in general. But if the relation of parasitism, and its capacity to displace the illusion of predator-prey relations, is general , then what parasitism discloses are irreducible dif-  ularities that require highly discerned cuts and judgments. Whereas a predator would be a vaguely self-sufficient body, capable of maintaining itself and using some other body as means of sustenance, the parasite would have no existence other than that of supplementarity: ‘And that is the meaning of the prefix para- in the word parasite: it is on the side, next to, shifted; it is not on the thing, but on its relation.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It has relations, as they say, and makes a system of them. It is always mediate and never immediate’ (Serres 2007, 38-39). To claim that man is parasitic, rather than a predator, and that this occurs in a life of parasitism in general entails several consequences for humanism, posthumanism and the ‘disciplines’ that might be adequate to thinking the inhuman. If one abandons the concept of predator then one also abandons the concept of the good and just relation: it would not be the case that a proper humanity would use ‘its’ natural milieu according to reasonable or ecological needs, maintaining a balance with a world he uses but towards which he could also contribute (by cultivating, re-planting, mitigating, adapting, capping, trading and offsetting). There would be no good humanity of reasonable predatory use that might be morally distinguished from a parasitic humanity that would be nothing more than a consumer or digester of energies not its own. For that is the nature of distinction and being: one is not a unified body that then might produce good (self-sustaining) or evil (ultimately short-term and destructive) relations to one’s milieu. Let us accept that humanity is and must be parasitic: it lives only in its robbing and destruction of a life that is not its own. Our current predicament of climate change, whereby we have consumed and ingested blindly—bloating and glutting our body politic through the constant destruction of resources without recompense—would not be a late accident, nor a misjudgment of a post-industrial age.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  To be a body is to be a consuming body, to be in a relation of destructive consumption with what is effected as other, as resource, through consumption. Climate change would be the condition of human organicism in general: for there would be no climate, only clinamen, an inclination, deviancy or parasitism that creates a supplemental body (of man) who would then retroac-  a general parasitism, then it is also the case that ‘man’ occurs as a specific inclination or deviation, and it would be the task of thinking to examine each parasitic swerve (human and non-human) according to its own differential. The deviation that enables mathematical systems, for example, would occur when the counting procedure deflects from living praxis and becomes a formalized supplemental system. From here one could then examine the geneses of formalization and ideality. Similarly, one could see poetry as a specific parasite, taking the language of speech and action and developing a relation among sounds and rhythms of the voice and script, but with no benefit from the organic or living bodies and practices from which it emerged. Attempts to return systems to the sense of their origin—to see literature as benefiting the bodies from which it emerged, to see digital media as grounded in affect and embodiment, or to see all disciplines as expressions of one self-maintaining life-world would be to suffer from the illusion that parasitism goes in two directions. Not only does Serres insist that it does not; this irreversibility can be evidenced by any semi-autonomous or parasitic system. A system develops its own laws of survival irrespective of its host, and this is so even if the complexity of relations often confuses—for observers—who is host and who is parasite.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Not only could there be no general inter-disciplinary humanities, whereby each discipline recognized its place in the ongoing self-understanding of man; each declination or parasitism would have its own inflection. As parasitic it could not be grounded in ‘the’ body of a single life. This leads to pollution, which cannot be seen as some late-industrial nor specifically human inclination. It would not be the deviation from proper inhabitation, for inhabitation as such involves not just added markers or territorial inscriptions but contributing something like waste or matter that elicits disgust or revulsion to an approaching outsider (Serres 2008, 29). There is a connection here with parasitism that further debilitates (or ought to debilitate) ‘our’ usual notions of ecology, environment and symbiotic interconnectedness. Pollution is not simply making a niche, having a world that would, in turn, contribute to other worlds; to pollute or mark a space as one’s own habitus is to subtract, diminish  could not attribute climate change to man alone. That is another way of saying that climate change would not be recognizable as long as one remained in a human or posthuman mode of thinking: for such a mode would begin with man destroying his milieu (anthropogenic climate change would then require man to mitigate, adapt or trade in order to live on). And posthuman celebrations of a single ecology would not be able to face a condition of climate change in general.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  To live and inhabit is to be parasitic, to pollute, to alter the clima, to effect an inclination that cannot be remedied or mitigated by some return or retrieval of the proper. This suggests several critical and positive conclusions. Critically one could no longer ground ethics on an understanding of a proper humanity: not only humanity in general but any living form—any being that marks or territorializes itself—must distinguish itself from its milieu. In the beginning would be neither mutual exchange nor symbiosis but theft (Deleuze and Guattari 2004a, 203). Survival and self-maintenance, or the creation of a specificity or identity, require deviation and distortion. Where does this leave notions of ecology, symbiosis and Gaia? On the one hand Serres’s focus on the clinamen reinforces the relational aspect of all being: there are not identities or terms that then enter into relation, nor a world of individuals or beings who must then somehow contract with or contact each other. But this is not to suggest either that there is one harmonious world, expressed each in its own way by each living form.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  On the contrary, as in Deleuze’s monadology, Serres’s Leibnizian world is one of incompossibility. Not only is each inclination or deviation an opening and disruption of a quite specific or singular differential—a quite singular creation of a field—it occurs always as disruption of other differentials and relations. The emphasis on parasitism and pollution precludes any nostalgia or restoration; in the beginning is defilement. This then yields a far more positive conception of a natural contract, which would not be man becoming one with nature as one living and symbiotic whole. Rather, it is precisely the supposedly ethical position of man as an interdisciplinary animal—man as assembler and negotiator of a single field of knowledges—that would give way to a natural contract that is a multiplicity, with divergent rather than harmonious lines of inflec-  infinitely multiple. The contract is at once epistemological and legal, for it requires not only that man recognize his natural milieu, but that the very concepts of milieu, environment and climate in their singular sense would have to be rendered obsolete if nature also ‘contracts.’ Nature also has its inflections, worlds, multiplicities and differentials. We could not, then, imagine a grounding or ideal (even inaccessible) nature that is lost in the creation of technical systems. There has always been globalization; each event in the world is a disturbance or distortion that enables something like an inflection or inclination to occur from chaos.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (A new threshold occurs with modern post-industrial humanity precisely because its inflections do not just radiate outward and create local distortions but deterritorialize or become inflections of the whole, capable of infecting or polluting every other line of system or parasitism.) The ‘contract’ of the natural contract is therefore not a signature (an act of the hand, inscribing a blank surface) but a contraction (the introduction of a noise or pollutant that ramifies throughout the open whole). Here is where Serres’s work connects with Deleuze’s similarly divergent Leibniz-ism. The world is a monadology, an infinitely divisible chaos in which smaller and smaller differentials will enable subtler and subtler relations and encounters— so that there is no nature in general outside or beyond the multiplicity of contractions: ‘organs fully belong to matter because they are merely the contraction of several waves or rays: the nature of a receptive organ is to contract’ (Deleuze 2006b, 111). If, today, networks of technology and techno-science have, in their parasitism, effected something like a totality of nature in general, this is not as an object of scientific knowledge so much as a field of implication: Classical Western philosophy never calculated the cost of knowledge or action but considered them to be free of charge. However, as soon as work appears, everything is subject to the martial law of price. The yield of work is never one on one; there are always residues and garbage. As long as work remains cold and local, price is calculated in terms of profit and loss.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  As soon as heat enters work, the productivity of the  dimension. Local, negligible waste is succeeded by global pollution of the world. (Serres 2006) In a manner that seems close to Hardt and Negri’s positing of a new global humanity effected through the immaterial networks of technology Serres suggests that a global ‘we’ has emerged, requiring a reflexive discipline concerned with humanity’s total polluting power. Here is where one might note a disjunction between the affirmation of the people as ‘missing’ in Deleuze and Guattari (1994, 176) and Serres’s almost mournful lament of this new ‘we’ with unforeseen destructive powers that finally produces nature as a totality (not so much as on object of knowledge but as a consequence of destruction). For Serres something like humanity has been rendered possible and effective not because of knowledge as recognition but because of a general polluting and parasitic power that has overtaken the locality of systems and relative disturbances. If we align this new ‘subject’ with Deleuze and Guattari’s recognition of capitalism as an axiomatic then this provides us with a new way of thinking about a positively destructive ‘humanities.’ This would be inhuman, rather than posthuman, precisely because the creation of the single system or axiom where work and production overcode all other relations, including supposedly environmental or ecological imperatives of survival and adaptation, would need to be annihilated to give way to differentials along a different axis. Consider, here, Deleuze and Guattari’s created concepts, in What is Philosophy? which are not extensive insofar as they do not name or generalize actually existing disciplines but are intensive: they create or mark out speeds and rhythms for thinking.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Consider concepts: although it is possible in a weak and general sense to locate concepts as one part of everyday speech, Deleuze and Guattari create a concept of concepts. A concept, considered philosophically, possesses a unique speed and rhythm. The concept of the cogito, for example, did not label an already existing entity, nor did it perform a move in an already practiced language game. Rather, when Descartes creates the concept of the cogito he slows thought down, retreats from action and efficiency, and from practical communi-  suspended or placed in parentheses. Similarly, Deleuze and Guattari also create the concept of affects\/percepts and functions. The former do not describe already existing art practices, nor what art always is. Like the concept of philosophy and its capacity to create concepts, the concept of art (as the production of affects\/percepts) intuits a potentiality that may exist in a mixed or impure form in thinking as it currently is, but that can be intimated and gestured to futurally in what thought might be. What would it be to create a percept that would not be the perception of some observer, or an affect that would be neither the affection of an author nor an affection produced in the reader\/viewer?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  By creating the concept of the concept in What is Philosophy? Deleuze and Guattari allow for a new mode of philosophy: if democracy is a concept then the problem of democracy is not so much what it is (what social systems are really democratic) but the orientation it creates in thinking. What would it be to develop a socius with no other power than its own capacity for decision? Similarly, by creating the concept of affects and percepts they enable a new mode of art theory: how might we imagine a work, not as the communication of an author, nor as the representation of a world, nor as the meaning it yields for its readers, but as a ‘stand alone’ or monumental detachment of percepts and affects from the lived? The affect or percept would yield color as such, melancholy as such: one might think here of the attempt to capture light in paint, to capture the sounds of the earth in synthesizers, or the striving to sculpt courage in stone. Deleuze and Guattari’s concepts—the concept of philosophy as the creation of concepts, of art as the production of affects—allow us to think beyond ‘the humanities,’ beyond ‘interdisciplinarity,’ and they do so in ways that intersect fruitfully with Serres’s concepts of parasitism, pollution and a new humanity. For Serres a threshold is reached with current extensions of pollution that create a difference in kind. Humanity is no longer one pollutant or polluter among others, creating a territory, milieu or inclination.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Humanity effects a climate change of climates; there are no longer multiplicities of inclinations, but an inclination or clima that has extended to such a degree that is constitutes a difference in kind—a pollution of  a concept of humanity. Such a concept would not be a reflection upon man as he is or has been, would not be a critical uncovering of the specific life of man. As a futural concept it would, like Deleuze and Guattari’s created concepts of philosophy, art and science, require and enable an interrogation into humanity as inclination. How is it possible that in a life or earth that is nothing other than a multiplicity of inclinations and parasitisms one specific line or disturbance has taken over the whole, at the very expense of its own tendency? If all life is improper, noisy, disturbing and deprived of any grounding or proper form—if, in the beginning, is the swerve—then how might one account for both the overtaking of the plane of disturbances and the emerging desire for a survival not of man as he is—a humanity that would manage its polluting tendencies—but that might create a new concept of itself? The very concept of the humanities in its dominant form—as critical and interdisciplinary—would need to be destroyed in a productive manner. This is because the idea of man that underpins the humanities as an interdisciplinary problem has been extensive: disciplines are activities, achieved by a division of labor, with man examining himself as a historical animal whose life creates him as a social and linguistic being capable of self-reflection and communication. It is not surprising that this man of reflexive knowledge and moral self-management confronts climate change as an extensive and managerial problem: how might we use less in order to live longer, how might we act more frugally in order to survive?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But if we accept that there are capacities or potentialities that are not those of managerial man—either Serres future humanity or Deleuze and Guattari’s ‘still-missing people’—then we would have to abandon the idea of earth as environment to which we might bear our proper and restorative relation, along with the humanities as some domain of communication that might return us to our better selves. A futural approach to disciplines would embrace and intensify the distinct inclinations of thinking—the differences of thinking in concepts, colors, sounds, affects—and would not assume precisely what climate change forces us to question: Why, if information regarding our polluting and parasitic existence is so extensive, are we so incapable of thinking intensively, of  Chapter 9  Why Saying ‘No’ to Life is Unacceptable Just what counts as acceptable or unacceptable is obviously a cultural, social and historical variable. That being so it might still be possible to make claims regarding broader structures of unacceptability, and certain motifs that, within epochs, dominate cultural production. We can perhaps begin by asking—today—just what might count as unacceptable in general. That is to say, one can imagine all forms of socially refused content, ranging from prohibited actions and lifestyles to censored content. But on what grounds or by what logic is the border between the acceptable and the unacceptable drawn? The problem can be given some generality and purchase today if we ask what the rationale for accepting or refusing something might be, and—further—what forms the limit of acceptability today. I would suggest that despite dispute over what counts as acceptable the governing rationale for dispute is the concept of life: one either argues for an intrinsic ‘right to life’ or one asserts one’s rights to choose on the basis of the autonomy of one’s own life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The logic of normativity is grounded on life, which is to say that norms are not—as they once might have been—given transcendently (as what is dictated by God or social propriety)—but are immanent to life. One either argues against gay marriage, single parenting or other alternative lifestyles on the grounds that it threatens ‘our way of life’ (including the family, reproduction, maintaining humanity as it is), or one insists on the right to determine one’s life. Cultural production also reinforces this unquestioned affirmation of life: from lifestyle channels, to reality television’s display of life, to celebrity culture to legal and medical dramas and the increasingly close-angled camera work displaying the minutiae of life, all external criteria give way  State, privilege and prejudice—has been achieved, and now there is nothing other than life. And yet, such a frenzied surge in an unquestioning insistence on the value of life is accompanied both by an inability to confront the imminent demise of life (whether that be by way of accelerated extinction due to climate change, or disaster scenarios resulting from terrorism, nuclear warfare, viral pandemic or bio-weapons and resource depletion—or, the inevitable panic that would follow on from and exacerbate the appearance of any of these threats.) In addition to the shrill insistence on the primacy of life, and alongside the deluge of information regarding increasing and exponentially accelerating threats to life, there has been a strange incapacity to ask the question of life. That is: now that life appears to be in danger of disappearance, diminution or mutation beyond recognition, living humans indulge both in greater and greater insistence on the sanctity of life, and seem incapable of directly confronting the intensifying threats that menace the present. The hinge of the acceptable is life, both because acceptability is negotiated on the basis of life, and because any question of life is evidently unacceptable. This inadmissibility of the question is most clearly the case precisely when the question of life seems to have been posed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  That is, when cultural production turns directly (as it does occasionally) to the problem of life, it is precisely at that point that the question of life refuses to be asked. The question of what we accept and do not accept, what we can consider or question and what remains beyond question, is probably always a query of some interest. But the question of the value of life should gain in interest (if not urgency) for us now, and for three reasons. First, the question or problem of life is now an actual question that is everywhere being asked (and yet also deferred in the very mode of the question’s formation.) We are no longer simply confronted with the ‘meaning’ of life, or the enigma of existence, for it is quite possible, probable or increasingly certain that we will begin to witness the beginning of the end of life (mass extinctions, resource depletion threatening human order, climate change that is moving at a pace beyond predictions of exponential acceleration, and even the strange mutation of the human brain via digital technologies and visual culture that may spell the ‘end’  of meaning, with a flurry of supposedly deeply philosophical accounts of the unavoidable horizon of meaning when approaching what appears as life (Wolf 2010; Cottingham 2003; Eagleton 2007). Further, and despite recent academic and philosophical insistence upon life’s meaning, there has been a surge of cultural production focusing on life’s termination— ranging from disaster fiction and cinema to survival guides for end-ofthe-world scenarios. In addition to a flourishing genre of post-apocalyptic cinema and literature, there have also been documentaries and non-fictional thought experiments about the world without humans, the aftermath that would follow catastrophes, and other human-witnessed posthuman scenarios. In sum, the problem of the continuation of life ought to be at the forefront of reflective inquiry (and is indeed played out in a series of fictional and semi-fictional scenarios) but the problem is (in that very process of being played out) displaced.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is as though cultural production, at least in its dominant mode, is indulging in Freud’s grandson’s Fort-Da game: we play and replay the disappearance and reappearance of life, and do this to anticipate and master an event that concerns our (in this case, very real and possible) non-existence. Third and finally, even in its barely articulated, suggested, but not fully posed mode, the form of the question of life has altered in the twenty-first century. Until recently, if the problem of life were posed it took the form of theodicy, or justification: of how ‘we’ can explain life’s utter cruelty and seeming disregard for human suffering. It is this question that is played out in Job, in Greek tragedy, in Milton’s Paradise Lost and even perhaps in modern novels, such as William Godwin’s Caleb Williams, where inscrutable injustice is now politicized (and can be attributed to corrupt and therefore remediable institutions). A pre-modern form of tragedy would, in pre-Christian mode, confront the tragic contingency and inhumanity of life (and it was Nietzsche who admired this noble capacity of Greek tragedy’s encounter with the brute force of existence); in Christian thought, especially in its modern Miltonic mode, the seeming tragic senselessness of life will ultimately be redeemed in a regained paradise. In works such as Godwin’s Caleb Williams the experience of tragic desperation and the inhumanity of life is historicized and seen to be symptomatic of a social  dignity of withstanding the force of existence. The endpoint of this tradition might be Kafka or Beckett, in which the individual confronts a life that is tragically void of all sense and (for that individual at least) hope. One can either interpret Kafka and Beckett existentially (as writers who face the void of non-meaning) or regard that experience of the void as a (potentially) political hope for a world of non-damaged life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is perhaps thoroughly modern to shift from a tragic acceptance of the brute contingency of life to some sense that the struggle itself is one of personal meaning. (This was why Nietzsche so admired the ancient Greeks, for having the capacity to experience the violence and ‘festive cruelty’ of life’s force, without moralizing [Nietzsche 2000]. Today, and for some time, the tragic mode has become less acceptable as tragic. Some form of resolution or compensation usually closes narrative form. The forces of good triumph in the end, or suffering itself is given meaning: Hollywood cinema rarely allows itself a conclusion void of redemption, while tales of suffering—from Born on the Fourth of July (1989) to The Pursuit of Happyness (2006) and 127 Hours (2010) are morality plays of individual triumph rather than an exploration of cosmic indifference.) Even so, and despite a refusal to confront the limits of life just when the historical actuality of life’s end is becoming apparent, though not witnessed, it is possible to note a shift of genre away from human-to-human adversity to, at least initially, something like a war between humans and the cosmos (and this despite all the deep ecology proclamations of our oneness with life). A new mode of the question of life has come to dominate cultural production: not, ‘Why are humans subjected to the brutal force of existence?’ but: given human brutality and life-destructiveness, by what right will humans continue to survive? It is no longer life that needs to be justified, but the human species’ malevolent relation to life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Nietzsche had already charted the ways in which ‘man’ as a moral animal had been effected from an inability to accept the violence of the forces of life. Whereas Ancient Greek tragedy was initially akin to a theater of cruelty, not yet indulging in justification, the positing of a ‘higher world’ that would justify life created man as a slavish animal (Nietzsche 2007). When that higher world was turned inward, it was not God who enslaved man, but ‘humanity’:  higher world seems no longer real. Freud made a similar observation: once we move from a tribal competitiveness and warring aggression and take on the command to love one’s neighbor as oneself we can only react neurotically: in my failure to love my fellow man I will turn that guilt back upon myself in damaging self-aggression. Both Freud and Nietzsche diagnosed the twentieth century’s incapacity to face up to the inhuman contingency of existence; if life is horrific then someone must be guilty, and why not both attribute that guilt to man as he has been, while insisting on a proper humanity that will emerge from the human wreckage? We simply cannot live existence without granting it some sort of meaning. That, itself, is not the problem. As Adorno and Horkheimer described the dialectic of enlightenment: the ‘shudder’ of existence prompts a magical projection of our own anthropomorphic limits on the world.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If enlightenment destroys the mimesis or doubling of the world that has reconfigured life in order to render it acceptable to humans, this process of enlightenment nevertheless achieves ‘disenchantment’ by containing and mastering the world—silencing all the sounds of damage and suffering. The horrors of twentieth-century atrocities did much to destroy our forms of meaning, allowing high modernism and the art of the absurd to emerge. For Adorno, modern art’s refusal to grant the world harmonious order was a sign that we might be able to move beyond our inability to confront disjunction. We need to move beyond an absurd abandonment of all hope without falling back into kitsch resignation with art acting as the promise of happiness. Yet today it is not nihilistic despair in the face of non-meaning that seems to be the dominant affect. On the contrary, not only is meaning now the seemingly unquestionable horizon of human existence—ranging from ‘philosophical’ studies to the Oprah Winfrey Network and projects of individual self-development—cultural production reaches its points of tragic despair by questioning the rampant violence of humans in relation to life rather than life’s lack of concern for humans. It is not humanity that is cruelly placed in an inhuman world, so much as an inhuman humanity that has become unjustifiable in an anthropomorphized world. The Post-Apocalytpic The opening of the twenty-first century is marked by a supposedly new genre (or the efflorescence of an old genre) of the post-apocalyptic.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  However this term is used, one way we can make sense of the post-apocalyptic is to note that scenes of near-destruction of the human milieu are followed by an exploration of what will survive or remain, or what ought to survive or remain, after the absence of humanity as we now know it. The post-apocalyptic is best read as a question posed: just as the human species starts to approach the real possibility of its actual nonexistence (whether through climate change, viral pandemic, terrorist use of nuclear or bio-weapons, wars on the terror aiming to avert the latter, resource depletion, panic, or any conjunction of the foregoing) there is a barely perceived and half-articulated problem of how and whether humans ought to survive. What is it about humanity that one would want to accept? Further—as the very use of the word ‘post-apocalyptic’ indicates—the genres and modes in which this problem is articulated preclude the problem from being posed. There is a constitutive inability to confront the very content that ‘we’ are nevertheless constantly replaying. According to Freud art is primarily a rendering acceptable of otherwise indulgently unacceptable private content (Freud 1908). Jokes, similarly, allow otherwise unacceptable content to circulate, allowing what can be thought but not really said to find some outlet (thus explaining, for Freud, the body’s explosion in laughter). Beyond Freud, and in a line that runs at least from Adorno to Jameson, there is a commitment to the idea of narrative and form as processes that render the intolerable tolerable.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Despite its debt to Marx, this strand of what I would refer to as existential or Hegelian Marxism problematizes a Marxist concept of ‘the political’ that has tended to dominate whatever is left today of ideology critique: according to this basic Marxist imperative of politicizing or denaturalizing whatever appears as simple, inevitable, universal or irrevocable, one ought to historicize the present, and account for the genesis of the social and political world on the basis of ‘man’s’ transformation of that world. What appears as intolerable should not be seens as inevitable but re-read  an irresolvable negativity or disjunction between the sense we make of the world and a ‘world itself ’ that can only be given as other than the human (Adorno 1983, 361). The shudder of existence, or the brute otherness of life that simply cannot be lived, is tempered in general by the projective processes that form the world. What appears today in the form of ‘the aesthetic’ enables us to have some sense of a historical trajectory in which the radically alien and contingent force of life has passed through a process of animism, or a mythologizing reduction of the world, through enlightenment (or the reduction of the world to so much calculable and ‘disenchanted’ matter) through to modernism (Adorno and Horkheimer 2002). Modernism, for Adorno, is counter-bourgeois and counter-kitsch, an experience of form in its deadness, in its incommensurability with life. Without endorsing Adorno’s high modernist resistance to the easily consumed and already circulating forms that render the world always already amenable, it is nevertheless worthwhile to pursue this crucial insight: art can be seen as having a humanizing function, a rendering of the world into some form of manageable order. In quite different ways Paul de Man, also indebted to Hegel in some respects, and also less ready to see language’s ordering of the world as a process of meaning or familiarity, sought to draw attention—however impossibly—to language and form as radically inhuman (Cohen, Colebrook and Miller 2011). For both Adorno and De Man, the text or art operates as a disjunction, negation or instance of ‘deadness’ or ‘afterlife.’ It is the lure of ‘the aesthetic’ to imagine that art is somehow an expression of ‘life.’ If art in general is a formalizing process that grants the raw violence of life some moralizing structure, then certain modes of narrative would seem to intensify what Fredric Jameson (writing after Adorno) has summarized as the ideological transformation of existential horror into social symbolization.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Science fiction, for example, codes otherness as such into the delimited and opposed figure of the alien or invader ( Jameson 2005, 141). (Spy fiction has its different narrative modes of discerning or reading just who or what counts as a threatening other, or just where the limits and readability of self and other lie). In so doing narrative parses into a temporal project—an overcoming of adversity—what could not be con-  once—in epic or tragic modes—required a confrontation with forces that required more than ‘life management.’ If one examines cultural production today the manifest content that seems at first to confront radically threatening forces is ultimately returned to the genres of family drama and romance, as though even the end of human existence could be Oedipalized. That is, there is an efflorescence of disaster and postapocalyptic narrative, but always with a narrative resolution that restores a basic human binary (such as the romance ending that allows humanity to triumph in The Adjustment Bureau [2011] or the victory of New Age humanoids over corporate and military greed in Avatar [2009].) Even a story as bleak as Cormac McCarthy’s The Road (especially in its cinematic adaptation of 2009), devolves around a father-son relation: the man and boy wander a landscape while struggling for survival against remaining humans; the journey concludes with a sense of the possible renewal of the family-maternal bond as the son is taken in by a potential new family. In blockbuster entertainment, the 2008 film Traitor figured the ‘war on terror’ and the conflict between fundamental Islam and US security and espionage as ultimately a problem of fraternal misunderstanding: the warring individuals ultimately find common cause in the discovery of their underlying humanity. It is as though terrorism and militarism could be overcome if only we could return, once again, to face-to-face encounters. One might add to this continual anthropogenicism any number of disaster epics that are organized into human-human agonistics: it is never the earth, the climate, contingency or catastrophe as such that is presented as the intruding force of destruction; rather, it is some identifiable face that allows the sheer violence of adversity to be translated into a resolvable and symbolized other.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Occasionally, however, within narrative trajectories there have been moments when the question of life reaches articulation. If life—or the idea of a body that goes through time, manages an external world, and then arrives at its own end—has always been figured through some narrative imaginary that renders stark contingency into a mastered and acceptable sense (Brooks 1984), then the question of life seems to destroy narrative. I want to cite two pre-contemporary examples before looking at the dif-  Narrative Life In Milton’s Paradise Lost, which is a self-proclaimed theodicy or justification of the apparent intolerability of life, Adam asks God why he (Adam) was made so unfairly and impossibly free. If we accept that man deserves to be expelled from paradise because he chose to transgress the order of Eden, it does not follow that man deserved to be given this task in the first place. Adam’s lament cries out against the burden of human freedom, or man’s capacity to act against life. Why did God make him thus? Did I request thee, Maker, from my Clay To mould me Man, did I sollicite thee From darkness to promote me, or here place In this delicious Garden? as my Will Concurd not to my being, it were but right And equal to reduce me to my dust, Desirous to resigne, and render back All I receav’d, unable to performe Thy terms too hard, by which I was to hold The good I sought not.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  To the loss of that, Sufficient penaltie, why hast thou added The sense of endless woes? inexplicable Thy Justice seems; yet to say truth, too late, I thus contest; then should have been refusd Those terms whatever, when they were propos’d: (Paradise Lost 10: 742-757). God responds by unfolding a vision of history: Adam will see increasing violence and destruction, but will eventually see man benefit from grace and forgiveness. If, after all this evil, God will still sacrifice his son, allowing man to receive a law that is now internalized and accepted from a condition of forgiven fallenness, then life once more makes sense. Human life, for all its apparent perversity is ultimately a higher good, all the better for having turned away from, and then re-found, itself. One might say that all narratives are theodicies, or ways in which the seemingly sense-  upon being presented as more palatable—but in a more radical sense in which something like the social is formed. Narrative creates the lure of a world in common, an order of sense and humanity, in which otherness is personalized and rendered familial and familiar. This has specific purchase today: it is almost as though the more unimaginable the possible forces of destruction appear to be, the more local our narrative imagination becomes.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In addition, though, to the process of narrative as social symbolization—in which order as such is constituted—the problems, intolerable conflicts or disjunctions to which narrative responds are varied. One can imagine the ways in which race, sex, social disintegration, internecine conflicts, historical transitions and so forth, all need to be worked through by narrative ( Jameson 214). What is suggested by Adorno’s approach, and in Jameson’s concept of ideology, is that these ‘political’ figures are ideological precisely because they give a binary and humanized form to existential conflict as such: The fantasy level of a text would then be something like the primal motor force which gives any cultural artifact its resonance, but which must always find itself diverted to other, ideological functions, and reinvested by what we have called the political unconscious. ( Jameson 129) On the one hand, then, there is an ordering or meaning-producing function of narrative, a function that answers what might be referred to in general as the problem of existence. On the other hand, there are historically specific ways in which the modes of this question or conflict are formed; the ways in which intolerable life is reconfigured and rendered acceptable vary according to just what the horrific other of humanity is deemed to be. In Paradise Lost, and theodicy generally, the problem is the burden of human freedom in relation to a God and life that must be conducive to harmony. In Mary Shelley’s Frankenstein the similarly formed question is now directed to man (Victor Frankenstein) by his monstrous progeny. Here the question is not so much human freedom as humanity’s creation of a world in which its offspring are then abandoned.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What duty do we  and yet deemed by him to be lesser, but also in his tyrannical laying down of terms the monster cannot accept. Allegorically, Shelley can be seen to be posing Milton’s question again, somewhat blasphemously: what sort of God creates a being and then leaves it wandering in a world of despair? Or, as the monster accuses Victor, ‘You, my creator, abhor me; what hope can I gather from your fellow creatures, who owe me nothing? They spurn and hate me? The desert mountains and dreary glaciers are my refuge.’ (Shelley, 94.) The creature’s plea to his maker is also an allegorical questioning of humanity’s relation to production: how can we leave a populace of the future so miserably orphaned? In Shelley’s case this is sharpened by the fact that the monstrous being of the future promises to be less rapacious than man (even though he still is refused by his creator): My food is not that of man; I do not destroy the lamb and the kid to glut my appetite; acorns and berries afford me sufficient nourishment. My companion will be of the same nature as myself, and will be content with the same fare.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We shall make our bed of dried leaves; the sun shall shine on us as on man, and will ripen our food. The picture I present to you is peaceful and human, and you must feel that you could deny it only in the wantonness of power and cruelty. (Shelley, 128-9) Shelley’s novel is a play of mirrors (directly re-writing Paradise Lost), in which ‘man’s’ plea against existence is at once given a political-allegorical form (so that the monster appears to be a disenfranchised other who could, in theory, be redeemed and included), at the same time as the monster’s creator and pseudo-God also feels the utter horror of what it had intended to create as a free, productive and world transforming being. The maliciously and thoughtlessly reproductive Victor poses the same question to himself: how can one go on living when existence is intolerable, when one’s free actions yield such monstrous outcomes: ‘Cursed, cursed creator! Why did I live? Why, in that instant, did I not extinguish the spark of existence which you had so wantonly bestowed?’ (121). Shelley’s formulation aims to give some political purchase to the  of man and morality in the face of the monster’s rather ecological and reasonable request. Even so, Shelley—like Milton—begins by posing the question of the intolerable terms of life for man.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  If Milton seeks resolution in grace, a ‘paradise within’ and a future when the world shall be ‘all in all,’ Shelley suggests a more radical response: the truly human future does not close itself off to the non-carnivorous generations who will live in the glaciers and deserts. Something like the ‘properly human’ functions as Shelley’s political answer to the question of life. Like Marx, Adorno and Jameson after her, Shelley will suggest that the existential shudder of existence should properly be understood not as a relation between man and world, but among men. To varying degrees all these writers—from Milton and Shelley, to Marx, Adorno and Jameson—recognize that it is ideological and hasty to present adversity as a simple problem in the form of an isolated and humanized other, but it is also insufficient to abandon thinking and fall into an existential despair with regard to the brute violence of existence. Criticism, in this tradition, has as its task to hold on to the notion that damaged life might be redeemed, while avoiding the easy fantasy solution that would lie in attributing evil to some binary other. To this end Shelley undertakes a genealogy of the self: she describes the genesis of Victor’s monster, who first encounters the sensations of life and then becomes humanized by overhearing a reading of Milton’s Paradise Lost (and then Volney’s Ruins of Empire). After this basic training in humanity the monster is, however, spurned by those he encounters, primarily because of his visible difference from the humans with whom he feels such kinship. Shelley’s politicization of what seemed for Milton to be a problem of human freedom (or the relation between life and law) is— if we accept Jameson’s definition of ideology—a counter-ideological gesture.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What appears as the pure horror of life, or what for the moralizing Victor can only be the menacing threat of beings who are radically other, is seen ultimately by Shelley to be a problem of critical enlightenment. What appears as existentially unacceptable should be transformed through social and political revolution. If recognition were granted to the potential hordes of the future one would be faced not with violence but  or horrifically other can be given resolution by transforming torment as such into an anthropogenic problem. If Jameson argues that ideology is the way in which politically unacceptable structures are given imaginary resolution, and that the social symbolism of narrative completes a redistribution that should properly be revolutionary, then this is because of his post-Marxist commitment to transforming seemingly natural, universal or intractable problems into human-to-human struggles. Minus the Political An entire genre of what has come to be known as post-apocalyptic film and literature currently and repeatedly, with ever increasing verve, plays out a fantasy of human near-disappearance and redemption, and does so precisely when our energies ought to be focused on what humans have done to the planet and how they might desist from so doing. In response to this deluge of cultural production, we would need to adjust the Marxist approach to politics and humanization. Marxist critique aims to humanize and historicize—the two gestures being the same: what appears to be simply and universally intolerable needs to be recognized as having a history, where history is a history of labor and human relations. When those human relations are naturalized or ‘frozen’—when the family or the male-female couple appears as the fantasy frame through which all horrors can ultimately be resolved—then, for Marxism, it is the figure of bourgeois man that needs to be criticized and historicized.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The problem is deemed to be intra-human and intra-historical: we should be able to imagine forms of collective, non-exploitative and historically transformative modes of life—not resign ourselves to the apparent ‘natural’ injustices of the present. But what if the problem today were not that of a justice among humans? What if social political revolution among human beings were still to leave the relation between the human species and life in the same place? Today’s frequently cited Marxist cry—it is easier to imagine the end of the world than the end of capitalism—should be read as symptomatic. Should we not be more concerned with the world’s end than the relations among markets and individuals? The Marxist premise  world to be primarily anthropogenic, or emerging from human meaning and history, we will not confront the disjunction between the human species (in all its modes) and the life that it regards as its own. A new mode of critique that would not be political would be required. Indeed, it is the political gesture, or the understanding of conflicts as ultimately intra-human, that needs to be questioned.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  One needs a hypo-Marxism or counter-Marxism whereby the very premise of Marxism—man as a laboring animal who furthers his own life—needs to be recognized as the limit of thinking. For what ‘we’ cannot accept is the obvious counter to this assumption: man is not an animal who furthers his own survival. For Milton and Shelley the problem was that of the violence of life for an ill-equipped human. Whereas Milton will respond theologically—arguing that God’s grace and the unfolding of human history will justify the seemingly unjustifiable torments of life, Shelley will adopt a more modern and political approach: humanity is capable of living well, living in a humane manner, if only social and political structures were transformed to be conducive to sympathy and recognition. If we came into existence like Frankenstein’s monster—through sensations, reading and a dwelling with loving others—rather than through doctrines of piety, then we would be capable of living without the torments of implacable injustice. Shelley diagnoses human despair and regards its genesis as human, but for that very reason also resolvable. And this is in accord with the critical tradition that I have already and that culminates in an Adorno who regards the violence of existence to be something humanity finds intolerable and will thereby either mythically project onto an animated other, or ‘rationally’ subject to its own order. Critique or dialectics recognizes that the sense or acceptability we have projected onto the world is at once not the world’s own and yet—politically—demands to be brought into being.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Things have changed. The overwhelming question that presses itself upon us—requiring incessant repression and working through—is not the question of how we humans were placed in a world in which the task was too hard, the conditions too bleak or the burden of freedom too confronting. The question is not one of how we humans can justify hostile  The current vogue for what is misleadingly called post-apocalyptic fiction seems to indicate that we are now feeling (if not thinking) a new relation between the human species and time. More accurately, we are experiencing humanity as a species, not just a humanity that emerged from the depths of time but a specified mode of organism that will one day have had its time. Just as post-Darwinian nineteenth-century literature had a sense of deep time—feeling some alarming presage of a time before humans and adjusted its plot structures accordingly, literary and cinematic form is struggling with forms of expression that might capture a new mode of inhuman time. We rehearse over and over again our near annihilation, playing a cosmic version of Freud’s grandson’s fort-da game, in which we replay our disappearance (semi-traumatically) and then stage our return and redemption (Freud 1961). This problem now focuses not on creation—why was man created given the hard terms of his existence?—but on extinction: what reasons might we fathom for wanting our survival? (Here it is not a question of justifying the life that man must face, but of justifying the man who has done so much to deface life).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Humanity has been violent all too violent; it is not the horror of existence that tortures humanity but a humanity that can do nothing other than destroy itself and its milieu, and all—perversely—for the sake of its own myopic, short-circuited and self-regarding future. Living Extinction In 2008 The Day the Earth Stood Still featured a deadpan alien (played appropriately by Keanu Reeves) who informed humanity that its violence and destructive modes of consumption no longer entitled it to life on earth. The narrative of the film proved this judgment and diagnosis to be peremptory: Keanu is given the chance to see the benevolent side of humanity through the eyes of a young boy, and the annihilation of the human species is delayed. A common motif in science fiction narratives of alien invasion, the judgment of humanity as life-denying and life-unworthy is neither refuted nor answered, but simply set aside as the plot hurtles toward redemption. Humanity is split in two: the worth-  by the morality tale of the narrative. In The Adjustment Bureau of 2011, human freedom—that which makes us human and therefore supposedly worthy—is judged to be the cause of sufficient destruction to the point where man’s free existence can no longer be permitted. This adaptation of a Philip K. Dick story features a team of intervening agents whose task is to allow humanity to run its proper and seemingly free course while making minor corrections if events appear to stray from their appropriate end. The heart of the film concerns a love story that is at odds with the prescribed order of events.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Despite a series of more and more complex adjustments, and in the face of all adversity, the lovers—even with one of them knowing about the ‘adjustments’—remain committed to their love. They stand firm, despite the warnings of the catastrophes that follow. The tale is heroic and Promethean, but not tragic. In the end it is this miniscule and possibly disastrous granting of human love and freedom—against the ‘adjustments’ of the angelic guardians—that wins the day. One of the adjusters had already explained to the male lead (Matt Damon) that human freedom, when given free reign, has led to the dark ages and (among other things) the first and second world wars (including the Holocaust). Even so, narrative sympathy is with the love and freedom that asserts itself against such bureaucratic calculation, and this is in accord with a common motif of science fiction’s postulates of the end of man. There is something pernicious, evil or apolitical in simply denying the right to existence of humanity; such diagnoses appear as unacceptably ruthless, as having no feeling for the love and passion that makes us human. This is so much the case that dystopian visions of the world need be no different from the present other than presenting the absence of human passion, even if that absence creates a world of peace and happiness.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The classical statement of this malaise is Brave New World (Huxley 1932) where a manufactured happiness is presented as horrifically inhuman, but the reasoning is the same in The Adjustment Bureau; there is something insidious about a world that might be managed, for our benefit, or in which it had been decided that we ought to be guided away from our freedom to be violent. As I have already suggested, the once common question of theodicy  problem of human destructiveness towards an otherwise neutral, if not benevolent, milieu. In the 2007 Oliver Hirschbiegel film The Invasion, the central character played by Nicole Kidman faces a world in which a virus is released when a space shuttle crashes to earth. The virus causes its hosts to become inhumanly robotic, void of all passion. Despite the absence of war and violence that would ensue, the narrative has a typical redemptive trajectory that sees the virus vanquished with the world returned to its human order. (Or disorder: the film concludes with newspaper headlines of war and other returns of violence.) Why, we might ask, do Brave New World scenarios of passionless peace seem so objectionable, and why—precisely when we do indeed face a future of possible human nonexistence (and sooner rather than later)—is present discourse focused on how we might survive, rather than whether we ought to survive? Or, if we accept the parochial desire to survive why can we not hear all the voices that accuse us of an existential worthlessness?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The present seems to be split between two myopias of the future: the first is evidenced by climate change policy’s discourse of managerialism. We speak of adaptation, mitigation, sustainability, cap and trade and even—despite cataclysmic game-changers—of recovery and renewal. Given the stark facts, how could ‘our’ survival possibly be adjusted in terms of using slightly less, or consuming at a slower rate, or with one part of the globe trading its destructive emissions with another? Even beyond the crises of climate change, other disaster scenarios—ranging from terrorism and viral pandemic to panic and systemic collapse—seem to require something that is a difference in kind, not degree. It could not be a question of either adjusting our desires and expectations to a diminished future, or finding other resources of energy and maintenance. For the problem lies not in the substance of energy—of what, if you like, we accept as our milieu— but the mode of acceptance as such. As long as there is something like life that presents itself as that which must be sustained, or—worse—as that by which we value sustainability (such that the good is what allows life to continue as it is), we have failed to ask the question that is being repeatedly articulated and yet never addressed. I want to conclude by looking at the new dominant mode of reaction  the future is covered over.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  In short, one may say that it is precisely at the point in humanity’s history when the question of the acceptability of the species ought to be asked that this very question mutates into a defense mechanism. By asking how we will survive into the future, by anticipating an end unless we adapt, we repress the question of whether the survival of what has come to be known as life is something we should continue to admit as the only acceptable option. The Violence of the Question Before looking at the culturally dominant modes of the question I want to consider a philosophical example, for it brings the flagrant self-delusion of humanity into sharp focus. For quite some time the philosopher Peter Singer has posed a rather uncomfortable thought experiment: I am wearing a pair of designer shoes and I pass by a child drowning in water that is deep enough to kill the child but insufficiently deep to pose any risk to me. I decide not to save the child because doing so would damage my shoes (2009). (In an earlier version [1972] Singer simply set saving the child against allowing our clothes to become muddy.) Singer suggests that few, if any, of us would accept this decision. We would save the child.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  And yet, he goes on to argue, we continually choose small and not highly significant or necessary material pleasures over the minor and barely noticeable material sacrifices it would require to save the lives of distant others. If we faced up to the real situation of our choices—which Singer suggests we ought to do by extending the range of our consideration beyond the immediate sympathies of those who are present to us—then we would conclude that we ought to give up a not too significant portion of our material wealth for the sake of benefiting an other in a way that is far more life-preserving than the minor life-enhancement of a pair of designer shoes. In response to this provocation Richard W. Miller (2010) starts to assess the degree to which sympathy and sacrifice for others diminish what is integral to the self. He argues that it might make sense, in terms of a person’s self-definition and the duty they owe to themselves, to act more kindly to those closer at hand (including one’s children and  the sake of saving other lives, just those that would not diminish our own pleasures and happiness significantly. Singer accepts a limitation of sympathy and an apparently non-negotiable selfishness, such that his argument—for all its audacity as a thought experiment—is really quite compatible with a world in which some people just do have more than others. The critical responses to Singer’s principles of sympathy and charity disclose the degree to which human selfishness or self-maintenance is not only the accepted principle of living well, but lies at the heart of moral philosophy. Morality is deemed to be a question of doing what is required in order to be the being that I am (Wolf 2010). There is, it seems, a sense in which either acting without principle or giving up too much of one’s wealth would threaten my self-identity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  What is scandalous, I would suggest, is not that humans have placed their own survival as more valuable than other lives, but that at the heart of moral philosophy is an assumption that nothing is more valuable or definitive of value than human life’s capacity to maintain and define itself. We ground value on life, either the sustainability of life, or our capacity to give our lives form and definition, or—to really face up to the circularity—we value life because it is life that makes value possible. Life is, properly considered (which is to say, always considered in terms of what defines humanity), selection: we say that something is living if it maintains or strives to maintain itself through time. The dispersed, the haphazard, the inert, the contingent, the diffuse and the unformed— these are not living. They are therefore not only not valuable but also (significantly) not valuing. We value what values: we defend animal life because it too makes its way in the world, possesses a degree of choosing this rather than that, and is therefore on its way to something like meaning or sense. We seem to think not only that the prima facie value of life lies in its modes of flourishing, but that something like destruction and annihilation are other than life and therefore unacceptable. This brings us back to the new mode of the existential question: how can humanity be at once the figure of that which renders life self-evidently valuable (because humanity is that animal that values) and yet be the being that has—through valuing itself—annihilated not only oth-  inevitably chooses life, and yet has done so by saving only its own life?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Why is it that the increasingly shrill affirmation of life—not just human life, but life as a living that furthers and values itself—occurs precisely at the moment in the history of life when it is at its most destructive and at its most evident end? In series three, episode nine, of True Blood (2010), the villainous antihero Russell Edgington appears suddenly on live National News to tear out and chew the spine from the broadcasting newsreader. Edgington announces an end to vampire-human reconciliation—the seeming motif of True Blood’s ongoing elegy to the desirability of human passion—and declares that a vile, destructive, violent and planet-destroying humanity must give way to another more worthy species. The question is not so much answered as deflected. The narrative trajectory of True Blood, its romantic propulsion, lies in the desirability of being human: while the villainous vampires embrace their immortality, the heroic central figure seeks the love that is only possible with human finitude. Despite this, of course, the vogue for vampire fiction and the fanzine embrace of Edgington as the twenty-first century’s ‘mad, bad and dangerous to know’ type suggests that the manifest yearning for being human covers over a deeper flirtation with a sense of the end of man. If humanity has always asked questions about its predicament, it has—as I have suggested— begun to consider the violence of its being in relation to the very figure of life that has rendered the human exemplary of life as such. Now, when the actual end of man approaches, when it seems necessary to ask what mode of the human—if any at all—should live on, the discourse of life can apparently only consider questions of degree rather than questions of kind.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  We ask how we might survive, adapt, mitigate or even trade our way into the future; we do not ask whether there is a future for us, and we cannot ask this because the ‘we’ of the question is at once that which has defined life and that which is essentially hurtling towards its own extinction. What disturbs us today is not theodicy, or how human life can live with the violence of its milieu, but anthropodicy, or how human life can avoid asking how it might justify itself. Finally How has the common figure of the self-evident value of human life given way to an increasing sense of species guilt and preliminary mourning? Why, just as humanity begins to have some sense of its end, are policies of survival, adaptation, mitigation and climate change, accompanied by a wide sense and figuration of the unacceptable nature of human life? Nothing defines the concept of reaction formation better than the present: everywhere there is evidence of the nonviable and unacceptable modus of human life, and yet the one notion that is unacceptable—incapable of being heard—is that human life has no value. This is not to say that—being without value—what has come to be known as humanity ought to extinguish itself, but rather to say that what is left of the human needs to confront the absence of value. (Some arguments, such as those of David Benatar (2006) that ‘prove’ that coming into human existence is always a harm—for all its provocation—remain thoroughly within the axiology of life: Benatar argues that human lives are more likely to be dominated by suffering rather than joy and are therefore not to be chosen. He therefore considers human life as something that humans choose or do not choose—when it is perhaps more probable that life is thrown at humans, and humans are thrown into life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is perhaps more provocative not to ask about the value of human life for humans but of human life for life.) For it is value and the holding on to that which saves itself, preserves itself, values itself and maintains itself that has precluded confrontation with the question that we are at once screaming out and yet also not hearing. One way to pose the question of the unacceptable is to consider what we, as a species, might affirm as our own or reject as inhuman. This is a standard and complex border, played out in the thought experiments of monstrosity and the genre of the supposedly post-apocalyptic. If we imagine a future where certain aspects of humanity take over then we may adjust ourselves accordingly. Dystopias are warnings or cautionary tales in which a tendency of the present may be averted. (This is perhaps why many post-apocalyptic dystopias have considered unacceptable solutions  Such dystopias would, presumably, act as salutary cautions against us following the course of our current actions to the nightmarish conclusions that would follow. If we imagine another species—vampires—who are defined by a certain inhumanity that has manifested itself in the human species, then the battle for humanity as life becomes a figural war against the future.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The vampiric or zombied other is an allegory for humanity gone awry, the bad humanity from which we can save ourselves in order to emerge as properly and justifiably human. That is: we imagine what it might be for the inhumanity within ourselves—a rapacity, ruthlessness and consuming rage—to become a species in its own right (figured as the dystopian man of the future). Rather than deal with humanity’s war on itself we have narrativized and figured the horror of humanity into some distant other. We imagine that it is in the future that man becomes cannibalistic, void of empathy, ruthlessly calculative, and so dependent on technology that he ceases to think; in this exercise of the imagination we preclude considering all the ways in which this ‘other’ dystopian ‘man’ has already (and has always already) arrived. The supposedly future narratives of the post-apocalyptic are counterfutural. We represent the future as possibly overtaken by destruction, cannabilism, zombies, violent technocracy or the invasion of mindlessness; in so doing we present as possibly futural and counter-human just those tendencies that have marked the species to date. In so doing—for all our post-apocalyptic or techno-utopian posthuman imaginings—we remain tied to a nostalgia for the properly human that has supposedly been threatened by an inhumanity that may appear from without. We remain in a state of denial or reaction towards the future in two senses: humanity’s end presents itself to us, and rather than ask the question this poses we instead imagine external threats to the species that are then warded off in a clear species-species agonistics.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (One would not want to read too much, or perhaps anything at all, into the current vogue for vampire fiction, except perhaps to note that like late eighteenth-century gothic it occurs alongside the frenzied affirmation of the life of man against various forms of threatening transcendence.) We also war against the future by presenting the world of the present—a world of species self-annihi-  would lie a possible acceptance of the future, is not whether man ought to survive, but why this question is so unacceptable as to be constantly displaced and dis-figured. Chapter 10  The Joys of Atavism A single duration will pick up along its route the events of the totality of the material world; and we will then be able to eliminate the human consciousness that we had at first laid out at wide intervals like so many relays for the motion of our thought: there will now only be impersonal time in which all things will pass (Bergson 1965, 47) Every living being borders on death; or perhaps it might be more accurate to say that every being has one side turned towards the non-living. Without that border between life and non-life, without the living being closing itself off to some extent from the fullness of life, there would be a pure influx, intensity or becoming without any resistance or stasis. If there were to be something like pure life, then it would be akin to Bergson’s ‘pure perception’: in its purest mode perception would be an unmediated capture of what is given, without the distinguishing and forming marks of memory: we ask that perception should be provisionally understood to mean not my concrete and complex perception—that which is enlarged by memories and offers always a certain breadth of duration—but a pure perception, I mean a perception which exists in theory rather than in fact and would be possessed by a being placed where I am, living as I live, but absorbed in the present and capable, by giving up every form of memory, of obtaining a vision of matter both immediate and instantaneous. (Bergson 2007 [1912], 26)  Creative Evolution as a force of explosive power that is not yet divided into an exploding or differentiating power and an exploded matter that is differentiated. But a living being is never ‘pure life,’ for a living being closes itself off, to some extent, from the world’s energies; a being is in part its open engagement with the world, but also a certain refusal of the dynamic life of the world, a selfsameness that remains unto itself and limits relations and stimuli. To say that every being borders on the nonliving is to acknowledge a certain inertia that is intertwined with what it means for a being to become.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Life can be considered as a double tendency, an explosive power of creative difference, and a counter-tendency of resistance: ‘it is probable that life tended at the beginning to compass at one and the same time both the manufacture of the explosive and the explosion by which it is utilized. In this case, the same organism that had directly stored the energy of the solar radiation would have expended it in free movements in space. And for that reason we must presume that the first living beings sought on the one hand to accumulate, without ceasing, energy borrowed from the sun, and on the other hand to expend it, in a discontinuous and explosive way, in movements of locomotion’ (Bergson 1911 A, 115-16). But, like Bergson’s ‘pure perception,’ this pure life of explosive\/ exploded force is speculative: what we encounter are mixtures, which we can intuit by seeing each composed being as in part dynamic and open, in part closed and stable. Rather than refer to this counter-tendency of resisting creative difference as death, it is perhaps more accurate to say that the condition of any ongoing sameness is some capacity to resist the differentiating fluxes of time—a certain non-living or material fixity. This way of thinking about the fold between life and non-life would allow us to think about texts and their relation to a counter-vitality without assuming that texts were living beings (or it would allow us to think of living beings as texts, as in some part detached from the life from which they emerge and distinguish themselves). Today, more than ever, it might appear to be fruitful to mark a distinction between texts and life, for there is currently an efflorescence of theories seeking to explain writing and other technical systems as extensions of the living organism’s will to sur-  sought to see literature as primarily adaptive and cognitive (Boyd 2009; Zunshine 2006). Insisting on a certain and necessary lifelessness in all beings, including texts, is perhaps one of the great ideas we can take from a Bergsonian\/Deleuzian tradition of modernism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  On the one hand we would need to insist on a certain lifelessness of the letter, but to do so would not be to mark a simple binary distinction between texts and living bodies, but to see all bodies as both living and non-living (and perhaps at their most alive when exposed to annihilation). Perhaps a text, to be a text (or to be read), must at least in part be considered alive. When John Milton made a case for allowing books to circulate freely he suggested that one would destroy more life (or spirit) by annihilating a book than would be lost by murdering a human: unlesse warinesse be us’d, as good almost kill a Man as kill a good Book; who kills a Man kills a reasonable creature, Gods Image; but he who destroyed a good Booke, kills reason it selfe, kills the image of God as it were in the eye. Many a man lives a burden to the Earth; but a good Booke is the pretious life-blood of a master spirit, imbalm’d and treasur’d up on purpose to a life beyond life. (Milton 1905 [1644], 9) A book has the capacity to extend the spirit or sense from which it emerged well beyond the author’s life; but it is also because of that afterlife that a book is always potentially dead, not only because it lives on by taking a material form that could be destroyed, but also because that same materiality has a force of its own that cannot be contained by the organic life of authors, readers or even the world from which it emerged. The condition for any being’s survival, its ‘living on,’ is that it take on some distinct and repeatable form: but it is that very distinction, ipseity or separateness that also cuts the text or body off from an ongoing life that will necessarily outlast the living. If there can be something like ‘a’ life then this is only because there is a difference and distinction between a specified being and the milieu from which it draws its sustenance. In the case of literary texts: a book can survive and be read if it is incarnated or given a material support that is not reducible to the animating intention  In the case of literary modernism we can be even more specific: modernism could emerge and have being only because it made a claim to life, but this claim was destructive of life in its actual self-maintaining modes and appealed to another life, beyond organic survival.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Key to this joyous atavism was a disdainful attitude towards the textual archive, alongside a recognition of deep archival forces. As a literary movement, modernism needed at once to regard the textual archive as so much noise and dead weight; at the same time, modernism could only take hold not by producing more literary life but by deadening the textual corpus that was at its disposal. One would read texts not as extensions or expressions of life, but as detached fragments with an odd afterlife. There is, I will argue, something to be gained—today more than ever—by reading modernism not as vitalism but as murderous textual annihilation. Further, this counter-vital modernism of the dead letter is best read through the supposedly vitalist work of Henri Bergson. If modernism were to be reread not as a lament on the infertility and deadening of the West, with the implied goal of revitalization of the word, but as a creatively destructive movement of willed extinction, then several consequences would follow. First, we would need to rethink both postmodernism and post-structuralism, given that both these movements are rendered possible by a certain response to modernism. Second, a new sexuality of modernism would emerge that would be essentially queer.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  (That is, it would be by deflection, divergence, deviation and dehiscence—and not reproduction— that modernist writing would operate: at once destroying the archive while allowing new archival forces to emerge.) To make this second point more clear and specific, I’d like to begin with the counter-thesis of modernism as a vitalism, with the underlying sexual (and racial) normativity that any vitalism or privileging of life would entail ( Jones 2010). Modernism and vitalism: responding to the mechanized, industrial, rationalized, quantifying, capitalist and reifying forces of an increasingly reductive world of homogeneous time and space, modernism sought to inject life into a desiccated western tradition by giving blood to the voices of the past. Descending into Hades where all the voices of history and becoming had been reduced to so much noise, the modernist artist  with just such due homage to the prophetic souls of the past, with the task of finding voices other than the ‘impetuous impotent’: ‘Poured we libations unto each the dead … I sat to keep off the impetuous impotent dead, \/ Till I should hear Tiresias’ [1987].) Such a theme of revitalization could be figured in profoundly sexual, and intensely heterosexual terms. Joyce’s Ulysses returns to the murmur of Molly Bloom’s body— ironically distancing itself from the novel’s long series of feminine\/maternal oceanic motifs (such as Stephen’s early figurations of his mother’s image as ‘Ghoul! Chewer of corpses,’ or Leopold Bloom’s recollection of Palestine as the ‘grey sunken cunt of the world’ [ Joyce 2000, 8, 50]). Although Ulysses is in tune with so much of modernism in its depiction of a series of failed and infertile sexual encounters, it nevertheless ends with an affirmative, fluid, embodied, feminine and open return to life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is as though the novel’s narrative trajectory, from Bloom’s urination and defecation, through the city of Dublin and a funeral—interspersed with the disembodied voices of newspapers, advertisements, fragments of the past and Stephen Dedalus’s scholarly musings—can be opened towards a future, however fragile and ironic, of purely potential (not yet embodied or actualized) life. It is possible to read the canonical texts of literary modernism as all addressing the problem of an infertile archive by imagining some act of (hetero)sexualized and unselfconscious redemption. Such a claim is easy to make in the case of Yeats, Lawrence, Pound, and Eliot. Yeats’s ’Leda and the Swan’ presents the involuntary and inhuman event of sexual coupling as a violently creative force, and this could be contrasted with the personal and immobilizing passions that are elicited by women caught up in the petty and historical plays of politics. (‘The Circus Animals’ Desertion’ laments: ‘I thought my dear must her own soul destroy \/ So did fanaticism and hate enslave it’ [Yeats 2011, 212].) Lawrence also contrasted a dark, disruptive, and counter-bourgeois sexual force with the ‘human all too human’ (paralyzingly infertile) love of marriage. In ‘The Ladybird,’ Count Dionys tells the very English Daphne: ‘The true living world of fire is dark, throbbing, darker than blood. Our luminous world that we go by is only the white lining of this’’ (Lawrence 2002,180).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Eliot’s The Waste Land diagnoses the inertia of the modern  and mourned softly flowing Thames. Pound situates bankers, journalists and homosexuals in the same infertile circle of hell. Like the other modernists, redemption is not gained by any form of Romanticisms’s ‘spousal verse’; classic muse figures are, if anything, ironized. But there is something akin to a distant oceanic feminine that would seem to offer life beyond the limits and disenchantments of actual women. That this nonreified, flowing, dynamic and pre-systemic life is feminine is clear in literary modernism (allowing the artist in turn to be something like a creator giving form to the formless). There is a tension, then, in the vitalist strategy of modernism: on the one hand, literary revitalization takes the form of a critique of already actualized and bounded forms (and is implicitly powered by a drive to overcome already constituted norms of ‘man’ and gender); on the other hand, this shockingly new vitality is figured via a highly sexualized metaphorics of the force of life infusing passive matter. The vitalist philosophers of modernism—including Bergson—would seem to be so focused on a critique of human and bounded figures of life that nothing like a gendered or sexual normativity could be valorized. And yet if we take the accepted reading of Bergson as a vitalist who was critical of ‘man’ into account, it seems hard to avoid the problem of sexual difference in two senses: Bergsonism would be set against a static norm of man and yet would affirm all those masculine figures of active, forceful, creative, incisive, penetrative and productive life that have marked gendered thinking (Hill 2008).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Why, we might ask, has sexual difference been such a rigid and persistent figure in questions of life? Apart from narrowly psychoanalytic answers, which have their legitimacy, it seems obvious that questions about life would take their cue from the image of the living being, and that sexual reproduction—despite being one mode among many of reproduction—would be a ready figure for considering not only the emergence of bounded living forms from an otherwise not-yet-specified matter, but also the living being’s relation to the life that it expresses. What psychoanalysis contributed to the understanding of the imaginary conditions of life was that the border between living and non-living was sexual. That is, the living being, in order to live, must be open to what is  But in order to be a living being, the organism must also close itself off, in part, from the full force of the life from which it emerges: full overcoming of desire or difference would annihilate the being’s individuation. Sexual difference figured as gender allows this strange border between living being and life to be negotiated imaginatively or (following Bergson), intellectually, for the intellect is that faculty that allows the complexity of life to be managed through concepts that reduce intensive difference. Life would be imagined as some fluid, oceanic, maternal plenitude from which the bounded form of a distinct and representing body would emerge. To think of mind as a camera that cuts the world into assimilable units of information: this, according to Bergson, is at how the intellect manages and imagines itself. An ‘image of thought’ is formed in which mind is a picturing machine.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  This capacity of the intellect to reify itself via some image of detached mind could only be countered by retrieving an intuition of life that would be at odds with all our figures of ‘man.’ In many ways this Bergsonian appeal to life beyond the bounds of the already formed organism is in line with a broader modernist critique of the figure of man as a Cartesian subject. Anti-Cartesianism generally has proceeded by appealing affirmatively—against man—to qualities that had once been figured as feminine but that now seem to offer ways of thinking about the vital order as such. Life would not be rational, bounded, logical, efficient and progressive, but dynamic, open, fluid and affective. One would move from gender—or older motifs of man as subject relating to formless but potential matter—to sexual difference. Fecund, creative, explosive, fluid, unbounded, potential, and intensive life would be that from which the desiccated and disenchanted intellect would emerge. All those predicates that had once been attributed to a chaotic femininity opposed to male reason would now characterize life as such, and the modernist-vitalist critique of the subject would be a critique of man. Man would, through an intuition of vitality, destroy the gendered binary that had locked him into an affectless, lifeless, disembodied Cartesian prison; he would become one with—and not simply the medium for—all that had been projected onto the feminized figures of life. Whereas other modernists used scenes of jouissance to overcome  boundlessness, Bergson contrasted the joy of transcending intuition with the self-serving consumption of bourgeois pleasure: There is a difference of vital tone.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Those who regularly put into practice the morality of the city know this feeling of wellbeing, common to the individual and society, which is the outward sign of the interplay of material resistances neutralizing each other. But the soul that is opening, and before whose eyes material objects vanish, is lost in sheer joy. Pleasure and well-being are something, joy is more. For it is not contained in these, whereas they are virtually contained in joy. They mean, indeed, a halt or a marking time, while joy is a step forward. (Bergson 2002, 325) Bergson’s vitalism—like modernism more generally—could be considered as a passage to impersonality via something like ‘becoming-woman.’ Not surprisingly, then, Bergson’s way of thinking about thought’s overcoming of its own imprisonment in the image of man takes on a phallic mode: penetrating what is not itself, emerging with ever more nuanced, distinct, differentiating and dynamic forms (Hill 2008). Imagine, though, another Bergsonism, another modernism and—in turn—another twenty-first century (another way of proceeding after modernism that would not be the usual—if multivalent—postmodernism). What if modernism were not a vitalism?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  How would a different reading of Bergson create a different present, after a different, non-vital, and essentially queer modernism? Before exploring what this might mean I want to put forward the following claim: post-modernism, especially as it ceases to theorize a dynamic relation to modernism and becomes a form of proclaimed posthumanism, becomes an ultra-humanism. This is especially so if we take note of the turns towards affect, literary Darwinism, and cognition, all of which seek to explain complexity and systems as extensions of life rather than pursuing Bergsonian notions of splitting, bifurcation, and the branching out into differences in kind (rather than degree). If we reverse today’s vitalisms and then trace a genealogy of a counter-vital post-modernism, we can find another Bergsonian modern-  at once finding an explosive origin that would yield the force from which distinction emerges, while also finding a more profound difference. To revisit a tired question: what then is\/was modernism, and how did postmodernism mark its difference from the former? Modernism—against notions of revivification and the vitalist critique of technology—can be considered as a profound attention to the force of the dead (Goldman 2004). We should not, I would suggest, see James Joyce’s most explicit presentations of the dead voice—the newspaper lines, malapropisms, clichés and mechanical voices of the city—as points of inertia to be overcome by the life of writing. We could consider a transition from the paralysis of Dubliners, where the dead letters of cliché and script seem to immobilize life, such that the absence of expression leads to a detachment between bodies and their desires, to a liberation of proliferating voices in Finnegans Wake.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But I would suggest that there is already a counter-vital, counter organic, and lifeless (pro-paralysis) celebration of the word in Dubliners. Consider, here, Bergson’s theory of both laughter and dreams. For the most part the body’s energies are organized towards survival, focused on the efficient and productive present; when that organization breaks down, and the body appears less as organism and more as machine, the body convulses in laughter (Bergson 1911 B). Similarly, when the body is asleep, no longer oriented to tasks at hand, the images of dreams surge forth. In Dubliners it is the functional, embodied, practical, and seemingly expressive relation to language that operates through a unified, rigid, and organic image of life. In the ‘easy’ flows of conversation and banter, life moves on, steadily, progressively, automatically—and it is perhaps this ongoing life that is the real paralysis of Dubliners. By contrast, it is when language appears as dead, when the body is no longer given expressive passage to the word, that there is a break with the line of time; something like the perception of ‘time in its pure state’ emerges. It is, for example, when writing is seen as a proper and personal extension of the self—when writing is organic—that Joyce describes the same dull round of suburban normality: it is only when writing is liberated from life, when one no longer grounds systems of inscription on the supposedly self-maintaining organism, that one disrupts the normalizing figure  Bergson laid the grounds for formulating a counter-vitalist approach to system and techne.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Consider his key thesis of creative evolution: in the beginning is an explosive force of differentiation, with no distinction yet between differentiating force and differentiated matter. If this original explosive power or potentiality to differ could be considered to be life, then we would have to redefine life beyond its bounded forms, and beyond organic notions of self-maintenance. Certain vitalist moralisms would have to be rethought. We could not, for example, hold the standard narrative that begins with an organism or relatively stable form, with bodies then becoming enslaved to and alienated by the systems it created for its own efficiency; nor could we conclude from such a narrative of life-alienated-by-techne with the resulting imperative to revitalize the raison d’etre of life from which all systems emerged and towards which they ought to return. Reading Bergson and Modernism against this normalizing mode would open a new counter-politics. It is no surprise, perhaps, that Derrida—commenting on Heidegger’s theory of time—makes a brief remark pertinent to today’s renewed interest in Bergson and life: the problem, Derrida argues, with any attempt to avoid a ‘vulgar’ (spatialized, quantified, punctuated) notion of time is that in order to think about time or have a concept of time we must have some notion of time in general. The very nature of cognition or conceptualization must render any supposedly proper, fluid, pre-articulated or originating temporality into some repeatable mode. In so far as one thinks and experiences time as time there will always be a reduction of time to what cannot be considered as some pure temporality of difference.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  For Derrida, then, Bergsonian notions of intuition or of creating a concept adequate to every perception would be typical of a logocentric metaphysics of presence (Derrida 1982, 60). Rather than appeal to a proper temporality before the ‘fall’ into techne, language and quantification, Derrida suggests that one can might think forward to the promise of the concept. It is not the case that there is some proper origin of life belied by language; for it is the idea created by language that offers something like a time ‘to come,’ a future beyond any of the actualized forms of the present. This promise of concepts—or the difference of concepts from any  the concept to open ‘justice to come,’ or ‘democracy to come,’ via a messianic promise without the full body of the messiah (Derrida 2005, 86). Not surprisingly, then, Derrida reverses a Marxist ethics of alienation and the proper: it is not the case that one could or should ‘exorcise’ all the phantoms and ghosts that have deflected life from its original and purposive striving. The condition of ‘life’—some ongoing self-sameness—is death; some technical system that is not the body itself allows for a stable bounded form. The lived body is possible because of systems of labor, action, language, society and relation that are not the body’s own. Thus, Derrida’s ‘Marxism’ focuses on the double bind of spirit: on the one hand, the future, reading and ‘living on’ require some notion of spirit, of what life would or should be beyond its already actualized forms; at the same time, that appeal to spirit will always haunt and alienate the very life it supposedly fulfils (Derrida 1994).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Not surprisingly, Derrida, exploring the difference and distance of the ‘letter’ from anything like a bodily or originating life, increasingly focuses on the ‘word’ in modernist writing, especially the writing of Joyce. Whereas in his early work, Derrida (1978 A) had questioned the Joycean project of the book and its claims to equivocity—adopting all the languages of the world and time—he increasingly celebrated Joyce and literature as offering a mode of deconstruction and democracy. The word in Joyce would not be grounded in sense, and—as in all literature—the detachment of word from the presence of voice would allow the word as such, in itself, to circulate freely in a democratic opening that would not anchor language back to some putative origin. Democracy would not be some return of all systems (such as language) to the expressive life of man; democracy is the free circulation of anything that can be said, the open right to ‘say anything.’ One might say, then, that post-structuralism is indebted to a certain counter-organic vitalist reading of modernism: the word is not an extension of the body, and cannot be returned back to the living voice without remainder. The word itself has force or life, creating relations and events that are generated neither by bodies nor subjects. Close to this post-structuralist counter-organic vitalism of the word or trace—and yet importantly different—would be an attention to the power (if that is the  power, not of life, but of the word, trace, concept or idea that generates an open promise: there can be no actuality that can exhaust the idea or concept of justice, and it is the force of the concept—as that which would insist on a sense above and beyond any actual instance—that will yield a ‘justice to come,’ allowing us to conclude that deconstruction ‘is justice.’ For Bergson, rather than moving from the ideal promise of the concept to an open future, intuition would destroy what has come to be assembled by concepts. Intuition of differential movements would fracture ongoing sameness and the forward movement of concepts, and would ‘retrace’ the path from which concepts emerged. This would ultimately allow for the emergence of ever finer differences that would be destructive of the word, and would explode the forward propulsion of organic striving.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Life is at war with itself: it is at once an explosive differentiation that would preclude anything like a line of time in which a past would be retained in order to organize a future, while life also harbors a tendency towards quiescence that diminishes the force of the differential for the sake of self-sameness. Bergson’s criticism of organicism traces a different path from what would become the post-structuralist elevation of writing, not only in Derrida but also in Foucault. Despite Deleuze’s celebration of Foucault’s corpus, he criticized Foucault for focusing on language as the locus of deterritorialization (Deleuze 1988): yes, literary writing would detach writing and the word from ‘man’ as a reasoning and communicating animal, but one could also imagine life, and not just writing, in a deterritorializing mode. Here, Deleuze cited the force of silicon to produce syntheses that would not be organic. We can look at the genealogy of this remark to assess its consequences for thinking about Bergson and modernism. First, looking back we can see that Deleuze (unlike Foucault, Derrida and other post-structuralists) took his departure not only from phenomenology but from Bergson. Whereas for Husserl the thought of time would require us to think of something like pure synthesis, not a subject who synthesizes but synthesis as such or a transcendental subjective power, Bergson would regard subjects as effects of an impersonal, dispersed, and synthetic power that would have various rhythms and tendencies ranging  than Deleuze, would extend the phenomenological theory of temporal syntheses to see language itself as a power to create forces or ideas beyond intentionality and life. Not surprisingly, then, Derrida would turn frequently to Joyce, the futural force of the word, the promise of spirit along with all the ghosts, hauntings, and spectres that could not be grounded in anything like life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The modernism of this post-structuralism would be critical of the closed efficiency of the organism, and would focus on the release of the word into a future that could be neither contained nor regarded as an extension of life as it actually is. One could cite, here, beyond the free indirect and stream of consciousness styles of Joyce (and the tendency of the word to operate beyond intentionality and to open up networks and systems of its own), the mournful mode of Eliot’s The Waste Land where the bourgeois self-interest of bodies is at odds with the fragments of literary tradition, and where words indicate a lost lyricism or deeper meditative time in contrast with urban efficiency. One could also include Pound’s emphasis on the machinic qualities of texts, on non-phonetic script, on the autonomy of the image and the force of text. By contrast, although he was also indebted to phenomenology, Deleuze took up Bergson’s task of intuition and—though he referred to a modernist range of texts including Joyce—made more of the work of Woolf and Lawrence. If one does not focus on the synthetic and futural force of concepts and their power to open up to an ideality that cannot be grounded in life, and if one does not regard time as tradition or history (as a panorama or wasteland of dead voices) but takes up Bergson’s challenge of destroying concepts to go back to the explosive power of life, then this might open up the importance of pre-linguistic forces and a radically geological atavism. Bergson allows us to think of a modernism that is pre- or counterlinguistic, but this is so not because language is returned to organic or vital life but because, for Bergson, vitality is only one of the tendencies of life. Other tendencies, such as those in conflict with the organism, are not found in concepts—which are thoroughly organic and synthesizing—but in intuitions or the tendency towards pure perceptions, which are fragmenting and dispersing. It is true that Bergson wrote of a  against others, then one can take that capacity for bodies to extend their interests into communities and moral groupings, and release that capacity from any actual body and open an intuition of what it might be to act selflessly as such, not self-sacrifice now for the sake of gain later, but selfsacrifice or self-annihilation (becoming-imperceptible as such) (Bergson 1935).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Contrast, again, with Derrida: Derrida recognizes that if we can operate with a comportment of justice or ethics towards this other here and now, then this is because there is something like the concept of ‘the other’ in general, which might be opened by a face to face encounter but always exceed that presence (Derrida 1978B, 102). The concept of the other in general, of hospitality in general, or democracy in general would liberate thought to move beyond actuality towards futurity. By contrast, even though Bergson (1935) does write of the saint or mystic who can think beyond any actual ‘humanity’ towards spirit in general, this power is not achieved through language and it is the same power that will operate in the smallest of intuitions. It is neither a futural move nor a nostalgic return but an explosive atavism that then allows for an inhuman future— not a posthuman future, which would be man’s capacity to think beyond himself, but a thought of a world without man that is released from the orbit of evolving time. Here I would suggest that we take our cue from Deleuze and Guattari’s reading of Woolf and Lawrence in A Thousand Plateaus in order to open a modernism of inhuman time—not a modernism of either stream of consciousness or stream of text (Deleuze and Guattari 2004, 278). This atavistic modernism might in turn allow for a re-reading of other modernists and post-modernism. Rather than posit something like tracing, marking, writing, text, differance or the word that would disperse and fragment any supposed grounding life, Bergson makes a direct claim about life as that which creates difference. Life is neither psyche, nor organism, and certainly not an inchoate chaos that is repressed by the order of psychic and organic wholes; life is an organizing power that operates in part by reducing the proliferation of intensive difference to allow for ongoing selfsame wholes, but life operates also by creating complexities and relations that cannot be contained by the human logic of organic efficiency.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A modern-  the human to be invaded by the forces of the cosmos that he has all too efficiently silenced. Consider D.H Lawrence’s poem, ‘The Shadow of Death,’ which opens with a description of the earth’s movement (‘again,’ so that we are already adopting a planetary duration). The point of view is initially not that of any human observer; a space, rhythm and ‘seeing’ that is non-human— ‘the sun stands up to see us’—precedes the poetic ‘I,’ and when the ‘I’ enters, it is as though the human is an emergence and intrusion from a far deeper time: The earth again like a ship steams out of the dark sea over The edge of the blue, and the sun stands up to see us glide Slowly into another day; slowly the rover Vessel of darkness takes the rising tide. I, on the deck, am startled by this dawn confronting Me who am issued amazed from the darkness, stripped And quailing here in the sunshine, delivered from haunting The night unsounded whereon our days are shipped. Feeling myself undawning, the day’s light playing upon me, I who am substance of shadow, I all compact Of the stuff of the night, finding myself all wrongly Among the crowds of things in the sunshine jostled and racked. The human voice, far from being the word through which the world is mediated, seems to be nothing more than a deathly silence, incapable of viewing what is other than itself other than in terms of death (‘What are they but shrouds?’): I with the night on my lips, I sigh with the silence of death; And what do I care though the very stones should cry me unreal, though the clouds Shine in conceit of substance upon me, who am less than the rain. Do I know the darkness within them? What are they but shrouds?\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  perception of inhuman durations followed by a joyous sense of the minor resistance or rhythm of one’s own existence at odds with a complex time of the planet: The clouds go down the sky with a wealthy ease Casting a shadow of scorn upon me for my share in death; but I Hold my own in the midst of them, darkling, defy The whole of the day to extinguish the shadow I lift on the breeze. The defiance of voice emerges as perception overcomes the sense of haunting and disjunction to intuit a ‘virility’ of life that is not that of man and that—more importantly—gives itself in the form of a ‘bright’ ‘living darkness’: And I know the host, the minute sparkling of darkness Which vibrates untouched and virile through the grandeur of night, But which, when dawn crows challenge, assaulting the vivid motes Of living darkness, bursts fretfully, and is bright: The poem then shifts from the relation between perceiving speaker and perceived world, to a perception of a ‘conflict’ of light, as though intuition had somehow passed from point of view and observation to something like the force of life as light: Runs like a fretted arc-lamp into light, Stirred by conflict to shining, which else Were dark and whole with the night. Runs to a fret of speed like a racing wheel, Which else were aslumber along with the whole Of the dark, swinging rhythmic instead of a-reel. Is chafed to anger, bursts into rage like thunder; Which else were a silent grasp that held the heavens Arrested, beating thick with wonder. Which erst was darkness sleeping. Runs into streams of bright blue drops, Water and stones and stars, and myriads Of twin-blue eyes, and crops Of floury grain, and all the hosts of day, All lovely hosts of ripples caused by fretting The Darkness into play. (Lawrence 1993, 132-33). If there is a vitality here it is not one of self-furtherance and homeostasis, but one of splitting, bifurcation, recombination and multiple paths.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  From here it follows that concepts do not open life to some ideal and non-actualized future, but anchor perception into known forms; those forms can, though, be pulverized beyond human recognition and point of view, to achieve something like a ‘fretting’ of darkness. It is as though our usual notion of perception as illuminating representation, passes over into illumination as a fleeting ‘fretting’ of a deeper geological plane of darkness. The waning of light and the increasing absence of human conceptual order is not presented by Lawrence’s poem as some descent into lifeless chaos, for the absence of light as we know it—light as cognizing illumination—gives way to light as the play of darkness, as though our perceived illuminated world were a fragment of a broader life, time and cosmos beyond the man of reason. Lawrence takes the great motif of man’s gaze into the cosmos (‘wonder’) and attributes it to the heavens, ‘arrested, beating thick with wonder.’ Far from this inhuman world being a negation or absence of life and order, the poem discloses rhythms (‘swinging rhythmic’), durations, and even ‘myriads \/ Of twin-blue eyes.’ Virginia Woolf ’s To the Lighthouse also describes a familial, gendered, historical and thoroughly archived world in the first section of the novel: Mr. Ramsay and his philosopher friends are concerned both with ‘subject, object and the nature of reality,’ and with their possible legacy and reputation in the maintained tradition of philosophy. Mrs. Ramsay is caring,  first section of Woolf ’s novel, the younger Lily Briscoe aims to paint Mrs. Ramsay, even though she is told by Charles Tansley (an aspiring philosopher) that ‘Women can’t paint, women can’t write....’ At the level of narrative, this section of the novel, ‘The Window’ ostensibly concerns whether or not a journey towards light—a trip to the lighthouse—will be take place. As in the first stages of Lawrence’s poem, a human world of love and filiation is set over against a world of what can broadly be referred to as climate—forces that play havoc with human intentionality and cannot be mastered by either a philosophy of subjectivism or an art of representation. Accordingly the middle section—‘Time Passes’—shifts away from a human temporality of expectation and calculation to the falling of darkness. Here the point of view shifts from the novel’s characters, with their desires and expectations, to rhythms, durations, and interactions of the earth’s forces entering the house.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Narrated in third person, the subject of the journey through the house is not even the single personified wind, but ‘airs’ that question the stability and steadfastness of the human world (again, an inversion of the human observer looking into a cosmos): Nothing stirred in the drawing-room or in the dining-room or on the staircase. Only through the rusty hinges and swollen sea-moistened woodwork certain airs, detached from the body of the wind (the house was ramshackle after all crept round corners and ventured indoors. Almost one might imagine them, as they entered the drawing-room questioning and wondering, toying with the flap of hanging wallpaper, asking, would it hang much longer, when would it fall? (Woolf 2007, 337) These ‘airs’ interacting with the human world of objects are directed by ‘some random light.’ Eventually the narration moves towards what I would refer to as the geological sublime: a sublime that is not that of the world appearing as if in accord with our intentionality, a world that is not that of harmonious order, but that is destructive of the anthopomorphic sense we make of things: The nights now are full of wind and destruction; the trees  choke rain pipes and scatter damp paths. Also the sea tosses itself and breaks itself, and should any sleeper fancying that he might find on the beach an answer to his doubts, a sharer of his solitude, throw off his bedclothes and go down by himself to walk on the sand, no image with semblance of serving and divine promptitude comes readily to hand bringing the night to order and making the world reflect the compass of the soul. The hand dwindles in his hand; the voice bellows in his ear. Almost it would appear that it is useless in such confusion to ask the night those questions as to what, and why, and wherefore, which tempt the sleeper from his bed to seek an answer. (Woolf 2007, 339) Here, in conclusion, I would suggest that we take our line of thinking from Woolf ’s Bergsonian modernism—destructive of concepts, order, and any notion of a single illuminating light of reason—towards Deleuze and Paul De Man.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  De Man, discussing the sublime, insisted that going beyond the order and human harmony of beauty would allow for a thought, always resisting figuration, of a blank and inhuman materiality: ‘The dynamics of the sublime mark the moment when the infinite is frozen into the materiality of stone, when no pathos, anxiety, or sympathy is conceivable; it is, indeed, the moment of a-pathos, or apathy, as the complete loss of the symbolic’ (De Man 1996, 126). Deleuze, writing on Bergson, also focused on the power of intuition to arrive at inhuman durations: ‘To continue Bergson’s project today, means for example to constitute a metaphysical image of thought corresponding to the new lines, openings, tracings, leaps, dynamisms, discovered by a molecular biology of the brain: new linkings and re-linkings in thought’ (Deleuze 1991, 117). That is, to be after Bergson’s modernism, would be to continue the two tendencies of life: both the durations of matter, and the capacity—from those durations—to produce ‘a metaphysical image of thought.’ Art and writing in their human modes are neither mutations of a single archive of man (for the archive is in concert with times and rhythms not its own),  today, that are responding to the new rhythms of the earth—writing that aims to imagine what it might be to perceive a world without humans— are provocatively postmodern. I would conclude, then, by contrasting various posthumanisms that aim to imagine one life of interweaving and interacting powers—where man overcomes his distinction to merge with digital technologies, animal life, or the ecology of the planet—to a more radical atavism, suggested by Bergson, where humans intuit rhythms that are distinct, inhuman, and beyond the time of the present. A postmodernism of this mode can be discerned, not only in a range of texts that are concerned with life after the end of humans, but in new modes of writing that aim to take point of view beyond that of man as a speaking animal. One example might be Don DeLillo’s Point Omega, which takes the novel form but adopts the point of view of a man viewing an art installation (Douglas Gordan’s 24 Hour Psycho), with the art installation, in turn, being a slowed down scene from Alfred Hitchcock’s Psycho. It is as though DeLillo is at once writing in language in the genre of the novel, and yet tracing the temporality and distributed rhythms of nonliterary visual and cinematic forms. Just as Woolf concludes her novel To the Lighthouse with Lily Briscoe painting a single dark line down the center of a canvas, DeLillo opens Point Omega with sentences that follow the path of an eye following the slowed down frames of a section of film.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  DeLillo writes of the movements of light and the display of unseen images before turning to the perceiving eye and its relation to the screen, as well as the screen’s capacity to produce cadences that alter the relation between eye and cognition. Eyes, screens, light, and images: all harbor their own tendencies, and yet all enter into contingent relations, generating distinct rhythms and lines of becoming. The sentences of the novel’s opening double the repetitive rhythm of the gaze and the different angles the screens are able to produce of the same scene; the simple syntax and shift to present tense empties the point of view of any mental content, affect or interiority—‘Anthony Perkins is turning his head’: The gallery was cold and lighted only by the faint shimmer on the screen. Back by the north wall the darkness was nearly  there was a glancing light from the area beyond, where others were gathered, at some distance, browsing the art books and postcards. […] The man at the wall watched the screen and then began to move along the adjacent wall to the other side of the screen so he could watch the same action in a flipped image. He watched Anthony Perkins reaching for a car door, using the right hand. He knew that Anthony Perkins would use the right hand on this side of the screen and the left hand on the other side. He knew it but needed to see it and he moved through the darkness along the side wall and then edged away a few feet to watch Anthony Perkins on this side of the screen, the reverse side, Anthony Perkins using the left hand, the wrong hand, to reach for a car door and then open it.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  But could he call the left hand the wrong hand? Because what made this side of the screen any less truthful than the other side? The slightest camera movement was a profound shift in space and time but the camera was not moving now. Anthony Perkins is turning his head. It was like whole numbers. The man could count the gradations in the movement of Anthony Perkins’ head. Anthony Perkins turns his head in five incremental movements rather than one continuous motion. It was like bricks in a wall, clearly countable, not like the flight of an arrow or a bird.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Then again it was not like or unlike anything. (DeLillo 2010, 1) It is true that Bergson regarded the cinematic camera as the ill of the modern eye: we carve the world into so many snapshots, and then regard the world as nothing more than a collection of unified images, forgetting that the frozen image is a lesser cut in a complex and intensive  and carries it forward into the perceptual power of the machine; the slowed down frames of Hitchcock’s Psycho allow the human eye to experience durations and angles not its own. That perceiving eye, in turn, allows for a mode and style of writing that is not the linear narrative of a novel, but closer to a haiku, as if composed forces yield a certain meter that allows writing to form. If Bergson’s modernism challenged the human point of view of subjects representing objects and did so by suggesting that intuition might find other durations, he also opened a tradition of writing that would not rest easily with its own structures and systems but would—through encounters with other perceptions—strive to think, from within language, of rhythms beyond language. I would suggest that Bergson’s formal method of intuition, whereby perception in the present decomposes the evolved forms of experience to disclose the tendencies from which bounded and organic life has emerged, enables a genealogy of the future. If we slow down the frames through which the world is given—not assuming one whole life of interconnected unity, but an open whole of divergent and incompossible potentials—then what has taken to be posthuman (or the vanquishing of our own being to perceive life as such in its full reality) may be surpassed by the counter human. Living beings are at once emergent from life and at war with life if life is defined as temporal progression towards complex and self-maintaining systems. If, however, there is no such thing as life as such—if there is only an ongoing war between bounded complexity and unbounded dissolution—then we will be compelled to confront the human stain: ‘man’ cannot erase himself, for he has always composed himself as self-erasure, as a being who can become nothing more than a life and world that he properly perceives.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  It is precisely this stain of non-erasure or the awareness of our geological mark on the time of life that may enable us to think a future that is neither posthuman nor human so much as superhuman. If humans exist it is through a deflection of survival, a strange torsion of being at once closed off from life while at the same time claiming to be nothing more than life: this history of the human as an oscillation between self-formation and self-destruction rather than the joyous and blind declaration of the posthuman provides a  Works Cited Adorno, Theodor and Max Horkheimer. 2002. Dialectic of Enlightenment: Philosophical Fragments. Trans. Edmund Jephcott. Stanford: Stanford University Press. Adorno, Theodor.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1983. Negative Dialectics. Trans. E.B. Ashton. London: Continuum. Adorno, Theodor. 1984.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Aesthetic Theory. Trans. C. Lenhardt. Ed. Gretel Adorno and Rolf Tiedemann. London. Adorno, Theodor. 1991.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Culture Industry: Selected Essays on Mass Culture. Ed. J.M. Bernstein. London: Routledge. Agamben, Giorgio. 1998. Homo Sacer: Sovereign Power and Bare Life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. Daniel Heller-Roazen. Stanford: Stanford University Press. Agamben, Giorgio. 1999. Potentialities: Collected Essays in Philosophy. Trans. Daniel Heller-Roazen.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Stanford: Stanford University Press. Agamben, Giorgio. 1999B. The Man Without Content. Trans. Daniel Heller-Roazen. Stanford University Press. Agamben, Giorgio.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2004. The Open: Man and Animal. Stanford, CA: Stanford University Press. Ansell-Pearson, Keith. 1997. Viroid Life: Perspectives on Nietzsche and the Transhuman Condition London: Routledge. Apel, Karl-Otto. 2001.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Response of Discourse Ethics to the Moral Challenge of the Human Situation as Such and Especially Today Leuven: Peeters. Appiah, Anthony Kwame. 2006. Cosmopolitanism: Ethics in a World of Strangers. New York: Norton. Arendt, Hannah. 2005. The Promise of Politics.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Ed. J. Kohn. New York: Schocken. Attridge, Derek. 2004. The Singularity of Literature. London: Routledge. Ayala, Franciso J.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2010. ‘The Difference of Being Human: Morality.’ PNS 107.2: 9015-9022. Baldick, Chris.1983. The Social Mission of English Criticism, 1848-1932. Oxford: Oxford University Press. Bate, Jonathan. 1991. Romantic Ecology: Wordsworth and the Environmental Tradition.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  London: Routledge. Bate, Jonathan. 2000. The Song of the Earth. Cambridge, MA. : Harvard University Press. Baudrillard, Jean. 1994.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Simulacra and Simulation. Trans. Sheila Faria Glaser. Ann Arbor: University of Michigan Press. Beer, Gillian. 1983. Darwin’s Plots: Evolutionary Narrative in Darwin, George Eliot, and Nineteenth-Century Fiction. London: Routledge and Kegan Paul.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Benatar, David.2006. Better Never to Have Been: The Harm of Coming into Existence. Oxford: Clarendon Press. Benjamin, Walter. 2008. The Work of Art in the Age of Mechanical Reproduction. Harmondsworth: Penguin. Benn Michaels, Walter.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2001. ‘The Shape of the Signifier,’ Critical Inquiry 27.2: 266-83. Benn Michaels, Walter. 2009. ‘What Matters,’ London Review of Books. August. Bergson, Henri. 1911A.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Creative Evolution. Trans. Arthur Mitchell. New York: Henry Holt. Bergson, Henri 1931. Creative Evolution. Trans. Arthur Mitchell.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York. H. Holt and Company. Bergson, Henri. 1965. Duration and Simultaneity. Trans. Leo Jacobson. Indianapolis: Bobbs Merrill.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Bergson, Henri. 2002. Henri Bergson: Key Writings. Ed. Keith Ansell-Pearson and John Mullarkey. London: Continuum. Bergson, Henri. 1911B.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Laughter: An Essay on the Meaning of the Comic. London: Macmillan. Bergson, Henri. 1912. Matter and Memory. Trans. Nancy Margaret Paul and William Scott Palmer. London: G. Allen; New York: Macmillan.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Bergson, Henri. 1913. Matter and Memory. Trans. Nancy Margaret Paul and W. Scott Palmer. London: George Allen. Bergson, Henri. 1935.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Two Sources of Morality and Religion. Trans. R. Ashley Audra and Cloudesley Brereton. London. Macmillan. Bergson, Henri. 1977. The Two Sources of Morality and Religion.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. R. Ashley Audra and Cloudesley Brereton. Notre Dame: University of Notre Dame Press. Bérubé, Michael and Nelson, Cary. Ed. 1995. Higher Education Under Fire: Politics, Economics, and the Crisis of the Humanities. New York: Routledge.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Bloom Howard. 2000. The Global Brain: The Evolution of Mass Mind from the Big Bang to the 21st Century. New York: Wiley. Bostrom, Nick. 2005. ‘The Fable of the Dragon Tyrant.’ Journal of Medical Ethics 31.5: 273–277. Boyd Brian.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1998. ‘Jane, Meet Charles: Literature, Evolution, and Human Nature.’ Philosophy and Literature 22.1: 1-30. Boyd, Brian. 2006. ‘Getting it All Wrong,’ The American Scholar. http:\/\/www. theamericanscholar.org\/getting-it-all-wrong\/ Boyd, Brian. 2009.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  On the Origin of Stories: Evolution, Cognition, and Fiction. Cambridge, MA. : Belknap Press of Harvard University Press. Braidotti, Rosi. 2006. ‘Posthuman, All Too Human: Towards a New Process Ontology.’ Theory, Culture & Society 23. 7-8: 197-208. Brassier, Ray.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2008. Nihil Unbound: Naturalism and Anti-Phenomenological Realism. New York: Palgrave Macmillan. Brennan, Timothy. 2001. ‘Cosmo-Theory,’ The South Atlantic Quarterly 100.3: 659-691. Brooks, Peter. 1984.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Reading for the Plot: Design and Intention in Narrative. New York: A.A. Knopf. Bryant, Levi, Nick Srnicek and Graham Harman Eds. 2011. The Speculative Turn: Continental Materialism and Realism. Re: Press. Butler, Judith. 1990.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Gender Trouble: Feminism and the Subversion of Identity. New York: Routledge. Butler, Judith. 1993. Bodies that Matter: On the Discursive limits of ‘Sex,’ New York: Routledge. Butler, Judith. 1997. The Psychic Life of Power: Theories in Subjection.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Stanford: Stanford University Press. Butler, Judith. 2005. Giving an Account of Oneself. New York: Fordham University Press. Butler, Judith. 2006. Precarious Life: The Powers of Mourning and Violence.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  London: Verso. Carr, Nicholas. 2009. In the Shallows: What the Internet is Doing to Our Brains. New York: Norton. Carr, Nicholas. 2010. The Shallows: What the Internet is Doing to Our Brain.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Atlantic. Carroll, Joseph. 2004. Literary Darwinism: Evolution, Human Nature, and Literature. London: Routledge. Clark, Andy. 1997. Being There: Putting Brain, Body, and World Together Again.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Cambridge, MA. : MIT Press. Clark, Andy. 2003. Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence. Oxford: Oxford University Press. Clark, Andy. 2008.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Supersizing the Mind: Embodiment, Action, and Cognitive Extension. Oxford: Oxford University Press. Clark, Timothy. 2010. ‘Some Climate Change Ironies: Deconstruction, Environmental Politics, and the Closure of Ecocriticism.’ Oxford Literary Review 32.1: 131-49. Clough, Patricia Ticineto with Jean Halley. 2007. The Affective Turn: Theorizing the Social.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Durham: Duke University Press. Cohen, Tom, Claire Colebrook and J. Hillis Miller. 2011. Theory and the Disappearing Future: On De Man, On Benjamin. London: Routledge. Colebrook, Claire. 2012A. Blake, Deleuzian Aesthetics and the Digital.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  London: Continuum. Colebrook, Claire. 2012B. ‘On the Spectacle of Financial Collapse: Beyond (Good) Investment and (Evil) Speculation. Loaded Subjects: Psychoanalysis, Money and the Global Financial Crisis. David Bennett ed. London: Lawrence and Wishart. Cottingham, John.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2003. On the Meaning of Life. London: Routledge. Crutzen, Paul. 2000. ‘The Anthropocene.’ Global Change Newsletter. 41.1: 17-18. Damasio, Antonio R. 2000.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Feeling of What Happens: Body and Emotion in the Making of Consciousness. New York: Harcourt. De Landa, Manuel. 2006. A New Philosophy of Society: Assemblage Theory and Social Complexity. London: Continuum. De Man, Paul. 1972.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘Genesis and Genealogy in Nietzsche’s, The Birth of Tragedy.’ Diacritics 2.4: 44-53. De Man, Paul. 1996. Aesthetic Ideology. Ed. Andrzej Warminski. Minneapolis: University of Minnesota Press. Debord, Guy.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1973. Society of the spectacle. Detroit: Black & Red. Deleuze, Gilles. 1988A. Bergsonism. Trans. Hugh Tomlinson and Barbara Habberjam.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Zone Books. Deleuze, Gilles. 1994. Difference and Repetition. Trans. Paul Patton. New York: Columbia. Deleuze, Gilles.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2006B. The Fold: Leibniz and the Baroque. Trans. Tom Conley. London: Continuum. Deleuze, Gilles. 1988B. Foucault.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. Seán Hand. Minneapolis: University of Minnesota Press. Deleuze, Gilles. 2006A. Foucault. Trans. Seán Hand.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  London: Continuum. Deleuze, Gilles. 2004. Francis Bacon: The Logic of Sensation. Trans. Daniel W. Smith. Minneapolis: University of Minnesota Press. Deleuze, Gilles and Félix Guattari.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1977. Anti-Oedipus: Capitalism and Schizophrenia. Trans. Robert Hurley, Mark Seem, and Helen R. Lane. New York: Viking Press. Deleuze, Gilles and Félix Guattari. 2004. Anti-Oedipus.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. Brian Massumi. London: Continuum. Deleuze, Gilles and Félix Guattari. 2004A. Anti-Oedipus: Capitalism and Schizophrenia. London: Continuum. Trans.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Helen Lane and Mark Seem. Deleuze, Gilles. and Guattari, Félix. 1986. Kafka: Toward a Minor Literature. Trans. R. Bensmaïa. Minneapolis: University of Minnesota Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Deleuze, Gilles and Félix Guattari. 1987. A Thousand Plateaus: Capitalism and Schizophrenia. Trans. Brian Massumi. Minneapolis: University of Minnesota Press. Deleuze, Gilles and Félix Guattari. 2004B.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  A Thousand Plateaus. Trans. Brian Massumi. London: Continuum. Deleuze, Gilles and Félix Guattari. 1994. What is Philosophy? Trans.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Hugh Tomlinson  Derrida, Jacques. 1978A. Edmund Husserl’s Origin of Geometry: An Introduction. Trans. John P. Leavey, Jr. Nebraska: University of Nebraska Press. Derrida, Jacques. 2002. ‘Force of Law: “The Mystical Foundation of Authority.’” in G. Anidjar Ed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Acts of Religion. London: Routledge. Derrida, Jacques. 1977. Limited Inc. Trans. Samuel Weber. Ed. Gerald Graff.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Evanston: Northwestern University Press. Derrida, Jacques. 1982. Margins of Philosophy. Chicago: University of Chicago Press. Derrida, Jacques. 1984. ‘No Apocalypse, Not Now (Full Speed Ahead, Seven Missiles, Seven Missives).’ Trans.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  C. Porter, P. Lewis. Diacritics,14.2 Nuclear Criticism: 20-31. Derrida, Jacques. 2001. On Cosmopolitanism and Forgiveness. Trans. Mark Dooley and Michael Hughes. London: Routledge.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Derrida, Jacques. 1994. Specters of Marx: The State of the Debt, the Work of Mourning, and the New International. Trans. Peggy Kamuf. New York: Routledge. Derrida, Jacques. 2005.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Rogues: Two Essays on Reason. Trans. Pascale-Anee Brault and Michael Naas. Stanford: Stanford University Press. Derrida, Jacques. 1978B. ‘Violence and Metaphysics.’ Writing and Difference. Trans.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Alan Bass. Chicago: University of Chicago Press. Diprose, Rosalyn. 2009. ‘Toward an Ethico-Politcs of the Posthuman: Foucault and Merleau Ponty.’ Parrhesia 8: 7-19. Donne, John. 2000. John Donne: The Major Works.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Ed. John Carey. Oxford: Oxford University Press. Dougherty, Stephen. 2010. ‘Culture in the Disk Drive: Computationalism, Memetics, and the Rise of Posthumanism.’ Diacritics 31.4: 85-102. Dreyfus, Hubert L., Stuart E. Dreyfus and Tom Athanasiou. 1986.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer. New York: Free Press. Dunbar, Robin. 1996. Grooming, Gossip and the Evolution of Language, London: Faber. Eagleton, Terry. 2007. The Meaning of Life.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Oxford: Oxford University Press. Emerson, Ralph Waldo. 1982. Nature and Selected Essays. Ed. Larzer Ziff. Harmondsworth: Penguin. Feinberg, Todd E. and Julian Paul Keenan.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2005. The Lost Self: Pathologies of the Brain and Identity. Oxford: Oxford University Press. Felman, Shoshana. 1987. Jacques Lacan and the Adventure of Insight: Psychoanalysis in Contemporary Culture. Cambridge, MA. : Harvard University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Felski, Rita. 2011. “Context Stinks!” New Literary History 42.4: 573-591. Fink, Eugen. 1970. ‘The Phenomenological Philosophy of Edmund Husserl and Contemporary Criticism.’ In The Phenomenology of Husserl. Ed. R. O. Elveton.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Chicago: Quadrangle Books. 73-147. Fish, Stanley. 2010. ‘The Crisis of the Humanities Officially Arrives.’ New York Times. October 11, http:\/\/opinionator.blogs.nytimes.com\/2010\/10\/11\/ the-crisis-of-the-humanities-officially-arrives\/?emc=eta1 Flanagan, Owen. 2007. The Really Hard Problem: Meaning in a Material World.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Cambridge. MA. : MIT Press. Foucault, Michel. 1978. The History of Sexuality: Volume One. Trans. Robert Hurley.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Pantheon Books. Foucault, Michel. 1977. Language, Counter-Memory, Practice: Selected Essays and Interviews. Ed. Donald F. Bouchard . Trans. Donald F. Bouchard and Sherry Simon.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Ithaca: Cornell University Press. Foucault, Michel. 1970. The Order of Things: An Archaeology of the Human Sciences. London: Tavistock. Foucault, Michel. 2002. The Order of Things: An Archaeology of the Human Sciences.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  London: Routledge. Freud, Sigmund. 1961. Beyond the Pleasure Principle. Trans. James Strachey. New York: Norton. Freud, Sigmund.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2011. Beyond the Pleasure Principle. Ed. Todd Dufresne. Trans. Gregory C. Richter. London: Broadview Press. Freud, Sigmund.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1908. ‘Creative Writers and Day-Dreaming.’ The Standard Edition of the Complete Psychological Works of Sigmund Freud, Volume IX (1906-1908): Jensen’s ‘Gradiva’ and Other Works. Trans. James Strachey. London: Hogarth Press. 141-154. Gallagher, Catherine and Greenblatt, Stephen. 2001.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Practicing New Historicism. Chicago, IL: University of Chicago Press. Gallagher, Shaun. 2005. How the Body Shapes the Mind. Oxford: Clarendon Press. Gardiner, Stephen. 2006.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘A Perfect Moral Storm: Climate Change, Intergenerational Ethics and the Problem of Moral Corruption.’ Environmental Values 15: 397–413. Gibbs, Raymond R. Jr. 2006. Embodiment and Cognitive science. Cambridge: Cambridge University Press. Goldman, Jane. 2004. Modernism, 1910-1945: Image to Apocalypse. New York: Palgrave Macmillan.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Greenfield, Susan. 2000. The Private Life of the Brain: Emotions, Consciousness, and the Secret of the Self. New York: John Wiley & Sons. Greenfield, Susan. 2008. I.D. : The Quest for Meaning in the 21st Century.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  London: Sceptre. Gregg, Melissa and Gregory J. Seigworth. 2010. The Affect Theory Reader. Durham: Duke University Press. Grosz, Elizabeth. 1994. Volatile Bodies: Toward a Corporeal Feminism.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Sydney: Allen and Unwin. Grosz, Elizabeth. 2011. Becoming Undone: Darwinian Reflections on Life, Politics, and Art. Durham: Duke University Press. Grusin, Richard A. 2010. Premediation: Affect and Mediality After 9\/11.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Palgrave Macmillan. Habermas, Jürgen. 1987. The Philosophical Discourse of Modernity: Twelve Lectures. Trans. Frederick Lawrence. Cambridge, MA. : MIT Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Habermas, Jürgen. 1991. The Structural Transformation of the Public Sphere: An Inquiry Into a Category of Bourgeois Society. Cambridge. Trans. Thomas Burger with Frederick Lawrence. MIT Press. Hansen, Mark B. N. 2003.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘Affect as Interface: Confronting the Digital-Facial Image.’ Journal of Visual Culture 2.2: 205-228. Hansen, Mark B.N. 2004. ‘The Time of Affect, or Bearing Witness to Life.’ Critical Inquiry 30: 584-626 . Hardt, Michael and Antonio Negri. 2000. Empire. Cambridge: Harvard University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Hardt, Michael and Antonio Negri. 2004. Multitude: War and Democracy in the Age of Empire. New York: The Penguin Press. Harman, Graham. 2005. Guerrilla Metaphysics: Phenomenology and the Carpentry of  Hartman, Geoffrey H. 1970. Beyond Formalism; Literary Essays, 1958-1970.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New Haven: Yale University Press. Hayles, N. Katherine. 1999. How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics. Chicago: University of Chicago Press. Hayles, N. Katherine. 2007. ‘Hyper and Deep Attention: The Generational Divide in Cognitive Modes.’ Profession.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  13: 187-199. Heidegger, Martin. 1996. Being and Time. Trans. Joan Stambaugh. Albany: SUNY Press. Heidegger, Martin.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1969. An Introduction to Metaphysics. Trans.Ralph Manheim. New Haven: Yale University Press. Heidegger, Martin. 1998. Pathmarks. Ed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  William McNeill. Cambridge: Cambridge University Press. Heidegger, Martin. 1968. What is a Thing? Trans. W. B. Barton, Jr., and Vera Deutsch. Chicago: H. Regnery Co. Hill, Rebecca.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2008. ‘Phallocentrism in Bergson: Life and Matter.’ Deleuze Studies 2: 123-136. Husserl, Edmund. 1965. Cartesian Meditations. Trans. Dorion Cairns. The Hague: M. Nijhoff.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Huxley, Aldous. 1932. Brave New World. New York: Doubleday. Jackson, Maggie and Bill McKibben. 2008. Distraction: The Erosion of Attention and the Coming Dark Age. New York: Promethues.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Jameson, Fredric. 2005. Archaeologies of the Future: The Desire Called Utopia and Other Science Fictions. London: Verso. Jameson, Fredric. 1977. ‘Imaginary and Symbolic in Lacan: Marxism, Psychoanalytic Criticism, and the Problem of the Subject.’ Yale French Studies 55\/56 Literature and Psychoanalysis. The Question of Reading: Otherwise: 338-395.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Jameson, Fredric. 1981. The Political Unconscious: Narrative as a Socially Symbolic Act. Ithaca: Cornell University Press. Jameson, Fredric. 1991. Postmodernism, or, The Cultural Logic of Late Capitalism. Durham: Duke University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Jones, Donna V. 2010. ‘Bergson and the Racial Elan Vital,’ in The Racial Discourses of Life Philosophy. New York: Columbia University Press. Joyce, James. 2000. Ulysses. Ed. Declan Kiberd.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Harmondsworth: Penguin. Kane, Joanna. 2008. With Duncan Forbes and Roberta McGrath. The Somnambulists. Stockport: Dewi Lewis. Kant, Immanuel. 1991.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘Idea for a Universal History with a Cosmopolitan Purpose.’ In Kant: Political Writings. Ed. Hans Reiss. Trans. H.B. Nisbet. Cambridge: Cambridge University Press. 41-53.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Kant, Immanuel. 1991. Political Writings. Ed. H.S. Reiss. Cambridge: Cambridge University Press. Kant, Immanuel.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1999. Practical Philosophy. Ed. Mary J. Gregor. Cambridge: Cambridge University Press. Kirby, Vicki. 1997. Telling Flesh: The Substance of the Corporeal.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Routledge. Knapp, Steven and Benn Michaels, Walter. 1982. ‘Against Theory,’ Critical Inquiry 8.4: 723-42. Korsgaard, Christine. 2008. The Constitution of Agency: Essays on Practical Reason and Moral Psychology. Oxford: Oxford University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Korsgaard, Christine. 2009. Self-Constitution: Agency, Identity, and Integrity. Oxford: Oxford University Press. Korsgaard, Christine.M. and Cohen, G.A. 1996. The Sources of Normativity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Ed. O. O’Neill. Cambridge: Cambridge University Press. Kronick, Joseph, G. 1999. Derrida and the Future of Literature. Albany: SUNY Press. Lacan, Jacques. 1977.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Ecrits: A Selection. Trans. Alan Sheridan. New York: Norton. Lakoff, George and Mark Johnson. 1999. Philosophy in the Flesh: The Embodied Mind and its Challenge to Western Thought. New York: Basic Books.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Langton, Rae. 1998. Kantian Humility: Our Ignorance of Things in Themselves. Oxford: Oxford University Press. Latour, Bruno. 2005. Reassembling the Social: An Introduction to Actor-Network-Theory. Oxford: Oxford University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Lawrence, D.H. 1993. The Complete Poems. Ed. Vivian de Sola Pinto. Harmondsworth: Penguin. Lawrence, D.H. 2002. The Fox, The Captains Doll, The Ladybird: Volume 2 of the Cambridge Edition of the Works of D.H. Lawrence. Ed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Dieter Mehl. Cambridge:  LeDoux, Joseph. 2002. Synaptic Self: How our Brains Become Who We Are. New York: Viking: 2002. Lenneberg, Hans. 1958. ‘Johann Mattheson on Affect and Rhetoric in Music (I).’ Journal of Music Theory 2.1: 47-84.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Levinas, Emmanuel. 1979. Totality and Infinity. Trans Alphonso Lingis. The Hague: Martinus Nijhoff. Levitt, Steven D. and Dubner, Stephen J. 2005. Freakanomics: A Rogue Economist Explores the Hidden Side of Everything.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Harper Collins. Ligotti, Thomas.2010. The Conspiracy Against the Human Race: A Contrivance of Horror. New York: Hippocampus Press. Lovelock, James. 1979. Gaia: A New Look at Life on Earth. Oxford: Oxford University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Lyotard, Jean-Francois. 1994. Lessons on the Analytic of the Sublime. Trans. Elizabeth Rottenberg. Standford: Stanford University Press. Macpherson, C. B. 1962.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Political Theory of Possessive Individualism: Hobbes to Locke. Oxford: Clarendon Press. 1962. Mann, Michael. 2009. ‘Defining Dangerous Anthropogenic Interference.’ PNAS 106.11: 4065-4066. Massumi, Brian. 1995.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  ‘The Autonomy of Affect,’ Cultural Critique 31, The Politics of Systems and Environments, Part II: 83-109. Maturana, Humberto R. and Francisco J. Varela 1980. Autopoiesis and Cognition: The Realization of the Living. Dordrecht: Reidel. Maturana, Humberto R. and Francisco J. Varela. 1987. The Tree of Knowledge: The Biological Roots of Human Understanding. Boston: New Science Library.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  McCarthy, Cormac. 2006. The Road. New York: Alfred A. Knopf. Meillassoux, Quentin. 2008. After Finitude: An Essay on the Necessity of Contingency. London: Continuum.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Mignolo, Walter D. 2000. ‘The Many Faces of Cosmo-polis: Border Thinking and Critical Cosmopolitanism,’ Public Culture 12.3: 721-748. Miller, Richard. 2010. Globalizing Justice: The Ethics of Poverty and Power. Oxford: Oxford University Press. Mithen, Steven. 2006.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Singing Neanderthals: The Origins of Music, Language, Mind, and Body. Cambridge: Harvard University Press. Montag, Warren. 2009. ‘Imitating the Affects of Beasts: Interest and Inhumanity in Spinoza.’ differences 20.2-3: 54-72. Morton, Timothy. 2007. Ecology without nature: rethinking environmental aesthetics.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Cambridge, MA. : Harvard University Press. Morton, Timothy. 2010. The Ecological Thought. Harvard University Press. Naas, Michael. 2008.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Derrida From Now On. New York: Fordham University Press. Nancy, Jean-Luc. 2010. ‘Let Them Speak Java? Jean-Luc Nancy in Defense of the Arts and Humanities.’ http:\/\/defendartsandhums.blogspot.com\/2010\/12\/let-themspeak-java-jean-luc-nancy-in.html Negri, Antonio. 2008. Empire and Beyond.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. E. Emery. Cambridge: Polity. Negri, Antonio, Michael Hardt and Danilo Zolo. 2008. Reflections on Empire. Cambridge: Polity. Nietzsche, Friedrich Wilhelm.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1968. Twilight of the Idols; and the Anti-Christ. Trans. R. J. Hollingdale. Harmondsworth: Penguin Books. Nietzsche, Friedrich. 2000. The Birth of Tragedy.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. Douglas Smith. Oxford: Oxford University Press. Nietzsche, Friedrich. 2007. On the Genealogy of Morality. Ed. Keith Ansell-Pearson.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Trans. Carol Diethe. Cambridge: Cambridge University Press. Overtveldt, Johan van. 2007. The Chicago School: How the University of Chicago Assembled the Thinkers Who Revolutionized Economics and Business. Agate Publishing. Petito, J., Varela, F.J., Pachoud, B. and Roy, J-M. 1999.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Naturalizing Phenomenology: Issues in Contemporary Phenomenology and Cognitive Science. Stanford, CA: Stanford University Press. Pound, Ezra. 2002. The Cantos. London: Faber and Faber. Protevi, John. 2009.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Political Affect: Connecting the Social and the Somatic. Minneapolis: University of Minnesota Press. Rancière, Jacques. 2009. The Future of the Image. Trans. Gregory Elliott. London: Verso.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Sartre, Jean-Paul. 1957. The Transcendence of the Ego: An Existentialist Theory of Consciousness. Trans. Forrest Williams and Robert Kirkpatrick. New York: Noonday Press. Serres, Michel. 2008.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Le Mal Propre: Polluer Pour S’Approprier. Paris: Le Pommier. Serres, Michel. 1995. The Natural Contract. Trans. Elizabeth MacArthur and William Paulson. Ann Arbor: University of Michigan Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Serres, Michel. 2006. ‘Revisiting The Natural Contract’ http:\/\/www.ctheory.net\/ articles.aspx?id=515. Serres, Michel. 2007. The Parasite. Trans. Lawrence R. Schehr.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Minneapolis: University of Minnesota Press. Shelley, Mary Wollstonecraft . 2000. Frankenstein. Ed. Johanna M. Smith. London: Palgrave Macmillan. Singer, Peter.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  1972. ‘Famine, Affluence and Morality. Philosophy and Public Affairs. 1.1: 229-243. Singer, Peter. 2009. The Life You Can Save. New York: Random House.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Smith, Adam. 1976. An Inquiry into the Nature and Causes of the Wealth of Nations. Ed. Edwin Cannan. Pref. George J. Stigler. Chicago: University of Chicago Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Stengers, Isabelle. 2000. The Invention of Modern Science. Trans. D. Smith. Minneapolis, MN: University of Minnesota Press. Stengers, Isabelle. 2011.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Thinking with Whitehead: A Free and Wild Creation of Concepts. Cambridge, MA: Harvard University Press. Stiegler, Bernard. 2010. For a New Critique of Political Economy. Trans. Daniel Ross. Cambridge: Polity.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Stiegler, Bernard. 2010. Taking Care of Youth and the Generations. Trans. Stephen Barker. Stanford: Stanford University Press. Stiegler, Bernard. 2009.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Technics and Time: Disorientation. Trans. Stephen Barker. Stanford: Stanford University Press. Susan Wolf. 2010. Meaning in Life and Why It Matters. Princeton: Princeton University Press.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Thompson, Evan. 2007. Mind in Life: Biology, Phenomenology, and the Sciences of Mind. Cambridge, MA: Belknap Press of Harvard University Press. Varela, Francisco J., Evan Thompson and Eleanor Rosch. 1991. The Embodied Mind: Cognitive Science and Human Experience. Cambridge, MA.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  : MIT Press. Welsh, Irvine. 2002. Trainspotting. London: Norton. Wheeler, Michael. 2005. Reconstructing the Cognitive World: The Next Step.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Cambridge: MIT Press. Wilson, Elizabeth, A. 1998. Neural Geographies: Feminism and the Microstructure of Cognition. New York: Routledge. Winterson, Jeanette. 1993. Written on the Body.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Knopf. Wolf, Maryanne.2007. Proust and the Squid: The Story and Science of the Reading Brain. New York: HarperCollins. Wolfe, Cary. 1995. ‘In Search of Posthumanist Theory: The Second-Order Cybernetics of Maturana and Varela.’ Cultural Critique 30.1: 33-70. Woolf, Virginia.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  2007. Selected Works of Virginia Woolf. London: Wordsworth. Wordsworth, William. 1991. The Prelude. Ed. Stephen Gill.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Cambridge:Cambridge University Press. Worringer, Wilhelm. 1953. Abstraction and Empathy. New York: International Universities Press. Wrathall, Mark A. and Jeff Malpas. Eds. 2000.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Heidegger, Coping, and Cognitive science. Cambridge, MA: MIT Press. Wright, Elizabeth. 1984. Psychoanalytic Criticism: Theory in Practice. London: Methuen. Wright, Robert. 2010.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  The Evolution of God: The Origins of Our Beliefs. New York: Little, Brown Book Group. Yeats, W.B. 2011. Selected Poems and Four Plays. Ed. M.I. Rosenthal.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  New York: Simon and Schuster. Ziarek, Eva. 2010. ‘Feminine ‘I Can’: On Possibility and Praxis in Agamben’s Work.’ Theory and Event 13.1 2010. n.pag. Žižek, Slavoj. 1998. ‘A Leftist Plea for ‘Eurocentrism’’ Critical Inquiry. 24.4: 998-1009.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  Zunshine, Lisa. 2006. Why we Read Fiction: Theory of Mind and the Novel. Ohio State University Press. Permissions Earlier versions of some chapters appeared in the following publications. ‘Extinct Theory’ in Theory After Theory, ed. Jane Elliott and Derek Attridge (Routledge, 2011) ‘The Sustainability of Concepts' in Sustainable Design, ed. Adrian Parr and Michael Zaretsky (Routledge, 2010).\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  'A Globe of One’s Own: In Praise of the Flat Earth' as ‘A Globe of One’s Own,’ SubStance 41. 1 (2012). ‘Destroying Cosmopolitanism for the Sake of the Cosmos,’ in After Cosmopolitanism, ed. Rosi Braidotti, Patrick Hanafin and Bolette Blaagaard (Routledge 2102); ‘Time and Autopoiesis,’ in Deleuze and the Body, ed. Joseph Hughes and Laura Guillaume (Edinburgh University Press, 2011), ‘Face Race,’ in Deleuze and Race, ed. Arun Saldhana and Jason Michael Adams (Edinburgh University Press, 2013). ‘Post-Human Humanities,’ in Time and History in Deleuze and Serres, ed. Bernd Herzogenrath (Continuum, 2012); ‘Why Saying “NO” to Life is Unacceptable,’ in The Unacceptable, ed.\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":"  John Potts and John Scannell (Palgrave 2013). ‘The Joys of Atavism,’ in Understanding Bergson, Understanding Modernism,  legacy of what had come to be known as ‘theory,’ and its contemporary supposedly posthuman aftermath. There can be no redemptive posthuman future in which the myopia and anthropocentrism of the species finds an exit and manages to emerge with ecology and life. At the same time, what has come to be known as the human—despite its normative intensity—can provide neither foundation nor critical lever in the Anthropocene epoch. Death of the PostHuman argues for a twenty-first century deconstruction of ecological and seemingly posthuman futures. Claire Colebrook is Edwin Erle Sparks Professor of English at Penn State University. She has written many articles and books on visual culture, poetry, literary theory, queer theory and contemporary culture, including most recently Theory and the Disappearing Future with Tom Cohen and J. Hillis Miller (2011). Cover Image: “Shriek & Flash” (detail) Dominic Minichiello © Creative Commons CC-BY-NC-SA Oil on board, 2009\n"}
{"prompt":"Death of the PostHuman Essays on Extinction ->","completion":" \n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  By deleuze, Sylvia Wynter, COVID-19, recursivity, colonial capital  Apocalypse & Universal Epistemology The apocalypse now occurring around the world is a continuation of yet another iteration of recursive colonialism.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  Apocalypse is about the end of the world. It is the liminal space warded off by the self-determining subject of Western history. Invoking the threat of uncertainty that can never become real, the end of the world is feared but never allowed. Instead, violent acts of pre-emption perpetuate the threat of an apocalypse that is constantly denied. The more the fear becomes real, the more violent reactions spread everywhere. The apocalyptic scenarios have been actualized in the planetary pandemic of  techno-scientific progress a universal model of civilization rooted in the mathematics of divide-and-conquer, where space becomes subsumed by the nexus of whiteness, patriarchy, and capitalist logics, which constantly anticipate the end by constantly reproducing its unconditional violence. Then this space moves from a disciplinary modification of the flesh (i.e., a constant self-checking; a discourse on risk and resilience) to strategies of control acting to fully preclude the future through the socio-techniques of prediction and its emergentist actions. As theorized throughout the literature, the constitution of whiteness necessitates the fabrication of Blackness; masculinity necessitates the creation of femininity; heterosexuality needs the construction of homosexuality; and ability will not exist without the formation of disability.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  While the double-edged sword of capital oscillates between these polarities and keeps the apocalypse as the placeholder of the full selfannihilation of the Western subject, on the other hand, in Octavia Butler’s The Parable of the Sower and Xenogenesis we see that “the end of the world as we know it” has already happened and the possibility to keep on living on this planet includes a becoming-alien and the abolition of all forms of enslavement to allow the thought, the image of trans-collective “difference without separability.”  The recursivity of colonialism is materially and discursively shaping the apocalypse, as illustrated in Chinua Achebe’s classic colonial studies fictional work Things Fall Apart, which was a response to Joseph Conrad’s Heart of Darkness, where the dread of the unknown at the core of humanity coincides with Blackness—and returns yet again to depict madness as a symptom of post-war American empire shocked by the alien war machine of Vietnam in Francis Ford Coppola’s movie Apocalypse Now. Each of these works portrays different variations of the colonial matrix of divide-and-conquer, re-constituting its  regeneration of the interiority of a system. The monologic universalism in the epistemic response to the emergence of contingency creates the apocalyptic scenario where the end of capital is also the end of the human and of freedom. If, as Mark Fisher reminds us, the end of the world is easier to imagine than the end of capitalism, the state of emergency of the pandemic reminds humans that they cannot let colonial capital die. Indeed, like COVID-19, the colonial is aerial and it’s aerosolized: it takes on the very chance of breathing. The pandemic has intensified Western methods of enslavement and technology, even enslavement as technology and the technological displacement of the enslaved subject, toward the protecting and maintaining of capital accumulation. The reparative pattern of enslavement and the epistemological ground of enslavement are one and the same: accumulation strategies of capital. Recursive technologies are modes and systems of thinking, a technological episteme that enables the changing same of universal epistemology.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  The planetary world of automated incarceration (i.e., a total dependence on technosocial systems) has arrived as the only response to the pandemic, instituting apocalyptic scenarios through the recursivity of colonial epistemology. What could not have been anticipated is how the pandemic would actualize the apocalypse globally and unleash the imperceptible pressures of, according to Gilles Deleuze’s characterization of control, a process of becoming. The recursivity of self-modulation coincides with the microdiffusion of policing, the transparency of which directs the behavior of the users across technosocial systems. But the pandemic is also a technopolitical acceleration of the destruction of white institutions. In concert with multiple other forces—including neoliberalism, patriarchy, and anti-Black violence—the pandemic arrival of the planetary apocalypse has met the repetitive brutality  be described as one of the steps or functions within a procedure calling back the procedure. Recursion is conceptualized in computational systems (e.g., the Turing Machine and artificial neural networks), in biological and cognitive systems (Maturana and Varela), and ecological and cultural systems (Gregory Bateson). The process of the past becoming reconfigured in the present, a mythopoetics that shapes the collective cultural ways of knowing, is what Bateson called a “recursive epistemology.” For Bateson, recursion or continuous looping is a departure from the linear progress of modernity and the Cartesian subject. Bateson’s conceptualization of recursive epistemology, especially his explanations of the influence of mythopoetics, was taken up by Sylvia Wynter in her articulation of the autopoetic turn\/overturn.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  For Wynter, the flesh inherits Western histories of Man that enter the constitution of new assemblages in a system of sociopolitical relations. An idea first named by Franz Fanon, the sociogenic principle is a concept that Wynter further developed as a way to account for how the sociopolitical becomes flesh. For Wynter, the sociogenic principle is an ontological account of how the sociopolitical assemblages of Man and the logic of symbolic “difference” become programmed in the body through the ontogenic formation of identity that brands the flesh. This sociopolitical assemblage of Man, what Wynter also calls Western Man, entails a process of auto-determinations based on the cosmogonies of human origin. She argues that the current iteration of cosmogony corresponds to a biohumanist homo oeconomicus, as informed by the economic theories of Adam Smith. Here the correlation between biological and economic survival, through the forces of selection and optimization of survival, defines the epistemological explanation of who is and who is not successful as a species. It is this correlation that consolidates the  more-than-human ontologies including the sociotechnical assemblages of data and algorithms. The sociogenic coding of the other as the negative marker, it is argued, is necessary to the recursive loops of the colonial enterprise, whereby the naturalization of the dyadic structure of equivalence between Man and the world ensures that all remains the same under the Western sun.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  However, a dynamic view of computation suggests that temporal processing in artificial intelligence systems can radically challenge the reproduction of the sociogenic principle in technosocial systems. According to Yuk Hui, Gilbert Simondon refuses Descartes’s rationalism by demonstrating that the cybernetic principle of feedback adds a new temporal structure to thinking that is described in terms of a spiral. As Hui further explains, according to Simondon, cybernetics replaces the telos of thought with a self-regulatory process. In particular, insofar as the recursivity of feedback makes the cybernetic system possible, it also impedes the system to become systematic, complete, and a reproductive whole. However, since human relations are abstracted and re-integrated into the temporality of machines, which constitute the engine of artificial intelligence, the question of temporality—and thus of recursive temporality in nonorganic machines—still needs to be further explored. For Hui, margins of indeterminacy not only describe the recursive temporalities of machines, but more importantly also describe a recursive thinking in machines. This argument suggests that the technical machine is not simply a mirror of the normative apparatus of knowledge reproduction. Computation instead can include both contingency and chance within itself because the temporality of the technical object or cybernetic machines precisely admits that errors, incident, and failure are part of the causal process of system’s learning.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  incorporated by the same self-determining subject without change. The horizon of the apocalypse is incomplete because it always needs the Other, in word and matter, to exist. The horizon is a parasite: fundamentally capital can do nothing without the subjection of the Other. There have been many apocalypses. Each of which enfolds within itself the incompleteness of the system in order to restore the unifying interiority of the human. Every time there is an apocalypse there is an expansion of enslavement, and each iteration brings an even more intensified form of enslavement. Apocalypse, in other words, is the sign of the limit and incompleteness of recursive knowledge, of science, technology, and governance. Cosmo-Computations Since recursivity exposes the incompleteness of self-regulating systems adapting to contingencies, it also discloses the incompleteness of the modern epistemological order of truth founded on the universal model of technology.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  It is in the name of the axiomatics of modern science that technology became the measure of progress against which the global world became measured. The self-posited universality of Western technology resides in the epistemologies of racial capitalism founded on principles of causal efficiency where knowledge becomes equivalent to automated tasks that carry out other tasks in a mindless chain of effects. Echoing Cedric Robison, Lisa Lowe argues that “the organization,expansion, and ideology of capitalist society was expressed through race, racial subjection, and racial differences.” Similarly, the global order of racial capitalism was  towards the account of epistemologies that transform (and have radically transformed) the standardization of knowledge as carried out by technologies, digital media, computation, algorithms, data. But how to do so, without following the claims of the ontological turn against universal epistemologies (such as Stacy Alaimo, Rosi Braidotti, Karen Barad, Jane Bennett, Elizabeth Grosz, and Vicky Kirby among others)? If the “ontological turn” argues against the Western opposition between nature and culture, it is because the suppression of different philosophies of nature and thus of ontologies, such as for instance the culture of animism, also involves the debunking of the universal model of technology. However, instead of accounting for a time before modernity, before racial capitalism in order to uncover different epistemologies of different cultures, how to engage with the question of technology as involving a techno-colonialism without eliminating difference? However, it seems that arguments about the incompleteness of recursive epistemology cannot be exhausted by the proposition of and for techno-diversity, whereby minor knowledges and representations are granted a particular access to (and under) the universal system of knowledge. In contrast to a multicultural techno-diversity that demands nonWestern techno-cultures conform to the Promethean metaphysics of progress, Yuk Hui’s theorization of cosmotechnics, we claim, offers instead a radical insight into how to turn the incompleteness of systems into multi-logical and transversal epistemologies.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  According to Yuk Hui, technodiversity does not describe how different technocultures follow the same techno-epistemology. Instead, it must account for a multiplicity of “cosmotechnics that differ from each other in terms of values, epistemologies, and forms of existence.” But what exactly is cosmotechnics? In contrast to the Kantian thesis of technology as anthropologically universal, in Hui’s view technology “is enabled and constrained by  When addressing these questions, however, we should be cautious not to neglect the way that the cognitive paradigms of colonial epistemology have changed through and with machine intelligence. Similarly, it is crucial to consider whether computation could already transform the axiomatics of racial capital and challenge the continuous surrogacy of humanity. Computational logic has shown how the self-determining subject is constituted by and throughout the enslaving of matter within the equation of value that incorporates the n-1 dimensions of Blackness, sexes, and desires. The tension between recursive colonialism and the artificial intelligence systems of today therefore demands that the universal epistemology of computation is radically defied by multiple cosmo-computations for which the continuous chain of algorithmic efficiency is, each and every time, overwritten by the indeterminate conditions of computation that allow for systems to become more than one. Instead of a universal master algorithm that surveils all through the constant addition of axioms by axioms and continuous updating of the system, the so-called age of planetary automation must be submerged by the plethora of trans-infinite axioms that account for trans-infinite worlds that inundate the system, deliver the system to its incompleteness, and make the system become more than one. For cosmo-computational epistemologies entail not only a limitless opening to different techno-cultural forms, but the transformation of the condition of computation such that the universal cannot slip back in as the mediator of particularities.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  Computation Without Separability  universal technology is said to be a mere extension of Western metaphysics, the call for multiple cosmo-computations instead follows Hui’s reflection upon multiple metaphysical spaces (spaces of indeterminacies or unknowns) that are culturally mediated through and with technics. From this standpoint, computation is at the center of a planetary negotiation with unknowns, which are represented under the rules of computational recursivity as the latter extends the strategies of preservation of the self-determining subject. Recursivity in computation is a computer programming technique of divide-and-conquer in order to solve problems by breaking down generalities into particularities. This colonialist language and logic in computation is not random nor by happenstance. To echo Lisa Lowe’s analysis of the colonial empire: recursivity was already part of the computational metaphysics of racial capital. Drawing on Cedric Robinson’s articulation of racial capital, Lowe reminds us that “racial capitalism suggests that capitalism expands not through rendering all labor, resources, and markets across the world identical, but by precisely seizing upon colonial divisions, identifying particular regions for production and others for neglect, certain populations for exploitation and still others for disposal” (149). In order to overturn the metaphysical recursivity of racial capital in and through computational recursivity, it seems necessary to argue that computation as the contemporary universal techno-system must be radically transformed first in itself so that it can become open to non-Western cosmologies. For instance, a heretic study of the post-Turing paradigm can contribute to a radical transformation of the matrix of computational logic by turning the axiomatic protocols of the included\/excluded through which the system constantly updates into a speculative computation of “differences without separation.” With the post-Turing paradigm, the irresolvability of the halting problem opened up a field of possibilities for computation to  systems.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  Within the framework of recursive axiomatics, incomputables demarcate the constant limit of the operations of dividing and conquering; a limit that must be replaced with another adaptable axiom that secures the operations of inclusion\/exclusion. Thus, speculative computation breaks with recursivity. The interaction between data sets, contexts, and algorithmic rules entails not a recursive learning, but a trans-ductive learning. This entails namely a transformation of the conditions of interaction across systems that stems from the indeterminacies at each level of the interaction. It is possible therefore to re-elaborate the limits of knowledge from the standpoint of what cannot be measured. This is a computational fabulation entailing a cross-interaction (or asymmetric and not mutual) relation between hypothesis and indeterminacy. As much as a hypothesis coincides with a logic of unknowns, so too indeterminacy defines the condition for this logic. We suggest that the contemporary articulations of cosmo-computations not only refuse the universality of the Turing machine, but also the recursive logic of divide-and-conquer, sequentiality, and determinacy.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  While addressing the reactions about the influx of refugees entering the Mediterranean to access Europe, Denise Ferreira da Silva talks about a “racial grammar” of modernity based on the rules of “separability, determinacy, and sequentiality” that have supported the epistemological program of modern philosophy. In addition, Da Silva asks us to reflect on the way that the content of modern epistemologies in explaining differences has shifted from physical forms to mental, moral, and intellectual differences, as, for instance, in the work of cultural anthropology. This shift from the biological to the cultural explanation of  separability”. The latter considers the social whole as constituted by separate parts that enfold different conceptions of humanity measured in relation to the universal standard of “white European collectives.”  Da Silva proposes to invert the pillars of modern epistemology from within the scientific explanations that defy the concepts of separability, sequentiality, and determinacy. In particular, she takes the principle of non-locality in quantum physics to argue that the epistemological explanation of difference can be defined in the fundamental terms of an “elementary entanglement” for which difference coincides with “singular expressions of each and every other existant as well as of the entangled whole in as which they exist….”  From this standpoint, we suggest that what could be called “quantum-technics” is yet another contribution to the current efforts to rethink how the incompleteness of systems becomes central to the articulation of cosmo-technical onto-epistemologies that are needed to defy the recursive re-ordering of universal technology. In particular, with cosmocomputation we ask, how can technological universality be refused and transformed through practices of difference with inseparability? We know that the computational techno-mentalities based on recursivity have already been counter-articulated by many attempts to argue for incomputability and indeterminacy as the conditions of computational processing, where spatio-temporal interactions step beyond the pillars of sequentiality, dividing, conquering, and determinacy. Recent efforts to challenge these pillars can be found in ludic logic that explains the computational search for proof in terms of interaction between the syntax and semantic dimensions of learning  admit not one changing system for all, but mainly a praxis and poetics of knowledging together, as humans and more-than-humans perform different actions inseparably because the computational correspondence between syntax and semantics can run in more than one direction and admit more than one elaboration of meaning.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  Coda on Post-Apocalyptic Abolitionism Our inquiry into recursive colonialism breaks from the metaphysics of the apocalypse because it shows that the foregrounding of incompleteness at the core of the colonial system of knowledge has broken open the immunity of the self-determining program of Man. As much as this technology extends the universal pillars of knowledge based on dividing, conquering, determination, separation, and iteration, it also exposes the system to its constitutive indeterminations because no whole can contain all of its parts, and no law of equivalence can account for what remains incalculable. Our inquiry starts in post-apocalyptic times, because it argues that this has been our everyday condition since modernity, when the war machine of colonial empires everywhere activated violent strategies of preemption against abolition, total war on difference in order to stop the full abolition of White Man and its white magic machine. In particular, the longterm process of abolition has started with the refusal of the recursive forms of colonial epistemologies that maintain raciality in the symbols, institutions, and codes of white supremacy. From praxis of refusal to the poetics of fugitivity, the critical work of abolition has hit the core of the logic of computation. The concretization of mathematical formalism  extending the universal response of total incarceration for everybody (e.g., selfquarantining). However, the regime of incarceration has a long history reflected in the perpetuation of racial violence and is not equivalent to the enforcing code of stay-at-home resulting from the planetary governance response to the COVID-19 pandemics. Indeed, this concentrated condition of incarceration has exacerbated the intolerable demand of being resilient and accept the continuous gratuitous violence against black people.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  But the refusal to re-become pre-incorporated into the recursive epistemologies of the empires has this time taken on a life of its own, searching for alliances beyond identity, demanding a reorigination of thinking, learning, knowing, and living beyond the programs that ensure accessibility, diversity, and delegated representation. The refusal to be under the recursive program of technological universalism, however, also requires that computation as we know it must change. The indeterminate dimension of interactive rules points to the possibility of re-articulating computational logic away from one universal language insofar as in ludic logic (Girard, Girard, Jean-Yves (2001) Locus Solum: From the Rules of Logic to the Logic of Rules. Mathematical Structures in Computer Science 11(3): 301-506) for instance the syntactical links between places are not static points but are assemblages of actions that elaborate meanings in an immanent fashion. As these action\/algorithms without programming prevent form from shaping matter, they also open computation to a multi-vocality of logics, to the plethora of parallel cosmo-computations, where there is no pre-modern past because all of the past is in front of us demanding to be debugged from the virus of fear, the fear of change that sustains recursive colonialism’s illusion that the apocalypse has yet to come. Cover image: Jean-David Nkot, PO.BOX.Ghost of space@gmail.co; 2019; Indian ink,  Ezekiel Dixon-Román is an associate professor in the School of Social Policy Practice at the University of Pennsylvania. His interdisciplinary scholarship is focused on the cultural studies of quantification and critical theories of difference. He is the author of Inheriting Possibility: Social Reproduction & Quantification in Education (2017) and is currently working on a book project that examines the haunting formations of the transparent subject in algorithmic governance and the potential transformative technopolitical ontoepistemologies.\n"}
{"prompt":"Recursive Colonialism and Cosmo-Computation – Social Text ->","completion":"  © Social Text Collective About Book Series Permissions RSS  2022\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  ORIGINAL ARTICLE  Can a machine think (anything new)?\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Automation beyond simulation M. Beatrice Fazi1 Received: 18 January 2017 \/ Accepted: 24 January 2018 \/ Published online: 12 February 2018 © The Author(s) 2018. This article is an open access publication  Abstract This article will rework the classical question ‘Can a machine think?’ into a more specific problem: ‘Can a machine think anything new?’ It will consider traditional computational tasks such as prediction and decision-making, so as to investigate whether the instrumentality of these operations can be understood in terms of the creation of novel thought. By addressing philosophical and technoscientific attempts to mechanise thought on the one hand (e.g. Leibniz’s mathesis universalis and Turing’s algorithmic method of computation), and the philosophical and cultural critique of these attempts on the other, I will argue that computation’s epistemic productions should be assessed vis-à-vis the logico-mathematical specificity of formal axiomatic systems. Such an assessment requires us to conceive automated modes of thought in such a way as to supersede the hope that machines might replicate human cognitive faculties, and to thereby acknowledge a form of onto-epistemological autonomy in automated ‘thinking’ processes. This involves moving beyond the view that machines might merely simulate humans. Machine thought should be seen as dramatically alien to human thought, and to the dimension of lived experience upon which the latter is predicated. Having stepped outside the simulative paradigm, the question ‘Can a machine think anything new?’ can then be reformulated.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  One should ask whether novel behaviour in computing might come not from the breaking of mechanical rules, but from following them: from doing what computers do already, and not what we might think they should be doing if we wanted them to imitate us. Keywords Automation · Simulation · Turing · Leibniz · Computation · Thought  1 \u0007An imitation game? Can a machine think? Famously, Alan Turing believed this to be a bad question. He argued that it was ambiguous, and that it should be replaced with a test: an “imitation game” (Turing 1950, 433) that would bypass what he considered to be a dangerous haggling over definitions of the terms ‘machines’ and ‘thinking’, and which would instead link the issue of the intelligence of computing machinery to that  of novelty in computation can afford a move away from what I will refer to as a simulative paradigm.2 Asking whether a 1  “I propose to consider the question, ‘Can machines think?’ This should begin with definitions of the meaning of the terms ‘machine’ and ‘think’. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words ‘machine’ and ‘think’ are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, ‘Can  machine can think anything new will then be a way for me to engage with issues pertaining to the possibility that computational processing might engender autonomous modes of automated epistemic production. In this sense, the question of novel thought in computation becomes a vehicle to tackle philosophical issues concerning what I will refer to here as the onto-epistemological autonomy of computational automation.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  I hope to show, therefore, that the question ‘Can a machine think anything new?’ can be a useful alternative to Turing’s ‘Can a machine think?’: for where Turing’s question led to an imitation game, and thereby to popular understandings of machine thought as simulative of human thought, the issue of novelty in computation helps to highlight precisely the opposite, i.e. the difference between machine thought and human thought. The novelty at stake here is, simply put, that of a new kind of thinking. The history of computing is characterised by a certain degree of enthusiasm regarding the prospect of computing machines being able to produce forms of thought. This was true in the 1950s, when Turing asked whether machines can think, and it is true today, when computing is not just something that happens in university labs, but is instead a condition that few worldly activities can evade altogether. Yet, in addition to the persistent dream of a thinking machine, the suspicion that computational cognitive or intellectual capacities can, at best, merely imitate human ones has also endured from the mid-twentieth century up to the present time. Again, when it comes to the question of machine thought, simulation still seems to be our safest bet. If, from the 1950s to today, society and culture have often imagined the arrival of technologies that can think like humans do (and which, consequently, might also one day want what humans want), then the fact that these technical agents might not really be thinking as we are, but may only be fooling us into believing that they do, has often helped to ease persistent technocultural anxieties about the “rise of the robots” (Ford 2015), as well as to deflate technoscientific prospects of a “second machine age” (Brynjolfsson and McAfee 2014) in which machines substitute rather than complement humans.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  The imitation of intelligent behaviour was the success  of his imitation game, Turing discussed the circumstances under which one might determine that a digital computer can think, and whilst it is also true that he did not explicitly claim that all human thinking is computation (see Harnish 2002, 184), it is nonetheless the case that the imitation game opened up a comparative link between human cognition and mechanical calculation. In effect, Turing asked whether the algorithmic procedures of discrete-state machines are in principle capable of producing a sufficiently convincing display of cognitive behaviour.4 The first AI initiatives that came after Turing’s enquiry took on this implicit link and made it explicit, vis-à-vis the development of computationalist theories of the mind in what was then the newly emerging discipline of cognitive science. In my view, technocultural and technoscientific retreats into simulation should be read in parallel with these computationalist attempts to mechanise the mind, but also in parallel with the twentieth-century development of the ancient dream of finding and automating the rules of thinking. Philosophical criticisms of these attempts and of this dream should in turn be read vis-à-vis the belief that the automated cognitive activities of machines are just reductions or simplifications of the thinking that originates from lived experience. This belief, however, is still based on the simulative paradigm. In other words, it is grounded on the  Footnote 3 (continued) sion of Turing’s 1950 imitation game) would be passed in less than a generation was widely shared amongst the AI pioneers who attended the event. So too was the conviction that “every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it” (McCarthy et al. 2006, 12).\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  At present, however, and more than sixty years after the Dartmouth College conference, the Turing test has still not been passed. Moreover, it should also be added that passing the Turing test is not the most prominent effort of current research in AI. Focusing too strictly on the human performance of intelligent behaviour is considered to be distracting and restricting, and the imitation game is seen as an “elusive standard” (Moor 2003) for AI research. Whilst it is necessary to acknowledge this condition in order to give a correct depiction of AI research, the fact that the imitation game is not  assumption that, at best, smart machines can only be said to simulate human thought, or to simulate the onto-epistemological conditions upon which human thought is predicated. My aim here is to show that, by taking some distance from the simulative paradigm, it is possible to challenge the all-enframing cognitivism inherent in the hope, and the effort, of automating thought. However, rather than discarding computational automation and its potential for thinking altogether, I also intend to demonstrate that it may be possible to open an autonomous onto-epistemological prospect for automated machine thought by freeing the latter from the expectation that automation is just an attempt at simulation, whether of human cognition, or of life and lived experience. 2 \u0007Calculative activities The issue of novel thought in computation can be articulated in many ways. An obvious and important field of reference for this problem is the area of study that goes by the name of ‘computational creativity’.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Efforts in the field see the contributions made by artificial intelligence, cognitive science, psychology, philosophy and the arts towards exploring the possibility of artificially modelling and replicating creative behaviour using the mechanical means of computation. This heterogeneous field is relatively young, but it has already achieved some surprising results.5 As often happens in AI research, this kind of experimentation has a mutual benefit: by trying to replicate human cognitive function in machines, it becomes possible to understand better what that function in the human is in the first place. So, by creating models of the multifaceted and protean qualities of human creativity, light is shed on the origin and the development of creative behaviour, regardless of whether that behaviour is natural or artificial. It would be unfair to characterise computational creativity as being uniquely concerned with simulating human creativity in machines. As a matter of fact, the field considers the nature of creativity and of creativity involving computational activity at large.6 At the same time, however, it should be  noted that debates in this area of research tend to praise capacities such as insight, inspiration, intuition, ingenuity, interest, improvisation, interpretation or even intelligence itself, all of which are valued features of the creative human mind. In this respect, I would then say that, by addressing novel thought in computation through the parameters of computational creativity, or even creativity in general, there is a risk of retaining simulation as an implicit measure for success.7 Seen in these terms, machines would be deemed to be capable of generating novelty insofar as they are recognised as doing something that one would characterise as creative if humans were doing it. It could be said that this mode of enquiry pursues computing machines that might be less computer-like: machines that might surprise us by doing what machines may not be likely to do successfully, such as crafting a moving speech, improvising jazz, or composing a beautiful dance. I believe, therefore, that what tends to be searched for in these practices is a type of thought process and of computational processing that is less automatic and less mechanical.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  In other words, one that resists or circumvents the stubborn automatism of logical machines. I acknowledge the importance of this type of work, and I recognise that I am painting a picture of a varied area and community of research in broad brushstrokes. However, I must also clarify that my question about novel thought in computation is not based on the successes and failures of the field of computational creativity. I want to take a different route here to that which computational creativity might be seen to adopt, for I will not linger on the capacity of computers to surprise us, or to do what they are not supposed to do. On the contrary, I wish to consider machines that do exactly what they are supposed to do. I want to engage with the question: can computing machines be generative of novelty in ways that are profoundly alien to humans, because they are so inherently computational? In order to develop this question, one must address traditional automated computational tasks, such as, for instance, prediction and decision-making. Both prediction and decision-making can be understood as typically calculative  activities.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  As such, they are activities that can be effectively mechanised via algorithmic means. For instance, it is possible to argue that it was better predictions that allowed the IBM supercomputer Deep Blue to beat chess grandmaster Garry Kasparov in their historic match in 1997. Both players were trying to predict each other’s moves. They were both calculating the consequences of changing the positions of the pieces on the board, and considering what their adversary would do next. Deep Blue won through the sheer brute force of its heuristics: it was able to evaluate two hundred million positions per second. It won because it predicted better, and it predicted better because it calculated faster and on a grander scale than a stressed-out Kasparov, whose thoughts, legend has it, were clouded by paranoia and suspicion.8 Algorithmic decision-making also promises similarly successful outcomes, and just like prediction, decision-making is also calculative when it is carried out via computational means. Operational decisions, such as what trades to make, are calculatory staples of today’s financial markets. It is not by following gut feelings that the quantitative finance models of automated algorithmic trading answer the question ‘Should I buy this stock or not?’ Instead, what one finds there is the deterministic operation of buying and selling securities on the market automatically, according to some pre-programmed strategy.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  This is decision-making on steroids, executing millions of orders and scanning multiple markets in fractions of seconds.9 It is easy to call both the supercomputer Deep Blue and the high-frequency trading algorithms ‘smart’. Indeed, it is also tempting to call these machines “smarter than us”, since “once computers achieve something at human level, they typically achieve it at a much higher level soon thereafter” (Armstrong 2014, 43). One might find it more difficult, however, to associate their smartness, and their ability to outsmart us, with the production of a form of epistemic novelty. Both the predictions of the supercomputer Deep Blue and the decisions of high-frequency trading (HFT) algorithms 8  These events, and Kasparov’s feelings about them, are narrated in  exemplify what computers do best: given certain premises, and by following certain instructions, they achieve certain goals. Or, to put it in more anthropomorphic terms, this is a case of selecting possible actions in order to steer the future towards a desired outcome. Both examples, then, are instances of an operational type of smartness that goes by the name of instrumental rationality, and which is, as Max Weber described in his study of industrial rationalisation, “determined by expectations as to the behaviour of objects in the environment and of other human beings” (1978, 24). These expectations “are used as ‘conditions’ or ‘means’ for the attainment of the actor’s own rationally pursued and calculated ends” (ivi). Of course, the affinity between calculating machines and instrumentally rational action, which “accepts itself simply as a tool” (Horkheimer 2012, vii), has been noted before.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  I am not going to reiterate the long history of the critical analogy between them here.10 What I want to ask, rather, is whether this instrumentality can ever be understood in terms of the creation of novel thought. Arguably, instrumental reasoning is not inherently opposed to novelty. The instrumentality of reason is often exemplified, according to the Frankfurt School interpretation, by the cunning of Odysseus, who tied himself tightly to the mast of his ship in order to hear the beautiful song of the sirens whilst also avoiding the danger of steering the boat off its course (see Horkheimer and Adorno 1972). We know the myth, and what it means for us moderns who have been betrayed by (or, conversely, have betrayed) the Enlightenment, as Adorno and Horkheimer argued. However, there is nothing in this story that prevents us from believing that Odysseus’ cost effective and efficient expedient is not a clever, inventive, although still perverse, form of novel problem-solving. The possibility of novelty within instrumentality would thus seem to be accepted when the instrumental rational agent is a human one. Machine instrumentality is, however, different, and it is judged differently. The crux of this difference, I would claim, lies in the fundamental disparity between machines on the one hand, and life, the lived and the living on the other.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  In order to explain this central claim in my argument, it is  of which pertain to the possibility of mechanising thought, or in other words, to the prospect of making thinking procedural, inferential, and indeed both automatic and automated. 3 \u0007The automation of thought: Leibniz and Turing A good starting point from which to address the expectations that have been invested (philosophically, scientifically and culturally) in the automation of thought can be offered by looking at the long-standing dream of mathesis universalis. Despite the erudition implied by the Greek-Latin origin of the expression, the actual meaning of mathesis universalis is not straightforward. For the sake of brevity, let us say that its most direct definition is that of a universal mathematical science. Aspirations towards such a universal mathematical science have been inherited from the ancient world, and became popular amongst the early modern philosophers of the sixteenth and seventeenth centuries.11 Notably, they were also shared by Descartes, who described mathesis universalis as “a general science which explains all the points that can be raised concerning order and measure irrespective of the subject matter” (Descartes 1985, 19). It is, however, the Baroque polymath par excellence, Leibniz, whom I wish to address here, for Leibniz’s philosophy will allow me to establish a conceptual link between mathesis universalis, the automation of thought and computing machines. Establishing this link is, in turn, important for the overall development of my argument about novelty qua the onto-epistemological autonomy of algorithmic automation. In this section, I will thus read Leibniz’s philosophical attempt to mechanise thought in parallel with Turing’s technical endeavour to show how thinking is already mechanical.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  I will do so in order to sketch a brief genealogy of the computationalist goal of mechanising the mind. As I have claimed above, this goal can be read in parallel with technoscientific concerns about simulation. By showing how they represent an enduring dream (and an equally enduring worry) in technoculture, I can slowly introduce my argument that questions about the  mathematical science than a generalisation of the rules of thought itself. The project of mathesis universalis, in other words, becomes the project of a universal science of reasoning, which is in turn to be supported by the construction of what Leibniz called a characteristica universalis. This characteristica universalis is an abstract symbolism that, according to Leibniz’s invention, would have unambiguously represented all that can be thought and expressed (see Leibniz 1989). Such a universal character, which in effect amounted to a universal conceptual language, was in turn to be supported by the calculus ratiocinator: a purely rational and ideal grammar that, for Leibniz, would have worked as a proper inference engine. Regrettably, Leibniz never described his project for a mathesis universalis in detail. His attempt can nonetheless be summarised in three steps: (1) to create a compendium of all human knowledge; (2) to select appropriate symbols to express this compendium; (3) to reduce rules of deduction to these symbols.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  By doing so, Leibniz aimed to demonstrate that it is possible to operate with concepts in a strictly formal manner. That is to say, that it was possible to find the general, symbolic rules for valid reasoning, and that once we had these rules, we would have the mechanism for never erring in our thinking. “Calculemus”: let us calculate! In Leibniz’s famous rationalist exhortation (see Leibniz 1951, 51), the valid reasoning which calculation expresses is the key to intellectual discovery, as well as the best tool we have for solving human disputes. Leibniz himself might never have accomplished his plan for a mathesis universalis, yet a Leibnizian faith in calculation became decisive for twentieth-century interpretations of a universal formal science of reasoning, which have in turn influenced modern developments of mathematical logic. In this respect, it is also impossible to ignore the influence that Leibniz’s dream of universal symbolic calculation has exerted upon the development of contemporary computing. It is useful here to refer directly to the establishment of the notion of computability by, once again, the mathematical genius of Alan Turing. More than a decade before he asked whether machines could think, Turing took on a pressing problem in mathematical logic: the decision problem  Gödel 2004), Turing then also proposed a specific method of computation that is said to have defined our current conception of mechanical calculation.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  In Turing’s 1936 formalisation of the notion of computability, to compute is to discretise a task into the algorithmic form. This means turning it into a rule-governed activity that can be addressed as a sequential succession of finite steps. In this sense, Turing’s algorithmic method of computation expresses an automatic principle of deductive inference, which is considered universal insofar as it is capable of computing anything that can, in principle, be computed via the sequential succession of finite steps of an algorithm. The postulation of this universal method of computation is one of Turing’s most influential achievements; an achievement that justifies the view that he ‘invented’ modern computers.12 This characteristic of universality, I would argue, is also quite important from the point of view of the connection that I am making here between calculation and the automation of thought. A universal calculative theory of reasoning, such as Leibniz’s mathesis universalis, stands as an attempt to construct what I would call a machine of thought, and to do so by trying to give thinking an inferential, normative and procedural form. This calculative enterprise searches for an ordering technique to mechanically control and reproduce the structure of thinking procedures. Fast forward a couple of centuries, and one can note that the algorithmic method of calculation, which Turing established, is also predicated upon computation as a formalisation of ‘valid reasoning’, according to which a finite set of instructions accounts for the full operationality and predictability of a mechanical system. In this respect, Turing’s algorithmic method of calculation becomes the technique proper to axiomatic reasoning: that is, reasoning that is fully automated insofar as it needs nothing but itself in order to prove its validity.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  In proposing the algorithmic method of computation, Turing modelled the action of his then-hypothetical ‘computing machine’ on what he believed to be the discrete-state operations of a human mind engaged in crunching numbers.13 So, whilst Leibniz proposed a machine of thought,  is one that tries to be as general as possible. To be universal is thus to be general, but also, and most importantly, to be abstract. This is, in my view, a crucial point. Despite the differences between Leibniz’s and Turing’s respective projects (and there are plenty of differences between them), the Leibnizian faith in calculation and Turing’s algorithmic method of computation share a confidence in abstraction, which is taken to be the safest ground for the operability of calculation. In this sense, aspirations to mechanise thought, or to show that thought could already be mechanical, are equally predicated upon the assumption that both proof and function can be placed outside of space and time, and outside of context and content. The universal strength of mechanical calculation capitalises upon the detachment of the mechanical procedure from the particular; a detachment that is in turn instrumentalised into procedures to best resolve disputes, as Leibniz hoped, or to obtain an output from an input, as Turing expected. This instrumentalisation of abstraction is a key feature of the inferential and rule-based character of computational systems. For every calculating process, the computational system engages, and then re-engages again, with the general problem of determining consequences from a handful of symbolised premises.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  The automation of thought thrives on this procedural determinism of rules of inference: it is its complete determination that makes a machine (of thought, as of anything else) a machine. 4 \u0007The clash between life and mechanism Let us linger, if only briefly, on this determinism, for doing so will allow us to consider the automation of thought in relation to my previous remarks about machine instrumentality, and about the fact that the latter is judged differently when it comes to the question of novel thought in computation. For Leibniz, the determinism of calculation is total. If Leibniz believed that it is possible to mechanise the rules of thought into a procedure of automatic inference, this is  “certain and determined beforehand” (1985, 151). In other words, it is possible to say that Leibniz’s epistemological project is substantiated by a metaphysical principle. Turing’s position on ontological determinism is more difficult to reconstruct, partly because, despite having profoundly influenced philosophy, Turing was primarily a mathematician with explicitly logical, rather than ontological concerns. I acknowledge this, of course, yet I also wish to highlight that computation, via Turing’s work, is formalised into an axiomatic process of showing how a conclusion necessarily follows from a set of premises. In my view, this deterministic activity of pinning down chains of reasoning into a fixed formal structure can be said to be an attempt to predicate deductive thought exclusively on its extra-empirical terms.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  On my reading of Turing’s work, then, the epistemological leaks into the ontological, or their boundaries become somewhat permeable. One can see the effect of this permeability in the computational theory of mind, which emerged in the second half of the twentieth century, partly as a consequence of the implicit links that Turing made between calculation and cognition. According to computationalist theories in cognitive science, “intelligent behavior is causally explained by computations performed by the agent’s cognitive system (or brain)” (Piccinini 2009, 515). Logos (i.e. software) informs matter (i.e. hardware), then, or rather bypasses matter altogether to directly lead behaviour. In any case, the thin line between issues of knowledge and issues of reality blurs frequently.14 I would further comment that this also seems to be the case amongst certain contemporary versions of information theory, such as that proposed by the mathematician Gregory Chaitin, who takes both Leibniz and Turing as guiding figures for his own work.15 For Chaitin, and for the advocates of what is known as ‘digital philosophy’ or ‘digital physics’, “all is algorithm” (Chaitin 2007, 235): the determinism of algorithms is not just a metaphor used to explain the workings of nature and the mind; rather, this determinism amounts to how reality actually is and how it actually operates. It is crucial to stress that past and present projects for  philosophy: namely, the relation between thought and being, and the ways in which that relation might be established, or simply recounted, via universalising tools such as abstraction.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Moreover, acknowledging this issue also highlights something important about the question of novel thought in computation. I have discussed how machine thought adheres to the deterministic and deductive rules of computational formalisation. In this respect, if computation seems incapable of producing novelty, this is because algorithmic formalisation does not construct any knowledge, but instead only breaks it down into a finite and discrete manipulation of symbols and instructions. However, recognising that questions about the automation of thought involve questions about the automation of being also helps us to consider here that views concerning the absence of novelty in computation are not only, or are not uniquely, based on the fact that, in machines, everything is pre-programmed. As a matter of fact, there exist (and there have existed for some time) machine programs that possess a degree of complexity sufficient enough to allow them to ‘learn’ to modify their behaviour and perform operations without explicit instructions.16 What I wish to argue, then, is that the popular belief about the impossibility of novelty in computation finds its justification in the observation that to compute is to formally abstract, and thus to generalise and reduce into a logical and deterministic relation the dynamism of life and of thought that comes from lived experience. To put this otherwise: my contention here is that the belief about the impossibility of novelty in computation could be said to be a consequence, or at least to reflect, the fundamental ontological disparity between machines on the one hand, and the non-mechanical on the other. This is an ontological disparity that is also mirrored in the (ontological, as well as epistemological) difference between automated and lived thought. The mechanical thought associated with computation involves, inevitably, abstracting from life, from sensation, from experience itself; in other words, from those grounds upon which, it is said, everything that could account for genuine epistemic as well as ontological production might arise.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Contra formalism and  instrumental reason, as well as wider philosophical arguments that emphasise the singularity and incommensurability of the lived, warned against. They warned that a thinking process that detaches itself from the particular is totalising, and thus dangerous, for “the concept of rationality that underlies our contemporary industrial culture […] contain[s] defects that vitiate it essentially” (Horkheimer 2013, vii), and “the rule of freedom” that is instantiated by this concept, “once brought to pass, necessarily turns into its opposite: the automatizing of society and human behaviour” (Horkheimer 2012, ix–x). Moreover, on this view, a thinking process that detaches itself from the particular is also somewhat ontologically ‘inferior’. This inferiority is due to the fact that the thinking associated with computing involves, once again, a structuring of formal relations, in which there is no room for the generative potential of life, the living and the lived. Poststructuralist, existentialist and phenomenological positions in philosophy have, in this respect, equally led the charge against the prospect of reducing the infinity and variability of lived thought to the finitude of an automated procedure. The eccentricities of thought that comes from Being or beings are thus vindicated against functionalism, operationalisation, universalism, instrumentalisation, and anything that wants to obstruct the ontological dynamic of thinking or entrap it within the programmable, abstracted and predefined structure. From this perspective, the automation of thought, or its full mechanisation, is not the dream that Leibniz dreamt, but in fact a nightmare. This nightmare finds its latest expression in some of the ways in which automation is culturally perceived today as posing a sort of existential threat to society.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Many cultural media outlets have attested to this. From the tabloid to the scientific journal via the glossy coffee table spread, the message that is broadcasted is clear: the robots are out to get us. In my view, and following from what I have discussed so far, the threat that is culturally perceived to be posed by automation must be understood not only in terms of a collective fear for people’s existence or survival. By saying this, of course, I am not underestimating real concerns  might never be, mechanised. The problem of automation is existential, then, insofar as it involves recognising an ontological clash between life and mechanism. It concerns the ways in which machines, thought and mechanical thought exist, endure or simply are. 5 \u0007Alien thought It is only at this point in the discussion that I can fully advance the view that philosophical, scientific and cultural withdrawals into a simulative paradigm mirror a generalised technical, scientific and cultural suspicion that an intelligent automatism might not in fact be so special, insofar as it is a reduction, an approximation, or at best just a simulation of what life (to be understood both as the living and the lived) will never be, i.e. automatic.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  I can finally fully advance this claim because I have now demonstrated that this suspicion taps into long-standing ontological and epistemological issues about the nature of thought and its relation to lived experience. It is also at this point in the discussion, however, that it is necessary to mention that a preoccupation with an onto-epistemological disparity between machines and life does not only characterise philosophy and critical theory, but belongs to computer science too. In recent decades, the classical algorithmic model of computation (i.e. Turing’s model) has been challenged by interactive, embodied and situated conceptualisations of the computing machine, which aim to complement the algorithmic rule with environmental inputs, so as to bring the physicality and sociality of the ‘real world’ (which is always leaning towards the behavioural richness of living and lived experience) into its computational representation. In this respect, it could be said that attempts to mechanise the mind have given rise to attempts to humanise the machine. This reflects the necessities of contemporary computing, which has to interact with and respond to the world at an unprecedented scale and speed. For me, however, there is more involved at a conceptual level. Twenty-first century society is not only witnessing attempts to make machines  a move away from the computationalism of much cognitive science (insofar as what it is pursued is not, strictly speaking, a computational explanation of a phenomenon), I believe that the contemporary debate concerning this topic remains, nonetheless, stuck in a computational metaphor of some kind.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Just as the mechanisation of the mind and the humanisation of the machine go together, the counterpart to the naturalisation of machines can be said to be the mechanisation of nature. What one finds here, of course, is not the clockwork mechanistic universe of Newton, but rather the dynamic structuralism of ants, bird flocks and neurons, which are all said to compute, or to do something similar to computation, insofar as they transmit and process information whilst organising themselves from simple procedures all the way up to complex behaviour. In this scenario, it is difficult to determine what simulates what, or who simulates whom. The walls of Searle’s Chinese room have come down to encompass nature itself.18 When they are looked at from this perspective, conflicting positions such as philosophical criticisms of the mechanisation of thought on the one hand, and technoscientific attempts to enlarge the domain of computability to include the human and the natural on the other, appear to have a common problem and a common target: formalism itself. The simulative paradigm reinforces this attack by aiming to intervene within formalisation: humanising it, I would argue, but also naturalising it. These operations, I would also claim, can be addressed as counterparts of similar simulative endeavours, which point, however paradoxically, not away from formalisation but towards it: for machines that can be humanised, there are minds that can be mechanised, and if a computer can do what nature does it is because nature, some say, is already computing.19 In this scenario, whatever direction we choose (away or towards formalisation) we are still stuck in an imitation game. And yet, once it is recognised that this entrapment is predicated upon a striving towards either making formalism more empirical, or towards making the empirical more  formal, it becomes possible to envisage a way out of this jam. The exit that I propose concerns accepting the disparity between machines and life, and in fact involves radicalising this disparity by accepting computational formalisation in its distinct specificity.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  I am arguing that computation’s epistemic productions should be assessed vis-à-vis the logico-quantitative character of those formalisms that underpin computing. This involves engaging with the epistemic contributions of computational formalisation by allowing automated modes of thought to operate independently of any aspirations towards replicating human cognitive faculties, and of the dimension of lived experience upon which these human cognitive faculties are ontologically predicated. Similarly, however, to engage with the epistemic contributions of computational formalisation also involves recognising that the automated modes of thought that are engendered by computation, precisely because they are formalised and formalising, propose a different order of intelligibility. This order of intelligibility corresponds to a machine ontology that cannot be simply dismissed as reductive, precisely because moving away from the simulative paradigm means that the assumption that the machine only represents humans has been invalidated. My point is that if we, as a society, are to engage with computation’s possibility of producing forms or modes of thought, then we need to start by acknowledging this other order of intelligibility, together with the way in which the computational procedure stands alongside the living organism, the physical object, and also the mathematical idea, as a distinct entity. By saying this I am not, of course, advocating a Platonism of sorts, because what I wish to look at are computational processes in their actuality, as opposed to viewing them in purely ideal terms. Similarly, I am not advocating the regression into a mind and body dualism. Instead, what I am supporting is the philosophical challenge of understanding the legitimacy of the processual and mechanical nature of this distinct entity, i.e.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  the computational procedure. This is a challenge that cannot be subsumed under the affirmation of the ontological superiority of life or machines over one another. computational processes of decision-making and prediction might constitute a novel modality of thought: not despite the deterministic, deductive, axiomatic, procedural and operational character of these processes, but rather because of it. IBM super computer Deep Blue did not beat Kasparov because it thought like him. Quite the opposite: it won because it thought in a manner that was completely different to the way in which he thought, and indeed from the ways in which we all think. Equally, the decision-making of highfrequency trading performs on a different epistemic scale. So, whilst I agree that formalisation, and also computation itself, might obscure what is exciting and creative about reasoning in humans, I would equally say that the simulative paradigm obscures what is exciting and potentially creative in a mode of reasoning that is purely computational, and which is, insofar as it is purely computational, dramatically alien to us. The case of machine learning can help me to explain this claim.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  I mentioned this AI technique earlier in this essay.20 Here I can add that machine learning is a type of artificial intelligence that endows computers with the capacity to learn from large data sets. This technique is much talked about today, as it lies at the basis of many promising developments. Along with the excitement, however, comes a caveat. It is often said that machine learning is a ‘black box’. In other words, it is stressed that, although these algorithms have a great impact upon society, they cannot be held accountable for the consequences of this impact because they are proprietary and thus closed to public scrutiny.21 Of course, I agree that deciphering the black boxes of machine learning is becoming more and more urgent, because their influence upon our world is becoming greater and greater each day. The point that I would like to consider here, however, is that machine learning is also a black box in another, more technical, sense. Because they are modelled to act as deep neural nets, these techniques are often very opaque, or indeed illegible, because they are so complex that they cannot even be understood by the programmers that created them. Machine learning works, but we do not fully understand how.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  The claim that ‘we do not know how they work’ is, for  learning, according to parameters of simulated behaviour, precisely because we cannot really tell what is going on. It is at this point, exactly when facing the prospect of this alien thought, that I find that asking ‘Can a machine think?’ might be an ambiguous, and yet by no means meaningless operation.22 As discussed in the opening section of this article, Turing recognised the poignancy of this question, but he also believed that the question risked giving rise to unproductive and frustrating attempts to define ‘machines’ and ‘thought’. However, if the question of whether a machine can think is not addressed from a simulative perspective, it becomes possible to realise that it is in fact extremely important to respond to the need to define, and to keep defining, the terms ‘machine’ and ‘thought’. What I propose to address here is indeed not just any type of thought, but a very special and peculiar one. This is a mode or form of thought that is procedural, instrumental and operational, and one that is also always quantifying, rationalising and discretising. The machine that is the subject of this investigation is also not just any machine, and Turing himself recognised this when he stated that the “machines concerned in the [imitation] game” (1950, 435) are “digital computers” (ibid., 436), which are in fact “discrete state machines” (ibid., 439). First and foremost, Turing’s digital computers are machines that are arithmetic, highly formalised and formalising, and which pertain more to the laws of abstraction than to the laws of matter and life. As such, they are also machines that can be universal, for all the good and bad that this universalism implies.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":"  Inevitably, then, conceptions of novelty must also be reframed as specific to these discrete machines. The aim of this article was to show that the possibility of novel thought in computation becomes specific to what algorithmic automation is and does. Just as the ‘machine thought’ that I have been concerned with is unique to the discrete and formal operations of computation, so the ‘novelty’ in computation that I am pointing towards is epitomised by the onto-epistemological specificity of these operations. For example, if we look for ingenuity and intuition as conditions for novelty, we might be disappointed and never find them in the discrete algorithmic operationality of machine thought, for the  ask whether a novel behaviour can come not from breaking mechanical rules, but from following them: from doing, in other words, what computers do already, and not what we might think they should be doing if we wanted them to imitate us. Novelty, then, can be found in the distinctiveness of the mode of thought that machines express, and which arises from self-determinate and self-determining rule following. In this sense, and to conclude: this reformulated question about novel thought in computation involves re-defining and enlarging the prospect of what rule-based thought might be, along with reconsidering what rules themselves are. The issue that comes to the fore, then, is whether novelty in computation might be described as predicated on a form of ontological and epistemological autonomy in the normatively instrumental dimension of computational automation. Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http:\/\/creat​iveco​ mmons​.org\/licen​ses\/by\/4.0\/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.\n"}
{"prompt":"Can a machine think anything new? Automation beyond simulation ->","completion":" \n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  Mass Debilitation and Algorithmic Governance Ezekiel Dixon-Román and Jasbir Puar  uncomfortably enumerating the unanticipated contours of black life.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  —Katherine McKittrick, “Mathematics Black Life”  In her article “Mathematics Black Life,” Katherine McKittrick’s interpretation of the indexes of colonial and anti-Black violence as “uncomfortably enumerating the unanticipated contours of black life” is not simply an alternative reading but a line of �ight from the damned and pejorative narratives of Black life. In my ���� article “Algo-ritmo,” I hyphenated the Spanish word for algorithm, creating a portmanteau consisting of the words “something” and “rhythm.”� I played o� the word “rhythm” to speak to what Derrida calls iterability in speech acts. Derrida argues that what makes speech acts e�ective are their iterability, that is, their repetition with alterity. For Derrida, it is alterity that enables conditions of possibility as opposed to determination—conditions of play. What McKittrick calls for in “Mathematics Black Life” is an alternative reading of the enumeration of colonial and anti-Black violence that renders an otherwise� understanding, one that is based on an onto-epistemology that accounts for Black survival and those who lived. McKittrick’s focus on the “contours of Black life” as well as my focus on the “ritmo” of algo-ritmo imply patterns or rhythms that I would like to focus on here. I will argue that these patterns or rhythms are where the art or poethics of quanti�cation lie. This is particularly important given that I will argue that algorithmic governance is a process of recursive rhythms and patterns.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  These rhythms and patterns are what preemptively shape a racializing a�ect, or what Jasbir Puar calls “slow life and debility.”� I argue that algorithmic governance is made up of a system of modulating di�ractive mechanisms (or di�ractive modulators) that seek to compress the information patterns and rhythms of the world. Here, I see the potential of a poethics of other-wise di�ractive patterns toward rerouting the onto-epistemology of the recursive system of algorithmic governance. I turn to algorithmic governance �rst. The Rhythms of Algorithmic Governance and Racializing A�ect Since World War II, societies have been shifting from systems of institutional enclosures that discipline citizens’ ways of being to systems of in�nite and continuous modulating mechanisms, which generatively control access to institutions and human behavior.� Digital technologies and the “internet of things” have enabled increasingly distributed logics, rationalities, and practices of governance via cybernetic systems of communication and predictive control. While sovereign, discipline, and control technologies of capture continue to exist in concert, it is increasingly control that becomes the dominant logic of systems of governance. Within this context of cybernetic systems of governance, control has become the guaranteed form of “truth.” That is, the assured path to “truth” is to shape the futurity of “truth” in the present. Thus, rather than try to prevent or deter the existence of what is empirically veri�able, cybernetic systems of control work via a play on temporality that manufactures a becomingassemblage such as an event, organization, or body in the form of a threat, an anxiety, or desire to mold futurity in the present  My intervention is not based on a critique of exclusion� but rather on an inherited onto-epistemology of the algorithm, an ontological process of becoming, and the epistemological processing of information. Here, algorithmic governance entails a potentiation� of value from and through machines in order to produce a recursive recon�guration of being.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  This recursion of recon�gured being is based on a transparency principle that the formation of the post-Enlightenment subject relies on. It assumes hierarchies of human di�erence that continue to haunt the machine. Thus, rather than ask the question of who is included in the design of technology or how “di�erence” is coded into the machine, I am interested in the techno-social system’s onto-epistemology, which is shaped by the colonial logic of the post-Enlightenment subject. This cybernetic system of governance processes patterns and rhythms of information that the system seeks to compress into its existing logics. In algorithmic governance the existing logics are based on the prede�ned operationalization of laws and policies. Algorithmic modulators process the information patterns and rhythms, attempting to enfold the variability of knowing into the political-juridical, transparent, or self-determining subject. The patterns and rhythms of this recursive system include the regular generation of data through individual digital interactions and individuals’ encounters with state institutions, the regular training of algorithms on available data, and the selective use of training data. Algorithms are systematically used to inform institutional decision-making and the shaping of behaviors and social interactions, due to the violence of the inability to make just decisions.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  The futures of algorithmic prediction already become the past, as the social is forged through the dividual data generated for algorithmic compression. It is important to note that this process of recursion is not a process of reproduction but rather a spiraling regeneration of the post-Enlightenment subject. These rhythms of algorithmic governance then become a signi�cant driver in a shaping of time and space that modulates the speed of life, what Puar calls “slow life.” The patterns are random, yet rhythms are calculated—for instance, when it comes to practices such as Israeli state checkpoints in Palestine. These rhythms are related to biopolitical technologies and logics of uncertainties that bring into emergence an assemblage of racialized ontologies. This is based on a recursive modulation of temporality that aims to slow down life, even in the face of the speed of modernity. Here, I think Sylvia Wynter’s sociogenic principle (the principle of the sociopolitical constitution of the �esh\/body) is helpful to rethink how the algorithmic rhythms and patterns of sociopolitical relations become ontogenic via the �esh\/body, shaping the neurobiological structure of the �esh, and as such creating what I’ve called racializing a�ect.�� My articulation of racializing a�ect borrows from Michelle Stephens in her book Skin Acts, where she argues that the �esh can be felt and mimetically shared with others.�� The racializing a�ect of the �esh is the ontological remainder of the skinned body—the material remainder of the symbolic and discursive constitution of the skin. For Massumi, the process by which a�ect is racialized is the proprioception that enfolds the sensations of the skin into the material memory of the muscular body and autonomic system. Stephens argues that this material remainder is where one �nds the racialized body, a Black subject standing before the symbolic race.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  Racializing a�ect is inseparable from the patterns and rhythms of techno-social systems and the historicity of colonialism, which reduce and stretch temporality while modulating the speed of life. These modulated patterns and rhythms, which have been exceptionally felt during the Covid-�� pandemic, can be understood in terms of “di�raction.” In my dialogue with Ramon Amaro in this issue, I mention the potential of di�raction for  relevance score for users. This alters who sees an advertisement before users even interact with it. In addition, this study found that the amount of money invested in Facebook advertisements, the content of the advertisements, and user intraactions with advertisements (i.e., generated clicks) shaped who became digitally interpellated by the advertisements. When the researchers created a bodybuilding advertisement, they found that it was delivered to over �� percent of men on average, while a cosmetics advertisement they created was delivered to over �� percent women on average. Although we may not know the speci�c algorithms of the Facebook API, we do have a good sense of its di�ractive force. Facebook’s advertising API is based on an autopoiesis and a recursive system that seeks to regenerate its logic as exempli�ed in its di�racted patterns. Patterns, rhythms, intensities, entangled relationalities, material movement, and temporal entanglements are di�racted and becoming processes.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  The recursive system is �nite, while the information rhythms and patterns are in�nite, thus when the recursive system seeks to compress indeterminacies it produces di�racted patterns and rhythms of discontinuity or disjuncture. In a system of autopoiesis, the algorithm will seek to regenerate the changing logic of transparency, as in the Facebook API. Yet, in a system of allopoiesis—that is, a system that is fundamentally open to the potential of epistemological transformation—the di�raction of the creative indeterminacies of Blackness will open up the system to patterns and rhythms other-wise, even toward what Luciana Parisi has called a xeno-patterning or alien intelligence.�� In the case of the Facebook API, the algorithm does not only shift from delivering the advertisements to those predicted relevant to those predicted irrelevant, but more importantly, the automated text and image classi�cation system is continuously altered, throwing any normative distinction between relevant\/irrelevant into �ux. It is here that I see Denise Ferreira da Silva’s articulation of a Black feminist poethics as helpful, particularly toward the development of the art or the poethics of quanti�cation.�� Through a Black feminist poethics, da Silva seeks to push a thinking and reading of text without modern categories. As she argues, it is via the formalizations of law, policy, calculation, measurement, and computation that Blackness’s creative potential is arrested. She pushes us to consider how modern categories, especially of time, history, and development, have shaped a text or an event and, as such, to address colonial and racial subjugation. As she states:  For the Black Feminist Poethics, a moment of radical praxis acknowledges the creative capacity Blackness indexes, reclaims expropriated total value, and demands for nothing less than decolonization—that is, a reconstruction of the world, with the return of the total value without which capital would not have thrived and o� which it still lives.��  This is a practice of thinking and reading that forces one to locate or identify the haunting logics of what happened that’s immanent in what is currently happening, how what is happening anticipates what is yet to happen, and how what happened is already immanent in what is yet to happen. Yet, I also want to argue that what da Silva pushes us to consider is a radical recursive praxis, one that is allopoethic, works without modern categories, and is open to the creative potential of Blackness.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  Such a system, what I might characterize as a poethics of quanti�cation, would enable the transformative potential of  striking unwittingly resituates a progressive teleology of modernity, and also reinforces an asymmetric geopolitical ordering (which leads me to the geopolitics of racial ontology that I discuss below). To hone the articulation of cybernetic logics of governance with their �eshly actualization—actualizations that he argues operate through the right to maim as a “�rst principal”—Modern helpfully parses out the “metaphysics of the right to maim” from the “physics of maiming.” The integration of discipline and control may well render their distinctions moot and transform them into what Helga Tawil-Souri, Omar Jabary Salamanca, and others have theorized as an “asphyxatory regime of power.”�� ***  Khaled Jarrar, Blood for Sale, ����. Courtesy of Open Source Gallery. Photo: Stefan Hagen. Jasbir Puar  colonialism, which reduce and stretch temporality while modulating the speed of life.” I have elsewhere described the racializing of a�ect, or something akin to it, as the “geopolitics of racial ontology … that examines the regulation of a�ect as a racializing form of control.”�� I emphasize geopolitics in order to situate bodies in the speci�city of techno-social systems that interface and instrumentalize the historicity of colonialism, while also cautioning against theorizing a “locationless notion of ontology.”�� Uncertainty, as theorists of computation and algorithms alert us, is already embedded in the calculus of statistical probability as the factor of the indeterminate. The indeterminate is the ontological capture of uncertainty by the algorithmic governance of the bio-necro-political state, an already anticipated moment when preemptive power directed towards shaping outcomes is exceeded by the emergent potentialities of those outcomes. In other words, preemptive power does not so much desire to control the emergence of the uncertain, but to create and direct uncertainty—the certainty of uncertainty. Slow life as I have understood it is therefore a reckoning with the capitalist captures of uncertainty.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  Questions then arise: Do (Palestinian) indeterminacies disrupt these calculative logics? What are the interstitial ontologies of the body that knows anything can happen or the body that is always prepared for something to happen, when uncertainty is not just something niggling the liberal subject but a foreground condition of being? I have called this kind of relation between time and space “time itself.” Time itself, I argue, is not the same as the time lost to the continual expansion of labor time and the re\/production of the laborer and her\/their\/his ability to get to and undertake labor. Time itself does not hew to the past, the present, nor the future as primary referent points. As a stratum of matter, time itself, as an a�ective modality, is not of the laboring body but of the para- and sub-individual capacities of bodies. Unlike a�ective labor, time itself refers to the laboring of a�ect, a laboring that contributes to the capitalist pro�tability and expansion (that is, the deepening entrenchment of technologies of containment globally) of occupation-as-land-use. Time itself is less a stripping-away of individual properties than an endless interfacing of dividual data and metrics. Time itself is not extracted from individual bodies, but is produced through the endless circuitry of dividual material.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  Time itself is dividual time. What is at stake in untangling the workings of the dividual? What is the corporeal in these dividual processes? I am interested in how dividualization is both digital and of the �esh, involving a series of recursive relationalities, as well as being a way of “unseeing” and reseeing corporeality. Following from Katherine McKittrick’s call for “an alternative reading of the enumeration of colonial and anti-Black violence,” Dixon-Román argues for attention to what he calls the “art or poethics of quanti�cation.” The art of quanti�cation is exempli�ed in a ���� performance piece by the artist Khaled Jarrar: in front of Wall Street, Jarrar sold a ten-millimeter vial of his own blood at the daily stock price of global arms industry companies, such as Smith & Wesson. The art of quanti�cation is inseparable from acts such as the tallying of the number of knees shot by the IDF during the Great March of Return in Gaza. Or we can think about the “epidemic of blindness” in Kashmir, the result of the targeting of more than three hundred eyes with pellet bullets since ����, or more recently the blinding of hundreds of protesters in the uprisings in Chile in ����. This art exceeds the process of tabulation, as it involves a scrambling of �eshly registers, of limbs, of organs, of blood.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  To explain and redress the violence of dividualization, there is often a recourse to the presumed relay of humanism: the  In light of Dixon-Roman’s invocation of Massumi’s preemptive ontopower, it’s important to note that Massumi’s belated analysis disregards the massive literature generated in the wake of �\/�� by critical race theorists grappling with state practices. These practices include demands for immigrants racialized as terrorists to self-report citizenship status to impel preemptive detention and deportation. Black feminist scholarship such as the luminous The Other Side of Terror by Erica Edwards makes clear that soft tactics of counterinsurgency are also technologies of preemption.�� It is also crucial to sketch a distinction here between preemptive and prehensive power, in part because it is not simple to parse them. If the preemptive is a mode of using information and calculation to create, delimit, or derail a certain event, to shut down the indeterminant e�ect or proclivity, the prehensive is a mode of intervention, modulation, and titration into what is understood to be lively beyond preemption. That is to say, the preemptive seeks to eliminate that which is indeterminate while the prehensive accepts the indeterminate, entertains it, plays with it. The prehensiveness of algorithms does not revolve only around “representations of data,” nor is it solely a “tool to accomplish tasks,” but it also fosters “occasions of experience” that are neither driven fully by computation nor that which is external.�� There is indeed slippage between the preemptive and the prehensive; they are nested technologies of temporality. Preemption is in part a narrative strategy—“Gaza will be uninhabitable by ����”—that assists the power of the prehensive to mess with vitality, with excess. In this sense, maiming as a strategy is not about preempting resistance, but about encountering, indeed prehending, the impossibility of such preemption, of stripping the body of resistance.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  The notion of un\/inhabitation is less a humanistic measure and more a pronouncement of the uneven demands to survive forces of exploitation and disposability. The livable\/unlivable binary is usurped by the prehension of incremental degrees of being. There is another form of dividual-making that is not reliant, or solely sustained by, data-driven technologies, an interfacing of computation sovereignty and a more banal and mundane sovereign right to maim, an imbrication of sovereign, disciplinary, and control forms of power. Israeli soldiers’ descriptions of sniper targeting suggest there is a proprioceptive process that is parallel and akin to the data dividual process of sensing, sifting, sorting.�� Dividualizing does not break down or dismember the body (knees, ankles, limbs); rather, it does not recognize these disparate elements as part of a composite in the �rst place. The target is not the body, not even the body’s limb, but simply the\/a limb. The �esh as felt takes on a slightly di�erent valance of racializing a�ect here. One learns not to see the limb as missing a\/the body. Spatial intimacy is what allows, rather than thwarts, seeing a human arm or leg as “a part” that �oats free of the human form, available to the sniper\/cop\/soldier as perceptually decoupled from the body.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  The intimacy that is produced with the part has as its corollary the situatedness of the rest of the individual’s body. This relational frame of sight dividuates by “unseeing” the body as a composite and situating these parts in a “more-than-human” biopolitics among other organic and nonorganic entities, be they infrastructural, ecological, biophysical, interspecial. In this visual-to-data economy, the dividual lends itself to a ground-zero analysis of fragments that are not of a whole, but instead embedded in the process of titrating life through bodily metrics and subindividual capacities. The composite of the body is irrelevant; it is unimportant that it exists. While the maimed individual is (fantasized as) available for empowerment and prosthetic technologies\/apparatuses, the dividual is a communicated expectation and a corporeal training rather than an ideologically driven representational �gure; it relies on soliciting the plasticity of parts. Understanding the �eshly rendering of dividuals entails apprehending something beyond the body signi�ed  while reinforcing old ones, we will be asking these questions again and again. I am struck by the emptying out of the ethical that Denise Fererria da Silva points to when she states: “I am interested in the ethical indi�erence with which racial violence is met.”�� If, per her work and others, mass debilitation is the precondition for the existence of this thing called humanity, then the ethical is still within the frame of the human and cannot address the dividual uses of data and information, and the force and necessity of a nonrepresentational critique becomes all the more apparent. Ezekiel Dixon-Román’s Response Khaled Jarrar’s performance piece is a political intervention.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  He performs the quanti�cation of the valorization of life by tying the value of Palestinian blood to the shares of US military or weapons manufacturers such as Smith & Wesson. I am especially struck by this example that Puar refers to because it uses the art of quanti�cation to make a sharp critique of the violent material e�ects of disaster capitalism. This quanti�cation is analogous to what Katherine McKittrick might speak of as “Mathematics Black Life,” in relation to biopolitical technologies and the logics of uncertainties that bring into emergence an assemblage of racialized ontologies. This mathematics is based on a recursive modulation of temporality in order to slow down life, even in the face of the speed of modernity. This is especially compelling when considering the calculation of the number of knees shot by the IDF in Gaza or the “epidemic of blindness” in Kashmir and Santiago. The focus on the dividual in a biopolitics of debility and the slowing-down of life is striking. Puar states: “Dividualizing does not break down or dismember the body (knees, ankles, limbs); rather, it does not recognize these disparate elements as part of a composite in the �rst place. The target is not the body, not even the body’s limb, but simply the\/a limb.” This is a profoundly important point that I don’t think can be glossed over.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  It gets at what is at stake in the focus on the dividual, a consideration that is often situated or deployed without a serious threading of the political and social through the dividual. Jarrar’s performance piece and the example of the number of knees or eyes shot makes the violence explicit and speaks to the biopolitical work the dividual does. When the dividual is thought of in relation to the human\/inhuman divide, Puar brings us right to the ethico-political. As Puar states, referencing Joseph Pugliese, “If we are to understand something, anything, about what Joseph Pugliese calls a ‘morethan-human biopolitics,’ it is that the dividual, not the individual, is the instrumentalized unit of such a biopolitics.” I appreciate this argument about the ways in which the dividual is haunted by the category of the in\/human and, as such, shaped by the post-Enlightenment subject. Given that the axioms of the techno-scienti�c developments of modernity include colonial logics of racial hierarchies as inscribed by temporality, spatiality, sequentiality, and separation (among other terms), the dividual data that is generated and processed is also an e�ect of the post-Enlightenment. In thinking with Puar, this raises many questions: What is the distinct performative work that the dividual does in contrast to the individual? In what ways might the dividual be more haunting than the individual? I’m also intrigued by a generative line of inquiry here, one that speculatively questions the conditions and processes for an opening, a rupturing, and even a fugitive potentiality in computational systems.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  For instance, what happens when there’s a shift in material and discursive conditions? What if the recursive system does not maintain an autopoietic posture toward indeterminacies and becomes allopoietic and  of iconography” (��). �� See Karen Barad, Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning (Duke University Press, ����). �� Denise Ferreira da Silva, “On Di�erence Without Separability,” in ��nd Bienal de São Paulo: Incerteza viva (Fundação Bienal de São Paulo, ����) →. �� Muhammad Ali et al., “Discrimination through Optimization: How Facebook’s Ad Delivery Can Lead to Biased Outcomes,” Proceedings of the ACM on HumanComputer Interaction, no. � (����). �� Luciana Parisi, “Xeno-Patterning,” in Angelaki ��, no. � (����).\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  �� Denise Ferreira da Silva, “Toward a Black Feminist Poethics: The Quest(ion) of a Blackness Toward the End of the World,” The Black Scholar ��, no. � (����). �� Da Silva, “Toward a Black Feminist Poethics.” �� Deleuze, “Postscript on the Societies of Control.” �� See discussion in The Right to Maim, ��–��. �� John Modern, “In the Age of Cybernetic Systems What Like a Bullet Can Undeceive?” Political Theology, April ��, ���� →. �� Helga Tawil-Souri, “Digital Occupation: Gaza’s High-Tech Enclosure,” Journal of Palestine Studies ��, no. � (����); Omar Jabary Salamanca, “Unplug and Play: Manufacturing Collapse in Gaza,” Human Geography �, no. � (����). �� Julie Peteet, “Stealing Time,” Middle East Research and Information Project, no.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  ��� (Fall ����) →. �� Rema Hammami, “On (Not) Su�ering at the Checkpoint: Palestinian Narrative Strategies of Surviving Israel’s Carceral Spaces,” Borderlands, vol �� no �: ����. �� Alex Weheliye, Habeas Viscus: Racializing Assemblages, Biopolitics, and Black Feminist Theories of the Human (Duke University Press, ����). �� Puar, The Right to Maim, ���. �� Puar, The Right to Maim, ��. �� Joseph Pugliese, Biopolitics of the More-Than-Human: Forensic Ecologies of Violence (Duke University Press, ����). �� See in this issue Ezekiel Dixon-Román and Ramon Amaro, “Haunting, Blackness, and Algorithmic Thought” →. �� Erica Edwards, The Other Side of Terror: Black Women and the Culture of U.S.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  Empire (NYU Press, ����). �� Luciana Parisi, Contagious Architecture; Computation, Aesthetics, and Space (MIT Press, ����), xvii. �� See Hilo Glazer, “‘�� Knees in One Day’: Israeli Snipers Open Up About Shooting Gaza Protesters,” Haaretz, March �, ���� →. �� Denise Ferreira da Silva, “� (life) ÷ � (blackness) = ∞ − ∞ or ∞ \/ ∞: On Matter Beyond the Equation of Value,” e-�ux journal, no. �� (February ����) →. �� Patrick Wolfe, “Settler Colonialism and the Elimination of the Native,” Journal of Genocide Research �, no. � (����). �� The brilliant constellation of thought generated by and between Hortense Spillers and C. Riley Snorton on ungendering, fungibility, and fugitivity is inspiring here.\n"}
{"prompt":"Mass Debilitation and Algorithmic Governance ->","completion":"  See Spillers, “Mama’s Baby, Papa’s Maybe: An American Grammar,” Diacritics ��, no. � (����); and Snorton, Black on Both Sides: A Racial History of Trans Identity (University of Minnesota Press, ����). �� Da Silva, “� (life) ÷ � (blackness).”  Category Colonialism & Imperialism, Performance Subject Social Media, Blackness, Black Feminism, Militarization Return to Issue #���  Ezekiel Dixon-Román is an Associate Professor in the School of Social Policy & Practice at the University of Pennsylvania. His research seeks to make critical interventions towards re-theorizing the technologies and practices of quanti�cation that he understands as mediums and agencies of sociopolitical systems, whereby race and other assemblages of di�erence are byproducts. He is the author of Inheriting Possibility: Social Reproduction & Quanti�cation in Education (University of Minnesota Press, ����), and the guest editor of “Control Societies @ ��: Technopolitical Forces and Ontologies of Di�erence” (Social Text Online, ����). © ���� e-�ux and the author\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  5 VIROID LIFE On machines, technics, and evolution The possibility of metaphor is disappearing in every sphere.This is an aspect of a general tendency…affecting all disciplines as they lose their specificity and partake of a process of contagion—a viral loss of determinacy which is the prime event of all the new events that assail us.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  (Baudrillard 1993:7)  This is evolution: the use of new technics.There is no such thing as ‘biological evolution’. …The most terrible mistake of the nineteenth century: the abandonment of creation theory was based on a biological rather than a technical-artificial foundation.We are the children of the consequences of this mistake. Instead of technical practices, we inherited the master-race as our God-function. As good children of the master-race elders, ‘we’ believe (green as we are) that we can protect ourselves against fascism with ‘nature’ (instead of realizing that only technics can abolish fascism). (Theweleit 1992:260)  Current continental philosophy contends that the human is necessarily bound up with an orginary technicity: technology is a constitutive prosthetic of the human animal, a dangerous supplement that enjoys an originary status.1 That is, the origin of the ‘human’ as a species and a Dasein is radically aporetic since what lies at the 1 As early as 1907, however, Bergson was insisting that mechanical invention, as well as the technics of invention, had to be seen as constitutive of the kind of intelligent life-form we label ‘human’ since ‘from the first’ technics has been ‘its essential feature’ (Bergson 1983:138).A powerful critique of twentieth-century schools of neo-Hegelian humanism for their forgetting of the technogenesis of the human, such as Debord’s situationism, has recently been evinced by Regis Debray, who argues that these ‘essentialist ontologies’, which fantasize about a final reconciliation of essence with human existence, are based on delusions of historical transparency and effective historical  origin of the making of man is the lack—or excessiveness, depending on one’s perspective—of origin. History appears to have reached the weird point where it is no longer possible to determine whether technology as an extended phenotype is an expression of the desire of our genes or a sign of nature’s cultural conspiracy. As Lyotard has put it: the ‘truth’ of the time of technics is not a ‘revelation’ but a ‘betrayal’ (Lyotard 1991:52). The task of the new technologies is to unblock the ‘obstacle’ constituted on earth by human life.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  However, this collapsing of bios and technos into each other is not only politically naive, producing a completely reified grand narrative of technology as the true agent and telos of natural and (in)human history, but also restricts technics to anthropos, binding history to anthropocentrism, and overlooking the simple fact that the genesis of the human is not only a technogenesis but equally, and just as importantly, a bio-technogenesis. The phenomenon of symbiosis provides the clearest demonstration of this thesis, presenting a genuine challenge to the entire Occidental tradition of speculative thought and suggesting the urgency of adopting a rhizomatic praxis. The image of the tree has dominated ‘all of Western thought from botany to biology and anatomy, but also gnosiology, theology, ontology, all of philosophy…’ (Deleuze and Guattari 1988:18). These new anthropocentric readings of history lead to the entirely spurious claim that with the coming of computers and the arrival of robot intelligence the planet is now entering a ‘silicon age’. What this ignores is the fact that metallurgy has an ancient prehuman history, with human metalworking following the bacterial use of magnetite for internal compasses by almost three thousand million years (Margulis and Sagan 1995:194). Moreover, symbiosis has a filthy lesson to teach us: the human is an integrated colony of amoeboid beings, just as these amoeboid beings (protoctists) are integrated colonies of bacteria. Like it or not, our origins are in slime. Biologists have established that the nucleated cell of eukaryotic life evolved by acquisition, not of inherited characteristics à la Lamarck’s model of evolution, but of inherited bacterial symbionts, in which ‘amid cell gorgings and aborted invasions, merged beings that infected one another were reinvigorated by the incorporation of their permanent “disease”’ (ibid.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  : 90). The attempt to develop a general theory of evolutionary systems is entirely dependent on the kinds of problems being set up. To consider the nature of species, organisms, and evolution itself, independently of the cognitive framing and mapping of theoretical inquiry—and all theory needs to be understood as a praxis (Reuleaux 1876\/1963: introduction) —is to produce nothing but  Conceptions of ‘evolution’ only make sense in relation to time-scales within which they are framed. For example, from the perspective of ‘universal evolution’ species and organisms cannot be treated as fixed or static points of reference or interpreted as the end-points of life’s novel activity of invention. The boundaries between species are constantly shifting, mobile, and porous, while geographical landscapes harbour only extrinsic harmonies of an order of ecology in which any equilibrium between populations can only be regarded as temporary. Indeed, on a certain model one could legitimately claim that the ‘success’ of a species is to be measured by the speed at which it evolves itself out of existence. Deleuze and Guattari’s most radical gesture is to suggest that there has never been purely ‘biological’ evolution, since ‘evolution’ is technics, nothing but technics: ‘There is no biosphere or noosphere, but everywhere the same Mechanosphere’ (Deleuze and Guattari 1980:89; 1988:69).2 All systems from the ‘biological’ to the ‘social’ and economic are made up of machinic assemblages, complex foldings, and movements of deterritorialization that serve to cut across and derange their stratification. This explains why for them ‘pragmatics’ (or ‘schizoanalysis’) becomes the fundamental element upon which everything else depends.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Deleuze and Guattari are most keenly interested in the differential rhythms and affective intensities of evolution, the ‘invisible’ becomings of non-organic life that can only be effectively navigated and mapped when situated on the plane of abstract machines which consists of non-formed matters and non-formal functions (ibid. : 637; 511). In this chapter I want to show how Deleuze and Guattari’s mapping of the ‘creativity’ of machinic life provides a fundamental challenge to both the natural bent of the intellect and to major scientific habits. 2 The term ‘noosphere’ was coined by Bergson’s successor at the Collège de France, Edouard Le Roy. It was taken up by Teilhard de Chardin, palaeontologist and priest, as a conscious layer of life superimposed upon the biosphere, and represents the fundamental component in the evolution of the ‘human phylum’. See de Chardin 1965:211ff. In the work of the Russian scientist Vladimir Vernadsky the ‘noosphere’ is used to account for the emergence of organized matter in terms of an emergent symbiosis between living matter and human technology. For Vernadsky the plastics and metals of industry stem from an ancient life process that co-opts new materials for a surface geological flow that becomes ever more rapid.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  See Vernadksy 1945:1–12. For a contemporary version of his position see Margulis and Sagan 1995, who approach ‘life’ as an autopoietic, photosynthetic planetary  In Difference and Repetition Deleuze deploys biological thinking in the service of a philosophy of internal difference. He approaches ‘evolution’ on the level of a philosophical embryology (‘the world is an egg’), insisting that ‘Evolution does not take place in the open air’ since ‘only the involuted evolves’ (Deleuze 1994:118). (Kant speaks of the need to move from a theory of ‘evolution’ to one of ‘involution’ in a discussion of ‘individual’ and ‘generic’ conceptions of preformationism, while also drawing on a notion of ‘virtuality’, in 1974\/1982: section 81.) Embryology demonstrates, for example, that there are vital movements and torsions that only the embryo is able to sustain, and which would tear apart an adult. This means that there are ‘spatio-temporal dynamisms’ which can only be experienced at the borders of the liveable: ‘Something “passes” between the borders’, he writes, ‘events explode, phenomena flash, like thunder and lightning’ (ibid.). Moreover, in this work Deleuze is already articulating the kind of ‘molecular Darwinism’ that characterizes Deleuze and Guattari’s joint work and their utilization of population thinking in modern biology with its attack on typological essentialism. Deleuze does not read natural selection as a theory about the evolution of ‘species’; rather, for him, what is primary is the play of the individual and processes of individuation, in relation to which the evolution of species is only a transcendental ‘illusion’ (ibid.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  : 250).3 In A Thousand Plateaus Deleuze and Guattari argue that neo-Darwinism’s emphasis on populations over types, and differential rates and relations over degrees, makes for a vital contribution to an understanding of biology as nomadology, steering the logic of life in the direction of a science of multiplicities. In the former work Deleuze will reverse the relationship between ontogeny and phylogeny as classically depicted in biological thought, such as Haeckel’s famous biogenetic law, insisting that it is the case not that ontogeny simply recapitulates phylogeny but rather that it creates it;4 while in the latter work Deleuze and Guattari make the identical point, speaking of the relationship between embryogenesis and phylogenesis as one that involves the virtual becoming of a creative ‘universal 3 For Darwin on the importance of ‘individual differences’ in selection see Darwin (1985:101ff.). On neo-Darwinism see Mayr (1991), who writes that ‘the discovery of the importance of the individual became the cornerstone of Darwin’s theory of natural selection’ (42); on the move to population genetics within evolutionary theory that characterizes the modern synthesis see Eldredge (1995:10–30). evolution’: ‘the embryo’, they write, ‘does not testify to an absolute form preestablished in a closed milieu; rather, the phylogenesis of populations has at its disposal, in an open milieu, an entire range of relative forms to select from, none of which is preestablished’ (Deleuze and Guattari 1988:48). One can only insist on the irreducibility of the forms of folding.5 The antinomies of modern biological thought—individual\/species, selector\/selectee, organism\/environment, variation\/selection, and so on—are fully caught up in the antinomies of bourgeois thought and are at play in Deleuze’s ‘Bergsonism’. In Difference and Repetition, I would argue, Deleuze too readily assimilates natural selection into the project of thinking difference and repetition at the level of philosophical embryology and morphology. He claims that selection works in favour of guaranteeing the survival of the most divergent (Deleuze 1994:248). In this work Deleuze conveniently ignores Nietzsche’s critique of Darwin where the critical focus is on the reified notion of ‘fitness’.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  On Nietzsche’s understanding, natural selection may well be a machine of evolution, but it functions in accordance with a specific entropic principle, namely, ‘survival of the fittest’ (see Nietzsche 1968: sections 684 and 685).6 It can 5 Deleuze suggests that the double helix of DNA should be treated in terms of the operations of the ‘superfold’. See Deleuze 1988b: 132. 6 Nietzsche felt isolated in his ‘contra Darwin’ position, in which ‘the error of the school of Darwin’ became such a ‘profound problem’ to him. How could one see nature ‘so badly’? he asks. In short, Nietzsche is maintaining that Darwinism is a biological theory shot through with assumptions of society and morality.‘I rebel against the translation of reality into a morality’, he writes (1968:685), while insisting that Malthus is not nature (Nietzsche 1979b: 75). Ultimately, the Auseinandersetzung becomes for Nietzsche a matter of transvaluation of so-called strictly ‘biological’ values. See, for example, the ‘critical’ denouement to essay 1 of On the Genealogy of Morality.The phrase ‘survival of the fittest’ appeared in the fifth edition of the Origin of Species.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It is associated with the work of Herbert Spencer and was adopted by Darwin at the insistence of Alfred Russel Wallace, who considered it a better description of evolution than the misleading ‘natural selection’, with its anthropomorphic personification of nature.Throughout the Origin Darwin speaks of the ‘economy’ and ‘polity’ of nature, and there are places where it becomes undecidable whether he is talking of ‘nature’ or of industrial society. Marx, for one, saw ‘civil society’, the Hobbesian bellum omnium contra omnes, as playing a major role in Darwin’s model of ‘nature’. One should also note the extent to which a philosophy of ‘good and evil’ figures in his description of the animal kingdom, and at times he comes dangerously close to reading the text of nature through the lens of an anthropomorphic sentimentalism. The best example of this is his claim that natural selection acts  thus not be so easily regarded, as it is in Deleuze, as a positive power of differenciation (a ‘differenciator of difference’). Indeed, the term ‘natural selection’ is something of a misnomer since nature does not at all select; rather, it operates as an arbitrary force of extermination, resulting in the differential loss of differently constituted individuals. Nature does not so much select the fittest as exterminate the ill-fitted, adapting forms of life to the environment slowly and imperceptibly in an entirely mechanistic, algorithmic fashion.Thus, we find in Difference and Repetition major tensions emanating from the uneasy alliance Deleuze makes between the competing claims of ‘complexity’ and ‘selection’. In the work with Guattari primacy is clearly given to ‘involution’ over ‘evolution’ and to modes of deterritorialization, that is, to the power of endogeny over that of exogeny:‘The more interior milieus an organism has…assuring its autonomy and bringing it into a set of aleatory relations with the exterior, the more deterritorialized it is’ (Deleuze and Guattari 1988:53–4). It is precisely the ‘creative’ reality of deterritorialization that Deleuze was articulating in Difference and Repetition in such novel terms and that serves to link the work up with current complexity theory in philosophical biology.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  For example, in Difference and Repetition, the ‘formula’ for ‘evolution’ (Deleuze has the word in scare quotes) is given as: ‘the more complex a system, the more the values peculiar to implication appear within it’ (Deleuze 1994: 255).7 It is the ‘centres of envelopment’ that function as both a ‘judgement’ of the complexity of any given system and as the differenciator of difference. For example, we know today that the difference between humans and chimpanzees consists not in their genetic difference, which is minimal anyhow, but in the spatial organization and folding of their cells. Such an insight counters the reductionism of those biologists who place the emphasis on the determination of genes and so erase the trace of genetic indetermination. It is precisely the endogenous powers of spatio-temporal rhythms and intensities that Deleuze is privileging in Difference and Repetition as a model of ‘evolution’ over the strictly exogenous mechanism of selection.This thesis is now supported by leading complexity theorists such as Stuart Kauffman who argue that many of the highly ordered features of ontogeny are not to be regarded as the achievements of selection, but rather as the self-organized behaviours of complex genetic regulatory systems. Moreover, the properties of 7  Compare Simondon (1992:305), whose text on the genesis of the individual, published in  self-organization are so deeply immanent in these complex networks that ‘selection cannot avoid that order’ (Kauffman 1993: xvii). On this model selection can in no way be regarded as the sole or primary generator of evolutionary order and composition. When in Difference and Repetition Deleuze calls for a ‘kinematics of the egg’, insisting that what is seminal in embryology is not the division of an egg into parts, but rather the morphogenetic movements, such as the ‘augmentation of free surfaces, stretching of cellular layers, invagination by folding’, and in which ‘transport is Dionysian, divine, and delirious, before it is local transfer’ (Deleuze 1994: 214), he is anticipating the turn to questions of embryogenesis and morphogenesis that characterizes current attempts amongst biologists to move beyond the hegemonic neo-Darwinian paradigm. Here the focus is on the production of spatial patterns that are explicable not in terms of the nature of the components involved, such as cells, but rather in terms of the way the molecules interact in time and in space (their relational order).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Deleuze goes further in insisting that these processes involve the creation of a space and a time that are peculiar to that which is actualized. On this model of a philosophical embryology, time and space are no longer treated simply as universal a priori forms of sensible intuition, but rather are understood as components in the production of variation and difference. As one eminent neuroscientist who works on embryology has recently put it: ‘Diversity must inevitably result from the dynamic nature of topobiological events’ (Edelman 1994:64). In short, what Deleuze does not appear to appreciate is that his thinking of difference and repetition, in terms of a thinking of the creation of the new and the different, along the lines of a philosophical embryology and morphology, presents a fundamental challenge to some of the core tenets of the neo-Darwinian synthesis.8 8 It is interesting to note that the major figure who appears after the cursory treatment of Darwin in Difference and Repetition is von Baer. It is the ideas of von Baer that Deleuze utilizes to maintain the highest generalities of life point beyond species and genus in the direction of individual and pre-individual singularities (1994:249–50). On von Baer’s understanding of development as a process of ‘individualization’ and ‘differentiation of the unique’ see Gould (1977:52–9). It is clear that Darwin was unable to take on board the full challenge of von Baer’s stress on ontogeny over phylogeny since it would have fundamentally altered his theory of natural selection. At the time of Darwin’s writing of the theory of descent embryology was undergoing a significant transformation in its own ‘evolution’, away from Naturphilosophie in the direction of modern epigenetic theory.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Darwin’s position on embryogenesis—that embryos mirror the history of the race by being similar to adult, though extinct, forms—is the one that Haeckel was later to  A strand of contemporary biology has sought to move away from the genetic reductionism of ultra-Darwinism—best typified in Richard Dawkins’s Schopenhauerean-styled theory of the selfish gene—insisting that questions of form cannot be reduced to those of simple adaptation, since the organism enjoys an integrity and autonomy of its own and has to be treated as a self-organizing structural and functional unity (see Goodwin 1995). But this move from genetic reductionism to organismic holism in complexity theory is by no means a straightforwardly progressive move. The ‘organism’ is always extracted from the flows, intensities, and pre-vital singularities of pre-stratified, non-organic life in order to produce, through techniques of normalization, hierarchization, and organization, a disciplined body, a controlled subject and a subject ‘of’ control. The organized body of both biology and sociology is an invention of these techniques of capture and control. It is the judgement of theos: ‘You will be organized, you will be an organism, you will articulate your body—otherwise you’re just depraved.’ (Deleuze and Guattari 1988:159). This explains why it becomes necessary to think about machines, about the reality of parts and wholes, about machinic modes of ‘evolution’, and about a ‘machinic surplusvalue’ that produces an excess which cannot be located within a ‘subject’ since it lies outside. Evolution, like the egg, does not take place in the open air: invention in evolution takes place not simply in terms of a process of complexification, say from a less to a more differentiated state, but rather in terms of a process of what Deleuze and Guattari call ‘creative involution’. The word ‘involution’ should not be confused, as it is in Freud, for example, with regression, but suggests the emergence of a symbiotic field that allows assignable relations between disparate things to come into play.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It is this ‘block of becoming’ that represents the ‘transversal communication’ between heterogeneous populations, making becoming a rhizome and not a classificatory or genealogical in its suggestion that the work of Darwin and his so-called ‘pre-Darwinian’ predecessors, such as Cuvier, Geoffroy Saint-Hilaire, and von Baer, can be held together to provide a more complicated conception of ‘evolution’, one that is not evolutionist. See Deleuze 1988b: 129, where it is argued that the tendency to diverge is produced through endogenous processes of folding. The same shortcoming which contemporary embryologists, such as Lovtrup, find in Darwin, has also been identifed as a major weakness of the modern synthesis (neo-Darwinism). tree.9 The ‘tree’ model of evolution is highly ambiguous, being both genealogical (the tree of the family man) and the tree of non-human nature that shows no particular concern for mankind. As one commentator has also noted, it is both an oppressive colonial image and an organic image (Beer 1986:239). Becoming is to be conceived neither in terms of a correspondence between relations or identities nor in terms of progression or regression along a series. This is to posit evolutionism as linearism (Deleuze and Guattari 1980:292; 1988:238– 9). It thus becomes necessary to think of a reality that is specific to ‘becoming’.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  9 Evolutionary trees were introduced as the standard iconography for phylogeny in the 1860s by Ernst Haeckel, and have served to buttress an anthropocentric view of life, based on the ladder of progress and a cone of increasing diversity, in which evolution gains a ‘moral’ meaning as it slowly but surely becomes imbued with consciousness after a history of upward striving and vertical perfection that culminates in ‘man’. Stephen Jay Gould has sought to expose the anthropocentric conceits of this tree model of life in his magisterial study of the Burgess Shale dating from the Cambrian period. See Gould 1990:240ff., especially 263–7. The word ‘involution’ to account for distinctive features of ‘evolution’ is used prominently by de Chardin in his The Phenomenon of Man (first published in France in 1955): ‘Regarded along its axis of complexity, the universe is, both on the whole and at each of its points, in a continual tension of organic doubling-back upon itself, and thus of interiorization’ (de Chardin 1965:330). De Chardin employs orthogenesis to support a theory of evolution that gives, in quasi-Hegelian fashion, primacy to self-consciousness and spirit (see ibid. : 176). Thus, for him the physico-chemical process of organic involution—an involution of ‘complexity’ —is ‘experimentally bound up with a correlative increase in interiorization, that is to say in the psyche or consciousness’ (ibid. : 329).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In this schema of, supposedly, ‘biological’ evolution, in which ‘cosmic involution becomes the key perspective through which to grasp its essential dynamic, consciousness is co-extensive with the universe, and the universe ‘rests in equilibrium and consistency, in the form of thought, on a supreme pole of interiorization’ (ibid. : 338). The ‘great human machine’ can only ‘work’, and must work, in terms of the production of ‘a super-abundance of mind’ (ibid. : 282). Deleuze and Guattari’s contention that there is no ‘noosphere’ or ‘biosphere’, only the ‘mechanosphere’, must be seen as being, in part, directed at the overly spiritualist and cosmicist interpretation of ‘evolution’ and ‘involution’ advocated by de Chardin. Deleuze and Guattari’s conception of evolution as ‘creative involution’ is radically different from that found in the likes of de Chardin in that it does not in any way privilege mankind as the apex of evolutionary life (in spite of his utilization of involution de Chardin is still reliant on a ‘tree’ model of life to support his elevation of consciousness and spirit). ‘Man’ for them is the molar category par excellence; the ‘human being’ only becomes an interesting phenomenon when it is conceived machinically. In his 1960s study of Bergson,  The important role played by symbiosis in the history of technology, in which previously disjoint and unconnected technologies merge, is widely recognized (Sahal 1981).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In biology, however, symbiosis has had a curiously awkward history which reveals much about the anthropocentric determination of the subject and about hominid fears of contamination. It has played, and continues to play, a subversive role in biology since it challenges the boundaries of the organism.10 Indeed, it has been argued by one commentator that it was not until 1950, when geneticists extended their field of study to micro-organisms, that biology recognized that there were means other than sex for transmitting genes, such as infections and symbiotic complexes. Prior to this it was the institutionalized boundaries of the life sciences themselves, such as zoology, botany, bacteriology, virology, genetics, pathology, etc., which prevented the synthetic studies of symbiosis from being properly assessed (Sapp 1994:208–9). The importance of symbiotic bacteria in the ‘origin of species’ —repeated bacterial symbioses result in the emergence of new genes—is now widely appreciated, but must ultimately be disturbing to our anthropocentric claims upon life (and death). The detailed structure of the organelles in eukaryotic cells, such as the mitochondrian, and the composition of the DNA in those organelles show that crucial evolutionary processes were not the result of slow accumulation of random changes (mutations) in the genes of ancestral prokaryotic cells. Rather, it seems highly probable that they were the result of intracellular symbiosis in which some cells incorporated into their own cell contents partner cells of another kind that had different metabolic abilities. Over time the genetic and metabolic organizations of host and guest cells fused to the point where it became impossible to distinguish where one cell began and another finished.The strength of this hypothesis lies in the fact that it offers the most convincing explanation as to why both mitochondria and chloroplasts contain their own ribosomes and DNA. The case of multi-cellular organisms is now part of the ‘orthodoxy’ of contemporary biology, but there are other more disturbing examples of the transversal character of genetic lineages such as viruses (‘poisons’), for example.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Modern biology has identified not only ‘bacteroids’ as playing a crucial role as symbionts in certain metabolic processes, 10 The seminal text is Margulis 1970. See also Margulis 1981 and Jacob 1974:311–12. Margulis has used her work on symbiosis to challenge the view that natural selection provides the prime explanation of evolutionary life. The fossil record and other evidence suggest that evolution from bacterial to nucleated cellular life did not occur by random mutation alone, but rather  but also symbiotic ‘viroids’. Indeed, a leading researcher in the field in the 1940s postulated the idea of a distinct kingdom for such viroids, the Archetista, arguing that within evolution they have acted, on account of their molecular composition, as highly adaptable intracellular symbionts, so supplying from ‘amoeba to man’ a virtual ‘reservoir’ for viruses in the course of evolution (Sapp 1994:151–2). More recently, Dennett has referred to these pioneers of evolution as ‘macros’, which is the name given by computer programmers to cobbled-together fragments of coded instructions that perform particular tasks, in order to draw attention to the similarities between the machinery of ‘natural’ viruses and ‘artificial’ viruses such as computer viruses. Both are ‘bits of program or algorithm, bare, minimal, selfreproducing mechanisms’ (Dennett 1995b: 156–7). Standing as they do at the border between the ‘living’ and the non-living’, and virtually real, viruses serve to challenge almost every dogmatic tenet in our thinking about the logic of life, defying any tidy division of the physical, such as we find in Kant, for example, into organisms, the inorganic, and engineered artifacts (for further insight see Eigen 1992:101–6).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Creative evolution on earth would have been impossible without the intervention of the genetic engineering that characterizes viroid life. The scientific work that was carried out on genetic engineering in the 1950s, which today provides the basis for recombinant DNA technology, derived from observations of the mechanisms of recombination in bacteria. The emphasis was on ‘transformations’, such as ‘conjugation’ and ‘transduction’, which involve the transfer of genetic material from one cell to another by a virus (Sapp 1994: 158). This research, however, must necessarily lead to a fundamental revision of dominant models of evolution. If it is the case that viroid life is one of the key means by which the transferral of genetic information has taken place, then it is necessary to entertain the idea that there are cases where this transfer of information passes from more highly evolved species to ones that are less evolved or which were the progenitors of the more evolved species, with the result that reticular schemas would have to be substituted for the tree schemas that dominate almost all thinking about the logic of life. Transversal communications between different lines serve to ‘scramble the genealogical trees’ (Deleuze and Guattari 1988:11). The existence of complex phenotypic traits in organisms has long been recognized as a problem for Darwin’s theory of evolution by natural selection, but recent research in biology seeks to show that the paradigm of symbiosis can be used to explain how novel phenotypic traits can come about through the association of organisms of different species. by the leguminous host (Law 1991:58).The boundaries which ensure the evolution of separate identities begin to collapse and a machinic mode of evolution comes into play.This is a perfect illustration of the rhizomatic evolutionary schema proposed by Deleuze and Guattari, who themselves supply the example of the type C virus with its double connection to baboon DNA and and that of certain domestic cats.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Here we have taking place an ‘aparallel evolution’ in which there is neither imitation nor resemblance. The becoming-baboon which characterizes the cat does not mean that the cat is imitating the baboon, but rather denotes a rhizomatic becoming which operates in the zone of the heterogeneous (a zone of invention as opposed to imitation) and the connection of already differentiated lines: ‘We form a rhizome with our viruses, or rather our viruses cause us to form a rhizome with other animals’ (Deleuze and Guattari 1988 : 10). Or: the organism unbound. Taking machines seriously requires that the autonomy of the machine is de-reified, along with a linearevolutionary model of machine development, in favour of an analysis of complex machinic becomings. Like philosophy, the field of biology is full of born Platonists, but symbiosis shows that the delineation of ‘organic units’, such as genes, plasmids, cells, organisms, and genomes, is a tool of a certain mode of investigation, not at all an absolute or ideal model. It challenges notions of pure autonomous entities and unities, since it functions through assemblages (multiplicities made up of heterogeneous terms) that operate in terms of alliances and not filiations (that is, not successions or lines of descent). The only unity within an assemblage is that of a plural functioning, a symbiosis or ‘sympathy’ (on the importance of sympathetic relationships in creative evolution see Bergson 1983:173–4). An animal, for example, can be defined just as productively in terms of the assemblages into which it enters (man-animal symbiosis, animal-animal symbiosis, plant-animal symbiosis) as it can by standard biological classification in terms of genus, species, organs, and so on.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  When viewed in terms of symbioses a clear establishment of distinct kingdoms is rendered problematic and what becomes important is a ‘machinic’ phylogenetic becoming. Symbiosis also challenges the notion of informationally closed systems, and corresponds to the function of the idea of the ‘rhizome’ in the work of Deleuze and Guattari, in which evolution is removed from the limits imposed by filiation. A rhizome operates as an open system, both entropically and informationally, designating, in the words of one commentator, ‘a constructive feedback loop between independent information lineages’, whether  conventional phyletic lineages, rhizomatic lineages serve to demonstrate the extent to which exclusively filiative models of evolution are dependent on exophysical system descriptions that are simply unable to account for the genuinely creative aspect of evolution (machinic becomings). If the organism is a function of the frame within which the science of biology encodes it, then it is necessary to recognize that the frame captures only a small part of the possible information that assemblages are able to express. A code is inseparable from an intrinsic process of decoding (no genetics without genetic drift, as Deleuze and Guattari pithily express it). Modern work on mutations shows that a code, which is necessarily related to a population, contains a margin of decoding. This decoding takes place not only through the ‘supplement’ that is capable of free variation, but also within a single segment of code that may be copied twice with the second copy left free for variation. In utilizing the notion of a ‘surplus value of code’—codes are always paralogical, always beside—to account for the transferral of fragments of code from the cells of one species to those of another, Deleuze and Guattari insist that this is not to be understood as a process of ‘translation’ (viruses are not translators), but rather in terms of a singular process of ‘side-communication’ (communication d’à-coté’) (Deleuze and Guattari 1980:70; 1988:53).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In accordance with this new model of machinic evolution becoming is to be conceived neither along the lines of a correspondence between relations nor in terms of a resemblance or an imitation. This is not to think becoming but to reduce it to the given. There are no series or stages involved in becoming, whether regressive or progressive. What is actual in becoming is the ‘block of becoming itself’ and not the fixed terms through which becoming passes. This is the force behind Deleuze and Guattari’s idea that ‘becoming is not an evolution’ (ibid. : 291–2; 238).That is, not an evolution if evolution simply denotes descent, heredity, or filiation along an axis of linear or genealogical becoming. 11 The only 11 It should be recalled that in the Origin of Species Darwin’s account of evolution is a theory of ‘common descent’, what he calls ‘descent with modification’, which is genealogical identity in difference. The discussion of matters of embryology and morphology in the final chapter of the book, before the ‘recapitulation and conclusion’, takes place in the context of an examination of ‘classification’: ‘community in embryonic structure reveals community of descent’ (Darwin 1985: 427).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Darwin does not understand genealogy in linear terms, but rather in terms of a ‘branching’ in which ‘all living and extinct beings are united by complex, radiating, and circuitous  veritable becomings present in evolution are those produced by symbioses which bring into play new scales and new kingdoms. Only involution breaks with filiative evolution by forming ‘blocks’ which allow things to pass through and freely become. Involution is difference conceived not on the order of filiation or heredity but excessively in terms of the surplus value of code. Involution is genuine freedom, the rhizome as opposed to the genealogical tree. The model of becoming that the rhizome brings into play has obvious affinities with recent attempts within feminist and postcolonial theorizing to go beyond the genealogical prejudices of an autochthonic politics of identity. Hybridization, however, takes us only so far away from arborescent schemas. Hybrids involve the connection of points, but do not facilitate the passing between points. A point remains wedded to a point of origin.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In rhizomatic-styled becomings becoming denotes the movement by which the line frees itself from the point and renders points indiscernible. Machinic ‘evolution’ refers to the synthesis of heterogeneities, whereas hybridization is still tied to the idea of there being elements that are pure and uncontaminated prior to the mixing they undergo in hybridism.The difference is crucial and enables Deleuze and Guattari to posit ‘ethology’ as a privileged molar domain on account of its demonstration of how the most varied components—from the biochemical, the hereditary and acquired, to the social—are able to crystallize in assemblages that do not respect the distinction between orders. What holds the various components together are ‘transversals’, in which the ‘transversal’ itself is to be understood as the deterritorialized component within the complex adaptive system, that is, as the nonsubject ‘agent’ of the evolution of complexity (Deleuze and Guattari 1988: 336). In this novel conception of ethology the ‘assemblage’ is being privileged over the classical emphasis on ‘behaviour’. This means that we must arrive at a much more complex understanding of ‘evolution’ than is facilitated by the Darwinian emphasis on adaptation to external circumstances, which ultimately rests on a reified and unmediated notion of the ‘environment’. On Deleuze’s ethological model an animal or life-form is never separable from its rapport with the ‘world’ and its relations with it, but that world is never just ‘given’ or simply passively adapted to.‘Evolution’ involves learning. In nature there is invention (technics): ‘Artifice is fully a part of Nature’ (Deleuze 1988a: 124). An originary technics thus informs Deleuze’s socalled Naturphilosophie.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Within philosophy the machine has been classically defined in contradistinction to the organism along the following lines: an organism is a self-organized being in  in its genus, Gattung); a tree produces nothing other than itself, and so preserves itself ‘generically’. By contrast, a machine is entirely lacking in (self-propagating) formative power (fortpflanzende bildende Kraft), and so is unable to self-produce, reproduce, and self-organize. The efficient cause of the machine lies outside the machine in its designer. The only power given to the machine is a ‘motive power’ (bewegende Kraft) (Kant 1974\/1982: section 65).12 On Kant’s model an ‘organized’ being is one in which each part has been trained and disciplined to exist ‘for the sake of the other’, so that all the interacting parts exist for the sake of the whole which is ontologically prior and primary (Kant 1995:60). It cannot be simply a question of inverting the dualism of machine and organism which has structured the history of metaphysics. Rather, the mapping of machines can be constructed in novel ways to the point where the fixity and certainty of techno-ontological boundaries and distinctions begin to de-stabilize and break down in true machinic fashion. The idea that when we speak of living things as machines we are being merely metaphoric also needs to be contested (Emmeche 1994:50), since again such a view rests on little more than an anthropocentric bias, which itself is not ‘natural’ but ‘artificial’, the product of a certain historical formation and deformation of the human animal\/ machine. For all its good sense, this philosophical determination of the machine rests on the privileging of notions of unity and finality that then allows for the strict partition between organismic and non-organismic life.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Dawkins has conceded that the concept of the organism is of dubious utility precisely because it is so difficult to arrive at a satisfactory definition of it. Much depends on the hierarchy of life which we are seeking to establish. To plant biologists, for example, the leaf may be a more salient ‘individual’ than the plant, since the plant is a ‘straggling, vague entity for whom reproduction may be hard to distinguish from what a zoologist would happily call “growth”’ (Dawkins 1982:253). For Nietzsche, the organism is not to be reified as a monadic entity but to be viewed as a ‘complex of systems struggling for an increase in the feeling of power’ (Nietzsche 1968: section 703). 12 Compare Hegel (1970a: 198–202; 1980: sections 256–60), where the constitution of the organism is compared to the constitution of self-consciousness, as that which ‘distinguishes itself from itself without producing any distinction’.This non-machinic conception of the organism as a functional and structural unity resulting from self-organization figures in the work of one eminent contemporary biologist,  Moreover, there are only ‘acentred systems’ (ibid. : 488). The ‘organism’ enjoys a largely semiotic status and cannot be conceived independently of our cognitive mapping of systems and their boundaries. In his 1867 speculations on teleology since Kant, Nietzsche questions the extent to which Kant demonstrates that only organisms can be viewed as ends of nature, arguing that in nature ‘a machine would also lead to underlying final causes’.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Human thought can only reify the ‘eternally becoming’ (ewig Werdende) of life by grasping living things solely in terms of their forms. In an insight that anticipates the Bergsonian-Deleuzian understanding of creative evolution, he argues: our intellect is too dull to perceive continuing transformation: that which it comes to know it names form. In truth no form is given, because in each point sits infinity (Unendlichkeit). Every thought unity (point) describes a line. A concept similar to form is that of the individual. We call organisms unities, as centres of purpose (Zweckcentren). But unities only exist for our intellect. Each individual has an infinity of living individuals within itself.13  In spite of everything Kant seeks to do with the notion of teleology, Nietzsche insists that the standpoint of reflective judgement is utterly whimsical and arbitrary (willkürlich).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The moves Kant makes, in which the end of the ‘real existence’ of nature can only be discovered by looking beyond nature, amounts to a violent (moral) subordination of nature to the human reason. Today, he argues, as we undergo the experience of morality’s self-overcoming (the self-overcoming of the will to truth), we are compelled to recognize that man has become an animal whose existence in the visible order of things appears as ‘arbitrary, beggarly, and quite dispensable’ (Nietzsche 1994: II, section 25). It is no wonder that the issue of teleology so often appears as little more than the refractive influence of provincial human interests. The transhuman imagination does not rest content with anthropocentric prejudices about machines but seeks to devise ways of tapping into their nonhuman enunciation. A philosophy of the machine begins with the contention that the machine ‘is’ not, since it does not exist in itself but only through alienation. As Deleuze and Guattari point out, an abstract machine is destratified and deterritorialized with no form of its own. An abstract machine in itself, that is, viewed from inside according to its intelligible (virtual) character, is neither  physical nor corporeal. It is not semiotic but diagrammatic, operating by matter, not by substance (too hard), and by function, not by form (too unelastic).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In other words, the abstract machine is ‘pure Matter-Function’ that exists independently of the forms and substances it brings into play and distributes. A critique of the machine in terms of a machine’s inability to replicate and reproduce itself does not begin to touch on the problematic of machinic heterogenesis. As Butler points out, it is illegitimate to declare that the red clover has no reproductive system simply because the bee must aid and abet it before it can reproduce. He writes: ‘Each one of ourselves has sprung from minute animalcules whose entity was entirely distinct from our own, and which acted after their kind with no thought or heed of what we might think about it. These little creatures are part of our own reproductive system’ (Butler 1985:211). 14 The notion of machinic evolution, therefore, does not refer specifically or exclusively to human contrivances, gadgets, or tools, but rather to particular modes of evolution, such as symbiosis and contagion, and is not specific or peculiar to the human-machine relationship, since it also speaks of the machine-machine nexus and alterity. The ‘machinic’ is the mode of evolution that is specific and peculiar to the ‘becoming’ of alien life. A machine can only exist through exterior elements.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It thus enjoys an existence in terms of being a complementarity, and not simply in terms of its relationship to human design or a designer. A machine lives and dies in connection with other virtual and actual machines, suggesting ‘a “non-human” enunciation, a proto-subjective diagram’ (Guattari 1992:59; 1995:37). An assemblage works through invention, and does not imply a relationship of anastomosis between its components. Rather, it connects and convolutes things in terms of potential fields and virtual elements, crossing ontological thresholds without fidelity to relations of genus and species (Guattari 1992:56; 1995:35). The logic of life displays an infinite virtuosity, but, in truth, all that is happening is the transformation of seemingly determinate points into indeterminate lines. In his ‘book of machines’ Samuel Butler demonstrates, in an unnerving insight into the animal-machine nexus and the human-machine nexus, how it becomes virtually impossible to declare with any ontological certainty who is the host and who is the parasite. 14 Even this entrenched thesis on machines has been contested by Richard Laing (1979:201–  In an essay on ‘The Organization of the Living’ Humberto Maturana and Francisco Varela set out to define, working from within an assumed non-animistic perspective, living systems as machines. They confess that they are attracted to the word ‘machine’ because of its decisive dynamic connotations.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Entities are defined as unities with the power to reproduce and by their autonomy. ‘Autonomy’ is conceived as the ‘self-asserting capacity of living systems to maintain their identity through the active compensation of deformations’ (Maturana and Varela 1980: 73). This definition succeeds in capturing the essentially cybernetic nature of self-regulating systems in which feedback plays the crucial role. The question, however, is whether in their conception of the machine Maturana and Varela simply take ‘unity’ as given, with an underdefined deformation and ‘reproduction’ being posited in naive and essentialist terms (since things don’t just reproduce themselves). In seeking to define a ‘living system’, Maturana and Varela contend that evolutionary thought has ignored the autonomous nature of living entities. ‘Organization’ is the principle that is best able to account for the ‘unitary character’ of living systems. If living systems are ‘machines’, then they need to be understood in terms of ‘relations’ and not of component parts. Only in this way is it possible to generate the desired notion of dynamism (entelecheia).The usual view of machines is that they are concrete hardware systems, defined by the nature of their components and by the purpose they fulfil in their operations as man-made artifacts.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  But this view says nothing about how they are constituted. Maturana and Varela are concerned with relations, not components; the latter can be any, so it is the organization which is crucial and constitutive. The organization of machines can then be described as autopoietic. Such machines are homeostatic and all feedback is internal to them. What is peculiar to such machines, however, is not this feature but the fundamental variable which they maintain constant. Such a machine is organized as a network of processes of production (transformation and destruction of components) that produces the components which (a) continuously regenerate and realize the network of processes (relations) that produced them through their interactions and transformation; and (b) constitute the machine as a concrete unity in the space in which the components exist. An autopoietic machine, therefore, is one which continuously generates and specifies its own organization through its operation as a system of production of its own components. It does this in terms of an endless turnover of components  static relations, but by the particular network of processes (relations) of production.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The relations of production of components are given only as processes; if the processes ‘stop’, then the relations vanish. Therefore, machines require regeneration by the components they produce. An autopoietic machine has no inputs and outputs, although it can be ‘perturbated’ by independent events which cause it to undergo internal structural change. The claim that autopoietic systems are organizationally ‘closed’ can be misleading if it is taken to imply that these systems do not interact with their environment. Such systems are closed simply in the sense that the product of their organization is the organization itself. Internal changes which take place are always subordinated to the maintenance of the machine organization. A relation between these changes and the course of perturbations which can be pointed to pertain to the domain within which the machine is observed, and not to its organization. An autopoietic machine can be treated as an allopoietic machine, but this will not reveal its particular organization as an autopoietic machine.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  An autopoietic machine, therefore, is one which maintains as constant certain relations between components that are in continuous flow or change, and it is this which constitutes its modus operandi as one of ‘dynamic stability’. The actual manner in which the autopoietic organization is implemented in physical space varies according to the nature, or properties, of the physical materials which embody the structure of the machine in question. Although there are many different kinds of autopoietic machines in physical space, all of them are organized in such a way that any ‘interference’ with their operation outside their domain of compensations will result in their disintegration. Maturana and Varela reach two principal conclusions concerning the machine: firstly, if living systems are machines (physical autopoietic machines), which transform matter into themselves in a manner such that the product of their operation is always their own organization, then the converse is also true: if it is autopoietic, then a physical system is living; secondly, from this, it follows that the distinction between machine (automaton) and living (spontaneous) becomes untenable and must break down. The classic view is that machines are man-made artifacts with completely deterministic properties and perfectly predictable. Contrariwise, living systems are deemed to be a priori autonomous, unpredictable systems. The prejudice is that man could not manufacture a living system but ‘only’ a machine. As a result of these redefinitions, however, certain distinctions begin to break down and certain prejudices get supplanted.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  self-referential, self-reproductive monadic entity rests on an opposition between pure autonomy (self-maintenance and self-preservation), on the one hand, and impure heteronomy (invasion) on the other. They do not see that a genuinely machinic thinking of the ‘entropy\/evolution’ problematic must lead to a corrosion of molar-organized unities and identities, leading to the construal of a fluid relationship between ‘inner’ and ‘outer’, between autonomy and heteronomy, and between nature and artifice. Autopoiesis cannot allow for transformation except in terms of a highly restricted economy, presenting us with a stark either\/ or choice: either entropy or perfect performance. It is guided by a whole conservative metaphysics of living systems, and presupposes a paranoid machine. This is evident in the emphasis it places on systems as closed and recursive unities that are guided by, above all else, the maintenance of stability. To claim, as they do, that organization is an invariant of a component system is to equate change with simple destruction, and to render organization as something ‘over’ physical reality rather than ‘to’ it. In contradistinction to Maturana and Varela, Vilmos Csanyi and George Kampis maintain that if new components endowed with new functions come into existence in a system, then the organization of that system cannot remain invariant. Moreover, change in a system’s organization, as a result of the emergence of new components, does not result in the disintegration of that system.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  This must mean that the ‘autonomy’ of the individual organism is ‘always relative’ (Csanyi and Kampis 1985:306). For them the main problem with an autopoietic model of evolution is that it fails to appreciate that if a system were to be driven by the desire for perfect autonomy it would get trapped in an evolutionary deadlock, unable to form further relationships and connections. Exactly the same point was made by Bergson, in the context of a different debate, who argued against a vitalist position which rested on the assumption that nature evolved in terms of a purely internal finality and absolutely distinct individualities (Bergson 1983:42). It is impossible, he argued, to determine with any degree of fixity where the vital principle of the ‘individual’, or autonomous machine, begins or ends. In the three sections of ‘The book of the machines’ which make up his fiction Erewhon of 1872 Samuel Butler challenges the way in which lines are drawn between machinic life and animal life: Where does consciousness begin, and where end? Who can draw the line? Who can draw any line? Is  As Deleuze and Guattari argue, Butler’s reflections do not simply contrast two common arguments, one according to which organisms are only more perfect machines, the other according to which machines are never more than extensions of the organism.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Butler is not content merely to claim that machines extend the organism (the pre-established unity), or that organisms are machines; rather he wishes to show that (a) the field of evolution is thoroughly machinic from the outset, and (b) organisms can be compared to machines in terms of the sophisticated engineering which integrates their distinct parts (desire is engineering) (Deleuze and Guattari 1972:337–8; 1983:284). As a result, Butler destroys the vitalist argument by calling into question the alleged personal unity of the organism, and, by the same token, he undercuts the mechanist position by calling into question the alleged structural unity of the machine. If ‘life’ can be conceived along the lines of a ‘desire-engineering’, then there can be no pre-established boundaries and no fixed determination of what constitutes the parameters and identities of individuated entities, such as organisms or machines. The mistake is to view complex machines as single entities whose individuated existence is pre-given. In truth, every complex machine, Butler maintains, is to be regarded as a city or society. Like organisms, machines reproduce themselves through an integrated network of co-evolution (as in the well-known example of the red clover and the bumble bee). Butler’s reasoning forces us to question the fixity of Kant’s distinction between motive and formative powers. In Deleuze and Guattari’s terms the motive power of the technical machine requires the formative power of the social machine for its actualization and reproduction.The human animal enjoys no autonomy from nature and from technics.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Like everything else it too is caught up in the ‘surplus value of code’, which denotes an excess that refers to a process when a part of a machine captures within its ‘own’ code a code fragment of another machine, and, as a result, owes its reproduction to a part of another machine. It is thus the always excessive desire of machinic becomings that deterritorializes the evolutionary lineages of all phenomena, and which enables us to privilege alliances over filiations, heteronomous assemblages over autonomous entities. It becomes possible to appreciate the compound nature of Deleuze and Guattari’s formulation ‘desiring-machines’, in which the machine passes to the heart of desire and the machine is desiring desire,‘machined’:‘Desire is not in the subject, but the machine in desire.’ Desiring-machines are truly formative machines, but whose formativity is possible only through functional misfirings; that is, formation requires deformation, and what makes evolution a machinic process is the fact that  and force us to lose sight of the multitude of small machines which are dispersed in every organism, which itself is no more than ‘a collection of trillions of macromolecular machines’ (Dennett 1995b: 206). Ultimately, at the point of ‘dispersion’, where techno-ontological boundaries break down, it becomes immaterial whether one describes machines as organs or organs as machines: ‘A tool or a machine is an organ, and organs are tools or machines’ (Canguilhem 1992:55). Canguilhem also points out that the mechanistic conception of the body posited by Cartesianism is no less anthropomorphic than a teleological conception of the physical world. He shares Nietzsche’s view that machines can be considered to be purposive in their endeavour and activity. Indeed, ‘man’ is only able to make himself the master and proprietor of nature to the extent that he denies any finality or purpose to what lies ‘outside’ him, such as nature or machines, which are then treated solely as means to serve his hubristic Zwecken. Nature and technics take their revenge when the realization dawns that the entire evolution of what we take to be ‘spirit’ is, in actuality, the becoming of something altogether different than what appears in consciousness and reason, namely, the body: ‘In the long run, it is not a question of man at all, for he is to be overcome’ (Nietzsche 1968: section 676).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  So far in this book we have seen the extent to which Nietzsche does not think this overcoming in terms of the abolition of the human but rather only in terms of the destruction of its anthropocentric determination as the superior point of evolution. If the idea of autopoiesis is to retain any useful function it has to be thought in relation to entities which are evolutive and collective, and which sustain diverse kinds of alterior relations, as opposed to being implacably closed in upon themselves and maintaining their autonomous existence at the expense of casting out and dissipating anything external that would contaminate their inner purity (the machine as beautiful soul). In the case of the machine, entropy and evolution need to be viewed as co-extensive and mutually informative. The ‘man-machine alterity’ is inextricably linked to a ‘machine-machine alterity’. As Guattari points out, machines already ‘talk’ to each other before they talk to us.The reproducibility of machines is not a pure, programmed repetition, but precisely an evolution. Difference is introduced at this point of breakdown\/evolution and is both ontogenetic and phylogenetic. There is no simple or straightforward univocal historical causality since evolutive lineages present themselves as ‘rhizomes’, meaning that ‘datings’ are not synchronic but heterochronic (on the crucial role played by heterochrony in  associative becoming. Such becomings take place ‘in’ history but are not reducible to, or identical with, it.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Guattari has rightly insisted that the question of the ontogenetic evolution of the machine, for example, is not reducible to the ‘linear causalities of the capitalistic apprehension of machinic Universes’ (1992:79; 1995:52). In machinic heterogenesis it is less a question of the identity of a being that retains its heterogeneous texture while traversing different regions, and more of an ‘identical processual persistence’. One is speaking neither of a Platonic whole nor of an Aristotelian prime mover, but rather of transversal creatures that ‘appear like a machinic hyper-text’ (Guattari 1992:151; 1995:109). Guattari’s insight into this universe of machinic heterogenesis requires a fundamental reconfiguration of ontology. An ontology informed by an appreciation of the machine would not place qualities or attributes as secondary in relation to substance, nor would it conceive of being as a pure and empty container of all possible modalities of coming-intobeing. Rather, it would conceive being as first and foremost ‘auto-affirmation’ and ‘auto-consistency’ which actualizes itself through virtual and diverse relations of alterity. This would mean that we would cease viewing existence-for-itself and forothers in terms of the privilege of one particular ‘species’, such as mankind, and appreciate that everywhere ‘machinic interfaces engender disparity and, in return, are founded by it’ (ibid. : 152; 109).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  ‘Being’ ceases to be a general ontological equivalent and becomes modelled along the lines of ‘generative praxes of heterogeneity and complexity’ (ibid.). Evolution by symbiosis—the vitality of viroid life—and rhizomatic becomings constitute an essential part of this heterogeneity and complexity. In terms of the question of technology, there is no reification of technical machines in the work of Deleuze and Guattari since they readily appreciate that technical machines are only indexes of more complex assemblages that bring into co-evolutionary play material-forces in which the role played by the social machine is decisive. One is not ‘oppressed’ by a technical machine but by a social machine which determines at any given moment what is the usage, extension, and comprehension of technical elements (compare Braudel 1981:431: ‘there is no technology in itself’).Technical machines are not an economic category but always refer to a socius or social machine that is distinct from them. This is akin to Marx’s view that machinery is no more an ‘economic’ category than is the ox which draws the plough. Deleuze and Guattari insist that assemblages are never  one commentator has noted, in relation to the new cybernetic machines, in no arena will the technologies themselves be determining (Nichols 1988:45). In other words, questions concerning cybernetic technology can only be adequately attested to when they are articulated in terms of a social theory of the micro-physics of power. One of the reasons given for the primacy of the social machine by Deleuze and Guattari is that technical machines do not contain the conditions for their reproduction, but require the social machine to organize and limit their development.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  There is no attempt made in their work to crudely biologize the technical-social; both a biological reading of human history and an anthropological reading of natural history must be avoided since the dangers of either strategy are all too obvious. The social is already artificially biologized. The terms of political theory, for example, are terms of capture and regulation, in which the evolution of societies is referred to as ‘embryonic’, ‘nascent’, ‘underdeveloped’, and that of third world societies as ‘foetuses’ and ‘abortions’ of culture and civilization. In challenging the reified conception of the organism found within a variety of discursive practices one is not advocating a retreat into a pre-social biosphere, but rather presenting a challenge that operates on myriad fronts. A politics of desire —the machinic assemblage of new solidarities and formations—comes into play when it is recognized that technocracy and bureaucracy (the functioning of the social machine) can never be reduced to being simply the operation of technical machines along the lines of a perfectly run cybernetic machine. In the 1960s Vaneigem argued that, ‘by laying the basis for a perfect power structure, the cyberneticians only stimulate the perfection of its refusal. Their programming of techniques will be shattered by the same techniques turned to its own use by another kind of organization’ (Vaneigem 1994a: 85). In truth, the situation is now infinitely more complex than the likes of Vaneigem could ever have entertained, since the ‘outside’—virtual futures of all kinds—has been captured.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Capitalism, having embarked upon a programme of endocolonization, has become a futures market on every level one cares to think. ‘Nothing is true; everything is permitted’ is no longer the slogan of the revolutionary nihilist but that of established powers of capture. The revolution will be televised (and already has been). This is the force, for example, behind Umberto Eco’s astute insight into (post)modern terrorism: terrorism is not the enemy of the great systems but their natural counterweight, both accepted and programmed (Eco 1986:116). If the great systems function as headless systems, having no protagonists and not  making hard work for the computers that run the place’ (ibid. : 115). It is no longer sufficient to ponder Marx, he suggests; one must also ponder Norbert Wiener. Capital renders Marx’s great insight into history null and void: the history of all hitherto existing society is the history of class struggle except for the ‘history of (late, always late) capital!\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Forever the great cynic, capital cannibalizes all negativity, ‘parodistically going beyond its own contradictions’ (Baudrillard 1994:52). Technology’s powerful illusion of independence is part of its immense entropic and imperialistic success: the essence of technology is nothing technological, but it appears as if it is.15 Fetishism of technology is an essential— and vital—part of capital’s transcendental illusion. But the social definition of what is technologically feasible or desirable is not external to technology but intrinsic to it. A distinction between the ‘economic’ and the ‘technological’ is arbitrary and unintelligent (see Hornborg 1992). Capitalism rests on a particular conjunction of technical and social machines. As a distinct social formation it functions by turning the technical machines into constant capital attached to the body of the socius (as opposed to ‘human machines’, which are made adjacent to the technical machines). The social axiomatic extends its limits through the ‘non-technical’ means of administration and inscription. Culture works as a mechanism of selection, inventing through inscription and coding the large numbers—organisms and complete whole persons—in whose interests it acts.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  This explains why ‘statistics is not functional but structural’, concerning ‘chains of phenomena that selection has already placed in a state of par tial dependence…. This can even be seen in the genetic code’ (Deleuze and Guattari 1983:343). The State exists to regulate the decoded flows unleashed by the schizzo-tendencies of capitalism. While capital melts down everything that is solid and profanes all that is holy, bourgeois society guarantees that the productive forces of change are rendered 15 This illusion of the autonomous character of technical development is exposed in an instructive ‘critical’ fashion by Habermas (1987:57ff. ), who argues that ‘technology’—conceived as scientifically rationalized control of objectified processes—be taken to refer to a ‘system’ in which research and technology are coupled with feedback from both the economy and from modern social administration. As one of the few attempts to develop a ‘politics’ of technology and a ‘democratic’ technics, Habermas’s inquiry remains an apposite one in the face of the contemporary depoliticization of questions concerning technology and technics. As Habermas  equilibrial through the territorially fixed and juridically invariant structure of the modern State (Balakrishnan 1995:56–7) (and news of its death is premature). Moreover, through State regulation and control the decoding practices of science and technics are subjected to a social axiomatic that is more severe than any putative ‘scientific’ axiomatic.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The social and cultural revolution of postmodernity is about the potential liberation of technical machines from monopolistic and scientistic control by the molar forces of capture that characterize the modern capitalist State, a bifurcation point at which capitalism is no longer able to monopolize for itself technical machines as the constant capital attached to its social body. The critical task of an alien thought-praxis, therefore, can only be that of decoding and deterritorializing the prevailing administrative and regulatory machines—in the State, in philosophy, in science, in culture and information— that have defined and restricted the present by despotically blocking the free flow of energy and knowledge throughout the social machine. Grand narratives, it would seem, are coming back in fashion, and with a vengeance, assuming a distinctly inhuman character, in which we are offered a plethora of apocalyptic scenarios concerning an alleged phase-space transition to a new, ‘higher’ level of evolution based on machine intelligence, resulting in a genetic take-over of carbon life by soft machines (robots and computers) (for two accounts of our neg-entropic destiny from vastly different thinkers, see Lyotard 1991 and Tipler 1995). But this depiction of neg-entropic destinies, in which the human plays the role of a mere conduit in the inhuman process of complexification, can only provide simple options that are not options at all, such as a retreat into a new ethical purism (mourning the event, bearing testimony to the Event), futile Ludditism, or vacuous cyber-celebrationism. The dangers in conflating biology and technology are immense. Today palaeoanthropologists speak of life on earth taking place in terms of the evolution of techno-organic life that has cultivated positive feedback loops between ‘intelligence’ and biology resulting in an accelerated evolution, with the increasing hegemony of artificial life over natural life being understood as a Lamarckian invasion and take-over of so-called dumb and blind Darwinian natural selection (see Schick and Toth 1993:315–16). A new mythology of the machine is emerging and finds expression in current claims that technology is simply the pursuit of life by means other than life. 16 This  dubious neo-Lamarckism, which reaches an apogee in Kevin Kelly’s assertion that the advantages of a Lamarckian style of evolution are so great that nature herself has found ways to make such an evolution possible, is not only philosophical idiocy but also politically naive, resting on a highly vertical and perfectionist model of biotechnical evolution.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  He constantly speaks of ‘what evolution really wants’, as if one could easily speak of ‘evolution’ in terms of a global entity, as in the following gross assertion: ‘Evolution daily scrutinizes the world not just for fitter organisms, but to find ways to increase its own ability…. Evolution searches the surface of the planet to find ways to speed itself up, to make itself more nimble, more evolvable— not because it is anthropomorphic, but because the speeding up of adaptation is the runaway circuit it rides on’ (Kelly 1994:361). Such ‘searching’ on the part of evolution, we are told, results in the human brain providing the ‘answer’ to the problem of how evolution can gain the complexity necessary in order to peer ahead and ‘direct evolution’s course’. In the process of this ridiculous anthropomorphism questions concerning the utilizations and abuses of A-life and bioengineering for life are rendered completely uninteresting, since, as Bergson would have put it, ‘all is given’. In effect, what is happening in this kind of depiction of evolution is a blind, and dumb, reading of the dynamics of contemporary hyper-colonistic capitalism— Kelly’s identification of speed with simple acceleration illustrates this—back into the mechanics of the biosphere, resulting in a biological justification of entropic modernization in its most imperialistic guise (speed is irresistible).17 There are other reactive forces at play in recent paeans to the rise of machine intelligence. As Baudrillard has pointed out, having lost our metaphysical utopias we now build prophylactic ones in which our immortality is guaranteed (you can download your brain!). If in the past it was the dead who were embalmed for eternity, today it is the not in any sense replace life.’ This so-called postmodern thesis on the machine was captured in its essential import by Samuel Butler in his strikingly titled essay ‘Darwin among the Machines’ of 1863, where he poses the question concerning the machine in quasi-Nietzschean terms, posing it as a question about ‘the sort of creature’ that will succeed man in the supremacy of the earth. His concluding opinion, not surprisingly, was that ‘war to the death should be instantly proclaimed against them’.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  See Butler 1914. What perturbs Butler is the recognition that while machines have proved to be an indispensable aspect of human existence— ‘man’s very soul is due to the machines; it is a machine-made thing’, he writes—in the future hegemonic evolution of machine intelligence the human may prove to be utterly dispensable as  living who are being embalmed alive in a state of survival (life owes me a right not to die!) (Baudrillard 1994:87–8). At present what we are witnessing within the discernible logic of postmodernity is a transition from the thermodynamic machines of industrial capitalism to the cybernetic machines of contemporary information societies that govern through intelligent control. But this is still a mutation within entropic (post)modernity in which the development of new forces of production outstrips existing relations of production but in no way guarantees their radical transformation or liberation from social control and molarization. Society—and ‘we’ who exist outside—are becoming more like snakes every day. Did the ‘political’ die with the collapse of the great empires, including the great empires of thought (-control)? Today the life of the great empires has assumed a retroviral form, fragmented and peripheral, genetically infecting their wastes and by-products, their basic cells and ugly growths, no longer on the order of the political but of the transpolitical whose passion, notes Baudrillard, is that of the interminable work of mourning, lost in ‘the melancholy of homeopathic and homeostatic systems’, in which evidence for the death of the political is impermissible since it would ‘reintroduce a fatal virus into the virtual immortality of the transpolitical’ (Baudrillard 1994:51).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Postmodernity (human, all too human) spreads the virus of voluntary servitude, an ‘ecological micro-servitude, which is everywhere the successor to totalitarian oppression’ (and how green were those Nazi valleys). There is only the contagion of technics and the freedom of becoming imperceptible, invisible, and ignoble (learn to growl, burrow, and distort yourself). 6 TIMELY MEDITATIONS ON THE TRANSHUMAN CONDITION Nihilism, entropy, and beyond  In the investigation of nature, human reason is not content to pass from metaphysics to physics; there lies within it an instinct (which, though fruitless, is not inglorious) to transcend even the latter, to fantasize in a hyperphysics. (Kant 1995:17) Once more we are seized by a great shudder, but who would feel inclined immediately to deify again after the old manner this monster of an unknown world?… Alas, too many ungodly possibilities of interpretation are included in the unknown, too much devilry, stupidity, and foolishness of interpretation—even our own human, all too human folly. (Nietzsche 1974: section 374) It may be that believing in this world, in this life, becomes our most difficult task, or the task of a mode of existence still to be discovered on the plane of immanence today… (we have so many reasons not to believe in the human world; we have indeed lost the world …). The problem has indeed changed. (Deleuze and Guattari 1994:75) History as contingency is a prospect that is more than the human spirit can bear. (Heilbroner 1994:77)  1.Today, one might suppose, it is not so much we who are investigating the future as the future which is investigating us.The future appears to have announced its arrival in a hundred and one signs.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  If the Messiah arrived he would go unrecognized not simply because his arrival would be belated, but more because the flash of the future  hard-bodied plants and animals in the Phanerozoic aeon, suffers from what we might call a Cambrian chauvinism. A less anthropocentric timeline might fix it as one thousand and seven hundred million years ago, during the Proterozoic aeon, with the earliest appearance of eukaryotes and the birth of speciation. No doubt this attempt to determine the future is beside the point. One of the reasons why we are so blinkered about the future and its coming is the fact that we indulge in a highly anthropocentric meditation on the time of technology.When that perennial species, Luddites, declare that they are ‘not into’ technology, they need to be reminded that it is not so much a question of their personal likes and dislikes, but much more a question of technology being ‘into’ them. It is necessary to get the question of technology into some kind of perspective. The universe offers a comprehensive system of technics and technology, while humanity has discovered ways of employing and exploiting it. As Ernst Jünger pointed out in his 1932 study of ‘The Worker’, humanity oscillates between conceiving itself as the apprentice of a sorcerer that has conjured up powers beyond its control and as the creators of an unstoppable progress that hastens towards artificial paradises (Jünger 1982). The human fantasy is to devise a technological system so omniscient that it nullifies the power of the future, transforming the universe into a perfectly administered megamachine of predictable outputs and calculable energies.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Technology, we like to think, holds the ‘promise’ of a life lived in pure immediacy and total transparency. The task is now one of knowing how to cultivate a critique of this hell in which life is being lived ‘beyond’ illusion. As we continue to labour under what Baudrillard has called the ‘subjective illusion of technology’, we fail to identify the true ironic character of technology’s coming.1 For Baudrillard such a proposition delivers us from the Heideggerian vision of technology as the final phase of metaphysics, and from any nostalgia for Being and from all unhappy critique based on outmoded notions of alienation and disenchantment (Baudrillard 1996:83). If it is more a question of technology inventing the human than it is a question of humans inventing technology, then it is necessary to take this invention seriously. 2. The time of technics always exceeds itself because it is a time of invention (of the future, of time itself). In raising the question of technology, one wonders whether Heidegger is talking about about the invention ‘of’ technics at all (in spite of his employing the German die Technik), or simply about the human world of  technology that has become estranged from, and foreign to, mankind and now appears as something that is tremendously inhuman. The question of technology would appear to have little to do with the complex evolution of technics, and more to do with the control and mastery of all kinds of techniques for the purposes of human preservation and the political control of the flow of material-forces.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  To maintain that technology is making us ‘less human’ is to suppose that there exists some fixed nature of the human by which one could measure the excesses of technology, and so appraise its inventions in terms of some metaphysical cost-benefits analysis. Heidegger’s thesis that in order for the ‘truth’ of technology to be revealed it is necessary that mankind finds its way back to the full breadth of the space that is proper to its essence (Wesensraum) would appear to underestimate massively the extent of technology’s invention of the human animal and the nature and extent of its investment in mankind (Heidegger 1991a).2 Heidegger’s own mistake was to argue that the production of machines, which he recognizes is not identical to technics, exists to ‘realize’ the ‘essence of technics in its objective raw material’. The ‘essence’ of technics here refers to the desire of technology for total mobilization and control. But this desire for control can be recognized as a human, all too human desire, actualized within specific social formations and modes of production. Heidegger’s questioning of technology contains its own strange irony. In seeking to invert our instrumentalist and anthropocentric questioning of this event by construing it not as the invention of man but as a gift of Being, he turns the human into little more than an ‘instrument’, a mere organ of the time of technology, so that mankind is sacrificed on the altar of self-withdrawing Being. ‘Being’, we are told, ‘has sent itself into Enframing.’ All the voluntarism that Heidegger takes away from ‘man’ is now given back to ‘Being’. It is not surprising that he should reach the position he did: only a god can save us.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  3. Any thinking of the future would seem to be necessarily implicated in questions of theology and teleology, with questions of first and last things. It seems peculiar to our so-called ‘postmodern’ age, however, that whereas we have abandoned concern with the former (nothing is more intellectually discredited today than the question of origins), it cannot completely eschew the latter. The most radical 2 This separation of mankind and technology, which rests on the supposition that mankind  embracement of our current inhumanization can thus read like an upturned version of the Hegelian ascent to the Absolute, the absolute knowledge which, ever since Adorno, has proclaimed the horror! the horror!, now screams the delight! the delight! When it confronts the inside that comes from outside and invades its domain—the future—the human goes beyond itself and becomes subject to strange experiences and thoughts of the transhuman. The attempt to map the future is not a pastime peculiar to futurologists.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It has been a preoccupation of thinkers ever since nihilism started knocking on the door. In the case of modernity, this can probably be dated back to Kant. Nietzsche’s pithy claim that Kant believed in morality not because it is demonstrated in nature and history, but rather in spite of the fact that nature and history continually contradict it remains one of the most disturbing, but perplexing, insights into the character of our modernity. If the morality of a kingdom of ends cannot be located in history —and where else can it materialize?—then it becomes necessary for Kant to show how it is possible to read history as a story of a possible moral progress, an open-ended progression towards morality. All the resources of the human intellect and knowledge are to be garnered to ensure that we do not begin to gloat on the realization that history—the story of the becomingsick of the human animal—is utterly beyond redemption, that it is the site of ungodliness and immorality.3 This does not necessarily cancel the moral project, but it does call for its thorough revaluation, especially once the autonomy of the human is called into question. 4.The idea of a ‘philosophy of history’ is one of the strangest to emerge in modernity, suggesting, as it does, against all evidence to the contrary, that history is not a completely irrational, amoral, and purposeless affair, what Nietzsche calls the gruesome dominion of nonsense and accident, the great ‘monstrous fortuity’ (Nietzsche 1966: section 203). Rather, nature contains a hidden plan, and reason assumes a cunning disguise in history, working behind humans’ backs, deploying evil in the service of the ultimate triumph of good, making humans slaves of history in order finally to make them masters of it, and containing the promise of the ultimate conquest of that senseless beast called history and leading to the constitution 3 See Nietzsche 1968:12A; 1987, volume 13:46ff. : ‘Nihilism, then, is the recognition of the long waste of strength, the agony of the “in vain”, insecurity…being ashamed in front of oneself, as if one had deceived oneself all too long.This meaning could have been the “fulfilment” of some highest  of a thoroughly humanized world.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Kant’s presentation of the ‘idea’ of a ‘Universal History’ is deeply paradoxical. The human species likes to think of itself as the superior design of nature. However, Kant concedes that this intelligence is, in fact, thoroughly stupid, and, consequently, all the intelligence guiding history must be ascribed to nature and its hidden plan. If mankind is to become the purpose and goal of history it will only be the as the result of an inhuman force (nature), and not on account of human intentions or designs. In other words, mankind’s ultimate humanity can only be actualized through a process of inhumanization (Kant 1991:41– 2). In Kant the emphasis is placed on nature and its concealed plans for man’s perfection, which also represents at the same time the perfection of nature. Actual history encourages revulsion and a turning away, while philosophical history may be more than a work of fiction. What is weird about Kant is not his attempt to posit a noumenal reading of history, but rather his belief that the signs of this hidden becoming of history can be interpreted so as to conform to the will and wishes of a moral humanity.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Informing his thinking on nature’s design for mankind, which partly includes her invention of mankind, is a particular conception of evolution, one which stands at odds with the functional indeterminacy embraced by both Darwin and Nietzsche. Kant insists that an organ ‘which is not meant for use or an arrangement which does not fulfil its purpose is a contradiction in the teleological theory of nature’. If this principle is abandoned then we replace not only a lawgoverned nature but a nature that enjoys and knows purposes, including final ones, with an ‘aimless, random process, and the dismal reign of chance replaces the guiding principle of reason’ (ibid. : 42).4 Contingency is simply a truth too awful for the philosopher to bear. 5. It is this moralization and humanization of the forces of life that has characterized the imagination of modernity and that now strikes us as naively critical. The real danger lies in supposing that nihilism can be overcome through the reassertion of human will and autonomy over the recalcitrant heteronomous forces of nature and history. This has been the great myth of much critical modern thought, perhaps nowhere better illustrated than in Raoul Vaneigem’s Revolution of Everyday Life, in which a total transcendence of nihilism is envisaged in terms of a great refusal that breaks history into two, pogroms before and a new innocence afterwards, leading to the establishment of a non-alienated body and a thoroughly human time and  humanized world (Vaneigem 1994a: 179).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Speculating on the possibility of investing the cosmos with a human meaning, Vaneigem fantasizes, in a distintly Rousseauesque fashion, about history resulting for the first time in the achievement of a genuine ‘people’ and a new form of social organization in which ‘all the individual creativity will have free rein, so that the world will be shaped by the dreams of each, as harmonized by all’ (ibid. : 219). The task now, he claims, is ‘to subvert history to subjective ends’ (ibid. : 232). History will become authentically lived history when human action becomes transparent to itself. Not only is this so-called libertarian situationist philosophy of life saturated in a vacuous subjectivism, inane demands for absolute inalienable human rights over life, and metaphysical infantilism, but it is destined to result in a highly authoritarian politics, which indeed becomes clear with the publication in the 1980s of Vaneigem’s The Movement of Free Spirit (1994b: introduction). If Vaneigem’s Rousseauian-inspired moralism was concealed in the ‘Revolution’ book of the late 1960s, which did at least strive towards some dialectical comprehension of the antinomies of the present broken condition, its moral fanaticism is now all too apparent. The thesis of the book is frighteningly simple: the market economy is the evil destroyer of all human value and dignity, and it can only be fought against in terms of an ethics of love.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  ‘I take the demands of love’, Vaneigem writes, ‘to constitute entirely, at all times and in all places, the sole alternative to market society.’ This passage provides unequivocal evidence of the absolutism of Vaneigem’s position (‘entirely’, ‘at all times’, ‘the sole alternative’, etc.). He speaks naively of an authentic human species creating, contra the market, conditions favourable to its own harmonious development; and, finally, he advocates his own back to basics programme as a solution to the ills of the market, claiming that beneath the rubble of lies and fraud, late-modern citizens are beginning to re-experience and revalue some ‘plain truths of the distant past’. His nostalgia for all things palaeolithic leads him to the claim that economics ‘has been the most durable lie of the approximately ten millennia mistakenly accepted as history’. His commitment to harmony and static equilibrium not only belongs to a historically redundant theoretical paradigm— the entropic one of modern critical theory—but also reveals a deep hatred of history, becoming, life, etc. In the face of the marketization of the entire globe, his opposition has about as much practical value and relevance as a recommendation to the Eskimos that, in the face of global warming, they should take up habitation on Venus. The implementation of this green vision of life would require a highly  6. Viewed from a post-historical perspective, Guy Debord’s Society of the Spectacle now reads as a paradigmatic example of a classically modernist interpretation of the inhuman time of capital and technology. Looking back in 1988 on this work of 1968, Debord claimed that what he had revealed in his analysis of the spectacle— a kind of Marxian application of Heidegger’s thesis on das Gestell—was a gradual waning of the sense of history.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  This concern with the atrophy of historical transcendence has been a common feature of the various strands of critical theory since at least 1945, reaching an apogee in the works of Debord and Marcuse, and present also in the work of Lewis Mumford and his neglected classic of 1957, The Transformations of Man.5 The society of the spectacle denotes the ‘autocratic reign’ of the market economy which has acceded to an ‘irresponsible sovereignty’. In the spectacular society life is no longer lived immediately and resonantly, but has become detached, mediate, and illusory (it has, says Debord, become philosophical). Everything which hitherto had been lived directly has now moved into the domain of representation. We now live in a reality that is quickly becoming completely virtualized. As the concrete inversion of life, the spectacle is the ‘autonomous movement of the non-living’. In conformity with Marx’s analysis of commodity fetishism, Debord maintains that the spectacle does not constitute a collection of images, but rather denotes a social relation between people whose existence is mediated by reified images. Grasped in its totality it is both the result and the project of the current mode of production. It is not to be treated as a supplement to it, which would be to take it as merely decorative, but is to be analysed as the very heart and soul of ‘unrealism of the real society’.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In its own terms the spectacle represents an ‘affirmation of appearance’, of all human life as nothing but an appearance, amounting to the end of history as a history of depth. The spectacle is like a virus, spreading everywhere and infecting everyone who becomes contaminated by its illusion, and whose only goal is self-perpetuation. This autonomous self-reproduction of the economy is ‘the true reflection of the 5 Frederic Jameson defines postmodernism (the cultural logic of late capitalism) as a crisis of historicity in which people’s capacity for historical praxis—the activity of being subjects and objects of their own destinal making—has been completely nullified by the world space of multinational capital (Jameson 1991). But post-historic man was already being described as a ‘defective monster’ in the 1950s by Lewis Mumford. Jameson provides some useful and original cognitive mapping into the realities of our technological futurism in his tour de force of an essay on ‘Totality and Conspiracy’ in  production of things, and the false objectification of the producers’ (Debord 1983: paragraph 16). ‘Spectacular technology’ does not dispel the religious clouds under which mankind has led an alienated existence, but merely provides it with an earthly cloak. ‘The spectacle is the technical realization of the exile of human powers into a beyond; it is separation perfected within the interior of man’ (ibid. : 20).The critique which exposes the shallow truth of the spectacle, claims Debord in a moment of privileged insight, reveals itself as the total negation of life.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  With Debord we find ourselves once again in a Manichean universe, an absolute moralism and humanism confronting an equally absolute immoralism and inhumanism, with history and life posited as unmediated, estranged forces: the demon of history doing battle with the angel of life. 7. It is the forces of production that are responsible for inaugurating the time of history. History has always existed, but not in a historical form. The coming of history amounts to nothing less for Debord than the humanization of time: ‘the unconscious movement of time manifests itself and becomes true within historical consciousness’ (ibid. : 125). Debord notes that it is the bourgeoisie who perform a revolution of time by subjecting it to a law of perpetual change and innovation (as Marx said, bourgeois society can only exist through the constant revolutionizing of the forces of production). Historical time is not the time of being but the time of auto-production.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In an agrarian economy the coalesced forces of tradition which fetter all movement are nourished by a cyclical time. By contrast the irreversible time set into motion by the bourgeois economy eradicates all vestiges of tradition around the entire globe. ‘History, which had seemed to be only the movement of individuals of the ruling class, and thus was written as the history of events, is now understood as the general movement, and in this relentless movement individuals are sacrificed’ (ibid. : 141). The unfolding of economic time means that mankind is subjected to the ‘time of things’, the mass production of objects produced according to the law of the commodity. The result is a daily invention of history but also of a loss of lived time. However, this history is not historical, merely the repetition of the same, an ‘abstract movement of things which dominates all qualitative usage of life’. Debord counters this abstract and inhuman movement of history with the positing of a subject of history as the subject ‘of’ historical time, in which the nonalienated self-constitution and praxial transformation of the worker are pitted against the alienated and automatic objectification of the commodity form (don’t you  proletariat seizes control of the forces of history, and in the process transforms the invention of history brought into being by the bourgeoisie.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  If it was the destiny of the bourgeois class to unleash historical time into the rhythms of material existence, it is now the destiny of the working class to humanize this inhuman unleashing by assuming its rightful ownership of, and control over, it. 8. This thinking on time and history is suffused with a metaphysics of authenticity and inauthenticity. The worker, according to Debord, desires not only to make or produce historical time, to be immanent in himself, but to live the time it makes and produces. The ‘particular’ time of the bourgeoisie, which masquerades as the ‘universal’ time of the globe, will be replaced by the genuinely authentic time of the worker (echoes of Jünger in Debord—as in Heidegger, Marcuse, and so on). Spectacular time is inauthentic, the time of the commodity that exists in a consumable pseudo-cyclical time of repetition. Authentic time denotes the time in which, or ‘of which, history is simultaneously made and lived (it is not alienated history). The existence of the spectacle serves to remind us of the false consciousness of time, of a time that is not immediate and transparent to the subject who makes history.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Debord writes poetically of the prospects for a new proletarian dwelling in which communism offers the promise of the ‘total realization’ of human time. The ruse of history is that that which threatens this ‘twilight world’ is also ‘the force which could subject space to lived time’ (ibid. : 178). Debord ends his anthropocentric speculations on the fate of history and geography by speaking of the ‘historical mission of installing truth in the world’, a truth that can only be fulfilled when individuals link themselves up with the progressive forces of history. God may have been dead for Debord, but he was keen to resurrect his bloody spirit in the guise of a lordly humanity ruling over not only history but the entire evolution of life. 9. In a recent incisive analysis Regis Debray has compared Debord’s manifesto on the society of the spectacle to the posture of the Young Hegelians. He persuasively brings out the striking parallels between Debord’s depiction of the spectacle and Feuerbach’s critique of religious illusion in his Essence of Christianity of 1841, showing that, other than for the detail of phrasing, the discourse of Situationism follows word for word a Hegelian track of alienation, objectification, negation, and reversal, culminating in a reversal of the reversal.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In the hands of Debord, Debray notes, the tradition is kept safe. Following a ‘recognition’, a reversal of the reversal, humans  failure—a failure he has in common with the broad current of humanist Marxism— to grasp the ‘technogenesis of the human’ (it is the lack of origin that lies at the origin of mankind’s making).The theological postulate of a human essence continues to inform the atheist humanism of neo-Hegelians like Debord that dreams of a final reconciliation of existence with human essence. As a result, essentialist ontologies like Debord’s erase the trace of everything that has been discovered about the human animal and evolution since the middle of the nineteenth century, as if Darwin, Freud, Leri-Gourhan, and Simondon had never existed. Debord’s essentializing of the transhuman condition can be located within the very terms in which he chooses to ‘frame’ his analysis: the society of the spectacle. This is to erase all social, historical, and technological determination, with the result that an analysis is offered which disclaims all mediation, whether ‘political’ mediation in the form of the structuring instantiation of collective existence, or ‘technical’ mediation in the form of the structuring instantiation of the hominization process (ibid. : 136–7). The issue confronting critical theory is no longer one of political ‘correctness’, but that of intellectual anachronism. In an ironic condition of technology it is necessary to recognize that the ‘dialectic has indeed fulfilled itself…not at all by taking in the negative, as in the dream of critical thought, but in a total, irrevocable positivity’ (Baudrillard 1996:75).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It is no longer one’s alienation one is fighting aginst, but rather one’s transparency. 10.The thesis of the end of history which now dominates the postmodern Stimmung was, in fact, a common one in the sensibility of the 1950s. In the work of Maurice Blanchot it is specifically linked to the time of technology. As Blanchot notes, it is not that history comes to an end, but rather that certain principles, questions, and formulations stop making sense. Once the idea of a singular and unique origin, and the idea of a universal historical narrative that accompanies it, is given up on, then we no longer enjoy the right to a language in which the categories that have supported it up to now have become invalidated (categories such as unity, identity, primacy of the Same, the exigency of the self-Subject, etc.) (Blanchot 1993:272). The time of technology does not mean the end of everything since, as Blanchot notes, the end of everything doesn’t amount to much. An apocalyptic declaration of the collapse of the world through the dominance of technology and the erasure of mankind doesn’t say a great deal since it belongs to a language of eschatology wholly out of tune with the mood generated by the plural event of nihilism.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  As Hans Magnus Enzensberger  of the immense changes taking place as a result of the coming of modern technology, the philosopher will concoct a horrible mix of vague science, confused vision, and dubious theology. While speaking in the name of science he writes as an author of science fiction. This contains a healthy warning against superficial attempts to map inhuman futures and indulge in premature ejaculations celebrating the death of the human (an anthropomorphic declaration if ever there was one). One might begin to locate a way out of the impasse of the ‘end’ by recognizing nihilism as an inevitable feature of the transhuman condition. The question is whether one has the capacity and resources to emerge from the experience of Untergang free of anthropocentric conceits. 11. What takes place when nature is unhumanized and mankind is artificialized? Does nihilism not start knocking on the door as the uncanniest of all guests?\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  While nihilism may not be quite the a priori of universal history—or maybe it is as a parody of history that makes buffoons of humans—it can be recognized as the virtual truth of all human history to date. It is for this reason that Nietzsche claims that the causes of nihilism lie in our faith in the categories of reason by which we have measured the value of the world in accordance with categories that refer to a purely fictitious world. Considered psychologically—that is, from the perspective of a psychological a priori—human values are the result of utilitarian perspectives that have been designed to enhance human control and mastery over nature and the external world but which in the process have been falsely projected into the essence of things (Nietzsche 1968: section 12B). The positing of themselves as the meaning and measure of evolution is the anthropocentric conceit of humans that is exposed with the advent of nihilism. Now humans feel very small, dwarfed, as if their entire horizon of meaning had been wiped away, with the earth unchained from its sun, the so-called pinnacle of life on earth finds its world growing colder by the day, moving away from all suns, plunging backwards, sideways, forwards, in all directions (Nietzsche 1974: section 125). It is not simply a question of humans recuperating from the illness of nihilism, since their adaptive capacities are severely tested by it. Their hardware and software have been assaulted and invaded by the future. One solution to the problem of humans and their sick becoming is to envision the overhuman as the vision of a non-anthropocentric future of the human.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  This would be to conceive of the ‘human\/transhuman’ as neither a predicate nor a  individuation and the forms of their personality’ (Deleuze 1990:107). This requires a fundamental reconceptualization of the ‘value’ of evolution. For Nietzsche we lack the right to posit consciousness as the aim and wherefore of the total phenomenon of life. Becoming conscious is simply one means by which the powers of life unfold and extend. It is no more than an anthropocentric prejudice to posit spirituality or morality, or any other sphere of consciousness, as the highest value and seek to justify the world by means of this (Nietzsche 1968: section 707). The objection to be placed against all cosmic theodicies to date, to all the highest values in theology and philosophy (it is theological prejudice that has dominated in philosophy), is that one kind of means— consciousness and human existence—has been misunderstood as the end, with the result that life and the enhancement of its powers are reduced to a mere means. Our logic of means and ends is based on a perverse misunderstanding of the processes of life. It is this reified logic of life that can explain all human philosophies of pessimism and nihilism, such as that which we find in Schopenhauer, where the denial of life is posited as the aim of evolution.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  If life does not conform to the will and wishes of human needs and desires then it is to be denied and calumniated! Such a ‘lunatic interpretation’, Nietzsche says, is only possible because life is being measured by aspects of consciousness. In this case the means of inhuman life are made to stand against the wished-for human end. The mistake is that instead of a purpose being identified which might explain such a means, a goal that actually excludes such a means is presupposed and posited in advance. Nietzsche identifies the error of Kant’s thinking on technics and teleology, for example, as follows: we take a desideratum in respect of certain means as a norm—namely, pleasant, rational, and virtuous ones—on the basis of which is then posited the general purpose of what would be desirable. Kant’s ultimate solution is to posit God (theological prejudice), but it is precisely God who turns life into a monstrosity. The greatest reproach against the existence of God is the existence of God. Liberation from pessimism about the human condition and lot is possible once the total consciousness that posits means and ends is eliminated.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It is unwise to posit a conception of becoming which appeals to necessity in the shape of an overreaching and dominating total force acting as a kind of prime mover: ‘There is no total consciousness of becoming’ (ibid. : section 708). If the total value of the world cannot be evaluated, such as its ultimate purpose, then pessimism  is to be articulated, would be that concerning the conditions ‘of the preservation and enhancement for complex forms of relative life-duration within the flux of becoming’ (ibid. : section 715:1987, volume 13: 36–7). This is not to deny that Nietzsche is not caught up in the net of anthropomorphism. The paradoxes which afflict the doctrine of eternal return are sure evidence that Nietzsche is ensnared in naiveties and conceits like any other modern philosopher. It is, to give just one example, a massive contradiction on his part to urge us to will eternal meaninglessness as a way of embracing an eternal nihilism (Nietzsche 1968: section 55; 1987, volume 12:212ff. ).6 12.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The transhuman condition is not about the transcendence of the human being, but concerns its non-teleological becoming in an immanent process of ‘anthropological deregulation’.7 When Nietzsche asks his ‘great’ question, what may still become of man?, he is speaking of a future that does not cancel or abort the human, but one which is necessarily bound up with the inhuman and the transhuman. What will become of the human—including its meaning and application as a technical and ontological category—is a question ‘of’ the future. We children of the future can lend our weight to Nietzsche’s essential insight into ‘this fragile, broken time of transition (Übergangszeit)’: the ice that supports people today becomes thinner with each passing day, so that ‘we ourselves who are homeless constitute a force that breaks open ice and other all too thin “realities”’ (Nietzsche 1974: section 377). 13. Nietzsche maps the arrival of the future, therefore, in terms of an inexorable logic of nihilism, an event which can no longer come differently since it represents the logical conclusion of our great values and ideal so far (Nietzsche 1968 : preface, section 4). It is this insight into the logical inevitabilty of nihilism’s opening that enables Nietzsche to declare that it is the future which regulates our today. With the advent of this event of nihilism the present becomes a fractured time, a time of splitting, in which the very question of ‘man’ and the future of the human is called into suspicion and undergoes critical treatment. Nihilism arrives 6  The passage I am referring to reads: ‘Let us think this thought in its most terrible form: existence as it is, without meaning or aim….\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  This is the most extreme form of nihilism: the  to scramble the codes of the present and to undermine mankind’s anthropocentric claim on history. Why, Nietzsche asks, is it necessary to ascribe to everything that happens in nature and history a moral meaning and purpose, such as, he mentions, technology? The task is to become superficial about nihilism by exploring its depths, transmuting oneself into a perfect nihilist who has left the experience ‘behind’ oneself. An economic, and economical, reading of nihilism is called for. One should not give excessive weight to social distress or suffering in general, since every exaggeration of a narrow point of view is itself already a sign of sickness, like the preponderance of every ‘no’ over the ‘yes’. The ‘active negation’, the decisive ‘no’, arises out of the tremendous strength and tension of the affirmative ‘yes’ (Nietzsche 1968: section 1020). In exposing the transcendental illusion—showing that nihilism canot account for its own creative conditions of possibility and excessive becoming, or the fact that it is always ‘beyond’ itself —Nietzsche frees the time of nihilism from any passive movement and from any entropic conception of becoming.8 The danger does not lie in the failure to defeat or conquer nihilism, but rather in the insistence that it should not happen and should not be ‘allowed’ to happen. Nihilism always speaks of the future, heralding the arrival of something other than itself, and without its event growth would be impossible.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Nihilism arrives for us as a necessary learning experience which has been implicit in our positing of values all along. Is nihilism, therefore, solely a problem peculiar to man? ‘The most universal sign of the modern age’, Nietzsche writes, is the fact that ‘man has lost dignity in his own eyes to an incredible extent’ (Nietzsche 1968: section 18). Losing the centre of gravity by virtue of which we have lived, and doing penance for having been Christians for two thousand years, we abruptly plunge into opposite valuations ‘with all the energy that such an extreme overvaluation of man has generated in man’ (ibid. : section 30). Nihilism on this level of extremes is a pathological condition: from the realization that mankind enjoys no ultimate purpose in the evolution of life the inference is drawn that there is no meaning at all. As such, nihilism assumes the guise of a ‘monstrous event’ (ungeheure Ereigniss) that is ‘on its way and wanders’ (Nietzsche 1974:125). 8 Nietzsche’s construal of the arrival of nihilism in terms of the ‘uncanniest of all guests’ finds an echo in the literature of biology, where entropy is often perceived as the ‘uninvited guest’ that signals death, decay, and degeneration.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  A great deal of social and cultural thought from the late nineteenth century onwards has construed nihilism as an entropic force, corrosive in its effects,  As a sign from the future—and the past—of imminent collapse, decay, and transformation, the event of nihilism is monstrous in two senses: firstly, in the sense of scale, as something so tremendous that ‘man’ may not prove equal to it and will have to undergo a process of self-overcoming in order to endure it; secondly, in the sense of excess, the excessive time of its event which establishes new horizons of meaning: the horizon has become ‘free again’ (ibid. : 343).The geanealogy of morals establishes a new pathology of life. 14. Not only is it futile, but it is also deeply unintelligent to lament the loss of a centre of gravity, including the alleged corrosion in late modernity of an effective historical agency. Would not the praxis of such a historical agency ironically signal the death of any genuinely interesting becoming? A machinic philosophy of history, which displaces man as the phallogocentric object and goal of history, does not claim that it is machines as opposed to men that make history, since there is no subject or agent of history. To say that machines are inventions of humanity is to utter a truism. To say that the time of their invention is inhuman because it follows a logic of excess is to begin to think extra-morally beyond good and evil (which also includes the affirmation of good and evil).The end of history as conceived by critical modernity enables one to conceive of a more radical notion of becoming which does full justice to its complexity.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The notion of the ‘rhizome’, for example, serves to demonstrate that there is no central controlling agent, or overarching self-positing subject, in a process of complex evolution.Thus, it is no longer possible to conceive of evolution, whether of nature or of industry, in terms of isolated and individual dynamic regimes. The rhizome enables one to conceive of evolution in terms of an intricate, interweaving web of regimes and adaptive systems.The rhizome cuts across linear historical time, both heralding the future (which can come from anywhere), and warning of a scrambling of codes of life that rapidly approach ossification and petrification. So far as the question of technology is concerned, a rhizomatic mapping of our evolution would suggest the necessity of moving away from a Faustian conception of technology—what Toffler has called a ‘macho-materialism’ (Toffler 1990:69–84)—with its predilection for total control over nature, over machines, and over techniques of life of all kinds, to one in which the ‘undecidability’ (in the sense deployed by Deleuze and Guattari) and non-calculability of our ‘machinic enslavement’ and involvement with the becoming of technics are affirmed and engaged with. 15. At present we are witnessing in a wide range of discourses, including cybertheory, strands of continental philosophy, and the new biology, a renaissance of grand narratives in which pre-Darwinian notions of evolution are making a rapid come-back. Our objection to this come-back is partly a matter of taste—they smell offensively of a popular Hegelianism—and partly a matter of intellectual conscience. As Stephen Jay Gould has noted, all classic forms of evolutionary spin doctoring, now revamped in the guise of a techno-Lamarckism, are designed to avoid the unwanted consequences of the Darwinian de-anthropocentrization of evolution, namely, the fact that human beings are not the result of predictable evolutionary progress, but simply a ‘fortuitous cosmic afterthought’ (Gould 1996: 327). Spin doctoring revolves around two different subjects: the first is the ‘process’ of evolution considered as a theory and a mechanism; the second is the ‘pathway’ of evolution considered as a description of the history of life.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In the former subject spin doctoring is evident in the attempt to construe evolution as inherently progressive, and as working towards some higher good (the species, for example), producing better-designed organisms in terms of some linear progression; in the second subject spin doctoring is evident in the attempt to read life in terms of a continuous flux displaying directionality towards more and more complex entities, such as beings with large brains. Both of these expressions of spin doctoring are present in the techno-Lamarckism which characterizes many postmodern conceptions of evolution, in which the elevation formerly and anthropocentrically assigned to humans as their rightful privilege over nature is now bestowed on machines as theirs. But here there is an interesting story to tell about the coming of machines, a story of entropy and negentropy. 16. In a novel reworking of the philosophy of history, Richard Blackburn has argued that it is entropy and the destructive forces of nature, such as microparasitism, which serve to corrode the human species and its artificial environment. That which gives rise to humans’ invention of an artificial evolution is also that which compels them to enhance their artificiality continually: it is, ironically, both the producer and consumer of humanity and its distinctive artificial habitat (Blackburn 1990:20). Our entire civilization has evolved, therefore, in accordance with thermodynamic instability, transforming stable systems into unstable ones in order to release free energy. The cunning of unreason—reason’s vampire—exists in symbiotic relationship with the human animal, with the destructive forces absorbing human action and sucking human  can be designated as the predatory enemy of this rationality, the vampire of reason’ (ibid.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  : 22).This is where speculation on the coming of the machines enters the picture. It is machines that can now be read as an essential part of the biological ruse of reason. Recent scientific studies, including one on robotics by Hans Moravec, and another by the eminent mathematical physicist Frank Tipler, seek to demonstrate that what is driving the evolutionary push into a machine-dominated and controlled future, including the colonization of the universe, is the problem given to life by entropy, the ‘gift’ of ultimate and final heat-death (Moravec 1988:147ff. ;Tipler 1995:109ff. ).Tipler, who writes as a self-confessed anti-Heideggerian cybernetician, argues that the colonization of the universe by intelligent self-reproducing machines is the biosphere’s only chance of surviving the inevitable demise of our solar system at the grim hands of the second law of thermodynamics. He resurrects de Chardin’s notion of the ‘Omega Point’ to support his neg-entropic promise of guaranteed immortality for all in the future (see de Chardin 1965:283ff. ).9 The Omega Point refers to the point at which the noosphere coalesces into a supersapient being.Tipler does not deny that the second law is operative in the universe’s final meltdown, but maintains that the ‘energy of the gravitational shear near the Omega Point is sufficient to avoid Heat Death’ (Tipler 1995:109). As the Omega Point is approached a free energy source—the differential collapse of the universe—diverges to infinity, so escaping the moment of final death.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  17. If this vision of the future sounds like a horrible concoction of science, science fiction and highly dubious theology, it is even more disturbing than appears at first sight. This vision of neg-entropic futures ultimately rests on a biologistic legitimation of capital and universal imperialism. This comes out clearly in Lyotard’s depiction of the monster of the future in his thinking of the time of the inhuman. In an essay entitled ‘Time Today’ Lyotard tells an uncomfortable—and, one might think, irrelevant—story about the next few billion years. While you read this book the sun gets older and older. In 4.5 billion years, though it is not necessary to fix an exact date, it will explode in a truly earth-shattering 9 In the perspective of ‘noogenesis’ the aim, de Chardin says, is not to ‘humanize’ time and space but rather to super-humanize them. Far from being mutually exclusive, the ‘universal’ and the ‘personal’ (the centred) can be posited as growing in the same direction and culminating simultaneously in one another.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Thus, ‘The Future-Universal could not be anything else but the Hyper-Personal—at the Omega Point’ (de Chardin 1965:285–6). display of fireworks. At the moment the earth is just a little beyond the halfway point of its expected lifetime, a life devoted to death, no doubt casting life on earth into a mid-life crisis. The only future one can be certain of is that of arrangements of matter and energy facing constant self-creation and selfdestruction. At the limit point of the death of the sun—a death which will dwarf that of God’s in comparison—history will truly end and our insoluble questioning will matter no more, existing beyond piety. Of course, the limit spoken of only makes sense in a human context. Once the sun explodes there will no longer be such a limit since the human will no longer be ‘there’ to experience either side of it. Only matter will remain, but, as we Daseins know, matter does not matter.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  18. According to Lyotard, we are witnessing in the age of hyper endo- and exocolonistic capital the gathering of forces in a process of neg-entropy that has been underway since life first began on earth.10 The problem—same as it ever was, and it was—is that of time, or rather to be more precise, the fact that the universe is running out of it. Moravec puts it like this: in a continually expanding universe time is cheap but energy has to be carefully husbanded, while in a collapsing universe, such as the one we unfortunately occupy, energy is cheap but there is no time to waste. All life-forms, Lyotard suggests, can be regarded as technical devices for filtering information useful to an organism’s survival and for processing this information in self-regulating terms. Now, the human being can be broken into its hardware and software aspects. The body is the hardware of the complex technical device we call ‘thought’. The software is the symbolic and recursive power of human language. The fate of technology is being decided by the attempt to provide the human software with a hardware that is independent of the entropic conditions of life on planet earth.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The new computer technologies are making possible the programming and control of information, such as its memorization, less and less dependent on earth-bound conditions. The human race thus finds itself pulled forwards—but not upwards— by this time of information at an ever-increasing velocity, experiencing more and more ‘future shock’, such is the race against time.Time is not, and never has been, on our side. The human brain can now be depicted as the midwife that services this cosmic  process of complexification.11 Cybernetics appears as the (in)human science of control and communication which freely places itself in the service of the negentropic evolution of the great cosmic mind, confirming Heidegger’s prophetic insight into the take-over of the heritage of philosophy by the new science of cybernetics (Heidegger 1972:58). In this autonomous process of complexification the aim is to stock more and more information, to improve competence, and to make efficiency gains (such as the junking of the outlived human body), and in this way to maximize performance and increase our chances of success against the demonic powers of the future.When seen in this context, Lyotard’s argument goes, capital can be seen for what it is, not so much a figure in or of human history, but more the effect of an ancient cosmic destiny. Human beings have never been the subjects of this process, even though they have been ironic agents of it, witless collaborators in the making of their own redundancy (the irony of technology would appear to be a lethal one). 19. It is in the context of these paradoxical—human or inhuman?—reflections on the time of the future that Lyotard reconsiders his definition of the postmodern condition as signalling the end of grand narratives of emancipation and enlightenment.12 He now suggests that we think of it in terms of a split between two pro’s, on the one hand the project of enlightenment modernity and its dream of self-transparency and social immanence, and on the other, the‘programme’ of inhuman neg-entropic postmodernity. The modern project of emancipation through the maturity of enlightenment was novel in not being governed by the past, being in essence futural.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In this way it has served the process of complexification, the process which ironically leads to its own demise. The illusion it endures, however, is believing that the entropy of time and its neg-entropic evolution can be made subject to human history. Unfortunately, at least from the perspective of our existence as humanoids, it is the ‘programme’ that is proving better able to meet the challenges thrown down to life by entropy. As Lyotard sees it, the dominance of the programme brings with it the attempt to neutralize as far as possible the unpredictable effects engendered by the freedom and contingency that belong uniquely to the human project. The reign of bodiless information means nothing less than the end of the event (of time). The task of philosophy 11 One of the earliest accounts of this phenomenon can be found in de Chardin 1965:53, who speaks  today is simply that of bearing testimony to the non-event of the event. If in The Postmodern Condition Lyotard had sought to live beyond nostalgia and mourning, he is now firmly entrenched in such a condition, devotionally mourning the event of lost time for the rest of time. 20.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Unknown to himself, Lyotard has in fact resurrected in this grand narrative of the time of the inhuman an old theory of technics that characterized a strand of thought in the late nineteenth century, notably in the writings of Henry Adams, which was taken up again in more recent times by Jacques Ellul in the 1950s. Adams, for example, believed that history was governed by a law of acceleration which involved a process of increasing energy, organization, and complexity that defied all attempts at either conscious direction or opposition.When the machines land we humans simply become the carriers of their will: ‘A law of acceleration’, he wrote, ‘cannot be supposed to relax its energy to suit the convenience of man’ (Adams 1931:493). On this model of the time of the inhuman, history is reduced to physics in which historical development is to be accounted for in terms of the government of thermodynamics, the science of the relationship of heat and mechanical energy. The increase in energy and organized complexity is what constitutes the anti-entropic becoming of material reality (Winner 1977:48–9). There are a number of problems afflicting this well-worn depiction of evolution by neg-entropy (there is nothing postmodern about it). For all its talk of complexity, or complexification, it rests on a dubious linear, rational, additive accumulation (see ibid. : 63), with the result that on this model technics does become Geist, nothing but Geist. As one commentator on the phenomenon has noted, entropy and the laws of thermodynamics, like all scientific constructs, can be deployed to secure an anthropocentric conception of life’s evolution (Rifkin 1981:260) (on the human organism conceived as ‘the perfect animal’, on account of its being a ‘spontaneously, self-producing’ neg-entropic ‘end’, and hence the apotheosis of nature in spirit, see Hegel 1970b: 108–9).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Jameson is simply wrong when he suggests that within postmodernity we witness the emergence of a new kind of narrative that is more consistent with the dynamics of the world system than the older anthropomorphic or humanist kind which centred on notions of personal agency (1995:56). The new grand narratives are as anthropormorphic as hell. The danger of this anthropocentric utilization of entropy thinking is that the phenomena of instrumental rationality and technological mastery are provided  to Darwinism a teleological drive in favour of the selection of complexity (1990: 211). But natural selection contains no inbuilt tendency in favour of complexity (indeed, it has real difficulties in explaining it). There is no ‘law’ within the theory of natural selection that would enable one to claim that evolution displays any kind of teleological progressivism, including a drive towards complexity. To propose otherwise, and to apply such a model to human technical evolution, is to naturalize and reify the contingent, non-linear, and rhizomatic character of our technological becoming.13 It is also to give the evolution of technology the status of social Darwinism, which rests on a highly crude conception of ‘fitness’. Indeed, this was precisely how Samuel Butler conceived of the coming of machines as far back as the 1860s as the next line of the fittest. Such a view necessarily results from any attempt to place ‘Darwin among the machines’ (and, one might add, the humans).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Instead of recognizing the challenge Darwinism presents for the philosophy of history, Blackburn identifies Kantian and Hegelian speculations with natural selection.14 The problem with current theorizing on our inhuman futures is that it ends up reifying the demonic powers it sets out to demystify. In the case of Lyotard’s thinking on time today, the monstrous logic of capitalism is granted a logic of autonomy which in reality it does not enjoy. His presentation of the inhuman time of our neg-entropic destiny results in an abstract and ahistorical opposition between a pure ethicism on the one hand and the unstoppable— because cosmic—accumulation process on the other. Is this not to be seduced by capital’s own desire to construct itself as the transcendental ground of all change and innovation?15 Capital enjoys a monopoly on neither entropy nor neg-entropy. 13 One will find little evidence in Darwinian theory for Blackburn’s contention that nature manifests a tendency towards an ever more complex and expansive order, an order, he claims, which has been ‘promoted in the case of living things by natural selection and in the case of human beings by means of the higher forms of existence’ (1990:160). Of course, the positing of a drive for complexity is entirely intelligible within a Lamarckian schema of evolution. For more on this see Burkhardt 1995:151ff. 14 ‘The cunning of reason in human history for Hegel and the cunning of nature in political history for Kant can be seen as intimating the operation of progressive forms of natural selection’ (Blackburn 1990:161).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The only problem here is that it is not ‘natural’ selection that is being identified but an entirely different process. 15 There is little that is ‘empirical’ about the claims of our current ‘capital-logicians’, as Jameson has called this new species of idol worshippers. On the contrary, their claims are purely  As Deleuze and Guattari argue, capitalism can be treated as an ‘axiomatic’ precisely because it operates immanently. In other words, it has no laws of development other than immanent ones, which is why when it confronts limits these prove to be nothing other than its own limits (Deleuze and Guattari 1980:579; 1988:463).16 Lyotard has, in key respects, provided a postmodern update of Marcuse’s wellknown and untenable thesis on one-dimensionality advanced with a degree of historical acuity in the 1960s. One-dimensionality in Lyotard’s schema is part of life’s long battle with entropy. The real problem with Lyotard’s fantastical account is that it ascribes to capital a vitalism and a teleology. He thus ends up, ironically, offering us the kind of meta-narrative which he had sought to show in the earlier essay on the postmodern condition was now discredited. Grand narratives concerning a neg-entropic future end up being complicit with the image that the system of control likes to project of itself, that is, portraying advanced technological life as if it were simply a mere continuation of natural history.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The cybernetic dream of a virtually instinctive machine of self-regulation is, as Habermas has noted, equivalent to the ‘biological base value of survival at any cost, that is, ultrastability’ (Habermas 1987:60). It is precisely for this reason that one must demand a continual politicization (and artificialization) of evolution. 21. The thesis on the autonomous character of technical development ignores not only the crucial mediating role played by the social machine, but also the origins of self-regulating capital in specific relations of production, such as private property. No matter how much cybernetic capital assumes a monstrous, reified form, abstractly and inhumanly pursuing its own logic of autonomy, this does not mean that it has transcended its origins in specific social relations of production. It simply gives the appearance or illusion of such transcendence. To propose the end of politics as far as the question of technology is concerned— on the basis of the intellectually lazy claim that technology is getting ‘out of control’—is simply to become seduced by capitalism’s effective depoliticization of the matter of planetary evolution. Certain power interests are nicely served by such 16 The difference Deleuze and Guattari are referring to here is that between an ‘axiomatic’ and a ‘code’.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  The former operates immanently in the sense that it deals directly with functional elements and relations, the nature of which is ‘indeterminate’, while the latter works transcendentally and expresses  depoliticization.Taken in themselves machines explain nothing since they are always part of apparatuses and assemblages that are as much social as they are technical. Moreover, the evolution of technology does not take place in terms of some rational teleology, and in its concrete details its history cannot be said to be either linear or a matter of destiny. Rather, the development of technical machines, including technology as a global system, is the story of contingencies and situations of historical lock-in. For example, the utilization and exploitation of certain energy resources and fuels is the result of such historical contingency and lock-in, in which the ‘decisions’ of the social machine of a capitalist world economy are crucial. Today new lessons about economics and politics can be learned from the biology of distributed control in fields of self-organization and in processes of emergent ‘informal’ order in complex systems, in which the role of central control is positively disastrous and simply unintelligent. On the level of global culture and politics the imperialist-entropic logic of ‘development’ needs to be contested in the light of knowledge gained from observation of these phenomena. The dominant monoagricultural policies imposed upon third world farming practices is just one example of this entropic logic of development pursued by technologies whose evolution is driven by capital’s logic of accumulation. The farming techniques of these local cultures already contain their own highly sophisticated and intelligent mechanisms and systems of feedback in which learning and adaptation take place and in which innovations are tried and tested.‘Third world’ economists and others have effectively challenged the widespread view prevalent among Western ‘experts’ that farming practices based on biodiversity enjoy only low productivity (see Goodwin 1995:213ff.).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  New developments in genetically engineered agriculture are a prime example of entropic development, the product of a monocultural mind-frame that ignores the qualitative fertility of species diversity in favour of quantitative reductionism, in which variety and diversity are sacrificed in favour of the cultivation of specific species’ traits that are maximized in order to give a high yield of certain products, such as milk from cows, seed from grain, and so on.This is not an argument against engineering and artifice in favour of some questionable return to nature; rather, it is an argument about types of engineering and modes of agriculture. Legitimations of the economic forces of entropic capital are based on the application of crude Darwinian models of survival of the fittest, but in such accounts the ‘test’ of fitness is naturalized and depoliticized. The issue of ‘development’ is not an issue of nature but one about politics. To account for the apparent universal triumph of  through the biologization of the forces of evolution, spuriously takes on the appearance of a destiny that is judged to be beyond ‘human’ influence. 22. There is much that is apposite in Lyotard’s reflections on time today. He is correct to claim that capital is a far greater inhuman force than we dare admit to ourselves. As he notes, capitalism is only the name given to a socio-economic process of development of which no one is master (Lyotard 1993:96).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  However, this insight opens up spaces of resistance as much as it encourages acquiescence in an evolutionary system alleged to be ‘out of control’. Here it is necessary to divorce a speculative comprehension of capital from conventional fascist-paranoid images of it. As Baudrillard has noted, capital is a ‘sorcery’ of the social relation, a challenge to society that needs to be responded to as such, not denounced according to some ahistorical criterion of morality or economic rationality (Baudrillard 1992:174). Capital operates as a virtual machine trapped within a productionist logic of eternal repetition. As Brian Massumi has argued, capital operates virtually in the sense that it transforms production into futural processuality in which activity is fundamentally energetic rather than objectoriented. It is not, for example, simply a question of late-modern society capitalizing on life-forms in terms of imposing upon them an external mechanism of capture and putting them up for sale. Rather, life-forms that have never existed, being solely the product of an artificial manufacturing, are commercialized at the point of their emergence. Within postmodern capital, human life exists within a virtual modality and from the angle of its mutational aptitude (Massumi 1992:135): ‘The capitalist machine has developed perceptual abilities that enable it to penetrate life and direct its unfolding.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  It can go straight to the code of its molarity, resolve it into its constitutent part-objects (in this case genes), recombine them to yield a special-order product (adult individuals) and market the final product—or the transformational process itself, at any one of its steps’ (ibid. : 133–4). Deleuze and Guattari have noted that as the molar mode of organization characteristic of the modern social machine becomes ‘stronger’, it reveals a tendency to effect a molecularization of its elements and relations. Such a process of miniaturization defines the existence of the human ‘mass’ individual within late-modern capitalism, which in order to perfect its exploitation of the human has learned how to molecularize the individual and introduce a whole micro-management of petty fears, so creating a macro-politics of society that is governed by a micro-politics  of administration and management, that is, a system of anti-production soaking up machinic surplus value, then a significant refusal consists in not granting capital the first and last word as the ‘subject’ and goal-less goal of evolution (goal-less because it is motored by cybernetic self-stabilization, the eternal return of entropic death cultivated as a living system). Capital is a certain type of machinic assemblage, a particular social machine which operates on the machinic phylum but which neither controls nor steers machinic evolution. With the advent of the modern State a mutation takes place in which the regime of ‘machinic enslavement’ that charaterized the imperial Signifier is replaced by a regime of ‘social subjection’. The condition of the modern\/postmodern is an ambiguous one because under capital decoded flows of energy and matter do not cease to flow or cease to engender new flows. The difference between enslavement and subjection can be understood along the following lines: in the former, pre-capitalist condition human beings exist as constituent pieces of a machine which they form among themselves and with other things, such as animals and tools, under the direction of a higher unity (a megamachine) (Mumford 1966:1–15).\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  In the latter, capitalist condition, however, human beings are no longer simply components of the great machine, but workers and users socially subjected and mediated rather than enslaved. Capitalism brings with it the triumph of motorized machines and the deterritorialization of technical machines, as Marx recognized, arguing that it is not machines that create capital but capital that creates machines (Marx 1976: 492ff.). It would be a mistake to view our modern condition as simply a novel form of ancient enslavement to the megamachine, since what is distinctly modern about it is that it takes place on the level of the immanence of an axiomatic, and not under the transcendence of a formal unity. Moreover, the rise of cybernetic and informational machines implements a more generalized and insidious mode of subjection: ‘recurrent and reversible “humans-machines systems” replace the old nonrecurrent and nonreversible relations of subjection between the two elements; the relation between human and machine is based on internal, mutual communication, and no longer usage or action’ (Deleuze and Guattari 1980:572; 1988:458). With the evolution of late-modern capital any distinction between the organic composition of capital (the source of human surplus value) and the machinic composition of capital becomes blurred and actually breaks down as a tenable or useful distinction (compare Marcuse 1968:27–37).17  23. The ‘evolution’ of the system of capitalism can be de-reified by exposing, through a machinic analysis, the illusion of total control it inevitably gives rise to. It has to be seen as a system of production that is subject to a complex evolution which proceeds by way of experimentation and testing, utilizing a pragmatic adaptiveness in the face of an ever-changing ‘environment’ that it itself has immanently and artificially produced. The function of an axiomatic—whether one is speaking of politics, morality, science, or technology—is to put a stoppage on decoded flows, to arrest their movement, so as to ensure that they do not break out in all directions and lead into uncontrollable and unpredictable trajectories.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Deleuze and Guattari list four main flows that persist in tormenting the centralized powers of the world economy: the flows of matter-energy, the flow of population, the flow of food, and urban flow (Deleuze and Guattari 1980:584–5; 1988:468). The problems associated with these flows are generated by the axiomatic but are not resolvable by it (an obvious example is the circulation and distribution that would make it possible to feed the entire population of the world). It thus becomes necessary to speak on behalf of life in all its immorality so as to give expression to all the other sonorous machines which fill up the messy universe. As Deleuze and Guattari argue, the very conditions that make the State and its capture of the war machine possible, namely, constant capital (tools, techniques, and equipment) and variable capital (human invention and ingenuity), also continually re-create unexpected possibilities for ‘counterattack, unforeseen initiatives determining revolutionary, popular, minority, mutant machines’, and for the creation of new non-organic social relations (ibid. : 1980:526–7; 1988:422–3). It is not a question of a (post-)historic creature—the human animal—facing inevitable and tragic death at the hands of a monster from outer space (neg-entropic capital). It now becomes a matter of affirming our involvement in a machinic becoming and actively participating in our inhumanization, as opposed to thinking that the human being stands outside the machine with the power to negate abstractly its own machinic conditions of existence. knowledge, information, and specialized education are as much parts of capital (‘knowledge capital’) as is the most elementary labour of the worker.\n"}
{"prompt":"Viroid Life On machines, technics, and evolution ->","completion":"  Toffler calls this the ‘Global K-Factor’, which he regards as decisive for an understanding of the economic and political dynamics of ‘third wave’ societies (Toffler 1990:391ff.). Indeed, Toffler goes so far as to claim that the K-factor poses a far\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Ornamentalism: A Feminist Theory for the Yellow Woman Anne Anlin Cheng  For a long time now there have been two primary conceptual frameworks through which many of us conceptualize racial embodiment: Frantz Fanon’s “epidermal racial schema”1 and Hortense Spillers’s “hieroglyphics of the ﬂesh.”2 The former denaturalizes black skin as the product of a shattering white gaze; the latter has been particularly instructive in training our gaze on the black female body and the ineluctable matter of ungendered, jeopardized ﬂesh.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Yet, has the “epidermal racial schema” hardened for us into a thing of untroubled legibility? To what extent have the “hieroglyphics of the ﬂesh” prevented us from seeing an alternative materialism of the body? This essay is driven by the haunting of a different kind of racialized female body whose “ﬂesh” survives through abstract and synthetic rather than organic means and whose personhood is animated, rather than eviscerated, by aesthetic congealment. Culturally encrusted and ontologically implicated by representations, the yellow woman is persistently sexualized yet barred from sexuality, simultaneously made and unmade by the aesthetic project. She denotes a person but connotes a style, a naming that promises but supplants skin and ﬂesh. Simultaneously consecrated and desecrated as an inherently aesthetic object, the yellow woman troubles the certitude of racial embodiment and jeopardizes the “fact” of yellowness, pushing us to reconsider a theory of person thingness that could accom-  416  Anne Anlin Cheng \/ Ornamentalism  modate the politics of a human ontology indebted to commodity, artiﬁce, and objectness. Although the yellow woman, like the black woman, has suffered long histories of brutal denigration and relentless prurience, her discursive construct is qualitatively different. Consider these two iconic nineteenthcentury images of racialized femininity (ﬁgs.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  1–2): on one hand, Sarah “Saartjie” Baartman, the so-called Hottentot Venus, was reduced to bare ﬂesh, what Spillers calls “the zero degree of social conceptualization”;3 on the other hand, Afong Moy, a young Chinese woman imported by the Carne brothers to tour major US cities in the 1830–1850s as a living museum tableau and known simply as The Chinese Lady, offered a scopic pleasure that centered on her textual thickness: her material, synthetic afﬁnities. Her appeal does not derive from her naked ﬂesh but from her decorative (and projected ontological) sameness to the silk, damask, mahogany, and ceramics alongside which she sits. While primitivism rehearses the rhetoric of ineluctable ﬂesh, Orientalism, by contrast, relies on a decorative grammar, a fantasmatic corporeal syntax that is artiﬁcial and layered. Where black femininity is “vestibular”\/bare ﬂesh\/weighted, Asiatic femininity is ornamental\/surface\/portable (“MB,” p. 73).4 The point here is not to posit a naturalized difference between Africanist and Asiatic femininities—indeed, my argument will insist on how modes of racialized representations mean to index racial difference but are in fact wholly promiscuous in application—but I do want to underscore here the speciﬁcity of a racial imaginary that has been at once pervasive and yet taken for granted. The tying of ornamental artiﬁce to Asiatic femininity in EuroAmerican visual and literary cultures is ancient and enduring, reaching as 3. The focus on Baartman’s ﬂesh extends well beyond her death; as we know, her reproductive organs, dissected by Georges Cuvier, were on display at the Musée de L’Homme in Paris until as recently as 2002. Spillers famously made the distinction between “body” and “ﬂesh,” the latter being pure matter that exists outside of any kinship or state apparatus even as it is enlisted to serve both: “In that sense, before the ‘body’ there is the ‘ﬂesh,’ that zero degree of social conceptualization” (“MB,” p. 61). 4.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Spillers also famously conceptualizes black female ﬂesh in spatial terms; as the black female is barred from crossing the symbolic threshold into personiﬁcation, she is both stuck in and a mechanical transit for the threshold dividing the human and the not human, rendering her “vestibular” to culture. An n e A nl i n C h e ng is professor of English, director of American Studies,  418  Anne Anlin Cheng \/ Ornamentalism  FIGURE 2. Afong Moy, “The Chinese Lady.” The Miriam and Ira D. Wallach Division of Art, Prints and Photographs. Courtesy of New York Public Library Digital Collections. far back as Plato, through the writings of Marco Polo in the thirteenth century, the novels of Joris-Karl Huysman and Oscar Wilde, the visual expressions of art nouveau, French symbolism, American rococo, all the way up to wide-ranging iterations in the twentieth and twenty-ﬁrst centuries (ﬁgs. Critical Inquiry \/ Spring 2018  FIGURE 3. Gustav Klimt, Woman with Fan (1917–1918). It is astounding that so little has been done to consider the production of this particular form of personhood.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  This vast and tenacious history of Oriental female objectiﬁcation is refracted through the lenses of commodity and sexual fetishism. Yet, the truth is, we barely know how to process the political, racial, and ontic complications of confronting a human ﬁgure that emerges as and through ornament. Neither mere ﬂesh nor mere thing, she\/it applies tremendous pressures on politically treasured notions such as agency, feminist “enﬂeshment,” and human ontology. When it comes to this exquisitely deﬁled subject, caught in the haunting convergence between aesthetic value and material abuse, it is not  419  420  Anne Anlin Cheng \/ Ornamentalism  FIGURE 4. Henri Privat-Livemont, Bitter Oriental (1897). the subjugated ﬁnd themselves or meet one another in and through aes-  Critical Inquiry \/ Spring 2018  FIGURE 7. Arnold Genthe, Little Tea Rose (1896–1906). Almost two hundred years after New Yorkers ﬂocked to the American Museum in New York to witness the living tableau of The Chinese Lady,  423  424  Anne Anlin Cheng \/ Ornamentalism  FIGURE 8.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Photograph of Anna May Wong taken by Otto Dyar (1932). Courtesy of Rex  Features, UK. American haute couture and avant-garde ready-to-wear from fashion luminaries such as Paul Poiret, Yves Saint Laurent, John Galliano, Alexander McQueen, and more. Interspersed among these resplendent sartorial crea-  Critical Inquiry \/ Spring 2018  FIGURE 9. 2000). Maggie Chung in ﬁlm still from In the Mood for Love (dir. Wong Kar-wai,  twelfth-century kimono echo a Cartier perfume ﬂask; an early ﬁfteenthcentury cobalt blue dragon jar ﬂanks a Roberto Cavalli creation in blue and white. This sumptuous collection rehearses for the twenty-ﬁrst-century audience the basic tenets of nineteenth-century Orientalism: that opulence and sensuality are the signature components of Asiatic character; that Asia is always ancient, excessive, feminine, available, and decadent; that material consumption promises cultural possession; that there is no room in the Orientalist imagination for national, ethnic, or historical speciﬁcities.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Most of all, the show reminds us that China (conﬂated throughout the show with Asia at large) equals ornament. The Metropolitan had accomplished quite an ornamental feat of its own: a byzantine build-out replete with intricate corridors and concentric spaces; large decorative arches leading to secret, enfolded rooms; a tall, transparent, plastinated bamboo forest—all nestled deep inside the museum’s bowels, ﬁlling up both the Anna Wintour Costume Center in the basement and the Chinese galleries on the second ﬂoor and claiming a large portion of the repurposed Egyptian Gallery. Through this labyrinth, one would, for instance, turn and suddenly ﬁnd oneself in a hushed “garden,” standing on a meditation bridge overlooking a large glistening pond encased by winding corridors (ﬁg. 10). No natural light disturbs this dreamlike, highly man-made environment. The  425  426  Anne Anlin Cheng \/ Ornamentalism  FIGURE 10. Exhibition hall of China: Through the Looking Glass (2015). The Metropolitan Museum of New York.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Photograph by Anne Anlin Cheng. as its own internal critique and alibi. A large sign greets the visitors as they enter through a set of imposing two-story-tall red lacquer doors: Empire of Signs For the designers in this exhibition, China represents a land of free-ﬂoating symbols, a land where postmodernity ﬁnds its natural expression. Like Marco Polo or Gulliver, they are itinerant travelers to another country, reﬂecting on its artistic and cultural traditions as an exoticized extension of their own. . . . When quoting Chinese artifacts or costumes, these designers are not reproducing literal copies or accurate facsimiles. Rather, they reinterpret them through seemingly paradoxical postmodern constructions.5 The show recuses itself from the burden of authenticity even as its misen-scène fetishizes the artifactually and culturally real.6 Invoking and recursively enacting Roland Barthes’s famously cool dismissal of the notion of (Japanese) cultural authenticity—“to me the Orient is a matter of indifference”—this exhibit disaggregates aesthetic pleasure from politics and 5. From the exhibition China: Through the Looking Glass, Metropolitan Museum of Modern Art, 7 May–7 Sept. 2015. 6.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  As the exhibition overview on the museum website states: “This exhibition explores . . .  Critical Inquiry \/ Spring 2018  reclaims postmodernism as cure to Orientalism, performing exactly what Hal Foster has referred to as capitalism’s revenge on postmodernism.7 There is much criticism one can offer on the grounds of racial appropriation, inauthenticity, commercialism, and neoliberal bad faith.8 Yet we should be less surprised by the tenacity of this racial imaginary and more concerned with the limits of our response to it. For a long time now the concepts of Asian authenticity and of Orientalist commodiﬁcation have remained our only safeguards against the vice of racist consumption. But neither the longing for the former nor the allegation of the latter can address the complex relations between appropriation and susceptibility, or between embodiment and style. Moral outrage in the face of consumption or fetishization, however warranted, cannot address or relieve the truly striking, idiosyncratic, and passionate exchange between thingness and personhood into which a display like this draws us. The exhibition’s visual and sensorial extravagance—its dizzying invitation for visitors to lose themselves in the fastidiousness of extreme aestheticism; the completeness of severe, scrupulous details; the sensorium of textiles and materials; the seductive dynamism of vivacious inanimateness and synthetic pleasures—all work to facilitate that slide between things and persons, an erotic and erratic plunge that both preconditions the making of Chinese\/Asiatic femininity and renders inadequate binary critiques when it comes to this kind of racial objection. Thus while Saidean Orientalism and the Foucauldian critique that it embodies help us identify symptoms and locate political culpability, neither can address the profound, queasily seductive entanglement between organic corporeality and aesthetic abstraction imputed to yellow womanhood. Let’s face it, critical discourse has never been very good at speaking to what Rita Felski calls the erotics of aesthetics beyond that of a critique of commodiﬁcation or an assertion of transgressive pleasure.9 I am not here to make an argument for pleasure, though that is often elided by the moral and gendered politics of consumption.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Instead, the exhibit gives me the 7. Roland Barthes, Empire of Signs, trans. Richard Howard (New York, 1983), p. 3. See also Hal Foster, “Postmodernism in Parallax,” October 63 (Winter 1993): 3–20. 8. There was much public protest. The New York Times published a scathing review, offering even a history lesson about the so-called China trade and its legacy for American imperialism; see Holland Cotter, “In ‘China: Through the Looking Glass,’ Eastern Culture Meets Western Fashion,” New York Times, 7 May 2015, www.nytimes.com\/2015\/05\/08\/arts\/design  427  428  Anne Anlin Cheng \/ Ornamentalism  opportunity to pay attention to the material, affective, and kinesthetic making of an aesthetic ontology that I will call the ornamental personhood of Asiatic femininity. So how do we begin to think about racialized bodies that remain insistently synthetic and artiﬁcial?\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  How do we take seriously the life of a subject who lives as an object, and how do we do so without either resigning that ﬁgure to the annals of commodity fetishism or assigning it to the sinecure of reassuring corporeality? The challenge here is to negotiate between, without abandoning, the very human stakes of deanimated persons and the very material history of animated things. Of the many “enigmatic objects” (a term used by the exhibition) displayed in this extensive exhibition, the most mesmerizing and confounding one is surely the specter of the yellow woman, synecdochized through faceless and at times headless mannequins and metonymized through luxuriantly sensuous fabrics.10 What is this charismatic sensorial presence that does not require a biological body or nature? Quite the opposite, Asiatic femininity is radiantly reproduced through inorganic and insensate mediums. Consider, for example, the evocation of Asiatic femininity via ceramics. In a series of rooms devoted to the theme of blue willow, an imitation Chinese china pattern made popular by Thomas Minton in the 1790s, we ﬁnd a grouping of blue and cream silk gowns designed by contemporary designers such as Cavalli and McQueen. We can dismiss this association between Asiatic femininity and Chinese ceramic as yet another Orientalist cliché. But if we do so, we would miss a much more intricate and intriguing proposition: the afﬁnity among racialization, imagined personhood, and synthetic invention.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  I am interested in how the primacy of the ornament, as artifact and as gesture, in this show acts as a crucial, transitional node through which the human is simultaneously invoked and displaced and how racialization functions in this transfer. I want to think through, rather than shy away from, that intractable intimacy between being a person and being a thing. Let us then build a different historiography of raced bodies: one constructed through fabrics, ornaments, and “skins” that never enjoyed the fantasy of organicity; one populated by nonsubjects who endure as ornamental appendages. Let us substitute ornament for ﬂesh as the germinal matter for the making of racialized gender. Let us, in short, formulate a feminist theory of and for the yellow woman. Critical Inquiry \/ Spring 2018  To begin to do so, I offer ornamentalism as a conceptual lens through which to attend to the afterlife of a racialized and aestheticized object that remains very much an object, even as the human stakes remain chillingly high.11 At the most basic level, ornamentalism, with its almost homophonic echo of Orientalism, names for me the critically conjoined presences of the oriental, the feminine, and the decorative. But more than naming a symptom, it identiﬁes a process whereby personhood is conceived and suggested (legally, materially, and imaginatively) through ornamental gestures: gestures that speak through the minute, the sartorial, the prosthetic, and the decorative. Ornamentalism is thus an admittedly rather inelegant word that describes a very elegant (that is, seamless) alchemy between the borrowing properties of thingness and personhood.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  It is important to note that ornamentalism, as I am deploying it, does not refer to agential acts of self-performance or willful self-making. That is, as ornamentalism is a technology of personhood that mobilizes a racial logic that operates ornamentally rather than requiring—and often even suppressing—a biological body or nature, it is very different from a corpus of scholarship that sees sartorial practice as recuperative acts of selfnaming or individualist performance. This is not a project about retrieving human agency, because the subject under discussion here (the yellow woman) is a seriously compromised subject and, in many instances, not a subject at all. At the same time, however, I do want to claim the orna11. The term ornamentalism has surfaced among art historians and those engaged in aesthetic philosophy to refer to the deployment of ornament for decorative purposes, especially when done in excess, but I wish to recall it precisely because of what has gone completely unheard in its previous iterations: its suggestive and almost-homophonic entanglement with Said’s deployment of Orientalism. The term was also most recently revived in David Cannadine, Ornamentalism: How the British Saw Their Empire (New York, 2001). But there “ornamentalism” does not refer to artifactual ornaments but more generally to sets of rituals and ceremonies that the British deployed to export Britishness to the far corners of their empire. And this study also remains curiously—perhaps even studiously—deaf to the sonic residue of Orientalism inhering in the word ornamentalism.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  I suspect this is largely due to the fact that Cannadine was eager to displace race as a critical term in British imperialism. His central thesis argues that class, more than race, offers the formative lens through which the British imagines its empire hierarchically. Orientalism as a racial imaginary thus makes no appearance in Canadine’s study. Finally, Cannadine’s treatise looks at British inﬂuence on its colonies but not vice versa. While scholars have noted how gendered the discourse of the ornament in the decorative arts has been, much less attention has been focused on how deeply racialized (indeed, how Orientalized) this history has been as well. It is my sense that retrieving the Oriental logic of  429  430  Anne Anlin Cheng \/ Ornamentalism  mental personhood of Asiatic femininity as a rare and valuable opportunity to consider alternative forms of being, not at the site of the free, natural, modern subject and his or her celebrated autonomy, but, contrarily, at the edges and crevices of a non-European, synthetic, aggregated, and feminine body. The stakes, therefore, of taking the insidious elision between the Oriental and the ornamental as the foundation for a yellow feminist theory are: 1) to detach us from the ideal of a natural and an agential personhood that invariably accompanies critiques of power and from which the yellow woman is already always foreclosed; 2) to take seriously what it means to live as an object, as aesthetic supplement; 3) to attend to peripheral and alternative modes of ontology and survival; and, ultimately, 4) to contend that the discourse of the yellow woman—at once pervasive and marginal, enhancing and disparaging—is part of a much larger debate about beauty and violence, about life and artiﬁciality, nestled in the making of Euro-American, modern personhood. The ornament and the ornamental gesture in China: Through the Looking Glass, far from being incidental or merely decorative, enacts critical labor through which powerful ideas of personhood, race, and objectness transfer.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Let us take for example the intimacy between Asiatic femininity and cool ceramics. Recent scholarship in the area of material culture has revealed the complex history of Chinese porcelain: its importance in early global imperial trade; its role in spurring European technological invention and decorative design; its impact on growing economic, social, and cultural values in Denmark, Germany, France, and England and its American colonies.12 To this richly documented history, I would add the wrought\/ fraught intimacy between this “‘White Gold’” and the making of yellow ﬂesh.13 For more than economic or social values, Chinese porcelain personiﬁes a set of affective and somatic values forged out of the kiln of what Gordon Change aptly called the centuries-old “fateful ties” between China and the West.14 Connoting old-world exoticism and modern material, civilization and decadence, durability and fragility, heat and coolness, imper12. See Jennifer L. Anderson, Mahogany: The Costs of Luxury in Early America (Cambridge, Mass., 2012); The Cultural Aesthetics of Eighteenth-Century Porcelain, ed. Alden Cavanaugh and Michael E. Yonan (Surrey, 2010); Madeleine Dobie, Trading Places: Colonization and Slavery in Eighteenth-Century French Culture (Ithaca, N.Y., 2010); Chi-Ming Yang, Performing China: Virtue, Commerce, and Orientalism in Eighteenth Century England, 1660– 1760 (Baltimore, 2011). 13. “With the exceptions of tapestry and silver, no artistic medium was more coveted or  Critical Inquiry \/ Spring 2018  viousness and susceptibility, Chinese ceramic was thought to embody characteristics that are mapped onto Asiatic persons and bodies.15 And the fates of Chinese bodies and Chinese porcelain run parallel. When this much valued and coveted material came to represent the precarity of a system of Western wealth based on importing novel Eastern goods, this prized object started to lose its radiance, along with other things Asiatic. As EuroAmerican acquisitiveness began to run in excess of what it could offer China in return, the early romance with china\/China began to deteriorate in a breakdown that left putative and lasting traces in American law and economic policy (from US foreign policy and trade agreements in the eighteenth century to discriminating immigration laws in the nineteenth and twentieth centuries); in the American popular imagination (think of the fate of Chinese porcelain itself, its fall from denoting precious goods to connoting tacky crockery); and, ﬁnally, for our discussion, on the bodies of Asiatic women.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  In 1996, the New York Times has this to say about the Chinese women’s gymnastics team at the Summer Olympics: “The Chinese remain the world’s most erratic top gymnasts, and today, like many a Ming vase, their routines looked lovely but had cracks in several places.”16 Thus more than exemplifying an incidental decorative motif or revealing the limits of the imperial imagination, the citation—indeed, the embodiment objecthood—of Chinese porcelain in this exhibition, regardless of curatorial intentions, reviviﬁes this long, expansive history of human imbrication with racialized and manufactured materials, fueling the fraught amalgamation between inorganic commodity and Asiatic female ﬂesh. We might say that the ubiquitous presence of ﬁne Chinese porcelain throughout the show generates a speciﬁc epidermal schema of its own. This creation by McQueen for his autumn\/winter 2011–2012 collection offers a play in simulation and contrast, juxtaposing the inorganic and the organic, the insensate and the sensorial, the hard and the soft (ﬁgs. 11–12). Most of all, it invokes a particular vision of the racialized female body, one that sustains these contradictions. The eruption of the ﬂuffy, layered extravagance that is the skirt, at ﬁrst glance, looks like supple feathers but turns out to be shredded silk organza. The exposed underskirt, suggestive of layers of artiﬁcial skins turned inside out, at once beautiful and violent, is then offset by the startlingly weight of the torso, which on closer inspection reveals the bodice to be made not out of the proverbial bone but of hundreds  431  432  Anne Anlin Cheng \/ Ornamentalism  FIGURE 11. McQueen and Burton, evening dress.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  From China: Through the Looking Glass. Photograph by Cheng. of reconstituted shards of blue and white porcelain: porcelain as ﬂesh and ﬂesh as porcelain. Dare we say it? Ornament becomes—is—ﬂesh for Asian American female personhood. Commodiﬁcation and fetishization, the dominant critical paradigms we have for understanding representations of racialized femininity, simply do not ask the harder question of what being is at the interface of ontology and objectness. Here Chinese femininity is not only more and less than human but also man-made; not only assembled but also reassembled. This reassemblage, by virtue of its materiality, memorializes the practice of ornamentalism and the techniques of race making.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  This image of the ﬂexible yet brittle body reminds us that this aesthetic discourse is fastened to a fractured history of craft, labor, and bodies in transit. If Eric Hayot has traced for us the persistent Euro-American conceptualization of the Chinese male body as inﬁnitely and stoically capable  Critical Inquiry \/ Spring 2018  FIGURE 12. McQueen and Burton, evening dress. From China: Through the Looking Glass. Photograph by Cheng. meable and insensate.17 The dream of the yellow woman is thus really a dream about the inorganic. The yellow woman is an, if not the, original cyborg. From the thingliness of Anna May Wong (whom Walter Benjamin once referred to as a “moon” and a “bowl”) to Nany Kwan’s trademark Porcelain Skin, for the Asian American woman, porcelain has always been ﬂesh and not ﬂesh.18 Going back to our blue willow room, we can now see a broader fascination with the inhuman human structuring the grammar of this stage.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  The McQueen gown is placed next to a Cavalli dress, and they in turn stand next to and echo an early ﬁfteenth-century Chinese porcelain jar painted with a cobalt blue dragon—urn as beauty as death as dress as corporeal gesture. The sensorial and somatic realization of Asiatic femi-  433  434  Anne Anlin Cheng \/ Ornamentalism  ninity fulﬁlls itself, paradoxically, through the forms of these empty-yetorthopedic vessels (ﬁg. 13). There is no ordinary ﬂesh here, by which I do not mean the obvious (that there are no real bodies on display) but that this show is palpably not that interested in the human, much less the woman. These garments do not need the human; indeed, the human would disrupt their composure. In fact, we are looking at a peculiar form of anthropomorphism or prosopopoeia whereby the human is being used to recall objectness rather than vice versa. The objects on display,  Critical Inquiry \/ Spring 2018  from frocks to vases, invite neither wearability nor usage. Instead of objects that function as appendages to the human (as one would expect fashion and furnishing to do), what we ﬁnd here instead are objects that reference other objects.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  In this room, the human is the ornamental gesture. And the ornamental in turn acquires its ancillary human aura by being “Chinese.” In other words, beauty here comes from the primacy of the object; the human or the anthropomorphic is the incidental alibi for, or an afterthought of, relishing this pure objectness. Crucially, at the same time, what renders this pure objectness legible as such is precisely the invocation of racial difference. While Orientalism is about turning persons into things that can be possessed and dominated, ornamentalism is about a fantasy of turning things into persons through the conduit of racial meaning in order, paradoxically, to allow us to abandon our humanness. If the modernist relation to the fetishized object is fundamentally a melancholic one, then we are getting here something of a twist to that subjectobject relation. That is, if we are prone to looking for ourselves in lost or alienated mass cultural objects—as Bill Brown elegantly describes it, “it is all those spaces within [the Thing]—the inside of the chest, the inside of the wardrobe, the inside of the drawer—that . . . enables us to image and imagine human interiority”19—then here we are looking at objects that short circuit that project by duplicating our own truncated or stunted relation to the very notion of interiority. In that blue willow room at the Met, all the empty containers—the urn, the dresses—are already wholly occupied by emptiness.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  They only seem to offer the promises of anthropomorphic possibilities as compensation for making us confront their (and potentially our own) thingness. We cannot ﬁll these voids with our fullness because they are easily occupied without us. This is possibly why one feels so essentially alone in the beauty of a room ﬁlled with things that were presumably meant to enhance us. The relationship here, however, is not simply one of an object refusing the human but an object that does so by mirroring the inhumanness of the human. To point to this enchantment of the inhuman is not to rehearse the problem of objectiﬁcation or to downplay the issue of race but to point to a provocative dilemma about how the object preconditions, rather than being the product of, the human ﬁgure—a modern crisis that Asiatic femininity personiﬁes. This is why ornamentalism is not only an object of fem-  435  436  Anne Anlin Cheng \/ Ornamentalism  human, even as raced and gendered corporeality are being imputed, compels a reconceptualization of feminized, racialized ﬂesh. The critique of power from Michel Foucault to Edward Said to Laura Ann Stoler has long taught us that carnality and ﬂesh, instead of being private domains, are sites that have been deeply penetrated and structured by power. Human ﬂesh has undeniably been one of the highest prices paid for the history of human enslavement in various forms.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  And often, understandably, in feminist and racial discourses, we end up with a longing for that lost and violated ﬂesh or, inversely, a total refusal of the body. But these stranded “bodies” in the Metropolitan invite further ruminations about the interplay between ﬂeshliness and the inorganic for certain raced and gendered bodies. What happens to our notions of the subject when carnality is cultivated not out of ﬂesh but of its fusion with inorganic matter? What happens when we accept that style (mediated through yet detached from a racial referent) may be not simply the excess or the opposite of ontology but a precondition for embodiment, an insight that challenges the very foundation of the category of the human? What is at stake here is not just the objectiﬁcation of people but how that objectiﬁcation opens up a constitutive estrangement within the articulation of proper personhood and life. More than denoting an aesthetic practice and a technology of power then, ornamentalism—the forging of the sense of personness through artiﬁcial and prosthetic extensions—provides an allegory for the crisis of personhood that the modern ideal of an integrated, organic, individual person was meant to alleviate. If we think of the Anglo conceptualization of modern personhood as indebted to an Enlightenment notion of natural and integral bodies (posited through John Locke, Thomas Hobbes, René Descartes, Montesquieu, William Blackstone)—the idea, for example, that the person is a living, organic, and organized human body “such as the God of nature formed us”—then we are tracing here another kind of body that confronts us: one that not only poses a challenge to this ideal but also insists on the primacy of aggregated objectness in the experience of the human.20 As if in answer to this bracing realization, we ﬁnd something else in the blue willow assembly (ﬁg. 14).\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Here, aesthetic congealment has grown into full-bodied ediﬁce. The to-be-used Chinese female body seems to 20. William Blackstone, Commentaries on the Laws of England, 1765–1779 (Chicago, 1979),  438  Anne Anlin Cheng \/ Ornamentalism  have petriﬁed into domestic and collectible things (teapots, cups, plates) whose value now resides in their aggressive uselessness. At the same time, this congealed and fractured domesticity, offering repurposed purposelessness, transcends its own mundanity to lay claim to art. Made by contemporary artist Li Xiaofeng (born 1965), this piece is clearly not human, but it is also not entirely a thing. The weight (of material, history, domesticity, femininity) implies petriﬁcation, but the form suggests ﬂight. Is this dress or armor? Is it winged victory or the madwoman in the attic?\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Is it a tribute to monumentality or a concession to the mundane? What has died here—the human or the ornament? And, ﬁnally, has the human outmoded itself or has the object outrun the human demand? We cannot read this piece from the Chinese artist as a rebuke of the Western commercial designers with whom he shares the space because the work is itself a meditation on troubled authenticity.21 The sculpture Beijing Memory No. 5 (2009) by Li was part of a series known for utilizing ceramics excavated from authenticated archaeological sites throughout China. The museum catalogue attributes the ceramic fragments to the Qing Dynasty (1644–1912), commonly known as the last great Chinese dynastic empire, suggesting that the memory being recomposed (or shattered) here is attached to the memory of a lost imperial China and making this piece something of an exercise in what Rey Chow calls the “ethnic detail.”22 Chow notes with her usual acuity that the Chinese detail is always already an ethnic detail—even for the Chinese. For Chow, this is so because of the pastness assigned to the Chinese by Anglo modernity; consequently, the Chinese detail functions for Western modernity as a kind of Nachträglichkeit. The historicity of Li’s version of the Chinese detail, however, has been subjected to much manipulation.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  On a closer look, among the rubble that is the body of this ceramic woman, we discern a scattering of some intact Chinese ideograms. Many are out of context, and several are positioned upside down (an ironic statement of value? a jab at the old joke about Chinese illegibility for Western viewers? ), with words like “precious,” “tea,” “superior.” Others offer seemingly precise self-authentication with stamped reign dates, such as “Xuande Reign of the Great Ming Dynasty (1426–1435),” purporting to indicate a royal workshop. 21. Li is himself an equally complicated ﬁgure who works in China, Hong Kong, and the US and whose work traverses the realms of art, commerce, and kitsch. In 2010, for example, he collaborated with Lacoste to create a collection of polo shirts. Critical Inquiry \/ Spring 2018  The shards thus speak to us and date themselves even further back in time, to the Ming Dynasty, prior to the Qing (ﬁgs.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  15–16). But we cannot rest easy in their promise of more precious pastness because these signatures of provenance, both inside and outside of the artwork, only serve to underscore the homelessness of these fragments. Given the fact that fairly early on the practice of such temporal inscription on objects degraded into anything within the spectral range of affectation to forgery, this kind of designation is likely to be more misleading than not. And since an earlier date would signal a grander affectation and the Xuande era was exactly when such inscriptions ﬁrst became common, it is probable that these fragments may be anything but Xuande. Even more intriguing than this little drama\/trauma of authenticity, moreover, is the possibility that this twenty-ﬁrst-century Chinese porcelain body made for an international audience may be seeking to petrify itself as a gambit for its continued relevance. Just as Beijing Memory No. 5 invokes a vanished China only to unsettle the very thing it claims has disappeared, the sculpture also summons via those calciﬁed, fragmented ceramics the memory of yellow female ﬂesh only to replace it with a more insistent, inorganic presence. This feels less like nostalgia for yellow female ﬂesh than  439  440  Anne Anlin Cheng \/ Ornamentalism  FIGURE 16.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Detail of Li Xiaofeng, Beijing Memory No. 5. Photograph by Cheng. like a consecration of its fossilized (raced and gendered) afterlife. This is ﬂesh congealed into porcelain and porcelain invoking the possibility of ﬂesh. No. 5’s tensile balance between formal preoccupation and suffocating mass asks us to consider the simultaneously dematerializing and materializing processes through which raced female bodies come to matter. It insists that commodity is also art, body, thingness, memory, and its evaporation.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  It instantiates the salvage, the reassemblage, and the subjunctiveness behind Asiatic, female corporeality. If the yellow woman has always been simultaneously embodied and erased through ornamental objectness, then this piece asks what life is or could be after such devastation. Sigmund Freud tells us that one of the most unsettling effects for human ontology is to be confronted by a machine that comes to life.23 Here, with No. 5, what is uncanny is that the machine refuses to come to life and, in its lifelessness, imagines what life might have been. And it is in this very might  Critical Inquiry \/ Spring 2018  have been that we experience the prospective and prosthetic quality of our ontology. In other words, No. 5 does not give us a memory of something; it is memory: the layered encrustations of absent but imagined lives. (It gives us not the human hand but the empty handle.)\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  This yellow woman is instructive, not because “she” offers us a sartorial performances as redemption or because she promises the possibility of the real behind the object. On the contrary, this memory gives us a chance to take seriously (rather than simply decry) the intractable intimacy between Being and being, to explore the entanglement between living and living as thing. In the end, this complicated congealment may be what is possible in a life of precarity. Sometimes, disposable lives ﬁnd themselves through disposable objects. (Is this why some Asian women, given limited options, would rather be ornamental than Oriental?) Freedom for the captured may not be the gift of uncompromised liberty but the more modest and more demanding task of existing within entombed shells. It is not only that bodies can leave their residue in the things that they produce (an insight that object studies has taught us) but also that objectness reveals the divergent, layered, and sometimes annihilating gestures that can make up personhood. More than memorializing bodies that may otherwise not be remembered, Li’s porcelain woman explores what it would mean to instantiate through excess materiality the dematerialized nonbody.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  It marks a kind of third nature, one that surrounds and approximates the human and one that manages to survive despite or through commodiﬁcation. The perihumanity of Asiatic femininity (that is, something at once inside and outside of civilizational ﬁrst principles) is why she is often a ﬁgure enlisted to represent contemporary apprehensions about more-than-human entanglements.24 The aesthetic language—the entanglement between the animate and the inanimate—with which the yellow woman has been infused draws from and sustains a dynamic but disturbing principle of artiﬁcial life that, 24. From Blade Runner (dir. Ridley Scott, 1982) to Ghost in the Shell (dir. Rupert Sanders, 2017), there has been a widespread use of Asiatic aesthetics and tropes in the genre of science ﬁction, especially in ﬁlm. I would suggest that the presence of the Asiatic (Asiatic femininity in particular) is more than an exotic, ornamental detail; it often serves as the site and the conduit through which ideas of the inorganic\/mechanistic interface with the human, more often than not as ethically problematic transgressions. That is, the ornamentalism of Asiatic femininity renders it the perfect agent and parable for the miscegenation of the inhuman and the human. Finally, in relation to the machine aesthetics, one might point out that there is a bifurcation within Asiatic aesthetics between the Chinese (ornate, layered, decadent) and the  441  442  Anne Anlin Cheng \/ Ornamentalism  rather than being peripheral to, intensiﬁes and haunts modernism itself.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  That is, the Asiatic ornamental object person is often seen as opposite to modernity, but it actually contains a forgotten genealogy about the coming together of life and nonlife, labor and style, that conditions the modern human conceit. It suggests a different genealogy of modern personhood: one that is not traceable to an ideal of a biological and organized body bequeathed from a long line of Enlightenment thinkers, but one that is peculiarly inorganic, aggregated, and non-European. This synthetic being, relegated to the margins of modernity and discounted precisely as a nonperson, holds the key to what I see as the inorganic animating the heart of the modern organic subject.25 She\/it brings into view an alternative form of life, not at the site of the free and individualist modern subject, but, contrarily, at the encrusted edges and crevices of deﬁled, ornamented bodies. If liberal racial rhetoric has not been able to tolerate the possibilities of subjective failures or corporeal ambiguity on the part of its cherished objects, it is because the female body and its ineluctable ﬂesh continue to offer the primary site for both denigration and recuperation. At the same time, if recent critical discourse about the posthuman or what has come to be known as object-oriented ontology can at times feel politically disconnected even as its intention has been to unsettle a tradition of insular humanism and anthropocentrism, it is because it has forgotten that the crisis between persons and things has its origins in and remains haunted by the material, legal, and imaginative history of persons made into things. Not only can the nonanthropocentric object (meaning both the potential to be not alive and not of use) not shed the attachment of racial and gendered meanings, but it has also been a vexing, constitutive potential within the human subject. This paradox is most powerfully and poignantly played out for the yellow woman and, for her, holds the most devastating consequences and, for us, the most challenging political and ethical implications, especially for our conceptualization of freedom and agency. We have at last arrived at an understanding of ornamentalism, not as a theory of thingness but as theory about the profound imbrication of things and persons.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  It tells a different story about a different kind of ﬂesh in the history of race making. We can now return to the juxtaposition between Asiatic and Africanist femininity with which this essay began and reconsider  Critical Inquiry \/ Spring 2018  the paths of their divergence. I started this essay by distinguishing the wounded, ﬂesh-laden black body from the immaculate, synthetic, ornamental yellow body. Our journey through the alternative logic of a racialized embodiment that is also not necessarily enﬂeshment, however, suggests that in the end there may be a potential for ornamentalism to speak also to Africanist female enﬂeshment. The body of labor (sexual, reproductive, economic) exempliﬁed by the black female body—ungendered and excluded from the realms of kinship, state, and aesthetic value— is nonetheless not wholly alien to the practice and afterlife of ornamentalism. Or to put it differently, ornamentalism may help elucidate for the black woman a set of different though related issues about the fraught convergence of material violence and aesthetic congealment. We do well to ask, how can we possibly talk about decoration or style in the face of the unimaginable corporeal brutality enacted through the history of slavery? Let me approach this question by bringing up another kind of object: Toni Morrison’s Beloved.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  I turn to Beloved because it is a text that would seem to offer, at least initially, the most powerful argument against the purviews of ornamentalism with its other-than-human aesthetic enchantments. Horrifying scars, wounds, ﬁssures of the ﬂesh abound in Morrison’s novel, giving us vivid and literal instantiations of the “hieroglyphics of the ﬂesh.” We are reminded that the black woman has been “decorated” by culture and law in very speciﬁc and corporeal ways. The novel also contains one of the most moving arguments for the ﬂesh. (It is hard to forget Baby Sugg’s sermon at the Clearing: “You got to love it. . . . Flesh that needs to be loved; Feet that need to rest and to dance; backs that need support. . . . Love your neck . . . and all your inside parts . . . the dark, dark liver . . . the beat and beating heart”).26 At the same time, however, Beloved is also a text that repeatedly compels us (and its main characters) to confront the troubling coincidence of the aesthetic and the abstract precisely at the most devastating of moments, moments of profound unmaking: lynching, rape, torture.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  In the novel, violent scars on the body often manifest themselves as unexpected sites of aesthetic eruptions: a necklace, a smile under the chin, soughing sycamores, a luminous skin dress, a gorgeous chokecherry, a rope around the waist, a little tobacco tin buried in the chest like a treasure box. How are we to understand the uneasy proliferation of ornaments in this novel of grief and violence; how are we to process its terrible beauty? 443  444  Anne Anlin Cheng \/ Ornamentalism  complicated ﬂuctuation between the literal and allegorical. Sethe’s scarred back is never described (by Paul D, Amy, or Sethe herself ) as being like a tree; it always appears to be a tree (see B, pp. 15, 78). In the human-yetnonhuman ﬁgure of the scar, the real entails the ﬁgural even as abstraction manifests materiality, reminding us that ﬂesh as “the zero degree of social conceptualization” is already ridden by conceptualization, the product of acts of imagination and brutality, an evacuation of one kind of the real only to redeposit another. Sethe—half woman, half ornament, with her dead back that is also a tree—is a hybrid being whose personhood applies tremendous pressure on our notions of what constitutes living versus surviving. Now to what extent is this bifurcated condition of being human and nonhuman always already the condition of being black and a slave?\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Why do we need ornamentalism to think about black female objectness? Because it names the aesthetic and inorganic entanglements repressed by (yet critical to) a history of human materialism. Not only does the law speak through abstraction and disembodiment (something that Barbara Johnson has taught us) but also the dehumanized body might actually require objectness in order to subsist.27 Ornamentalism is thus also potentially an operative component in the vestibular economy, helping us to see that there is no “zero degree of conceptualization,” because even bare ﬂesh is inscription—the hieroglyphics of the ﬂesh. Insofar as the fantasy of the organic ﬂesh has remained the single most cherished site of feminist and racial redemption, it has not been able to contest our assumptions about the basis for ontology, or how object life challenges whole sets of aspirations about individualism, freedom, agency, and self-possession. The ﬁgure of the tree in Morrison’s novel is particularly instructive here because, in replacing ﬂesh with wood, it registers the potential for life outside of the human-animal dyad. It introduces into the conversation about blackness and animality another category of being: plant life, itself an allusion to the perverse life produced by the ecology of the plantation. Monique Allewaert suggests that that plantation ecology not only maps the disappearance of human agency for the subaltern but it also charts “an emerging minoritarian colonial conception of agency by which human beings are made richer and stranger through their entwinement with . . . colonial climatological forces as well as plant and animal bodies.”28 The genealogy of the ﬂesh, alongside my genealogy of ornaments,  Critical Inquiry \/ Spring 2018  is not—and has never been—simply human; instead, it tracks something “richer and stranger.” Sethe’s tree is neither bare ﬂesh nor pure object.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Alternately gorgeous and repulsive, fragile and indelible, the clump of scars that is the chokecherry stands as the ﬁxed traces of sorrow, but it is not inert; it has “trunks, branches, and even leaves” and seems to grow and change its contours (B, p. 16). When Morrison tells us that Sethe was “divided . . . back into plant life,” the author registers the cleaving and deprivation of human agency at the plantation, but when she gives us the chokecherry, she opens the door to the possibilities of an alternative form of ontology that survives through its entwinement with dirt, soil, and death (B, p.188). This interspecies entanglement suggests a vision of “collaborative survival,” a shifting assemblage of humans and nonhumans that the modern human “condition” does not usually allow us to see.29 Sethe-the-woman-tree gives us an image of a particular kind of assemblage or deformed personhood that nonetheless evinces form. It is then not an accident that the tree is also the product of wrought labor, born out of different kinds of craft: alternately natural, maternal, creative, and manual. As an intricate and layered composite, it invokes insensate deathliness, wild vegetal extension, and artisanal fabrication: “a sculpture . . . , like the decorative work of an ironsmith” (B, p. 17). One of the reasons that the turn to the ornament as heuristic model has been productive for me has to do with precisely this insight that ﬂesh is an aggregate, an incorporation indebted to a logic of serial attachment that is at once violent and aesthetic, material and abstract.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  The question is no longer how we can think about aesthetics in the face of violence but how we could not. For the black woman, ornamentalism can name a particular mode of being that applies pressure on the fantasy of corporeal integrity. It is precisely when ﬂesh has been deﬁled and radically severed from its own sense of humanity that the path back to it requires mediation. That is, the ﬂesh that passed through objecthood needs ornament as a way back to itself. Even Baby Sugg’s much-quoted sermon, which so passionately urges a return to the ﬂesh, understands that selfpossession has to be courted—with all the strangeness and distance implied by that concept. This is why her song is also a blazon of body parts: “backs that need support; shoulders that need arms. . . . Love your neck; put a hand on it, grace it, stroke it and hold it up” (B, p. 88; my emphasis). This lesson on self-regard delineates an approach back toward the self as  445  446  Anne Anlin Cheng \/ Ornamentalism  a collation of lost objects. Having been made stranger to oneself by unimaginable brutality means that one must reapproach the self as a stranger.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Here the instructions for loving the “natural” body articulate this poignant and melancholic gesture of almost orthopedic reconstruction, of carefully tacking up a scaffold of the body as a prop for your psyche. This is why I think self-love in this novel comes down to Paul D’s advice: “‘You your best thing, Sethe’” (B, p. 273; my emphasis). The haunting in Beloved then is a haunting of the history of racialized ﬂesh—a history that is not opposed to but encompassed by ornamentalism. From the divergence between black ﬂesh and yellow ornament, we have arrived at this convergence: ﬂesh that passed through objecthood needs “ornament” to get back to itself. When it comes to racialized ﬂesh that has been mortiﬁed, ornamentalism points us not only to a history of disciplinary usage (where you mistake someone for something for invidious gains) but also to what it might take to reconceptualize personhood for unmade persons. If feminist scholars have been committed to the ﬂesh in order to undo the taxonomy of gender, then ornamentalism points us toward a consideration of object life that not only undoes but suspends the taxonomy of the human. In our eagerness not to abandon the ﬂesh, we have not been willing to attend to life’s a priori enmeshment with nonlife. Instead of considering what it means for a person to have been turned into a thing with an implicit nostalgia for that lost subject, I am suggesting that we must also consider the reversed process whereby things have been made into persons, thereby revealing the fundamental logic of abstracted decoration that constitutes the category of personhood in the ﬁrst place.\n"}
{"prompt":"Ornamentalism: A Feminist Theory for the Yellow Woman ->","completion":"  Ornamentalism identiﬁes both an epistemology and its fugitive meanings—both instrumentality and unexpected opportunities. It is tied to the practice and aesthetics of Orientalism, but it also offers a critical framework beyond the assumed racial categories and periodization implied by terms such as Orientalism, primitivism, and modernism. By opening up a broader and historically deeper set of inquiries about how the aesthetic entails the political and how the political entails the aesthetic, the coercion and the enchantment of ornamentalism allow the superﬂuous and the not-living that are integral parts of the human to come into view. It is precisely at the interface between ontology and objectness, animated by the ornament, that we are most compelled to confront the horizons and the limits of the politics of personhood.\n"}
{"prompt":"The Black Universe ->","completion":"  seven  The Black Universe  Part II began the process of withdrawing from the standard model.\n"}
{"prompt":"The Black Universe ->","completion":"  Relying first on Deleuze and Marx, we saw the difficulties of actually existing digitality. With the infrastructure of the world understood as essentially digital and computational, a number of alternative logics and conditions become important, among them the irreversibility of relation and the generic determination of the material base. Several areas remain to be explored. Because if the event and the prevent operate on being as apparently “political” forces, the one bent on transforming it internally and the other on rendering it determined and impersonal, the exact nature of these forces remains to be seen. Are the event and the prevent merely two different avatars for the political, or do they reveal the distinction between the political and the ethical? Such is the agenda of the last two chapters of the book, chapters 9 and 10. Yet before addressing the political and the ethical in earnest, we turn to the art and science of the one. Aesthetics is a recurring theme in Laruelle’s work.\n"}
{"prompt":"The Black Universe ->","completion":"  He has written two short books on photography and has several essays on art and related topics, including texts on color, light, seeing, drawing, dance, music, and technology. Technology or science? And what of art? Laruelle’s position on these different domains is not entirely intuitive. For example, he does not follow someone like Heidegger and reestablish a lineage from technology back to art, via the Greek concept of technē. Nor is he phobic of science following those skeptical of industrial modernity. Instead Laruelle is some­thing  of a purist about technology and science. He denigrates technology and elevates science, elevating it to such a degree that it becomes synonymous with non-­standard philosophy overall.1 The technology that surrounds us, from cars to computers to rocket ships, is all rather repulsive for Laruelle.\n"}
{"prompt":"The Black Universe ->","completion":"  Such technology provides little more than an avenue for transit or mediation in and out of things. From this perspective philosophy is the ultimate technology, because philoso­ phy is the ultimate vehicle of transit, and philosophers the ultimate mailmen. Philosophy is all technology wrapped into one, for it is at once mirror, conveyance, energizer, and processor. By contrast, science is the realm of immanence and unilateral relation. Science is the realm of discovery, axiomatics, and theory. If philosophy were a science it would remain immanent to itself, never transiting anywhere, never synthesizing or reflecting on anything. Philosophy would remain where it is, in the dark. But philosophy, always quick to demonstrate its illuminating potential, is never in the dark.\n"}
{"prompt":"The Black Universe ->","completion":"  “Our philosophers are children,” Laruelle reminds us. They are children “who are afraid of the Dark.”2 Alternations of light and dark are the fuel of philosophy. From Plato’s cave to Paul de Man’s “blindness and insight,” philosophers are forever transiting between shadow and illumination. Yet darkness itself is not the problem. The problem is alternation. The problem is not that phi­ losophy is dark. The problem is that philosophy is not dark enough. According to Laruelle we must jump further, not from light to dark but from dark to black, from the darkness of philosophy to the blackness of science.\n"}
{"prompt":"The Black Universe ->","completion":"  So forget your rocket ships and rocket cars. Leave behind the scaffolding of reflection and alternation. “Do not think technology first,” Laruelle commands. “Think science first.”3 Science is, in this way, the least illuminating profession, because it surpasses mere darkness by way of a profound blackness. Never afraid of the dark, Laruelle’s science begins from the posture of the black, communing with the agnostic darkness of the real. But what is this darkness? What is this black universe of which Laruelle sings? Is black a color, and if so can we see it?\n"}
{"prompt":"The Black Universe ->","completion":"  “Philosophy is thinking by way of a generalized ‘black box’; it is the effort to fit black into light and to push it back to the rear of the caverns.”4  Alternations between black and white drive philosophy, but they have also long been the subject of art, from chiaroscuro in Caravaggio, to the shadows in Night of the Hunter (1955). Just as there is an art of light, there is also an art of dark. Just as art has forever pursued what Victorian critic Matthew Arnold called “sweetness and light,” it has also been corrupted by the gloomy gloaming of blackest black. What are the great explorations of black in art? Chief among them would be the Malevich square, or Ad Reinhardt’s black paintings, or the Rothko Chapel in Houston, or some of Stan Brakhage’s films with their murky darkness, or Guy Debord’s notorious “Howls for Sade” (1952), a film that uses its blackness as a kind of weapon. But is the black screen in Debord truly black? Is the Reinhardt canvas a black canvas? All these heroic experiments are no more black than a bright summer day.\n"}
{"prompt":"The Black Universe ->","completion":"  As attempts to capture black they are abject failures, and all the worse for trying to be so avant-­garde, so utterly modern. Such meditations on the color black are quickly revealed to be what they are, meditations. Black appears only in alternation with white, just as quietude is punctuated by noise, and immobile finitude by infinite mobility. The black screen in “Howls for Sade” is not black, but a black box. The film offers us blackness, but only in as much as the blackness can withdraw from other things, in this case from whiteness or from the audible voice. These are all works of alternation, of oscillation into and out of the black. Thus they are properly labeled “reflections” on black—­ even “howls” for black—­because black never appears in these artworks, only the optical alternations of black-­against-­white, black-­against-­color, or black-­against-­sound. Deleuze explains such phenomena near the end of his writings on cinema: “The absence of image,” the black screen or the white screen, have a decisive importance in contemporary cinema. . . .\n"}
{"prompt":"The Black Universe ->","completion":"  They no longer have a simple function of punctuation, as if they marked a change, but enter into a dialectical relation between the image and its absence, and assume a properly structural value. . . . Used in this way, the screen becomes the medium for variations: the black screen and the under-­exposed image, the intense blackness which lets us guess at dark volumes in process of being constituted, or the black marked by a fixed or moving luminous point, and all  the combinations of black and fire; the white screen and the over-­exposed image, the milky image, or the snowy image whose dancing seeds are to take shape.5  Reinhardt’s paintings are the ultimate false lure. What appears at first glance to be black quickly shifts into a complex economy of micro shades of black, each with a different tone and luminosity. Richard Serra’s drawings using black paint sticks—­or some of Gerhard Richter’s works—­are similar in their reinvention of an entire color cosmos thriving both on the interior of black and as black relates to its own exterior. There is thus nothing black about these works, just as there is little silence in that notorious John Cage composition 4´33´´ in which no notes are played. Instead, these works are works of division and alternation, of contrasted extremities, of absence appearing as presence and presence returning to absence. These are meditative works, reflective works, great metaphysical works, great philosophical works even. But at the same time, merely reflective, merely metaphysical, merely philosophical. “Philosophers have divided up the undivided simplicity of the nothingness and the all,” Laruelle reminds us, “but human eyes have never divided up the unique night.”6 The universe is, for Laruelle, a night universe, and to look at the universe means to look into the darkness of the night.\n"}
{"prompt":"The Black Universe ->","completion":"  “Vision is foundational when it abandons perception and sees-­ in-­the-­night.”7 In other words, vision is never vision when the lights are ablaze. Vision is only vision when it looks avidly into the pitch black of night. Likewise art will never be art until it ceases to represent and begins to look into the Stygian monochrome, that blackness that has yet to be exposed to any living light.8 Is this all just another flavor of modern nihilism? Just another existentialism? Laruelle answers no: “The philosophical eye wants to see the nothing in man’s eye rather than see nothing. The philosopher wants to look man’s nothingness in the eye rather than be a nothingness of vision”—­nothing in man’s eye versus seeing nothing.9 Recall those horrible nothing worlds of the existentialists. The existentialist can see man as nothing; the existentialist might even be able to see the world as nothing. But he cannot yet see nothing as nothing.\n"}
{"prompt":"The Black Universe ->","completion":"  Philosophers have long asked why there is something rather than nothing. For Aristotle the question was always: Why is there something  rather than something else? For Nietzsche or Kierkegaard it was: Why is there nothing rather than something? But for Laruelle the question is poorly formed from the outset. For Laruelle the question might rather be, Why, in looking at nothing, do we still never see nothing? For as Parmenides said, nothing comes from nothing. “Man is this middle between night and nothing” writes Laruelle. Or rather, “less than this middle: nothing which is only nothing; night which is only night.”10 But still, what is this darkness, and where is the light?\n"}
{"prompt":"The Black Universe ->","completion":"  How does dark relate to black, and light to white? What is a hermeneutic light? Of the many unresolved debates surrounding the work of Heidegger, the following question returns with some regularity: Is Heidegger’s phenomenology ultimately a question of herme­ neutics and interpretation, or is it ultimately a question of immanence and truth? Is Dasein forever questing after a Being that withdraws, or does it somehow achieve a primordial communion with the truth of Being? In other words, is Heidegger the philosopher of blackness or the philosopher of light? Hermeneutics was an important topic for theory in the 1960s. Hence it is not surprising that Heidegger, who was being rediscovered and rethought during that period, would often be framed in terms of hermeneu­ tics. To be sure, the critical tradition handed down from post-­structuralism leaves little room for modes of immanence and immediacy, modes that were marginalized as essentialist or otherwise unpleasant (often for good reason).\n"}
{"prompt":"The Black Universe ->","completion":"  Thus it would be easy to assimilate into the tradition of her­ meneutics a figure like Heidegger, with his complicated withdrawal of Being. For where else would he fit? Indeed it is common to categorize Heidegger there. But is it not also possible to show that Heidegger is a philosopher of immanence? Is it not also possible to show that he speaks as much to illumination as to withdrawal? That he speaks as much to the intuitive and proximate as to the detached and distanced? For instance, consider his treatment of gelichtet, a word stemming from the noun for “light.” In the chapter on the “there” in Being and Time, Heidegger speaks of Dasein as lumen (one of two Latin words meaning “light”) and defines Dasein in terms of the “clearing” (gelichtet) or “illumination” of Being:  When we talk in an ontically figurative way of the lumen naturale in man, we have in mind nothing other than the existential-­ontological structure of this entity, that it is in such a way as to be its “there”. To say that it is ‘illuminated’ [“erleuchtet”] means that as Being-­in-­the-­world it is cleared [gelichtet] in itself, not through any other entity, but in such a way that it is itself the clearing.11  No one can deny the cryptological tendencies in Heidegger.\n"}
{"prompt":"The Black Universe ->","completion":"  No one can deny that, for Heidegger, Being likes to hide itself. But this is far outweighed by the fact that Dasein can indeed be experienced as an authentic disclosedness of Being, by the fact that phenomenology preaches—­with­ out irony or pathos—­that one may strive “toward the things themselves” and actually arrive at them. Recall that hermeneutics is the science of suspicion, the science of the insincere. But Heidegger, like Socrates before him, is the consummate philosopher of sincerity. The phenomenological subject is the one who has an authentic and sincere relationship with Being. Because of this, we should not be too quick to consign Heidegger to the history of hermeneu­ tics. Hermes’s natural habitat is teeming with deception; his economies are economies in the absence of trust. But Heidegger lives in a different world.\n"}
{"prompt":"The Black Universe ->","completion":"  His world is a world of authentic presence, of questing after truth. Thus running in parallel to the Hermes-­Heidegger, the Heidegger who touches on the tradition of interpretation and exchange in the face of the withdrawal of Being, there is also an Iris-­Heidegger, the Heidegger who touches on the tradition of illumination and iridescence along the pathway of seeking. Heidegger’s is not simply a Hermes narrative, but also an Iris arc.12 When Heidegger evokes the lumen naturale of mankind he is making reference to one of two kinds of light. The light of mankind is a terrestrial light. When bodies with their anima (their vital force) are vigorous and alive, they are illuminated with the light of the lumen naturale. Lumen is the light of life, the light of this world, the light that sparkles from the eyes of consciousness. But there is a second type of light. Being carries its own light that is not the light of man.\n"}
{"prompt":"The Black Universe ->","completion":"  This light is a cosmological light, a divine light, the light of the phenomena, light as grace, or, as Laruelle says, the kind of light that does not originate from a star. So just as there are two Heideggers, there are also two lights. One light is the light of transparent bodies, clear and mobile. It is the light of this world, experienced through passage and illumination. The other light is the light of opaque bodies. It is the light of color, a holy light, experienced only through the dull emanation of things. Dioptrics and catoptrics. If there exists a natural lightness, is there not also a natural darkness?\n"}
{"prompt":"The Black Universe ->","completion":"  And if there are two kinds of light are there not also two kinds of dark? Such questions lie at the heart of Reza Negarestani’s Cyclonopedia: Complicity with Anonymous Materials, a hallucinatory mix of theory and fiction that views the Earth as a quasi-­living, demonic creature, oil the blood in its veins. Oil petroleum is black, of course, in color if not also in its moral decrepitude. But oil is also light, because it is a transmutation of the light of the sun. Oil is the geological product of sunlight, first via photosynthesis into vegetable matter, and second via the decomposition of vegetable matter over time. In this sense, oil is, as Negarestani calls it, the “black corpse of the sun.”13 But before looking more closely at the two kinds of darkness, let us examine the two kinds of lightness a bit further. Negarestani writes about fog and light. He writes about the “mistmare.” But what is mist?\n"}
{"prompt":"The Black Universe ->","completion":"  He writes of Pazuzu, the wind, the dust enforcer. But what is dust? Of course, dust and fog have certain obfuscatory qualities. They strangle the light and interfere with one’s ability to see. But at the same time they have their own form of luminosity. Fog glows with a certain ambience. It transforms a space of absolute coordinates into a proximal zone governed by thresholds of intelligibility. (Fog is thus first and foremost a category of existence—­there can be no ontological fog; that would be something else.)\n"}
{"prompt":"The Black Universe ->","completion":"  Fog is a dioptric phenomenon, even if ironically it acts to impede vision. It is a question of light passing through materials, and likewise a question of the light of mankind passing through (or being impeded from passing through) a proximal space. This means that fog is part of the luminaria. Fog gives off no light of its own, even if it has its own luminosity by virtue of filtering and passing along a light originating from elsewhere. The term dioptric has been broached, and in order to continue it will be necessary to define this term in some detail, along with the related  term catoptric. These two terms are part of the science of optics, and hence the being of light, but they describe the dealings of light in two very different ways. Dioptrics refers to light when it is refracted, that is to say, when light passes through transparent materials such as glass or water. As a branch of optical science, dioptrics is concerned principally with lenses.\n"}
{"prompt":"The Black Universe ->","completion":"  Yet things not specifically conceived as lenses can also act as such. Some of the best examples are the tiny water droplets contained in clouds, spherical in shape, that allow light passing through them to refract twice, once as the light enters the droplet and again as it leaves. Prisms also offer a fine illustration of dioptric phenomena; like a water droplet, a prism splits light into color bands because different wavelengths of light refract differently. A dioptric device can therefore divide white light into colored light, just as it can merge colored light into white light again, given the right conditions. Catoptrics refers to light when it is reflected, that is to say, when light bounces off objects in the world. Whereas dioptrics is concerned with lenses, catoptrics is concerned principally with mirrors. All sorts of objects can act as mirrors proper—­polished glass or metal, the surface of water. But catoptrics also includes the duller quasi-­mirror effects of plain objects, which reflect light and allow themselves to be visible to the eye.\n"}
{"prompt":"The Black Universe ->","completion":"  Just as the prism can produce what Goethe called “physical color,” there is also a color capacity in catoptric phenomena, because some objects reflect certain colors and absorb others (Goethe’s “chemical color”). So if, in general, dioptric phenomena are the phenomena of prisms and lenses, catoptric phenomena are the phenomena of mirrors, screens, walls, and opaque surfaces. In short, the former is a question of transparency, while the latter is a question of opacity. Dioptrics is a perspective (seeing through), while catoptrics is a speculum or aspect (reflecting, looking at).14 Recall the god of so many aspects, so many epithets. He is Hermes, messenger to Zeus. And yet his counterpart Iris, messenger to Hera, has relatively few epithets; her business is that of shining through. In this way Hermes is the aspect god, the god of catoptrics, and Iris is the perspective goddess, the goddess of dioptrics. The effects of refraction “remain within” a transparent physical object such as a glass lens, and hence are to be considered a phenomenon of immanence.\n"}
{"prompt":"The Black Universe ->","completion":"  By contrast  the effects of reflection are to obscure the source object, to leverage the very opacity of the object for some other end, and hence they are to be considered a phenomenon of hermeneutics. These same principles can be stated in different terms. Both dioptrics and catoptrics have a special relationship to depth; however, the distinction between the two could not be more stark. Reflection is semiotically deep, that is, it is deep in the domain of meaning, whereas refraction is experientially deep, that is, it is deep in the domain of subjective experience. Saying “semiotically deep” means that opaque reflection creates a depth model wherein two opposing layers, one manifest and one latent, work together to create meaning. This is the same depth model that exists in Freud or Marx. Saying “experientially deep” means that transparent refraction creates a depth model wherein a real sense of volumetric space is created and presented to a viewing subject. This is the same depth model that exists in Heidegger (or even in others like Kant).\n"}
{"prompt":"The Black Universe ->","completion":"  There are veils covering the soul, but there are also telescopes for viewing the heavens—­the one is an aspect, the other a perspective. Yet beyond exhibiting depth in two contrasting ways, catoptrics and dioptrics are also equally distinct in how they deal with flatness. Being semiotically deep, catoptric reflection is at the same time ontically flat. That is to say, reflection is manifest in two-­dimensional surfaces and other flat things arranged in the world. The very existence of the reflected image is a flat existence. Dioptric refraction, however, being experientially deep, is at the same time ontologically flat. That is to say, refraction is immanent to materials; there is no transcendent or metaphysical cause that operates across or after the being of the phenomenon. This is why whatever is immanent also must be flat.\n"}
{"prompt":"The Black Universe ->","completion":"  This variety of flatness is best understood as a flatness of identity, a selfsame quality vis-­à-­vis the being of the thing. Dioptric refraction, as iridescent immanence, “remains within” itself. These claims, being somewhat abstract, should be explained a little further. We have asserted that dioptrics is experiential. What this means is that dioptrics is on the side of the subject. Dioptrics is always a question of crafting a clear or real subjective experience. This is why the concept of dioptric illumination is so closely associated with the modern period, why we refer to “the Enlightenment”—­which the French render with even less subtlety as les Lumières. But it is also why this same  modern trajectory ends up at Kantianism, at romanticism, and eventually at Heidegger and phenomenology, because the question of subjective experience must always remain at the heart of the modern experience.\n"}
{"prompt":"The Black Universe ->","completion":"  By contrast, we said previously that catoptrics is semiotic. What this means is that catoptrics is on the side of matter, on the side of the pharmakon. Catoptrics is always a question of meaning. Although subjects might be involved, the process is never primarily subjective. Rather the process is primarily a question of what Stiegler terms hypomnesis, the act of externalizing the subject—­or to be more precise, the subject’s memory—­ into material supports. This too is a modern trajectory, but it ends up at a different place: not in the illumination of the subject, but in the obscurantism of the culture industries, in spectacle, in ideology, and in the tra­ dition of critique that terminates in structuralism and post-­structuralism. Jesuit mathematician François d’Aguilon, in two propositions from his early seventeenth-­century opus on optics Opticorum Libri Sex, offers two additional points concerning the difference between dioptric transparency and catoptric opacity. The two points appear in propositions number 31 and 32 of book 1: Proposition 31—­Lux [light] and color are the properties of an opaque body.\n"}
{"prompt":"The Black Universe ->","completion":"  Proposition 32—­Lumen [illumination, luminosity] is the action of a transparent body.15  The distinction between two kinds of light made by d’Aguilon is the same distinction made since ancient times: in Latin lux and lumen; in Greek phos (φῶς) and phoster (φωστήρ); or in Hebrew or (‫ )דוא‬and maor (‫)דואמ‬. Recall the echo that occurs between Genesis 1:3 and 1:14, when God creates light, and then creates it a second time (see Francisco de Holanda, Fiant luminaria in firmamento celi, the frontispiece of this chapter). The echo nicely captures the difference between the two kinds of light. The first time light comes into the world it comes as lux. This lux means light, but it is a special kind of light, the light of being, the light of God, a cosmological light. The second time light comes, it comes as lumen (or rather as luminaria, the things that show lumen). This lumen also means light, but only in a very specific way. Lumen means sun, moon, and stars—­the bodies that give light in as much as they can shine through with the divine light.\n"}
{"prompt":"The Black Universe ->","completion":"  Although the English language differentiates between light and luminosity, English often loses the subtlety between the two kinds of light. D’Aguilon assigns the first term to opaque bodies, and thus, by association we may be certain that he speaks of catoptric phenomenon. The second he assigns to transparent bodies, and thus to dioptric phenomenon. In other words, lux is catoptric and lumen is dioptric. There is a precedence here too. For just as the Renaissance preceded the Baroque, lux in Genesis 1:3 precedes lumen in Genesis 1:14, and catop­ trics precedes dioptrics. Descartes would confirm this same sentiment in a 1638 letter written a few years after d’Aguilon: “Light, that is, lux, is a movement or an action in the luminous body, and tends to cause some movement in transparent bodies, namely lumen. Thus lux is before lumen.”16 (The firstness of Iris arrives, then, as a kind of counterintuitive miracle, scrapping all precedence, erasing diachrony for synchrony.)\n"}
{"prompt":"The Black Universe ->","completion":"  In this way God, bearing the lux light of the cosmological fiat, is absolute in His opacity. God is the absolute source of light, but at the same time the one who is absolutely inaccessible. Opacity is the quality that we can assign to His being. Yet, the light of lumen—­illumination, luminosity—­is absolute in its transparency, as it travels through the actually existing world. Thus transparency is the quality that we can assign to His existing. This is the second point that can be gained from d’Aguilon’s two propositions, that lumen or dioptrics is always an action of existence, an active motion of looking-­throughness, while lux or catoptrics is always a fact of being (a property). The black corpse of the sun. Now we are in a better position to consider the kinds of darkness and their relationship to the light.\n"}
{"prompt":"The Black Universe ->","completion":"  To summarize, illumination (lumen) refers to the action of transparent bodies in their luminosity and radiant iridescence. These bodies are the sun, the moon and stars, fire and mankind. Not white so much as bright. It is the light of life and consciousness. It is multiple, never singular. It is a perspective, and therefore allied with dioptrics and Iris. By contrast, light (lux) refers to the property of an opaque body in its fact of being. This is the light of God, the light of being, a cosmological light, but also the light of daytime (as opposed to sunlight).\n"}
{"prompt":"The Black Universe ->","completion":"  It is an aspect, and therefore allied with catoptrics and Hermes. It is singular,  never multiple. It is white only in so much as it is the whiteness of pure opacity. Lux is the plenum. It is the obscure. It is grace. Now on to the darkness. Here too are two modalities, all the more different because of their near identity.\n"}
{"prompt":"The Black Universe ->","completion":"  Darkness may be gloom, murkiness, shadow, or shade. It may be dusk, night, or twilight. Bodies may be dark. One might speak of “dark” materials, in as much as they are asleep, unconsciousness, dead, or cold. Likewise, habit or cliché may be understood as a kind of darkness of experience, an inability to revivify the normal routine of living. Hence the darkening, or obscuritas, described in Revelation 9:2—obscur­ atus est sol et aer de fumo putei, “The sun was darkened, and the air, by the smoke of the pit.” The sun is obscured by smoke, and hence the earthbound shadows of an obscuring darkness. As the sun and moon and stars are progressively snuffed out, they are obscurare. It is not yet a question of ontological darkness, but rather the darkness of the world.\n"}
{"prompt":"The Black Universe ->","completion":"  It is the nihil privativum discussed in Schopenhauer, the “privative nothing” that is dark by virtue of depriving the light. But there is another kind of darkness, the tenebrae, the shadows of black being separated from the lux of heaven in Genesis (2, 4, 5, and 18). No longer simply dark, the question now is that of a profound blackness. Such is the generic darkness of the abyss, the void and vacuum, the darkness of catastrophe and cataclysm. It is a cosmological blackness, the black of Satan, the black of absolute evil, the black of nonbeing. It is what Thacker describes as “cosmic pessimism . . . hermeticism of the abyss.”17 The shadows of black being are a hermeneutic blackness. Not simply a world gone dark, such blackness is a world without us.\n"}
{"prompt":"The Black Universe ->","completion":"  Not simply a question of dying or growing cold, such blackness means the leaving of being. In contrast to the “privative nothing” comes Schopenhauer’s nihil negativum (“negative nothing”), nothing as absolute foreclosure. In this sense, the shadows of black being are not part of any ontology, but rather constitute an encryption or crypto-­ontology. These are the shadows of the kruptos (κρυπτός), the hidden parts that form the inward nature of things. And hence in Revelation, beyond the sun being obscured and made dark, there is also a secondary darkness. The kingdom of heaven is  threatened secondarily by the blackness of the tenebrae, for ultimately factum est regnum eius tenebrosum, “His kingdom was full of darkness” (Revelation 16:10). Return now to Negarestani and the petroleum that fuels contemporary society. Is this oil, as putrification, the product of lux or lumen?\n"}
{"prompt":"The Black Universe ->","completion":"  Is oil black or dark? As Negarestani writes, oil is “Hydrocarbon Corpse Juice.” Sun is captured in photosynthesis, then via decay is putrified into a liquid fossil form. So as sun juice, oil is the darkening of sunlight. Oil is thus literally dead; oil is death. And as transubstantiated sunlight, oil is lumen, or at least some product thereof. But there is also a blackness to oil. “Oil is the Black Corpse of the Sun,” he writes. Now no longer simply solar, oil’s tellurian core wells up, the insurgent enemy of solar capitalism.\n"}
{"prompt":"The Black Universe ->","completion":"  This is oil at its blackest. This is oil as the “Devil’s Excrement,” oil as the conspirator—­not as lux but as the tenebra or shadow of black being—­who annihilates societies by “tear[ing] them apart slowly.”18 And so, just as it was possible to speak of the shadows of black being as a crypto-­ontology, Negarestani can speak of a crypto-­ontology for oil. In such a crypto-­ontology, oil is understood not simply as dark but as radical blackness, held in escrow by a cosmic pessimism, with its kruptos or hidden parts absolutely foreclosed to us, but also to being itself. Blackness is a crypto-­ontology absolutely foreclosed to being. Only through this final definition—­black as kruptos foreclosed to being—­can we begin to understand what Laruelle means by the black universe. Only by way of a withdrawal from the system of light and color can we begin to see the generic real of blackness. Channel that great saint of radical blackness, Toussaint Louverture, and return to the Haitian Constitution of 1804, which stated that all citizens will be called black regardless of color. Such blanket totality of black, such cataclysm of human color, renders color invalid and denies the endless dynamics of black-­as-­white or white-­as-­black.\n"}
{"prompt":"The Black Universe ->","completion":"  Black is no longer the limit case, no longer the case of the slave, the poor, the indentured or debt-­ridden worker. Black is the foundation of a new uchromia, a new color utopia rooted in the generic black universe. “Our uchromia: to learn to think from the point of view of Black as what determines color in the last instance rather than what limits it.”19  Our uchromia, our non-­chromia or non-­color—­what does Laruelle mean by this? As Laruelle would say, color always has a position. Color always has a stance. The color palette or the color spectrum provide a complex field of difference and alternation. The primary colors reside in their determining positions, while other colors compliment each other as contrasts. Hence the color posture: purple complimenting yellow, red complimenting green, the primary colors’ posture vis-­à-­vis the palette, and ultimately the posture of color itself governing the continuum of light and dark, as colors take turns emerging into a luminous and supersaturated visibility, or receding into a sunless gloom.20 Laruelle uses photography as a way to explain these never-­ending quests into and out of things.\n"}
{"prompt":"The Black Universe ->","completion":"  “Platonism is perhaps born of the absence of a photo,” he writes, proposing a provocative anachronism. “From this we get the model and the copy, and their common derivative in the simulacrum. And Leibniz and Kant alike—­the intelligible depth of the phenomenon as much as its trenchant distinction—­find their possibility in this repression of photography.”21 According to Laruelle, photography has long been held captive, forced to choose between two unappetizing options, philosophy on one hand (consciousness and reflection), psychoanalysis on the other (the unconscious and [automatic drives]). . . . The photo is then neither a mode of philosophical reflection—­even if there is plenty of photography integrated into philosophy—­nor a mode of unconscious represe­ntation or a return of the repressed. Neither Being nor the Other; neither Consciousness nor the Unconscious, neither the present nor the repressed.22  Photography is an ideal candidate for Laruelle’s intervention, because photography requires that light penetrate an aperture and write itself on a sensitive surface, resulting in prints that, in turn, reflect light back to viewers. “Philosophy remains an optics,” he writes. “Transcendental no doubt, but specular: intuitiveness is its unavoidable structure. The eye is first an external empirical sense; then it is divided and doubled, the introduction of the other gaze constituting an a priori optical or specular  field; then the gazes knot themselves together, form a chiasmus, and constitute a transcendental speculative field.”23 Which is precisely what Laruelle seeks to avoid.\n"}
{"prompt":"The Black Universe ->","completion":"  Using the language of optics invoked previously, Laruelle exhibits a unilateralized dioptrics, in that he rejects absolutely the reduplication and extension of the eye in favor of an immanent transparency of identity. But he simultaneously exhibits a unilateralized catoptrics, in that he assigns a pure opacity to the one, a pure density, a pure imperviousness. “The multiplication of the eye into a recursive spiral does not suppress it,” he reminds us, “for the eye is the intuition that now gives the other eye; the gaze that opens upon the other gaze—­such is the kernel of all transcendental aesthetics.”24 Is this not the great phenomenological gambit, that physiognomy is destiny, that our eyes and senses orient ourselves into a world, toward phenomena that orient and reveal themselves back to us? The philosopher says, Humanity was endowed with the faculty of sight, so humanity must devote itself to seeing, and seeing well. But Laruelle says, The decision is never between looking and seeing or between listening and hearing. That is no decision at all. The true decision, the decision already made implicitly by philosophy, is to see and hear in the first place. We decide each time we open our eyes.\n"}
{"prompt":"The Black Universe ->","completion":"  In other words, photography is always understood as color photography, black-­and-­white photography even, but never black photography proper. Rather than these other color photographies evident in phenomenology, psychoanalysis, or philosophy at large, Laruelle writes that we need photography (now recast as non-­photography) as science photography or identity photography. But what would “identity photography” mean? Identity photography is black photography. And thus identity photography is the only kind of photography that could inscribe the black universe. Laruelle calls such photography a “hyperphenomenology of the real”; it follows a logic of auto-­impression, not expression.25 Not a cliché snapshot, but an immanent identity of the Real. “One does not photograph the World, the City, History,” Laruelle claims. One photographs “the identity (of) the real-­in-­the-­last-­instance.”26 In this sense, although color always carries itself in terms of a “posture” or “stance,” black is immanent to itself and  thus can only be an in-­stance, an instance, or as Laruelle says, the last instance.\n"}
{"prompt":"The Black Universe ->","completion":"  “Simplify color!” he cries. “See black, think white! See black rather than believe ‘unconscious.’ And think white rather than believe ‘conscious.’”27 Don’t see, be a seer. Stop seeing and start visioning. Be a visionary. Watchers and lookers are the ones who see white, who see the thing that they know they will always see. But the one who sees black is the true clairvoyant. The black seer is the oracular prophet, what we call “a medium.” And hence to understand media—­and indeed to “do” media theory—­is to start visioning purely in the black universe.\n"}
{"prompt":"The Black Universe ->","completion":"  Never to see visions, never to hallucinate (for that is what philosophers do), rather to see vision. This is what Laruelle means when he says that vision “abandons perception and sees-­in-­the-­night.”28 This is what he means when he deploys that thorny non-­philosophical term of art “vision-­in-­One.” The blackness of the person. Laruelle’s black is not simply a theory of the universe, but also a theory of the subject, what he calls the “human” or the “person.” At the same time the black universe allows for a mystical justice that is irreducible to either Christian morality on the one hand or liberal ecumenicalism on the other. “All philosophical speculation is communication, and communication is always speculative,” he writes, in a re-­articulation of the media principle from Thesis I.29 The media principle is so troublesome because it limits the discussion to one of two scenarios: either to speculate for or on behalf of the other, or to speculate for or about the self. The subject is either reflective or introspective. The subject is either too nosy about others or too vain about itself. These are the two great maxims of philosophy: the first maxim, “to see for itself by seeing in the place of the other,” and the second maxim, the ancient law of “an-­eye-­for-­an-­eye.”30 This is why metaphysics is described by Laruelle in terms of vengeance. Either “an eye for an eye,” the symmet­ rical, retributive justice of the Old Testament, or what he calls “Eye-­for-­ the-­Other, as hostage-­of-­the-­Other-­eye,” the universalization of liberal relativism where we promise to see for the other, or even, in our infinite wisdom, to step back and let the other try to see for itself.31 Either way, the eye is held hostage, vision is vengeance, and vengeance is ours.\n"}
{"prompt":"The Black Universe ->","completion":"  Instead, the black universe allows for a mystical subject (capable of mystical justice) because it eliminates speculation. No more eye-­for-­an-­ eye, and no more eye-­for-­the-­other. No more exchange of looks, no more patriarchal gaze, and no more commerce in vision. Instead the black universe allows for an absolutely determined and unidirectional vision, a kind of visionary vision that looks without looking. To be clear, Laruelle does not take the usual exit; he does not escape the quandary of self-­other relations by singing the praises of a universalized multiplicity of voices. In fact he takes a different step, unexpected and rather unfashionable in today’s progressive theory landscape. Laruelle pursues an absolutely determined and unidirectional vision, all and everywhere, destiny and determination from before the first to after the last instance. To summarize before ending—­there are two kinds of light, the lux with its purely opaque source and the luminaria that reflect lux into this profane world.\n"}
{"prompt":"The Black Universe ->","completion":"  And likewise there are two kinds of dark, the darkening (obscuritas) of the luminaria as they sputter out and die, and the tenebrae themselves, the shadows of black being. But all of this, from black to white and from dark to light, is still a part of the standard model. If black is merely the absence of white, and dark the absence of light, then we remain locked in a world of relation, reflection, continua, and convertibility, black-­as-­white and dark-­as-­light. Such is the philosophical decision in a nutshell, to decide to frame the world in terms of digital color. Laruelle, by contrast, entreats us to withdraw from the system of color and enter into a purely radical and unilaterally black universe. This is a universe in which black is never defined in terms of light, nor ultimately exchangeable with or made visible by illumination. Just like in the introduction and the secret of Hermes that has never been divulged to any living human, the black of the universe has never been seen before by anyone. It is only through a kind of negative intuition that we dare to call it a color at all.\n"}
{"prompt":"The Black Universe ->","completion":"  This is the condition of the Laruellean person, and ultimately the condition for a new kind of black justice: unilaterally determined by the real, but never by mundane reality; faithful to the conditions of a generic humanity, but never debased to the banal conditions of the world. If you open your eyes partway you see white, but if you open them all the way you see black. Do not let the philosophers draw you out of the cavern and into the light, only to be dazzled by the first rays of the sun. But at the same time, do not douse the light and dig deeper into the abyss, in an attempt to spiral lower, darker, into your gloomy soul. Laruelle’s human is one who opens its eyes in the night, not to look or speculate but to know. We are this night. “The night is this human, the human who does not speculate about man. Who am I, me who is?\n"}
{"prompt":"The Black Universe ->","completion":"  I am neither this reason nor this way of thinking, neither this question nor this speculation. I am this night. . . .”32  This page intentionally left blank  August von Briesen, Drawing of Mozart’s Piano Concerto No. 22, 1981. 38 × 38 cm. Reproduced courtesy of Anastasia Ogilvie von Briesen.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Subscribe to Magazine » « Features  Notes on the Relational Aesthetics of Ambient A.I.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  By Jason Hoelscher Technologies become socially interesting only when they become technologically boring, to paraphrase NYU new media professor Clay Shirky. That is, people marvel at a new gadget when it debuts, because its rarity causes it to stand out. At that point it is technologically interesting but socially dull. It is only when a technology becomes integrated into everyday life, so prevalent as to be largely invisible, that its social effects become interesting. Artificial intelligence has already reached this point even before it has fully arrived, going straight to the technologically dull but socially compelling stage. While science fiction has long presented A.I. as some sort of large, well-spoken mainframe computer, in reality A.I. is largely invisible, less an object than a set of immaterial tools and processes that underlie systems of transport, security, finance, healthcare, law enforcement, and so on.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Put simply, A.I. has become deeply integrated into the fabric of everyday relations without our noticing, and the A.I. systems most of us encounter daily do not even register as A.I. in the first place. Art, on the other hand, operates quite differently. If technology must become materially dull before it becomes socially compelling, artworks can sustain interest in both senses, sometimes for centuries after their creation. Recall Erwin Panofsky’s description, in Perspective as Symbolic Form, of how Renaissance linear perspective established and reinforced a spatial and organizational logic for western visuality. This visual logic created an objectivity of human experience that anticipated the scientific revolution and the Enlightenment.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Consider further how, in the 20th century, cubist fragmentation not only ruptured this artistic plane of objective certainty, but opened the door to such fragmented and scattershot modes of contemporary experience as quick-cut film edits, memes,  our relational and social encounters. Whereas it took centuries for western art to become untethered from the object and to dematerialize into conceptual art, systems aesthetics, and relational aesthetics, A.I. has been post-object all along, or at least since its seamless emergence into widespread use. This prompts a question: what happens when social relations and aesthetic experience are permeated by atmospheric fields of invisible, technological intelligence? To update Guy Debord’s notion of the spectacle as a social relation mediated by images, what happens when social relations are mediated by ambient technologies? In order to explore some of these questions and ideas, this article is structured akin to the theory equivalent of a poetry slam, privileging the fast and rapid-fire over the methodically reasoned through. I offer ten prompts, ranging from the general to the specific, and from the plausible to the wildly speculative, regarding ways the accelerating emergence of artificial intelligence might influence art and creative culture in coming years, and vice versa. My goal here is less to provide an authoritative take on the issue-an impossibility, as we are too enmeshed within the moment to see it with any great clarity-than to suggest avenues for further consideration and exploration.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  One: Art’s indeterminacy will become a crucial counterpoint to A.I. quantification Although art has been a problematic philosophical subject since at least the era of Plato, aesthetics did not emerge as a distinct discipline until the mid-18th century. This emergence was in large part a response to the rise of Enlightenment thinking and the scientific method, both of which focused on quantification and objectivity at the expense of the subjective and non-quantifiable. Following on this, what roles might art and aesthetics play today, when every aspect of society, culture and experience is undergoing quantification at levels of high-granularity detail unimaginable even a decade ago? I would propose that art’s ability to generate and sustain indeterminacy and difference might serve as a counter to just such quantification by information technology. Consider that information in a technical sense is a measure of difference, but most differences settle. A new fact constitutes a momentary difference relative to its context-which is what we call information-but then quickly settles into the equilibrium of knowledge. Art’s difference, however, remains different over time, less a difference than a process of differencing.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  While we all know the factual information and purpose of a snow shovel, we still debate Duchamp’s readymade snow shovel a century later, because its difference never settles, but continues differencing. This capability of sustained differencing reveals art’s potentials for resisting high-tech standardization and quantification, as a complex mode of open information. An A.I. could tell us everything about the snow shovel or the Mona Lisa down to the atomic level, while never quite reaching whatever aspects make these things art. Will Penny, Hypershade III, 2018, (still), projection mapped 4:00 minute single channel digital video on RENshape 5014 panel, 46” x 94” x 3 ½.” 3D scanned forms converted into a sculptural relief with projection mapped animation overlay. Three: Art will become conceptual in new ways, as A.I. textualizes the world beyond anything Roland Barthes or Jacques Derrida ever conceived A.I. systems operate by way of algorithms, which are sets of instructions.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  In this sense, algorithms are a performative mode of operational textuality-not just text that describes things, but text that does things. I would argue that A.I. marks a new, pervasive, and accelerated textualization of the everyday. In a world saturated with Wi-Fi and 4G signals zipping back and forth, constant data flows from smart-watches and facial recognition systems, and GPS-based location trackers in every pocket or purse-not to mention the trillion other data points that undergo A.I. correlation every second in vast databases-contemporary life offers a new and algorithmic take on Derrida’s famous quote that “there is no outside-the-text.” As we continue to move beyond what Lev Manovich describes as older narrative modes of culture toward a database mode of culture, aesthetic approaches to such algorithmic textuality will open new ways to re-organize and re-integrate culture and creativity along relational rather than deterministic lines. Four: Art’s relation to information will change as A.I. transforms human modes of communication and relation In his recent book The Second Digital Turn, architectural historian Mario Carpo describes human  as bandwidth needs have loosened, we have seen a correlative rise of less-particular communication modes as emoji, less reliant on specificity of meaning and more open to interpretation. This is arguably the first time in history that a widely-adopted written language has been designed as deliberately less specific than its predecessors.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Further, the fact that emoji and related modes of textuality are entirely visual suggests interesting potentials in terms of relational art and aesthetics. Five: A.I. art is not fine art-not yet, anyway A web search of art + artificial intelligence yields a range of interesting results, mostly focused around A.I. systems that generate images both beautiful and strange. Of these, the results of the Google Deep Dream project are the most widely known, being hauntingly bizarre and often downright surreal. That said, unless they are created in tandem with a human creator, I do not believe the results of these works qualify as fine art-at least, not in the sense of “fine art” as promulgated by MFA programs, MoMA, the global biennial scene, and art history as constituted in the west over the last two centuries. Figuring out such things is why art students get MFA degrees in the first place, whether they know that fact beforehand or not. One thing that separates the fine arts from everyday vernacular art is art’s relationship to questions, to other art, and to the larger field of discursive relations in which art operates.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Vernacular art succeeds on its own terms as long as it looks and feels interesting, beautiful, or engaging. Although a Picasso, Pollock or Piper artwork might also succeed along these lines, these works also test, interrogate and complicate their world. Beautiful and engaging or not, these works also challenge those ideas of vision, experience, or performance staked out by other art of the past or present. Jason Hoelscher. Arbitrary Signage. 2019. Google Deep Dream Generator text-to-image transform, inception depth level 3. Courtesy of the artist.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  By these standards, then, an A.I. does not create a work of art any more than a bank surveillance camera creates art by occasionally capturing a dynamic or well-composed scene. This is not to say A.I. might not do so in the future. For now, however, A.I. is essentially limited to pattern matching and reconfiguration-based approaches, and thus creates little more than interestingly art-like artifacts. The first A.I. to become aware of fine art’s entanglement with artistic discourses, transtemporal relations, and ideological expectations will create works that pose serious challenges to how we have come to define art in the western world since the emergence of modernism.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Six: A.I. + Art = Ambiguous\/Aesthetic\/Indeterminate Artificial Intelligence, or A\/A\/I.A.I. Like all contemporary computational architecture, current A.I. systems are based on stark either\/or 0\/1 binary contrasts. What would a fuzzy, aestheticized A.I. look like, an A\/A\/I.A.I. (Ambiguous\/Aesthetic\/Indeterminate Artificial Intelligence) with input\/output options that range from the literal and specific to the increasingly conceptual, metaphoric and interpretive? Consider that, if A.I.s can already simulate fairly convincing analogs of Beatles songs or Modigliani paintings through nothing more than brute force data-mining and analysis of pitch and tempo, or value and line quality, might something like the Singular Computing company’s fuzzy processing chip, which is hardwired to resist precision, simulate the slippery ambiguities of aesthetic experience?\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  In other words, A.I. is already doing things thought impossible a decade ago using nothing more than brute force iteration and generative processing. What would happen if that brute force approach were applied not to specific data but to fuzzy, ambiguous, and approximate calculation? Harvard mathematics professor Leslie Valiant describes this as probably  Will Penny, Plein Air XI – Savannah, 2018, digital rendering, digital still life utilizing 3D photogrammetry scans taken around Savannah, GA. Seven: Art will take on a role of reality stabilizer as social relations undergo flux within socalled post-truth contexts  Will Penny, Plein Air X – Savannah, 2018, digital rendering, digital still life utilizing 3D photogrammetry scans taken around Savannah, GA. Eight: If the blank cube sculpture of Minimalism activated the two-way relational and  relations around and between, this process becomes unbalanced when the flow goes only one direction. Nine: Portraiture will experience a renaissance What are the possibilities for portraiture in a cultural context of real-time facial recognition systems? I predict that A.I.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  will generate new modes of portraiture as different from current modes as a Matisse portrait is from Vermeer’s Girl with a Pearl Earring-not only in obvious visual difference, but also in underlying material logic and pictorial goals. Consider how modernist approaches to paint changed due to the shift of focus from representation circa 1500-1800, to the material and semiotic tools of representation as explored circa 1800-2000. A.I. will prompt a similar shift from our present-day focus of isolated visual appearance to data aggregations and predictive algorithmic processes. Just as the emphasis of the modernist portrait shifted from a realistic likeness to a fusion of likeness + the materials used to construct that likeness, portraiture in an age of omnipresent A.I. will explore social, morphological, behavioral and economic flows, and hitherto unseen patterns of gait and circumstance, rather than the outer particularities of single sitters. Jason Hoelscher. Symmetry Breakage.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  2019. Google Deep Dream Generator image, inception depth level 3. Courtesy of the artist. Ten: Artistic approaches to space will move beyond the perspectival, optical, and networked in weird new ways as relational space becomes cognified A.I. is so far not monolithic and general, but distributed, specialized and ambient. This suggests interesting relations to Genevieve Bell’s observations that a technology is only truly transformative when it changes our relations to space, time, and each other. As Bell, formerly the Director of Interaction and Experience Research at Intel and now an anthropology professor in Australia, notes, the more of those three components a new technology changes, the more transformative it is. It is now practically impossible to remember what life was like prior to the smartphone or Internet, or to imagine a world without cars, trains or planes, because these technologies transformed not only our relations to each other and to time, but also our experience of space.\n"}
{"prompt":"Notes on the Relational Aesthetics of Ambient AI ->","completion":"  Along these lines, consider the fact that A.I.-not the large technical object we imagined, but rather a field of invisible computation capabilities-changes our relation to space by becoming spatialized, by cognifying space itself. If, as per Sol LeWitt, the idea becomes the machine that makes the art, what happens when idea and space become indistinguishable-when the entirety of our surroundings, visible and invisible, is even more saturated with data flows and information swarms than it already is? Jason Hoelscher is gallery director and assistant professor at Georgia Southern University. Hoelscher has exhibited his artwork in Atlanta, New York, Berlin, Hong Kong, Paris, Stockholm and elsewhere, and has presented papers at such venues as CAA, SLSA, SECAC, Harvard University, and the University of Copenhagen. Hoelscher has also written for BURNAWAY, ArtCore Journal, ARTnews, and Evental Aesthetics. He received an MFA in painting from the Pratt Institute, and a PhD in aesthetics and art theory from IDSVA. Tags: Ambient AI, Artificial Intelligence, Jason Hoelscher\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  The Labor of the Inhuman, Part I: Human Reza Negarestani  Issue #�� February ����  Inhumanism is the extended practical elaboration of humanism; it is born out of a diligent commitment to the project of enlightened humanism.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  As a universal wave that erases the self-portrait of man drawn in sand, inhumanism is a vector of revision. It relentlessly revises what it means to be human by removing its supposed evident characteristics and preserving certain invariances. At the same time, inhumanism registers itself as a demand for construction, to de�ne what it means to be human by treating human as a constructible hypothesis, a space of navigation and intervention.� Inhumanism stands in concrete opposition to any paradigm that seeks to degrade humanity either in the face of its �nitude or against the backdrop of the great outdoors. Its labor partly consists in decanting the signi�cance of human from any predetermined meaning or particular import set by theology—thereby extricating human signi�cance from human veneration fabricated as a result of assigning signi�cance to varieties of theological jurisdiction (God, ine�able genercity, foundationalist axiom, and so forth).� Once the con�ated and the honori�c meaning of man is replaced by a minimalist yet functionally consequential, real content, the humili�c credo of antihumanism that subsists on a theologically anchored con�ation between signi�cance and veneration also loses its de�ationary momentum. Incapable of salvaging its pertinence without resorting to a concept of crisis occasioned by theology, and unsuccessful in extracting human signi�cance by disentangling the pathological con�ation between real import and glori�cation, antihumanism is revealed to be in the same theological boat that it is so determined to set on �re. Failing to single out signi�cance according to the physics that posits it rather than the metaphysics that in�ates it, antihumanism’s only solution for overcoming the purported crisis of meaning comes by adopting the cultural heterogeneity of false alternatives (the ever increasing options of post-, communitarian retreats as so-called alternatives to totality, and so forth). Rooted in an originary con�ation that was never resolved, such alternatives perpetually swing between their in�ationary and de�ationary, enchanting and disenchanting bipolar extremes, creating a fog of liberty that su�ocates any universalist ambition and hinders the methodological collaboration required to de�ne and achieve a common task for breaking out of the current planetary morass. In short, the net surfeit of false alternatives supplied under the rubric of liberal freedom causes a terminal de�cit of real alternatives, establishing for thought and action the axiom that there is indeed no alternative.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  The contention of this essay is that universality and collectivism cannot be thought, let alone attained, through consensus or dissensus between cultural  Jordan Belson, Samadhi, ����. Film still. �. Commitment as Extended and Multimodal Elaboration A commitment only makes sense by virtue of its pragmatic content (meaning through use) and its demand to adopt an intervening attitude. This attitude aims to elaborate the content of a commitment and then update that commitment according to the rami�cations or collateral commitments that are made explicit in the course of elaboration. In short, a commitment—be it assertional, inferential, practical, or cognitive—can neither be examined nor properly undertaken without the process of updating the commitment and unpacking its consequences through a full range of multimodal practices. In this sense, humanism is a commitment to humanity, but only by virtue of what a commitment is and what human is combined together. The analysis of the structure and laws of commitment-making and the meaning of being human in a pragmatic sense (i.e., not by resorting to an inherent conception of meaning hidden in nature or a predetermined idea of man) is a necessary initial step before entering the domain of making prescriptions (whether social, political, or ethical).\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  What needs to be explicated �rst is what it takes to make a prescription, or what one needs to do in order to count as prescribing an obligation or a duty, to link duties and revise them. But it must also be recognized that a prescription should correspond to a set of descriptions which at all times must be synchronized with the system of modern knowledge as what yields and modi�es descriptions. To put it succinctly: description without prescription is the germ of resignation, and prescription without description is whim. Correspondingly, this is an attempt to understand the organization of prescription, or what making a prescription for and by human entails. Without such knowledge, prescriptive norms cannot be adequately distinguished from descriptive norms (i.e., we cannot have prescriptions), nor can proper prescriptions be constructed without degenerating into the vacuity of prescriptions devoid of descriptions. The description of the content of human is impossible without elaborating it in the context of use and practices, while elaboration itself is impossible without following minimally prescriptive laws of commitment-making, inference, and judgment. descriptive resources speci�c to sapience (such as the particular level of mindedness, responsibilities, and, accordingly, normative entitlements) to sentience and beyond. The rational demarcation lies in the di�erence between being capable of acknowledging a law and being solely bound by a law, between understanding and mere reliable responsiveness to stimuli.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  It lies in the di�erence between stabilized communication through concepts (as made possible by the communal space of language and symbolic forms) and chaotically unstable or transient types of response or communication (such as complex reactions triggered purely by biological states and organic requirements or group calls and alerts among social animals). Without such stabilization of communication through concepts and modes of inference involved in conception, the cultural evolution as well as the conceptual accumulation and re�nement required for the evolution of knowledge as a shared enterprise would be impossible.� Ultimately, the necessary content as well as the real possibility of human rests on the ability of sapience—as functionally distinct from sentience—to practice inference and approach non-canonical truth by entering the deontic game of giving and asking for reasons. It is a game solely in the sense of involving error-tolerant, rule-based practices conducted in the absence of a referee, in which taking-as-true through thinking (the mark of a believer) and making-true through acting (the mark of an agent) are constantly contrasted, gauged, and calibrated. It is a dynamic feedback loop in which the expansion of one frontier provides the other with new alternatives and opportunities for diversifying its space and pushing back its boundaries according to its own speci�cations. �. A Discursive and Constructible “We” What combines both the ability to infer and the ability to approach truth (i.e., truth in the sense of making sense of taking-as-  being good to each other, or to vegetables for that matter. Once discursive practices that map out the space of reason are underplayed or dispensed with, everything lapses either toward the individual or toward a noumenal alterity where a contentless plurality without any demand or duty can be e�ortlessly maintained. Discursive practices as rooted in language-use and tool-use generate a de-privatized but nonetheless stabilizing and contextualizing space through which true collectivizing processes are shaped.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  It is the space of reason that harbors the functional kernel of a genuine collectivity, a collaborative project of practical freedom referred to as “we” whose boundaries are not only negotiable but also constructible and synthetic. One should be reminded that “we” is a mode of being, and a mode of being is not an ontological given or a domain exclusive to a set of fundamental categories or �xed descriptions. Instead, it is a conduct, a special performance that takes shape as it is made visible to others. Precluding this explicit and discursively mobilizable “we,” the content of “being human” never translates to “commitment to human or to humanity.” By undergirding “we,” discursive practices organize commitments as ramifying trajectories between communal saying and doing, and they enact a space where the self-construction or extensive practical elaboration of humanity is a collaborative project. Making a commitment to something means vacillating between doing something in order to count as saying it, and saying something speci�c in order to express and characterize that doing. It is the movement back and forth, the feedback loop, between the two �elds of claims and actions that de�nes sapience as distinguished from sentience. To make a commitment means “what else,” “what other commitments” it brings forth and how such consequent commitments demand new modes of action and understanding, new abilities and special performances that cannot be simply substituted with old abilities because they are dictated by revised or more complex sets of demands and entitlements. Without ramifying the “what else” of a commitment by practically elaborating it, without navigating what Robert Brandom calls the rational system of commitments,� a commitment has neither su�cient content nor a real possibility of assessment or development.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  It is as good as an empty utterance—that is, an utterance devoid of content or signi�cance even though it earnestly aspires to be committed. it brings about. But since the content of humanity is distinguished by its capacity to engage rational norms rather than natural laws (ought instead of is), the concept of entailment for humanity-as-a-commitment is non-monotonic. That is to say, entailment no longer expresses a cause and its di�erential e�ect, as in physical natural laws or a deductive logical consequence. Instead, it expresses enablement and abductive non-monotonicity in the sense of a manipulable, experimental, and synthetic form of inference whose consequences are not simply dictated by premises or initial conditions.� Since non-monotonicity is an aspect of practice and complex heuristics, de�ning the human through practical elaboration means that the product of elaboration does not correspond with what the human anticipates or with the image it has of itself. In other words, the result of an abductive inference that synthetically manipulates parameters—the result of practice as a non-monotonic procedure—will be radically revisionary to our assumptions and expectations about what “we” is and what it entails. The non-monotonic and abductive characteristics of robust social practices that form and undergird the space of reason turn reasoning and the intervening attitude that it promotes into ongoing processes. Indeed, reason as rooted in social practices is not necessarily directed toward a conclusion, nor is it aimed at establishing agreements through the kind of substantive and quasi-instrumentalist account of reason proposed by Jürgen Habermas.� Reason’s main objective is to maintain and enhance itself.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  And it is the self-actualization of reason that coincides with the truth of the inhuman. The unpacking of the content of commitment to humanity, the examination of what else humanity entitles us to, is impossible without developing a certain intervening attitude that simultaneously involves the assessment (or consumption) and the construction (or production) of norms. Only this intervening attitude toward the concept of humanity is able to extract and unpack the implicit commitments of being a human. And it is this intervening attitude that counts as an enabling vector, making possible certain abilities otherwise hidden or deemed impossible. It is through the consumption and production of norms that the content of a commitment to humanity can be grasped, in the sense of both assessment and making explicit the implicit commitments that it entitles us to. Accordingly, to understand the commitment to humanity and to make such a commitment, it is imperative to assume a constructive and revisionary stance with regard to human. This is the intervening attitude mentioned earlier. Revising and constructing human is the very de�nition of committing to humanity.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  Lacking this perpetual revision and construction, the commitment part of committing to humanity does not make sense at all. But also insofar as humanity cannot be de�ned without locating it in the space of reasons (the sapience argument), committing to humanity is tantamount to complying with the revisionary vector of reason and constructing humanity according to an autonomous account of reason. Humanity is not simply a given fact that is behind us. It is a commitment in which the reassessing and constructive strains inherent to making a commitment and complying with reason intertwine. In a nutshell, to be human is a struggle. The aim of this struggle is to respond to the demands of constructing and revising human through the space of reasons. Jordan Belson, Samadhi, ����. Film still.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  �. Kitsch Marxism If committing to being human is a struggle to construct and revise, today’s humanism is for the most part a hollow enterprise that neither does what it says nor says what it does. Sociopolitical philosophies seeking to safeguard the dignity of humanity against the onslaught of politico-economic leviathans end up joining them from the other side. By virtue of its refusal to recognize the autonomy of reason and to systematically invest in an intervening—that is, revisionary and constructive—attitude toward human and toward norms implicit in social practices, contemporary Marxism largely fails to produce norms of action and understanding. In e�ect, it subtracts itself from the future of humanity. Only through the construction of what it means to be human can norms of committing to humanity be produced. Only by revising existing norms through norms that have been produced is it possible to assess norms and above all evaluate what it means to be human. Again, these norms should be distinguished from social conventions.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  Nor should these norms be confused with natural laws (they are not laws, they are conceptions of laws, hence they are error-tolerant and open to revision). The production or construction of norms prompts the consumption or assessment of norms, which in turn leads to a demand for the production of newer abilities and more complex normative attitudes. One cannot assess norms without producing them. The same can be said about assessing the situation of humanity, the status of the commitment to be human: humanity cannot be assessed in any context or situation unless an intervening, constructive attitude toward it is developed. But to develop this constructive attitude toward human means to emphatically revise what it means to be human. A dedication to a project of militant negativity and an abandonment of the ambition to develop an intervening and constructive attitude toward human through various social and technological practices is now the hallmark of kitsch Marxism. While kitsch Marxism should not be in�ated to the whole of Marxism, especially since class struggle as a central tenet of Marxism is an  servitude and noetic sloth. The response of kitsch Marxism to humanity is also problematic on the level of revision.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  Ceasing to produce norms by refusing to undertake a constructive attitude toward human in the sense of a deportment governed by the functional autonomy of reason means ceasing to revise what it means to be human. Why? Because norms are assessed and revised by newer norms that are produced through various modes of construction, complex social practices, and the unlocking of new abilities for going back and forth between saying and doing. Since being human is distinguished by its capacity to enter the game of giving and asking for reasons, the construction of human ought to be in the direction of further singling out the space of reason through which human di�erentiates itself from nonhuman, sapience from sentience. By transforming the ethos of construction according to the demands of reason into the pathos of negativity, kitsch Marxism not only puts an end to the project of revision. It also banks on a concept of humanity outside of the space of reason—even though reason’s revisionary force is the only authorized force for renegotiating and de�ning humanity. Once revision is brought to an end, understanding humanity and acting upon its situations has no signi�cance, since what is deemed to be human no longer enjoys any pertinence.� Similarly, once the image of humanity is sought outside of reason, it is only a matter of time before the deontological distinction between sapience and sentience collapses and telltale signs of irrationalism —frivolity, narcissism, superstition, speculative enthusiasm, social atavism, and ultimately, tyranny—heave forth. Therefore, the �rst question one needs to ask a humanist or a Marxist is: Are your commitments up to date?\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  If yes, then they must be subjected to a deontic trial—either a version of Robert Brandom’s deontic scorekeeping or Jean-Yves Girard’s deontic ordeal, where commitments can be reviewed on the basis of their connectivity, evasion of vicious circles and internal contradictions, and recusal instead of refutation. If commitment to humanity is identi�ed by active revision and construction, ceasing to revise and refusing to construct characterize a form of irrationalism that is determined to cancel out what it means to be human. It is in this sense that kitsch Marxism is not just a theoretical incompetency. It is also—from both a historical and cognitive standpoint—an impulse to regress from sapience back to sentience. To this extent, it is not an exaggeration to say that within every kitsch Marxist agenda lies dormant the germ of hostility to humanity and the humanist project. Practical negativity refuses to be a resignation, but it also refuses to contribute to the system and develop a systematic attitude toward the a�rmative stance “implicit” in the construction of the system. Humanism is distinguished by the implicitly a�rmative attitude of construction. Insofar as the kitsch Marxism resignation implies an abandonment of the project of humanism and a collapse into regressive passivity, we can say that kitsch Marxism’s refusal to both resign and to construct is tantamount to a position that is neither passive nor humanist.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  Indeed, this “neither\/nor” approach signi�es nothing but a project of active antihumanism that kitsch Marxism is in reality committed to— despite its pretensions to a commitment to human. It is in the wake of this antihumanism or hostility toward rami�cations of committing to human that the identi�cation of kitsch Marxist agendas with humanism appears at best as a farce, and at worst  � � �  � � �  consciousness, social cognition?” Wolfgang Wildgen, The Evolution of Human Language: Scenarios, Principles, and Cultural Dynamics (Philadelphia: John Benjamins, ����), ��. See Robert Brandom, Between Saying and Doing: Towards an Analytic Pragmatism (Oxford: Oxford University Press, ����). Ibid. Abductive inference, or abduction, was �rst expounded by Charles Sanders Peirce as a form of creative guessing or hypothetical inference which uses a multimodal and synthetic form of reasoning to dynamically expand its capacities. While abductive inference is divided into di�erent types, all are non-monotonic, dynamic, and non-formal. They also involve construction and manipulation, the deployment of complex heuristic strategies, and non-explanatory forms of hypothesis generation. Abductive reasoning is an essential part of the logic of discovery, epistemic encounters with anomalies and dynamic systems, creative experimentation, and action and understanding in situations where both material resources and epistemic cues are limited or should be kept to a minimum.\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":"  For a comprehensive examination of abduction and its practical and epistemic capacities, see Lorenzo Magnani, Abductive Cognition: The Epistemological and Eco-Cognitive Dimensions of Hypothetical Reasoning (Berlin: Springer, ����). See Anthony Simon Laden, Reasoning: A Social Picture(Oxford: Oxford University Press, ����). Thanks to Peter Wolfendale for the term “critical re�exes” as an expression of prepackaged theoretical biases used to preempt the demands of thought in the name of critical thought. It is no secret that the bulk of contemporary sociopolitical prescriptions are based on a conception of humanity that has failed to synchronize itself with modern science or take into account social and organizational alterations e�ected by technological forces. Category Philosophy, Humanism, Marxism Subject Kitsch Return to Issue #��  To be continued in “The Labor of the Inhuman, Part II: The Inhuman” Reza Negarestani is a philosopher. He has contributed extensively to journals and anthologies and lectured at numerous international universities and institutes. His current philosophical project is focused on rationalist universalism beginning with the evolution of the modern system of knowledge and advancing toward contemporary philosophies of rationalism, their procedures as well as their demands for special forms of human conduct. © ���� e-�ux and the author\n"}
{"prompt":"The Labor of the Inhuman, Part I: Human ->","completion":" \n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  CHAPTER 3  ART AND AUTOMATION  This book is fundamentally an attempt to rethink art from the perspective of cosmo­technics and its cosmo­technical future.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  What can be revealed through this reconceptualization? I have avoided the path of art historians who ask how technology determines the form and content of art; instead, I rather pose the question of how the perspective of art can allow us to rethink technology. I began with a proposal in the introduction to elaborate on the varieties of experience of art through Daoist and tragist cosmo­technics as two different non-linear ways of thinking in art. Chapter 1 asked what role art could play after modern technology brought an end and completion to Western philosophy. Through Heidegger’s The Origin of the Work of Art, his Contributions to Philosophy, and his later fragmented commentaries on Cézanne and Klee, we attempted to construct a cosmotechnical line in his thought, which may risk being considered an “unscholarly violation” or a “baffled descent into mysticism” by Heidegger scholars. Chapter 2 elaborated on the experience of art in China. Instead of taking the historical approach of sinologists, we followed the logic of xuan in shanshui painting and in both art and philosophy. The varieties of experience of art are discovered not only in style and technique, but also in the different non-linear logics and different pathways to truth it establishes.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The question of logic, however, has not yet been fully examined, largely because the term “non-linear logic” could be vaguely attributed to tragists, Daoists, and cyberneticians. Nevertheless, such a continuity implies a complicit and intimate relation between aesthetic thinking, philosophical thinking, and technological thinking, contrasting Simondon’s claim that philosophical thinking takes priority over aesthetic thinking. According to Simondon, the formation of aesthetic thinking is anterior to that of modern technology (along with its bifurcations) in the genesis of technicity commencing from the magic phase. This chronological difference legitimates philosophical thinking as the unique candidate for conceiving a convergence of key points analogical to the primordial unity of the magic phase, where subject and object are not differentiated while figure and ground have a reciprocal relation. Toward the end of his On the Mode of Existence of Technical Objects, Simondon proposed that philosophical intuition—which has to be distinguished from magic and aesthetic intuition—is crucial for conceiving the genesis of technicity. For Simondon, intuition employs neither concept, which is deductive, a priori; nor idea, which is inductive, a posteriori. Intuition enables a process that is neither induction nor deduction, neither purely transcendental nor purely empirical. But doesn’t this recourse to intuition also problematize the priority he gave to philosophical thinking over aesthetic thinking?\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  It seems that Simondon subordinates aesthetic thinking to philosophy because it is a reflective form of thinking; however, he was also aware that cyber­netics was supplanting philosophy as reflective thinking. This linearity, from aesthetic to philosophical and cybernetic thinking, presented as a genesis, is intriguing and worth further investigation. When Simondon wrote On the Mode of Existence of Technical Objects in the 1950s, the relation between philosophy and cyber­netics was not yet determined and had not been fully elaborated, as probably remains the case today. If we want to “rescue” aesthetic thinking from its obsolescence, we have to reconstruct the relations between aesthetics, philosophy, and cyber­netics. This chapter will draw upon the preceding ones to reflect firstly on the relation between aesthetic thinking and technology, especially cyber­netics \/ artificial intelligence, and secondly on shanshui after our exploration of the logic of xuan. We will focus on the question of episteme, which we defined earlier as the sensible condition under which knowledge is produced. From the development of Descartes’s mechanism to cyber­netics pioneer W. Ross Ashby’s homeostasis, through the neuroscience and biotechnology of today, philosophers and scientists have long sought to understand what is human, but also to render human existence as an axiomatic set of fundamental principles. The scientific and technological progress that has brought new understandings of nature has also brought desires to make the world predictable and transparent, calculable and controllable.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Modern technologies are anatomical tools—like surgical instruments, they cut through bodies without mercy. All penetrations arise from a desire  for transparency. However, the effort to achieve this absolute transparency, which does not and will not exist, can produce a delirium or frenzy, namely a source of confusion. And techno-scientific development can only accelerate mystification if it fails to find a mirror with which to look at itself and awaken from the fantasy that it is destined to be the conqueror of the universe. The satellites revolving around the earth are not yet mirrors, because they only offer a view of the earth as a whole from distance. Their view augments the desire to see, and seeks to turn the earth into a cybernetic system as if it will solve the global ecological catastrophe, according to the Gaia theory. § 17 THE STATUS OF MACHINE INTELLIGENCE TODAY I suggested in the introduction that it is necessary to articulate the status of machines today. Without understanding these machines, we will be unable to provide any insight other than a vague critique of political economy or a political ecology based on classical oppositions between technology and nature, organic and inorganic, human and god.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The fact is that we are no longer dealing with the mechanistic beings of the nineteenth century like steam engines, but rather with technical systems becoming organic. This becoming organic and reflective is based on the concepts of feedback and information, a foundation already established by Norbert Wiener in 1948. We are no longer in an epoch of repetitive mechanical reproduction, but rather of recursive digital reproduction. This takes a very different form, which increasingly resembles the organic mode of reproduction in plants and animals, but with much higher capacity and speed of mutation. What is the role of art in this epoch of organic machines? Heidegger, who was indeed a careful reader of cyber­netics, proposed in his 1967 essay “The Provenance of Art and the Determination of Thinking” a response to a futurism based in cyber­netics. Art has to identify its position in the scientific world, to open that which science conceals. Science’s dominance since the seventeenth century  has not been mainly due to its form of knowledge, but rather to the triumph of the scientific method, which we find in Kepler, Galileo, and Newton, among others.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  In the twentieth century, cyber­netics triumphed as another scientific method. Written in the same period as his famous Der Spiegel interview “Nur ein Gott kann uns retten (Only a god can save us),” “The Provenance of Art” already registered the domination of cyber­netics, and proposed that for art to seek its origin, it must do so through a reorientation. Heidegger was much more sober than most philosophers in confronting cyber­netics, precisely because he attempted to understand the significance of cyber­netics as well as its limits: The reciprocal regulation of the processes in their interrelation takes place in a circular motion. That is why the basic principle of the cybernetically designed world is the control loop. It is based on the possibility of self-regulation, the automation of a system in action. In the cybernetic world, the difference between automatic machines and living things disappears.1 Indeed, Wiener himself claimed that it is possible to produce a cybernetic machine that lives Bergsonian biological, creative, and irreversible time. The triumph of the cybernetic method seems to have obliterated the binary thinking that opposes vitalism to mechanism, but it also challenged dualist philosophical thinking in general through a mechano-organicism. As Heidegger himself points out, according to cyber­netics, the human and the world become understood as a unity maintained by feedback loops.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  However, this feedback loop also creates a closed world of input 1. Martin Heidegger, “The Provenance of Art and the Determination of Thinking,”“Die hin- und herlaufende Regelung der Vorgänge in ihrer Wechselbeziehung vollzieht sich demnach in einer Kreisbewegung. Darum gilt als der Grundzug der kybernetisch entworfenen Welt der Regelkreis. Auf ihm beruht die Möglichkeit der Selbstregelung, die Automation eines Bewegungssystems. In der kybernetisch vorgestellten Welt verschwindet der Unterschied zwischen den automatischen Maschinen und den Lebewesen.” 141–142. and output, demand and supply, realized by and in the industrial world. Such a world based on a reductionist cybernetics is doomed to be a closed one. The broadest control loop encompasses the interrelation between human and the world.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  What is happening in this enclosure? The world relationships of man and their entire social existence are included in the domain of cybernetic science. The same enclosure, i.e. the same captivity shows up in futurology … So it is evident: The industrial society exists on the basis of the enclosure in its own power.2 Though rarely heard in the discipline of computer science today, the term “cyber­netics” lends its aura to artificial intelligence, which is absolutely based in the paradigm identified by cyber­netics.3 Heidegger’s question remains valid for us today, when cybernetics is conceived to reduce organism to machine, life to calculation. For Heidegger, to seek the origin of art is to find a different beginning in Greek thought—or its experience of Being—for today’s industrial and technological world. This other beginning, however, is not self-evident, and demands a reorientation and departure from the already-chosen first beginning in order to re-appropriate the future through the past and the past through the future. This quest for the other beginning of thinking rejects the positive feedback loop of modern progress, and opens a path to thinking beyond a reductionist cybernetics. It is preparation to articulate a locality (Ortschaft).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Heidegger calls it orientation (Erörterung), namely to identify the place to which one belongs. We should go beyond the sheer rationality of science, since it is not yet rational enough. Therefore it is not about denying or rejecting rationality, 2. Ibid., 145. “Der weiteste Regelkreis umschließt die Wechselbeziehung von Mensch und Welt. Was waltet in dieser Umschließung? Die Weltbezüge des Menschen und mit ihnen die gesamte gesellschaftliche Exisenz des Menschen sind in den Herrschaftsbezirk der kybernetischen Wissenschaft eingeschlossen. Die selbe Eingeschlossenheit, d.h. die selbe Gefangenschaft, zeigt sich in der Futurologie … So zeigt sich: Die Industriegesellschaft existiert auf dem Grunde der Eingeschlossenheit in ihr eigenes Gemächte.” 3.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  See my Recursivity and Contingency, Chapter 2.  but about integrating science and technology into a way of thinking that does not form an obstacle to discovery and invention while providing a new frame to modern techno-science. But first let’s ask: What is the significance of artificial intelligence for art today? Artificial intelligence, insofar as it is artificial, is prone to mutation, meaning that it carries the possibility of deviating from all norms. As for intelligence, we cannot say what it is, since paradoxically any definition tends to limit intelligence itself. Understanding it in this way, the future remains both formally and ontologically open for us. The miserable view of technological development we have today identifies technology with a definite and narrow vision. For example, the transhumanist ideology excludes other imaginations and understandings of technology in favor of a new social class of enhanced humans or a relentless capitalist conquest of standing reserves. This contemporary vision fails to recognize the necessity and urgency of technodiversity—not the diversity promised by the free market, which is based on a homogenous technologism: Gestell.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Proponents of the free market represent a thermodynamic ideology that claims to embrace diversity, but only within the specific system in which the market find itself legitimate. I want to explore how the discourse on the varieties of experience of art can contribute to thinking beyond Gestell. Contemporary cybernetic machines carry a new epistemology and a new form of organization that increasingly determines social, political, and economic structures. Machines are silently liberated from mechanistic determinism and spread freely throughout society. As Jean-François Lyotard did from the late 1970s onward (most notably in The Postmodern Condition), we must constantly ask what happens to our sensibilities when the sky is covered with drones and the earth with driverless cars, and exhibitions are curated by artificial intelligence and machine learning software. Is this futurism really something that speaks to us? Or does it fall squarely into Heidegger’s critique of cyber­netics and modernity? Machines can learn to paint like a human, with the advantage that machines will remember all patterns and apply them with more variation than humans can.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Every combination is always already  present in less than seconds. It is possible to use TensorFlow, an open-source machine learning software, to transform any image into the style of Cézanne or Klee, and it is possible to train a robot to paint the brushstrokes that once distinguished the Impressionists. In these cases, every painting is already finished before it is painted, because the canvas is already calculated as a finite set of possibilities. These algorithms function well because they are based on the data we feed them and forced to recursively improve their performance. In other words, without data—and increasing computational capacity, largely based on cheap labor and cheap nature—there is no such “intelligence.” The human\/machine distinction is constantly reduced if we understand intelligence as merely the analysis of data, and we will likely soon find humans being outdone by machines since they will have much higher capacity for storing information and calculation. If one day artificial intelligence were to become the sole producer of scientific knowledge, it would require a scientific world that is solely based on the calculation of sense data and analysis of patterns. But let’s not underestimate the power of machine intelligence and calculation. We need to exhaust both the organic limit of the human as well as the limit of machine calculation in order to reflect on their possibilities.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The current relation between human and machine is dominated by the logic of replacement, as a search for equivalence whereby machine intelligence can replace human intelligence. It is primarily a logic of capital.4 This logic of replacement, however, tends to ignore that, insofar as such equivalence is only functional, it cannot understand the relation between human and machine organologically because it ignores both the physiology and psychology of the human-machine compound (this being Simondon’s critique 4. Marx in his Grundrisse applied this logic to the analysis of capital as well as the possibility of emancipation. Marx stated that capital invests in machinery in order to reduce necessary labor time because machine can perform certain work previously done by workers. The decrease in necessary labor time results in the increase of surplus labor time, which means so does surplus value. If machines are able to replace all the activities of the workers, which is now referred to as full automation, then it also means that workers can be emancipated from work, namely they become free people. of Marx).5 Secondly—especially in the hope that the functional equivalence of machines will liberate human beings from work and therefore put an end to capitalism, which is naïve at best—the logic of replacement ignores that new economic models will emerge and exploitation will take other forms beyond the wage relation. The most fundamental flaw of the logic of replacement is its ignorance of the reciprocity between humans and machines.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Machines and humans are seen as two realities, which are separate yet interchangeable. Marx’s understanding and analysis of the role of machines comes from his observation of factories of his time, containing isolated and specialized industrial machines. When machines and labor are considered as entities closed off from other domains, then we can understand how Marx arrives at the logic of replacement as the necessity of capitalism (surplus labor time) as well as the possibility of its sublation (free time). Today, this logic of replacement is omnipresent among leftists as well as neoliberals, who compete to arrive at the same full automation. Even in art, the logic of replacement resonates among those who want to invent the great machine painters, calligraphers, and curators. One may counter this book’s analysis in Chapters 1 and 2 by claiming that what paintings want to make visible can now be done by algorithms and digital technology. Modern computational machines hold more data and analyze them more precisely than a human mind. Moreover, what happens inside machines seems to be only “visible” to machines themselves, and remains opaque to human observers due to its complexity, often referred to as a “black box.” More than humans, machines become the shepherds of the unknown.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  How, then, can artificial intelligence possibly show us what is not yet sensible and can never be present as such? With patterns and data, it is possible to show that there are facts that are often ignored or not pronounced; for example, that “Asian men are the least desirable racial group to Western women,” or that “70 percent of the population in Bangkok wear white T-shirts.” Such knowledge is not part of what we call the Unknown, since 5. See Yuk Hui, “On Automation and Free Time,” https:\/\/www.e-flux.com\/ architecture\/superhumanity\/179224\/on-automation-and-free-time\/. Figure 12 Huang Gongwang (黃公望), Detail, Dwelling in the Fuchun Mountains (富春山 居圖), 1348–1420. Handscroll, ink on paper, 33 × 639.9 cm. National Palace  these are still facts. Is there any way these facts not registered by humans can tell us about the Unknown? With sensors and algorithms we may supplement our senses, which may also change the way we understand the world, as the telescope and microscope made visible orders of magnitude lying beyond our sense perception.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  However, these data, too, are still facts. In order to inquire into the Unknown, we have to ask where the Unknown is from and how it is determined. The triumph of AlphaGo over the game’s reigning world champion some years ago stands as proof that computers are better at calculating possible configurations of a particular game board than a human brain dedicated to the same task since childhood. AlphaGo is a functional equivalence of the brain’s capacity to play Go, though it now exceeds the latter’s capacity. In particular skills, machines will be able to take over gradually. Even with manual work, artificial intelligence can imitate the brushstrokes of different painters. The painting Edmond de Belamy, created by a generative adversarial network (GAN) and signed as “min G max D × [log (D(x))] + z [log(1 – D (G(z)))]” sold for US$432,500 at the auction house Christie’s in 2018. The art market, which operates on authenticity and authorship, granted aura to the machine painting.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This auction event signals a struggle between artists and robots, and their antagonism in the coming years. Seen in another light, it also marks a moment to go back to the task of artistic creation. One may choose to dismiss the machine painting by questioning whether it is art at all. This, however, is probably not a productive question, since it refuses the organological struggle between artists and tools. Furthermore, it denies the intimate relation between art and technology. As Walter Benjamin already suggested in “The Work of Art in the Age of Mechanical Reproduction,” instead of asking if photography and cinema are art, one should rather ask how they could transform art.6 This line of questioning and its resolution is tragist in the sense that desire and curiosity have careened so 6. Walter Benjamin, “The Work of Art at the age of Mechanical Reproduction,” in Illuminations: Essays and Reflections, trans. Harry Zohn (New York: Schocken Books, 2007), 217–252.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  forcefully toward the abyss that they can only respond to the accidental opening of Pandora’s box by transforming mistakes into new possibilities. Existence is tiring. It is repetitive and its primordial form is characterized by successions of crisis. Benjamin’s essay is an attempt to render explicit the task of transforming faults into new possibilities. He offers the example of technical reproducibility because it necessarily destroys the concept of the aura, which is used to compensate for the lack of technologies of mass reproduction in ancient times; for example for the ancient Greeks, it was limited to founding and stamping.7 In Benjamin’s essay, cinema and other reproducible technologies can be means toward revolutionary politics. The difference between a fascist politics and a revolutionary politics is that the former never aims to transform social relations but only manipulates emotions and sentiments through propaganda, while leaving class contradictions untouched. Therefore, toward the end of the essay, Benjamin draws a fundamental difference between communism’s and fascism’s relations to art: communism politicizes art, while fascism only aestheticizes politics. Almost a hundred years after Benjamin’s essay, we see that the culture industry and neoliberalism are capable of rendering technology and aesthetics productive for the accumulation of capital.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The optimism of Benjamin’s “Mechanical Reproduction” essay is transformed into an enthusiasm incubated by the contemporary art market and art\/design fusions. Benjamin’s essay is a reminder of a time when tragist thinking provided a possible response to the technological situation. From this perspective, his approach is not entirely oppositional to Heidegger’s, though these two essays on the work of art are often compared to each other for their apparently opposing attitudes towards tradition. The trajectory from Benjamin’s mechanical reproducibility to today’s artificial intelligence passes through a history of dynamic relations between art and technology as well as a crisis in artistic creation. Mechanical reproducibility is first of all a freeing of the hands, and artists were first de-skilled by the camera’s liberation 7. Ibid., 218.  of their hands from the canvas. As an 1890s advertisement for the Eastman Kodak Company promised, “You press the button, we do the rest.” 8 A realist painting, no matter how much it resembles its object, always falls short of a photograph’s capacity to capture detail. Hands are freed from the brush, but they are given a new task: to capture something not visible.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  How can a camera, which is sensitive only to light, capture something that does not appear in light? What is beyond all the objects apparent in the photo and cannot be recognized, pixel by pixel, or examined by machine learning algorithms? Today, we can easily simulate the movements of clouds and water. There is no longer any need to use a static medium to produce movement, to use trompe l’œil to produce a 3D effect. But does this mean we can say painting is dead? Isn’t all the effort spent re­articulating the significance of painting a reactionary resistance to its increasing obsolescence? Hegel attempted to show, though implicitly, that the spirit is determined by its medium: that Greek art, Christian religion, and philosophical thought have their own specific mediums, whether statues and temples, paintings and churches, or modern science and technology. If we agree with Hegel, then wouldn’t we also say that shanshui painting, as a medium, has already completed its historical task?\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Following this argument, we may also be able to proclaim the end of shanshui painting, just as many commentators have proclaimed the death of painting altogether. The attempts to revive shanshui in contemporary China—through the increasing number of exhibitions—intend to express a “national confidence” might also only demonstrate the opposite, since they failed to make shanshui contemporary. Here let’s recall that we showed earlier how Heidegger distinguishes his position from Hegel’s verdict on the end of art by insisting that art and technology share an intimate relation that is historically dynamic. Art is determined by its technology, but it is equally possible for art to transform technology, specifically by returning technology to a primordial question of Being. This 8. Lewis Mumford, Art and Technics (New York: Columbia University Press, 1952), 92.  reverses Benjamin’s materialist approach: instead of thinking how art is transformed by media technology, Heidegger asks how art can transform technology. This word Being could be equally replaced by the Unknown, the non-rational, nothingness, or dao in other geographical and historical contexts. It doesn’t mean every artist has to start using artificial intelligence, just as modern painters were not obliged to create art using machines.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Modern art wanted to go beyond mere Gestalt and the geometrical reason intrinsic to mechanisms and industrialism, and to transform them by returning them to “life.” For example, Henri Bergson’s Creative Evolution as well as Georges Canguilhem’s Knowledge of Life both proposed to return mechanism back to its place within life through a vitalist appropriation of technology.9 A more productive question seems to be: Is it possible to reframe the enframing (Gestell ) with a new interpretation of art and technology? § 18 THE LIMIT OF ORGANICISM We remain at the beginning of such an inquiry. But one hundred years after Bergson’s Creative Evolution (1907) we will have to take a different approach in view of contemporary technological developments and their corresponding forms of life. The becoming organic of machines constitutes a new condition for philosophy after the organic condition opened by Kant toward the end of the eighteenth century. Kant’s Critique of Judgment imposes an organic condition of philosophizing that was later taken up by post-Kantian idealists and biologists. Though Kant drew a line between Cartesian mechanism and the organismic mode of thinking proper to philosophy, more recently, cyber­netics’ elimination of the opposition between mechanism and vitalism through organicism (as was also  9. Georges Canguilhem, The Knowledge of Life (New York: Fordham University Press, 2008), 73, on Bergson and Canguilhem’s concept of life and organology, see Hui, Recursivity and Contingency, Chapter 3.  pronounced by Heidegger as early as the 1930s)10 seems to have realized the organismic logic that Kant prepared and Hegel elaborated more than anyone else of his time. One tends to align shanshui painting (or painting in general) with craftsmanship and contrast it to the “inhuman” rationality of machines.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  It follows the argument that the human is organic\/organismic and machines are mechanistic, so machines cannot achieve the level of perfection of human skill. Indeed, Chinese thought was characterized in general as an organismic and holistic thinking by many Western authors, notably Joseph Needham. According to these authors, this organicism is not only expressed in Chinese philosophy, but also in Chinese art and forms of life more generally. This argument was plausible in the first half of the twentieth century since it suggests that one can have very different views on evolution, nature, technology, and multispecies co-existence depending on where thought springs from. Donna Haraway has asked: “What if Western evolutionary and ecological sciences had been developed from the start within Buddhist instead of Protestant ways of worlding?”11 Haraway is a thinker and historian of organicism, and for her the science of the Anthropocene is not yet organismic enough, since it undermines the sympoietic nature of co-existence.12 Haraway has good reason to make such a claim, since the discourse of the Anthropocene is fundamentally anthropocentric, even a celebration of human domination. However, what concerns us here is that the opposition between organicism and mechanism central to philosophy since the eighteenth century—and therefore the organismic and ecological 10. See Martin Heidegger, Ponderings XII–XV: Black Notebooks 1939–1941, trans. Richard Rojcewicz (Indianapolis: Indiana University Press, 2017), 143.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  “It might very well still take a considerable time to recognize that the ‘organism’ and the ‘organic’ present themselves as the mechanistic-technological ‘triumph’ of modernity over the domain of growth, ‘nature.’” 11. Donna Haraway, Staying with the Trouble Making Kin in the Chthulucene (Durham and London: Duke University Press, 2016), 176, n12. 12. Ibid., 49. “The sciences of the Anthropocene are too much contained within restrictive systems theories and within evolutionary theories called the Modern Synthesis, which for all their extraordinary importance have proven unable to think well about sympoiesis, symbiosis, symbiogenesis, development, webbed ecologies, and microbes.”  solution as an exodus of Western modernity and the Anthropocene— has to be reassessed in view of the becoming organic of machines because the opposition between the mechanist and the organismic has to be put into question.13 Organicism, once a remedy for the problems posed by the industrialism of the nineteenth and twentieth centuries, as well as the foundation of the state, ceases to be the Ideal in the twentyfirst. Not only because machines have gone beyond the “becoming organic” of cyber­netics—illustrated by the recent invention of a robot made of frog cells and artificial intelligence14—but also because modern technology has penetrated into different orders of magnitude. From micro to macro physics, technology now forms a gigantic “organizing inorganic” force or power.15 The inorganic is no longer organized by the human body as was the case with simple tools, but rather constitutes an enormous technical system we can only live inside of, while submitting to its rules. In light of the new technological condition, it is necessary to reconsider the organismic function given to art in the twentieth century.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Whereas systems theory (i.e., Ludwig von Bertalanffy) has been regarded as a response to industrialism, art has been considered a counterpart to industrial technology. This is also why such an organismic aspect of art must be emphasized and considered as a remedy to industrialism and mechanism. The historian Lewis Mumford, in his series of lectures Art and Technics—which also inspired the title of this book—offers a dialectical view of the history of art according to the production of symbols and images. For Mumford, mechanism came out of the need to escape the overdetermination of the symbolic in religion—even though the symbolic is what distinguishes humans from other animals and  13. See Yuk Hui, “Machine and Ecology,” Angelaki 25, no. 4, 54–66, in which I explain how cyber­netics provides a non-dualist logic and why it is not yet the solution to overcome modernity. 14. Mindy Weisberger, “World’s First ‘Living Machine’ Created Using Frog Cells and Artificial Intelligence,” Live Science, January 14, 2020, https:\/\/www.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  livescience.com\/frogbots-living-robots.html. 15. See Hui, Recursivity and Contingency, Chapter 4.  allows for the development of the spirit. Mumford argued that it was not Prometheus who invented technology in Greek mythology, but rather Orpheus, the player of the lyre, the god of symbols.16 Mumford’s point was that symbols are necessary for the constitution of human life and intelligence, even to the point where they can be overproduced as means of domination and lead, for instance, to the violence that preceded the Renaissance: In the case of the Greek cities of the fourth century BC or the Italian cities of the fifteenth century, I would even say that an over-preoccupation with the fine arts themselves caused men to lose their sense of reality and to forfeit their liberty to the mainly symbolic seductions of costume and painting and public ceremonial and ritual.17 In an extremely intriguing argument, Mumford suggests that it was this overproduction of symbols that made mechanism—or more precisely, rationality as ground of the real—become necessary. Here symbols that remedied the lack of communal life gained a negative value that had to be overcome, thus rationality had to reign over the myths of symbols and restore order.18 It is at this moment that rationality and mechanical thought become necessary to overcome a loss of reality. For Mumford, mechanism saved the Europeans from the overproduction of symbols, but in the following centuries it also led to an “image-glutted world”: One more matter. The general effect of this multiplication of graphic symbols has been to lessen the impact of art itself. This result might have disheartened the early inventors of the new processes of reproduction if they could have 16.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Mumford, Art and Technics, 35. 17. Ibid., 52. 18. Ibid. “We are now, I believe, in a position to understand why, during the last few centuries, Western man’s absorption in the machine not merely increased the amount of physical power available, but actually gave him a great sense of subjective release.” And further (57): “Europe, at that time, had created an imposing symbolic structure, in the dogmas, the philosophy, the ritual, and the daily pattern of con duct promoted by the Christian Church.”  anticipated it … In order to survive in this image-glutted world, it is necessary for us to devaluate the symbol and to reject every aspect of it but the purely sensational one.19 This image-glutted world describes not only the Greek cities of the fourth century BC or the Italian cities of the fifteenth century, but more than ever the epoch of mechanical reproducibility. It was the era in which industrial technology, being mechanical in nature, dominated the production of art, whether in photography, cinema, or painting. Modern art wanted to overcome this image glut by providing another framework for art and technology.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Mumford suggests that cubism and constructivism were not able to provide a sufficient philosophical framework to absorb mechanism, because “on their own terms, they must suppress emotion, feeling, sentiment, any tendency toward organic richness of form.”20 In other words, cubism and constructivism moved against organicism by eliminating its major features. This could be best illustrated by what Picasso himself said to Françoise Gilot: that cubists “abandoned color, emotion, sensation, and everything that had been introduced into painting by the Impressionists.”21 A sufficient philosophical framework for art should be an organismic thinking that accommodates mechanical technology and integrates it into life, pointing it toward the perfection of humanity. Mumford found this in the “organic architecture” of Frank Lloyd Wright: Men, instead of feeling excluded and belittled by the machine’s achievements, will increasingly feel released by them; so that all our mechanical operations, instead of being geared to produce the maximum quantity compatible with profit, will be geared to produce the maximum quantity compatible with a fully developed life for both the person and community … That change is nothing less than 19. Ibid., 98. 20. Ibid., 53. 21. Cited by Authur Danto, After the End of Art (Princeton: Princeton University Press, 1998), 28.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  22. Mumford, Art and Technics, 155–156. a change of interest in the direction of the whole organism and the whole personality. A shift of values; a new philosophic framework; a fresh habit of life.22 Of course, Mumford was not the first person to make this kind of statement. The Romantics, notably Novalis and the Schlegel brothers, were attracted to the concept of the organic, seeing it as the resolution of literature, art, and politics. Indeed, Schiller, in his Letters on the Aesthetic Education of Man—a work highly informed by Kant’s Critique of Judgment—already put forward a similar claim regarding art. For Schiller, art is the play drive, capable of organically accommodating the dyad of formal drive (rationality) and material drive (emotion and sentiment). As Mumford said himself— “We know in 1951 as men did not know in 1851, that the machine is only a limited expression of the human spirit”23—we may say that we are in an epoch unimaginable for the preceding generation of thinkers, who were implicitly and explicitly nurtured by a mechanistic\/organismic opposition.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Since the rise of cyber­netics in the mid-twentieth century, critiques based on this dualism seem increasingly suspicious. The relation of technical objects to human beings, which we can call the organized inorganic (in the sense that it is the human being who organizes the inorganic and integrates it as its organ), becomes the organizing inorganic, meaning that instead of humans integrating tools, humans are integrated into technical systems, which have the tendency and capacity to totalize. The organism, as that which organizes the inorganic (through the invention of tools, which for Bergson is also that which distinguishes intelligence from instinct) seems to be losing its significance in face of technical systems. The body, in contrast to what is considered to be only the mind, also partially defines intelligence. It is only through the body that a tool can be invented and integrated. The body is the base upon which its extensions can be loaded and operated. The body was the carrier of automatism, like in Denis Diderot’s The Paradox of Acting, in which a great comedian practices to the point of becoming an 23. Ibid., 123.  automaton before being able to improvise onstage.24 Indeed, this can be applied to all domains of art before the era of cyber­netics.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Automatization of the body through repetitive practice is the precondition of being able to act freely with both organic and inorganic limbs, whether in art or in sport.25 A critique of the organic human body can also be found in Simondon’s concept of the “technical individual,” which is key to his 1958 On the Mode of Existence of Technical Objects. According to Simondon, we can say that there are three modes of existence of technical objects: as element (for example, a gear or a diode), as individual (for example, an automatic machine capable of autoregulation), and an ensemble (for example, a laboratory consisting of multiple machines). Different from an element, which is passive and portable, a technical individual possesses an “associated milieu,” which adopts a “recurrent causality” (causalité récurrente or résonance interne are Simondon’s own translations of Wiener’s “feedback”) to allow the technical object to acquire the capacity of auto-regulation, for example, homeostasis. The industrial era is characterized by technical individuals, which possess an associated milieu, while the artisanal era is characterized by simple tools that depend on the human body to organically constitute an associated milieu in the atelier, namely the body that integrated the tools to work together. When industrial machines have their own associated milieu, namely “becoming organic,” the body, which is the source of “auto-regulation” in the artisanal era, is rendered redundant; the worker only has to repeat the same gesture, like what is demonstrated in Charlie Chaplin’s Modern Times (1936). 24. Denis Diderot, The Paradox of Acting, trans. Walter Herries Pollock (London: Chatto & Windus, 1883), 30–31.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  In a note, Diderot cited FrançoisRené Molé, who talked about his experience of acting: “I was not pleased with myself. I let myself go too much; I felt the situation too deeply; I became the personage instead of the actor playing it; I lost my self-control. I was true to Nature as I might be in private; the perspective of the stage demands something different. The piece is to be played again in a few days first appeared like automata; afterwards they became fine players” (italics mine). 25. This also holds true for non-human beings, such as elephants can also learn to draw, by imitating the trainer stroke by stroke, each stroke when correctly followed is awarded with a banana. The elephant, like a human being, is able to fully automatize the nose, so that it is capable of painting itself. What Diderot says in The Paradox of Acting concerning repetition still reflects a non-technological notion of automation.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Diderot was first and foremost an encyclopedist who aspired to a technical and moral optimism, represented by the possibility of infinite improvement of technical elements. The emergence of the technical individual after the technical elements (which are symbols of the eighteenth century’s optimism for progress) has complicated the relation between machine and the human body. Artists, as probably the most enduring type of craftspeople, also form the last wave of resistance against mechanical automation. This resistance takes a tragist approach to transform the machine and integrate it into the production of art, not simply as a tool but rather by turning art forms into machines. It was already evident in Duchamp’s famous Nude Descending a Staircase, No. 2 (1912), which attempts to integrate chrono­photo­ graphy into painting. It becomes even more explicit in conceptual art, where one finds an imperative to address the human\/machine relation by ceaselessly attempting to integrate both the machine and the machine metaphor into the production of an art beyond the limit of industrial machinery. In 1963, more than a decade after Mumford’s appraisal of the organicism of art, Andy Warhol said in an interview with Art News: “I want to be a machine.”26 What does it mean to become a machine in an epoch when mechanism and industrialism have both been devalued since they are considered both philosophically insufficient and ecologically unsustainable?\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Warhol doesn’t mean that he wants to be mechanical, but rather that his “Dadaist (dandyist) nihilism” wants to liberate itself from art and the meanings imposed on it.27 Here the machine is opposed to the organic human body, which is the source of authenticity in traditional artmaking. The machine is not yet dominant, while the organic body no longer reigns, and has to 26. “The reason I am painting this way is that I want to be a machine, and I feel that whatever I do and do machine like is what I want to do.” See Andy Warhol, “Top Ten ARTnews Stories: The First Word on Pop,” ARTnews. November 1, 2007, https:\/\/www.artnews.com\/artnews\/news\/top-ten-artnews-stories-the-first-word-on-pop-183\/27. A term borrowed from Jeffrey Shaw in our email exchange. 27. A term borrowed from Jeffrey Shaw in our email exchange. transcend the human\/machine opposition by “becoming machine” or pretending to become machine.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  We may call this “becoming machine” a tragist gesture, like the tragic hero who affirms his destiny in order to be free, and it is central to how an objective idea like a machine gains autonomy in conceptual art. In his “Sentences on Conceptual Art,” the minimalist and conceptual artist Sol LeWitt wrote, “The artist’s will is secondary to the process he initiates from idea to completion. His willfulness may only be ego.” 28 The idea—as the life of the Concept—must not be subordinated to the will of artists conditioned by the organic body. Instead, it should be positioned above both the organic body and the inorganic machine. This is even more explicit in his “Paragraphs on Conceptual Art,” where he states, The idea becomes a machine that makes the art. This kind of art is not theoretical or illustrative of theories; it is intuitive, it is involved with all types of mental processes and it is purposeless.29 We can say that post-1963 conceptual art marks the end of a first dialectics between the inorganic industrial machine and the organic human body. In “becoming machine,” a mechano-organismic gesture is also paradoxically the last defense of the artist’s organic body. Through the conceptual artists, the idea becomes visible and expressed in a recursive or tautological way (exemplified in the work of Joseph Kosuth) by rejecting art in order to become art.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Let’s recall how Hegel became furious when he was provoked by his contemporary Wilhelm Traugott Krug to say whether the Idealists can deduce a pen from thinking.30 Krug sees an opposition between 28. Sol LeWitt, “Sentences on Conceptual Art,” in Theories and Documents of Contemporary Art: A Sourcebook of Artists’ Writings, ed. Kristine Stiles and Peter Selz (Berkeley, Los Angeles and London: University of California Press, 2012), 991. 29. Sol LeWitt, “Paragraphs on Conceptual Art,” in Theories and Documents, 987. 30. Hegel fiercely responded to Krug, first in his 1802 review of the latter’s work and his article in the Kritischer Journal der Philosophie, as well as later in a footnotes in the Phenomenology of Spirit and in the Anmerkung of Section 250 of the Encyclopaedia. idea\/form and matter, while Hegel insists that the Concept (Begriff ) is concrete and real.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Conceptual art could have been material proof of Hegel’s becoming concrete and real of the Concept. As we now enter the third decade of the twenty-first century, the technological condition and the meaning of the machine have changed. Cyber­ netics, and now artificial intelligence, have made the Concept even more effective (wirklich) and rational (vernünftig). At the same time, cybernetic machines have forced the body to confront its limits on at least two different orders of magnitude. The first order is biotechnology, which enters into the nano level of the body to modify genes, for example, by reprogramming eye color and height in embryos. The second order is the gigantic technological systems that integrate bodies as part of their functioning. State administration in Hobbes’s Leviathan was considered as mechanical machine, and in Hegel’s Philosophy of Right, it was one stage toward the realization of an organic state, a true ethical life. But it is only today that the social contracts that connect bodies are realized in an even more materialized sense, via data, network protocols, algorithms, sensors, mobile phones and servers, and in such a way that commands and executions can be directly implemented through electronic signals.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Mumford’s aspiration to the organic took up a common philosophical task, no longer responding to the mechanism on the conceptual level as Kant did, but also attempting to overcome the mechanism’s material incarnation in industrialism. Therefore, there is no reason to reproach Mumford and his contemporaries (Whitehead, Needham, Helmut Plessner, among many others) for taking recoursing to organic forms of organization against industrialism and mechanism. Rather, we must recognize the necessity of surpassing the opposition between the mechanistic and the organic. This is also the condition required to conceive the future of art and philosophy. § 19 THE INCOMPUTABLE AND THE INCALCULABLE Though cyber­netics promises an organicism that can be realized in the machine, such behavior is bounded by calculation, or more precisely by computability. Needham gives his readers only an impressionistic idea of Chinese thought as organicism—a school of philosophy he belonged to before turning to sinology. He didn’t elucidate the difference between his mathematically grounded organicism and Chinese “organismic” thinking. Impressions can be helpful for comparing certain ideas, but one should be also careful not to generalize too quickly.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  One may even claim that neoliberalism is Daoist for being laissez-faire, yet because Daoism doesn’t propose any form of accumulation, it cannot produce capitalism, whose essence is accumulation. The exploration of xuan in Chapter 2 is an attempt to elucidate how its logic must be distinguished from vague ideas of holism, organicism, and neoliberalism. The logic I explore in the tragic and shanshui is based on the limits of calculation and the possible experience of what is incalculable, or what in Chapter 1 I termed the “non-rational.” I have to clarify two terms here: “incomputable” and “incalculable.” “Incomputable” refers to a number that cannot be recursively enumerable, which is to say that it cannot be reduced to the finite steps of an algorithm. “Incalculable” means that something cannot be submitted to calculation at all, such as love, friendship, desire, or happiness. The incalculable doesn’t only serve spiritual and religious purposes, but is central to any economy and politics that transcends calculability. It can serve a concrete function in a spiritual economy or a libidinal economy, as well as in Amartya Sen’s economy of capability, for example.31 In Recursivity and Contingency, I attempted to enlarge the concept of recursivity by reconstructing a history of modern Western philosophy centered on it, thus extending it from computation and 31. See Bernard Stiegler, The Automatic Society, trans. Dan Ross (London: Polity, 2018).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  cyber­netics to a generalized logic no longer restricted to the operation of machines, as it can also be identified in the relation between human and machine, technology and environment, the organic and the inorganic. In this work, I examine the concept of recursivity moving between world and earth, mountain and water, showing cyber­netics to be only one type of recursive thinking and logic in a longer history. In so-called first-order cyber­netics, “feedback” is a term used to describe the mechanism of self-regulation. In second-order cyber­ netics, the term “recursion” is used more often to extend beyond machine operation to address other social and political domains. For example, Niklas Luhmann has applied Humberto Maturana and Francisco Varela’s concept of autopoiesis to study the operation of society, developing the field of sociology known as systems theory. Recursion is key to automation in forms based on the principle of calculability. Let’s first look into the relation between recursion and calculability, before elaborating on the distinction between the incomputable and the incalculable. In computer science, a recursive function is one that “calls itself during its execution.” A simple example given to first-year computer science students generates a finite Fibonacci sequence: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34 … , where each following number in the sequence would be the sum of the two that preceded it.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  If we are asked to list all the Fibonacci numbers below the number n—which could be any number—the simple approach would be to create an iteration (loop) that counts until n is reached. We can understand this way of looping as a linear repetition, even though it is called a loop. The recursive version is less intuitive. It means that a function calls itself, for example, f(n) = f(n - 1) + a. This may be clearer when we try a number n = 5, and see how it unfolds each time it calls itself: fib(5) fib(4)  +  fib(3) fib(3)  +  fib(2)   fib(2)  +  fib (1)  Recursion generates a complexity that is beyond iteration (mere repetition), because it consists of various spiral loops instead of only one mechanistic, repetitive loop (for example, a cooking recipe). Iteration may sound like it’s circular, but in fact it is a linear logic, since it only repeats the same process. Therefore, if not simply misleading, the comparison often made by computer scientists between a recipe and algorithm doesn’t really hold. From a computational perspective, computational time (the time required to arrive at the output) can be largely reduced through recursion.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  But it is not only about efficiency. Something that is recursively enumerable is also computable; that is to say, one can find an algorithm that can generate this number in finite steps. A number is not computable or decidable if it is not recursively enumerable. For example, Kurt Gödel negatively proved what David Hilbert called the Entscheidungsproblem, an algorithm that decides, given a set of axioms and a mathematical proposition, whether the proposition is provable. Gödel’s genius can be seen in two major steps. Firstly, Gödel used numbers—now known as Gödel numbering—corresponding to the logical propositions, as in the following table: Symbol  Number  Symbol  Number  0  1  x  9  s  2  1  10  +  3  |=  11  X  4  �  12  =  5  (  6  A  14  )  7  →  15  . 8  13  The replacement of the qualifiers with numbers allowed Gödel to turn the symbolic propositions into arithmetic, thereforeallowing one to focus on calculation rather than inferences of different propositions. Secondly, Gödel developed a recursive function to execute the mathematical proof.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Before Gödel, Thoralf Skolem had already proposed to replace logical qualifiers with numbers in order to recursively prove the validity of a logical proposition:  If we consider the general theorems of arithmetic to be functional assertions and take the recursive mode of thought as a basis, then that science can be founded in a rigorous way without use of Russell and Whitehead’s notions “always” and “sometimes.” This can also be expressed as follows: A logical foundation can be provided for arithmetic without the use of apparent logical variables.32 Gödel developed what is now known as the general recursive function in 1934. It is mathematically equivalent to the Turing universal machine and Alonzo Church’s lambda calculus. This is the foundation of modern computational theory. If we talk about a computational world, it means one in which everything is enumerable in finite steps. If recursion is the foundation of computation, it doesn’t mean that any thought implemented in programming language is recursive. For example, we can write a simple program to print “Hello, World!”  1. 2. 3.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  4. 5.  int main() { printf(\"Hello, World\"); return 0; }  Even though the execution is recursive on the level of the hardware, the logic of the program is simply procedural or mechanistic. This is what we have to bear in mind as we analyze the concept of recursivity according to different orders of magnitude rather than just an abstract universal sense. More than computational thinking, recursion is an epistemology opposed to mechanism. We can’t simply discard the mechanistic epistemology, however, since though insufficient, it still has explanatory power in certain cases. Insofar as we have the computable, we also have the incomputable, meaning the undecidable; 32. Cited by Rod Adams, An Early History of Recursive Functions and Computability: From Gödel to Turing (Boston: Docent Press, 2011), 22; see also Yuk Hui, On the Existence of Digital Objects (Minnesota: University of Minnesota Press, 2016), Chapter 6.  but the incomputable is not incalculable, precisely because, by definition, incalculability cannot be a mathematical concept. We may say that Being is incalculable, precisely because it is not a mathematical concept.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  If we were to say that God is the incomputable, then God would be reduced to a mathematical concept, because incomputability acquires its meaning from its opposition to the computable. To demonstrate our thesis, let us put forward an initial claim that the world is incalculable, and then ask how that has been articulated in the development of artificial intelligence—because intelligence means primarily making sense of the world. With that, we may be able to understand in a more precise way, firstly, how the humanist concept of reason—which was used to firmly demarcate human intelligence from machine intelligence—is being remade by and redistributed to machines; and secondly, how the concept of incalculability is undermined in the modeling of intelligence, which also leads to the limit of intelligence. Such modeling is not simply a replacement or subsumption of reason, as many theorists argue.33 It requires us to inquire into reason itself, as well as to conceive more profound reconfiguration of concepts other than reason, which are essential for the process of rationalization. In the 1970s when the American philosopher Hubert Dreyfus published a series of writings on the limit of artificial intelligence, notably his What Computers Still Can’t Do: A Critique of Artificial Reason, he accused AI scientists, especially Marvin Minsky, of limiting cognition to a “particular knowledge or model structure.” Minsky, one of the founders of artificial intelligence, anticipated that sort of critique when, in his seminal 1961 paper “Steps Toward Artificial Intelligence,” he admitted that “there is, of course, no generally accepted theory of ‘intelligence’; the analysis is our own and may be controversial.”34 This means that there is probably no “objective” or “universal” definition of intelligence; therefore, what intelligence is is open to interpretation. 33. See Sindre Bangstad and Torbjørn Tumyr Nilsen, “Thoughts on the Planetary: An Interview with Achille Mbembe,” New Frame, September 5, 2019, https:\/\/www.newframe.com\/thoughts-on-the-planetary-an-interview-withachille-mbembe\/. 34.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Marvin Minsky, “Steps Toward Artificial Intelligence,” Proceedings of the IRE 49, no. 1 (January 1961): 8–30, 8. Dreyfus’s critique can be understood as a pragmatic reading of the first division of Heidegger’s Being and Time, especially Section 17, “Reference and Signs,” and Section 18, “Involvement and Significance: The Worldhood of the World.” In these sections Heidegger laid down the ontological foundation for the analysis of tools and signs, namely references (Verweisungen), and how involvement (Bewandtnis) conditions the structure of the references, for instance, the encounter between the tool and the human Dasein. Following Heidegger, Dreyfus shows that Minsky et al.’s ontological assumption of cognition is fundamentally Cartesian. Or, in the words of Heidegger, Cartesian intelligence sees an object in front of it simply as Vorhandene (present at hand), that which has to be contemplated as a bearer of properties discrete from the subject. The present-at-hand presupposes a Cartesian mechanistic logic. Dreyfus suggests instead to understand an embodied cognition that corresponds to what Heidegger calls Zuhandene (ready to hand), meaning that the thing in front of me doesn’t appear simply as a bearer of properties. Rather, its mode of being is conditioned by the world—a temporal structure that couples cognition and the object being encountered.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  For example, in using a hammer, we don’t contemplate the shape and color of the hammer, since the world, which could be presented as a matrix of relations or a totality of references, is already embedded in cognition. Dreyfus concludes: Even a chair is not understandable in terms of any set of facts or “elements of knowledge.” To recognize an object as a chair, for example, means to understand its relation to other objects and to human beings. This involves a whole context of human activity of which the shape of our body, the institution of furniture, the inevitability of fatigue, constitute only a small part … In assuming that what is given are facts at all, Minsky is simply echoing a view which has been developing since Plato and has now become so ingrained as to seem self-evident.35 35. Hubert Dreyfus, What Computers Can’t Do: A Critique of Artificial Reason (New York: Harper & Row, 1972), 122–123. Dreyfus could be interpreted to be critiquing the use of linear and mechanistic thinking instead of recursive and organic thinking to comprehend cognition. He arrives at the conclusion that the impasse of AI is also the impasse of Western metaphysics, whereas Heideggerian thought—as an attempt to go beyond metaphysics— provides an alternative. One might conceive of a Heideggerian AI, though ironically such a project would mean only the continuation of the metaphysics Heidegger wanted to destroy. Though it might seem unsubtle to identify weak AI with the history of philosophy from Plato to Leibniz, Dreyfus nonetheless pointed out that one has to look into the ontological, epistemological, and psychological assumptions of computation, and question their limits and legitimacy.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This effort to go beyond formal representation of perception and reasoning is known as connectionism, represented by a movement in cognitive science that uses artificial neural networks to explain cognitive capacities, and it resonates with the twentieth-century philosophical attempt to go beyond representation. A representation demands a description of the phenomenon according to a specific order of magnitude; for example, a visual representation consists of shapes, colors, and perspectives. A non-representational description exploits different orders of magnitude; for example, the same object could be interpreted as a map of intensities or a network of signals that can dynamically update itself. Machine learning uses the neural networks first proposed in 1943 by Warren S. McCulloch and Walter H. Pitts, who imagined neurons as Boolean functions and the network as multiple layers of neurons whose operations allow logical inferences. The further development of neural networks led to the 1967 statement from Minsky that “neural networks with Boolean neurons can simulate any finite automaton,” and further from Heikki Hyötyniemi (1996) that “neural networks can simulate arbitrary Turing machines.”36 The development of feedforward neural networks (the simplest form of neural networks, in which connections between the nodes don’t form a cycle) in the 1960s confronted a bottleneck, which leads to the development of what is now known as the backpropagation algorithm: 36. Mark Burgin, Super Recursive Algorithm (New York: Springer, 2005), 66. [Paul] Werbos in 1974 elaborated an algorithm for the credit assignment problem. This algorithm realized the method called “back error propagation” or simply backpropagation … back-propagation networks were rediscovered by Parker in 1982.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Then discovered again and made popular by Rumelhart, Hinton and Williams (1986). In essence, a back-propagation neural network is an advanced perceptron with multiple layers, a different threshold function in the artificial neuron, and a more robust and capable learning rule. Today back-propagation networks are, probably, the best known and widely applied class of the neural networks.37 The alternative to representation offered by connectionism also prompted Dreyfus to search in a similar direction for the possibility of realizing a Heideggerian AI, for example in Walter Freeman’s research on neurodynamics. Freeman developed research into the way that actor and environment are coupled, involving years of study of olfaction, vision, touch, and hearing in alert and moving rabbits. Freeman shares Dreyfus’s view of anti-representationalism: “the brain moves beyond the mere extraction of features … it combines sensory messages with past experience … to identify both the stimulus and its particular meaning to the individual.” 38 Freeman denounced representationism by saying, Who needs them [representations]? Functionalist philosophers, computer scientists, and cognitive psychologists need them, often desperately, but physiologists do not, and those who wish to find and use biological brain algorithms should also avoid them.39  37. Ibid., 65. 38.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Walter Freeman, “The Physiology of Perception,” Scientific American, 242 (February 1991). 39. Walter J. Freeman and Christine A. Skarda, Representations: Who Needs Them?, http:\/\/sulcus.berkeley.edu\/FreemanWWW\/manuscripts\/IC10\/90.html. Freeman’s neurodynamics involves complex processes. To simplify and summarize in accordance with the purpose of our investigation: it maintained that the animal’s perception (which already selects what is significant) and its response to the external milieu are conditioned by patterns rather than by concepts with distinctive representations. When a rabbit smells a specific odor, the oscillation pattern of neurons in the rabbit’s olfactory bulb (located in the frontal lobe) is strengthened. The configuration of the connection is understood to form cell assemblies. The cell assemblies will be reconfigured when the experience is repeated, and the result will follow the reward given for the experience.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  For example, when the rabbit smells the carrot and eats it, the relation of smelling to eating is strengthened.40 So the contextual response of the brain is always an accumulation of past experience with the same input. A local input is responsible for the global output, for example the signal initiated by the carrot activates the global configuration of the basins of attraction. The pattern of attractors is modifiable and stores input with the past memory of similar stimuli. As Dreyfus puts it: Significance is not stored as a meaning representation nor an association. Rather the memory of significance is in the repertoire of attractors as classifications of possible responses—the attractors themselves being the products of past experience.41 Dreyfus is emphasizing the hermeneutics of the world—a vorstructure, which determines the meaning of the present—and how transgressions reciprocally transform the world itself. He highlights the recursive nature of human interpretation or thinking in contrast to the Cartesian mechanism of early artificial intelligence. Though he hadn’t engaged with the recursivity of modern computation, he finally identified it with connectionism. 40.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This is widely understood as Hebb’s rule. 41. Hubert Dreyfus, “Why Heideggerian AI Failed and How Fixing It Would Require Making It More Heideggerian,” Artificial Intelligence 171, no. 18 (December 2007): 1137–1160, 1155. Artificial intelligence is recursive not only in terms of the structure of its program, but also in the way that cognition is understood. Cognition is not mechanical, but recursive—it always goes back to itself in order to know itself. Cognition is open to errors in order to learn from and correct them. Machine learning draws from cognitive science, but instead of completely relying on models from neuroscience, it has also to have produced an epistemology for the discipline, which became the model through which intelligence can be demonstrated.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  More and more frequently today computational models cease to be mere simulations and become the proper apparatus of scientific experiments. The demarcation line between human intelligence and machine intelligence has been blurred. It is in this sense that we can understand Achille Mbembe’s claim that reason “may well have reached its final limits. Or, in any case, reason is on trial.”42 The memory of such distinction, however, exists today and forms a threshold yet to be fully crossed. Presumably influenced by John Haugeland and Dreyfus, like many in his generation of AI scientists, the Canadian cognitive scientist Brian Cantwell Smith provided an updated assessment of the development of AI in his 2019 book The Promise of Artificial Intelligence: Reckoning and Judgment.43 He proposes that AI, insofar as it wants to be intelligent, must develop a different scheme to interact with the world. The intelligent agent must be able to situate itself within the world, and in doing this, must also recursively engage and modify the world. The agent and the world must constitute a structural coupling that is not only biological but also semantic. Human intelligence is embedded in the world, and it embodies the world with the help of artificial organs, such as limbic and nervous systems that are extensions of bodily organs.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Smith’s argument can be aligned with the argument I put forward in Recursivity and Contingency that recursion is the fundamental model for thinking the relation between intelligence and its milieu at various orders 42. Bangstad and Tumyr Nilsen, “Thoughts on the Planetary: An Interview with Achille Mbembe.” 43. I engaged with Brian Cantwell Smith’s earlier book On the Origin of Objects (Cambridge, MA: MIT Press, 1996) in Chapter 2 of On the Existence of Digital Objects. of magnitudes: biological, semantic, systemic, and so on. The basic criteria according to Smith are as follows: For a system to care, its orientation to the world must be backed by a complex constitutive web of normative commitments. The system (knower) must be committed to the known, for starters.44 Commitment to the known means primarily recognizing the object as object—not simply a bunch of representations (which Smith calls appearance), 45 but rather something understood by an intelligent agent as being in the world and with other beings (which he calls reality). A machine’s capacity to calculate is a form of reckoning, while the capacity to situate oneself in the world of objects is what he calls judgment. This capacity to know what one is talking about—meaning to recursively return to itself in order to determine itself—can be formally achieved in any recursive algorithm as a form of reckoning.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  But the functioning of the world cannot be represented only as a form of reckoning.46 Smith emphasizes that this commitment to the object and its world cannot be understood in terms of emotion, as it stands in contradistinction to reason. This is a point that I can agree with, because emotion is only a counterargument against a homogenous definition of rationality. Emotion doesn’t yet rationalize what is excluded by this homogenizing definition. Rationalization is a recursive process that renders the relation between the subject and the world coherent.47 This is where we differ fundamentally from Smith’s argument, especially concerning art. The world is incalculable in 44. Brian Cantwell Smith, The Promise of Artificial Intelligence: Reckoning and Judgment (Cambridge, MA: MIT Press, 2019), 92. 45. Maybe we can also think in parallel with what Kant says about phenomenon as appearance.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  46. Smith claims that “no matter how otherwise impressive they may be, I believe that all existing AI systems, including contemporary second-wave systems, do not know what they are talking about” (76). 47. The intelligence and emphasis on the world that Smith described follow the line of argument already put forward by Hubert Dreyfus, and then more finely formulated in technical terms by computer scientists such as Terry Winograd and Philip Agre. its totality, which already places it beyond the reckoning power of calculation. In order for any intelligence to produce art, its object cannot be the known, but the unknown. The unknown may be mystical, but not mysterious nor mythological; and by mystical (as Wittgenstein would call it) or enigmatic (as Adorno would prefer calling it), we mean something that cannot be entirely grasped and demonstrated objectively, for instance, through its reduction to appearances and representations. Heidegger was able to say that “the world worlds [die Welt weltet]” because there is no prime mover behind the world—a metaphysical monism doesn’t exist if we understand it in Smith’s sense: that an ultimate reality could be derived linearly from the known.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The unknown has to be recursively rationalized through the known, which I discussed in Chapter 1 regarding the rationalization of the unknown. For example, the birds in Paul Klee’s Twittering Machine do not merely live in a biological world. They are also open to interpretation, and such openness also allows them to enter into the realm of the spiritual, as in Arthur Danto’s reading of the painting: Klee is making some kind of point about the futility of machines, almost humanizing machines into things from which nothing great is to be hoped or feared, and the futility in this case is underscored by the silly project of bringing forth by mechanical means what nature in any case provides in abundance.48 Even if a machine learning algorithm reproduces a painting in the style of Klee, and even if it “recognizes” that these are birds, it is no closer to entering into the “invisible” world that underscores Klee’s paintings. In art and philosophy, the unknown is the object of intelligence and also the condition for the development of such intelligence. This is a significant demarcation between an intelligent machine performing calculative tasks for human agents and another type of intelligence taking the unknown as its subject. 48. Arthur C. Danto, Encounters and Reflections: Art in the Historical Present (Berkeley: Univeristy of California Press, 1997), 84. Beyond what Brian Cantwell Smith calls “reckoning” and “judging,” we have to recognize another type of engagement with the world.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Continuing from Chapter 1, we can say that Smith’s notion of judgment still falls within Heidegger’s phenomenological understanding of the world outlined in Being and Time, while the turn to Being and history of Being that characterizes Heidegger’s Kehre is beyond Smith’s explication on artificial intelligence (as well as that of Dreyfus). In Heidegger’s Contributions to Philosophy, he indicated that Being and Time was a transition to the Kehre; this transition is also a movement from a phenomenological explanation of the world to a rationalization of the unknown (in this case, Being, the Open, the last god). If we interpret it in this way, we can understand that any machine intended to fully imitate human intelligence cannot be limited to two activities such as reckoning and judgment, since to do so would ignore that meanings are no properties of beings, but rather its profoundness comes from that which is unfounded. Smith’s notion of the world can be reformulated in practical terms as “context,” in the sense that, when entering a new environment, an intelligence determines what is happening and its relevance to itself. A context depends on the objects present, in a room for instance, but its totality is not the sum of the descriptions of these objects. Every object in an environment contributes to the manifestation of the world (as when Heidegger says “the world worlds”), and a context is determined in the encounter between the intelligent agent and the objects. The worlds of the objects and the intentionality of the intelligent agent recursively inform each other in order to arrive at a determined context. Smith proposes what he calls a “context-sensibility,” as he writes, “The world requires commitment to keep in view.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Contextual awareness must be based on such commitment. As such, conceptual sensitivity requires judgment. It will never be achieved by mere reckoning.”49 Concerning the question of sensibility, again we have to broaden it beyond reckoning and judgment, which is to say that  49. Smith, The Promise of AI, 140. Figure 15  we must go beyond the phenomenal sensibility (reducing the object to sense data) and contextual sensibility (constructing context according to the reciprocal relation between subject and object), to a philosophical sensibility that shares Mou Zongsan’s assimilation of Kant’s intellectual intuition into his own definition of the “heart” as the feeling of the whole cosmos. § 20 INTELLIGENCE, REASON, AND INTUITION We have seen that while recursivity is fundamental to computation and that the world is also recursive, it doesn’t imply that the world is computable. The world, in Heidegger’s sense, is abandoned when our environment becomes computational and computable. After Dreyfus, we have to go beyond what Heidegger intended, not only because it was written in 1927, before the time of cyber­netics and artificial intelligence, but also because its philosophical concepts have to be rethought in view of what is happening in our time.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  From the outset, the world that Heidegger describes is the other of cognition (to which it is irreducible), since cognition is made possible by the world. The world and cognition could be seen in terms of the relation between ground and figure in Gestalt theory. The world is constituted by a complex totality of references, and cognition depends on these references in order to reason. In other words, cognition is a part to the whole of the world. However—and this will also be key for reinterpreting Sections 17 and 18 of Being and Time—the world is no longer the phenomenological world that Heidegger described, but one increasingly captured and reconstructed by mobile devices and sensors (this also implies a significant change of the meaning of the term phenomenological epochē [i.e., suspension], from that of the world to technology).50 The world is largely on screens, especially considering that today one can virtually do everything with apps on their mobile phones. Smart cities, sensors, and platforms assume a world 50. I initiated the trajectory of such a rereading in On the Existence of Digital Objects; see especially Chapters 3 and 4.  purely based on data that can be analyzed and modeled. The contingency of materiality is such that, for example, one may use a product in ways the designer had not anticipated.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The exteriorization of any design logic always exceeds the logic itself, and discrepancies between theory and practice are contingent but also sources of inspiration. Such an opening to contingency is allowed by a materiality irreducible to form, and this opening is minimized in a totalizing technical system. As the world becomes a technical system, so to speak, the world Heidegger described as the ground of truth—in the sense of aletheia—is reduced to logically analyzable sets of data. This is also why we think artificial intelligence is becoming increasingly powerful today, while the question of the world emphasized by both Heidegger and Dreyfus becomes insignificant. We are living in a digitalized world, a world of the Gestell, where the power of AI is based on the reduction of the world to computational models. We endowed terms such as dreaming and thinking to machines for the sake of their “ontological dignity” or for mere marketing purpose, though we all know that the Deep Dream of Google has nothing to do with dreaming. This is not to say that reductionism is altogether bad, but rather that it is bad when taken as the totality of reality, as was the mistake of mechanism. As the computational environment displaces the world, the incalculability of the world withdraws further from us, until the question itself disappears or a catastrophe appears.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  We only hear of affirmative technological acceleration, human enhancement, and geoengineering. The disappearance of the world initiates an ecology of attention, since it is no longer the world that conditions the appearance of phenomena. An economy of attention in the digital age is not only an economy of the eyes and the screen, but more importantly one in which relevance is determined through calculation and data extraction. From social media recommendations to the manipulation of votes during political elections, the economy of attention becomes increasingly significant as the world becomes more calculable. When the computational environment displaces the world, it doesn’t mean that the world disappears, but rather that it becomes silent. It is still functioning, like the “thing in itself”  described by Kant—behind the phenomenon, but ceasing to be sensible. It may reveal itself when the world of calculation breaks down. Computational recursivity provides an epistemological proof of the genetic structure of nature, like what the Romantics and idealists such as Kant, Fichte, Schelling, and Hegel have tried to construct.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Idea, insofar as it is auto-positing and auto-regulating, possesses great potential as it was explored by the idealists and conceptual artists. What can come of this “mechanical proof” of idea in recursive algorithms today? Some observers speculate on the conception that the universe is a perfect recursively generated whole in which every being is a unique instance of the same genetic process. We may want to call this a Platonic proof, after the philosopher’s invocation in Timaeus of the demiurge’s mathematical design of the world, in which actual existants are nothing but imitations of the world of ideas. Kant’s attempts to set the limit of knowledge and the regrounding of metaphysics could be seen as a modern take on of the Platonic proof, according to which the thing in itself is responsible for the appearance of objects. The recursivity of the world has to be distinguished from the recursivity that technology is in the process of mastering. A generalized recursive thinking needs to understand and to co-exist with machines. When technology seeks the ground, it will only lose it, because technology itself wants to become the ground of all beings.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This reciprocal structure between figure and ground stands as an ontological refusal of the idea that the world is reducible to a bunch of recursive algorithms, no matter how powerful they are in simulating the emergence of phenomena similar to natural ones. Another such refusal is the fact that the computable implies at the same time the incomputable, namely, that there are existants in the universe that are not recursively enumerable. These two ontological refusals are not identifiable. The incomputable alone is not sufficient, since it only sets the limit of computation without being able to unleash its potential. The incomputable is not yet the incalculable. The incomputable is a mere negation of the computable, while the incalculable is the affirmation of a groundless ground. The incalculable is not reducible to the incomputable, though the latter also offers the former a “rationalist” support of the realm beyond the computable. The development of science and technology allows us a better understanding of the world, but reducing the world to a recursive universe only leads to an exhaustion of the technological world itself.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  If it is still not too late, perhaps it will recover after having “hit bottom,” like Gregory Bateson described alcoholics doing. We may want to ask: What should we expect from a futurism based in artificial intelligence? How should we respond to the challenge the human has undertaken to eliminate its own condition of existence? Similar to how we proposed to fragment the concept of technics and art, we may also have to inquire into the diversity of the concept of intelligence, though all these categories cannot be isolated. We know that since the Greeks, it has been reason (or intellect), ratio, that occupies the highest position in the hierarchy of the soul. Intuition (like its close relatives, perception and imagination) is a source of error because it is immediate, and therefore not yet exempted from mistakes. In Western philosophy, reason has been considered the ultimate judge and the mediator of all other faculties (this, however, doesn’t imply its dictatorship).51 What about things that are unconceptualizable (Unbegrifflich),52 which was called the non-rational in Chapter 1? Reason and the unconceptualizable clash with each other, since reason marches on concepts.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Reason can only denounce the unconceptualizable or speculate on it without being able to grasp it (to grasp, greifen, in German, is the root of the word for concept, Begriff, therefore unbegrifflich is that which cannot be grasped). In Chapter 1 I tried to show that for Heidegger the question of Being is unconceptualizable, and, insofar as it is not clarified, may fall back to dogmatic mysticism. Thinking must be open to that which is excluded by philosophy. The task of thinking is to elaborate the unconceptualizable not only through concepts and ideas, but also intuitions. Intuition is very often considered to be the lowest of the faculties of the spirit, 51. This humble yet determinant role of reason is best demonstrated by what Kant says in the Critique of Pure Reason: “Reason has no dictatorial authority; its verdict is always simply the agreement of free citizens, of whom each one must be permitted to express, without let or hindrance, his objections or even his veto” (A738-39\/ B766-67). 52. See Hans Blumenberg, Theorie der Unbegrifflichkeit (Frankfurt am Main: Suhrkamp, 2007).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  for example in Kant’s Critique of Pure Reason, we find a hierarchy moving upward from pure intuition (time and space), through the understanding, and on to reason. The limit that Kant imposes on the knowledge proper to a human subject is restricted to scientific explanation. While it is necessary to engage with science, it is also necessary to go beyond it. The non-conceptualizable, however, threatens the systematicity of reason. Reason cannot seize the unconceptualizable, but can only pretend to have grasped it through sublime experience or through postulates in practical reason. The sublime is the failure of the understanding and imagination to subsume sensible data into concept. Such a failure demands the intervention of reason, which cannot turn the experience into concept either, but can put a halt to the process. It is through this violence imposed on the imagination by reason that human subjects, like the tragic heroes, are able to overcome the fear provoked by uncontrollable and enormous nature.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The sublime is the human use (Gebrauch) of nature in order to move beyond mere fear and into respect (Achtung). Why did Kant want to renounce human beings’ intellectual intuition? It is because a positive and objective definition of the unconceptualizable is logically contradictory. For example, what I think freedom is may contradict with what others understand. We can only define freedom firstly in relation to the other, be that human or thing, and secondly in a negative sense, by reference to what is not free. The realm of the noumenon, being negative to human subjects, has a positive use of completing the architectonics of reason with the notion of intellectual intuition. Since intellectual intuition cannot be identified as a human faculty, Kant gives the highest position to reason. We have already seen in Chapter 2 the New Confucian Mou Zongsan’s disagreement with Kant.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  He suggests that the intellectual intuition that Kant excludes from the human lies at the core of Chinese philosophy. It has to be examined elsewhere whether Mou really grasps Kant’s concept of intellectual intuition, and if this philosophical and cultural translation is legitimate. But it is nevertheless an astonishing and refreshing argument, as well as an inspiring method of transductive thinking. Mou clearly shows the Chinese  to have a different way of sensing and knowing, which in turn defines their notion of intelligence. Mou talks about the cultivation of intellectual intuition, namely that it is not given as something complete, but rather demands practice. It is only possible to conceive the human being as a moral subject because of this potential to go beyond the realm of rationality bounded by phenomenon. For Mou, the possibility to develop intellectual intuition is the ground of the moral. For Kant, the noumenon always works in the background, since it is the thing-in-itself that makes the phenomenon appear.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  For Kant, however, in contrast to Mou, the cultivation of intellectual intuition is not possible. One should be careful in squaring the sensibility toward dao in Chinese philosophy with what Kant calls intellectual intuition, since this presupposes a certain compatibility between Chinese philosophy and the Kantian system. Instead, I propose to reinterpret the difference in their understanding of intellectual intuition. If Kant has to renounce the possibility of intellectual intuition for the human being, it is because he wants to secure a place for reason as the higher form of transcendental faculty: reason is a “faculty of principles,” the “faculty of the unity of the rules of understanding under principles.” 53 This hierarchy of sensible intuition, understanding, and reason could be seen as the heritage of Aristotle, as we can see in his De Anima (On the Soul ), where he presents us a similar tripartite structure in terms of sensation, imagination, and reason (noiesis).54 In the rationalist tradition of Baumgarten, sensible intuition is the inferior faculty of knowledge, since the human being is an animal of reason. In the twentieth century, it was Croce, Bergson, and Heidegger, among others who struggled to combat this hierarchy. Bergson affirmed the primacy of intuition, not simply as our first point of contact with the world, but also as a method of knowing with 53. In Critique of Judgment, Kant proposed a different scheme, which consists of three basic faculties of the spirit: namely, basic cognitive faculty, basic capacity of feeling pleasure and pain, and basic capacity of desire (Begehrensvermögen), each with its respective higher faculty: understanding, judgment, and reason. 54.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  See Aristotle, De Anima, Books II and III, trans. D.W. Hamlyn (Oxford: Clarendon, 1993), Book III, Chapter III. precision. Heidegger gave priority to the world as that which conditions cognition, namely being-in-the-world. Dreyfus criticized the Cartesian attitude of early AI researchers by mobilizing Heidegger’s concept of the world as that which partially conditions cognition. Dreyfus proposed what he calls Heideggerian AI as a way to model cognition embedded in and embodying the world. Dreyfus’s challenge to AI has to be pushed further. If Dreyfus succeeded in influencing AI research by introducing a phenomenological approach, then it remains our task to fragment the concept of intelligence and redirect its calculative and totalizing tendency.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Such an operation cannot escape the question that grounds Kant’s critical philosophy: How can we achieve this without falling into the schwarmerei of mere speculation? Kant’s decision is conditioned by a future of metaphysics that demands a specific definition of reason. But if we suspend such a future and return to fragments, then we may be able to identify different futures that are not necessarily metaphysical. The return to art is such an experiment, and the repositioning of intuition is a way to “rehabilitate reason,” in the words of Mbembe. In the East, we can find different reformulations of the question of intuition. As discussed earlier, we see Mou Zongsan’s attempt to thematize the notion of intellectual intuition as a counter­argument to Kant’s cognitive model. We can also find in another important thinker, Kitarō Nishida, an effort to rearticulate what he calls “intuition-acting” as an inseparable unity already formed by the historical social world, which implies another logic: It is true that from the standpoint of logic of judgement, everything that is given can be regarded as being irrational, and [that, therefore,] every intuition can be regarded as being a-logical. But we, as concrete human beings, are born in the historical-social world, as acting-reflecting beings.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  And so far as we may proceed, we cannot abandon this standpoint. That which is given, is given historicalsocially, and that which is seen by intuition, is seen acting and producing; it moves us through expression.55  The hierarchical structure from intuition to reason, passing by the understanding and imagination, has been the cognitive model defining intelligence. We are not claiming that it is wrong, but rather we want to question the extent to which this definition of intelligence is sufficient. Or maybe there are many kinds of intelligence, for example rational intelligence based on formal logic, as well as artistic intelligence based on intuition. To what extent can those faculties undermined by reason have their role in what is called “intelligence”? If Mou Zongsan argued that what Chinese philosophy ceaselessly aims to cultivate is intellectual intuition, how, then, can that fit into the hierarchical structure of cognition? In Chapter 2, I attempted to elaborate on intellectual intuition and its mode of operation through the logic of xuan. It is also on this question that Mou Zongsan joined Bergson and Heidegger; and by redefining Chinese philosophy as cultivation of intellectual intuition, it also entails an “education of sensibility.” Intelligence doesn’t necessarily come out of a philosophical system, but also may come from aesthetic thinking.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  It is not only because there is no distinction between aesthetic thought and philosophical thought for the Chinese, but also because a great artist is necessarily a philosopher (though not necessarily vice versa).56 Instead of identifying the position of Chinese thought in between mechanism and organicism, one might ask if the distinct model of intelligence implicit in Chinese philosophy can contribute to the development of artificial intelligence. For example, could it inform an intellectual intuition in machines, developing a stronger and more powerful artificial intelligence? This contribution could actually reinforce a mono-technological culture, in the way that a Heideggerian AI may actually prolong the very metaphysics that Heidegger wanted to put to an end. Such a temptation may risk 55. Kitarō Nishida, Intelligibility and the Philosophy of Nothingness: Three Philosophical Essays, trans. Robert Schinzinger (Honolulu: East–West Center Press, 1958), 226. It is also worth noticing that the chapter is titled “The Unity of Opposites.” 56. On this point, François Cheng has reason to claim that “in China, art and the art of life are one and the same.” See François Cheng, Full and Empty: The Language of Chinese Painting, trans.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Michael H. Kohn (Boston: Shambhala, 1994), 2.  following a path that betrays dao and the openness that it promises, because it has the immediate tendency to subordinate the incalculable to the computable. Instead, we could seek to understand how Chinese thought could augment the very idea of intelligence and intelligence itself. The strict rationality of computability is powerful, since it is first of all a universal “technical tendency” that allows it to easily sweep away obstacles posed by cultural differences and other factors contributing to particular “technical facts.” However, this opposition between the universal and the particular (and local) has yet to be contested and reflected upon. If we take the standpoint of oppositional discontinuity, something is either universal or particular. If we take the standpoint of oppositional continuity, we may question the relation between the two poles without subordinating one to the other. This is one way—bearing in mind that there may be other ways to be rediscovered and invented—to reflect on how an epistemology of the Unknown can be inscribed in technological thinking without subordinating to or abandoning calculability. § 21 SECOND ATTEMPT CONCERNING SHANSHUI: PLACE Let us return to shanshui to explore the relevance between intellectual intuition (or intuition in general) and the framing of artificial intelligence today. What is the function of shanshui in the time of artificial imagination, when machines claim to increasingly occupy the domain of creativity?\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  We cannot simply refuse the hypothesis that one day machines may be able to appropriate the style of Dong Yuan, Wang Wei, Ma Yuan, and Shitao, and paint in a way that renders machine and painter indistinguishable. Or perhaps they will acquire an “intellectual intelligence” when the technological singularity is realized. We cannot exclude this possibility of machines developing intelligence precisely because we cannot reject possible future epistemological breakthroughs in scientific research. In the context of art and technology, digitalization and its virtually infinite possibilities force us to question the relation of  aesthetic thinking to other kinds of thinking—religious, philosophical, scientific, and technological, for instance. Without political and philosophical significance, aesthetic thinking only provides “added value” for consumerism and easily submits to the logic of replacement by machines. It leads to an impoverishment of sensibility and reason by reducing everything to “experience,” which is totally insufficient for inquiring into the role of art. But this caricature of reason and intuition is still ahistorical and asocial. It is for this reason that I will carry out a second attempt on shanshui more concrete than my effort in Chapter 2 concerning xuan zhi you xuan (玄之又玄).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  To think more concretely in the sense of both Simondon and Hegel—for Simondon, the realization of technical objects toward higher autonomy; and for Hegel, the movement from immediacy and contingency toward objectivity and necessity—I will ask how to address the openness of intelligence without falling prey to the schwarmerei of techno-positivism. § 21.1 THE BASHO OF SHANSHUI In Chapter 2, we saw that xuan zhi you xuan (literally, “mystery upon mystery, darkness within darkness”) stands for a non-linear logic that opposes being to nothing in order to arrive at a continuity. We call this “oppositional continuity and unity.” However, being formal and logical, this too remains ahistorical and asocial. Daoists are not thinkers of history, since they understand very well that human history is only a very tiny part of the history of the cosmos. This recognition of the finitude of human existence allows Daoists to downplay the human desire for all types of accumulation, ranging from material wealth to knowledge, therefore proposing that freedom is conditioned by the awareness of one’s own limit and the world’s incalculability. In other words, the limited is the condition of the unlimited. Here lies a difference between Confucian thinking and Daoist thinking, because in contrast to the curvilinear thinking of xuan in Daoism, Confucianism is fundamentally a rectilinear thinking, as Mou Zongsan has shown;  though we also saw in Chapter 2 that Confucians have to accept certain forms of recursivity as a solution to conceptual dualities. In Chapter 2, we considered the question of shanshui in relation to logic of space.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  To go further, I would like to show that it has to be supplemented by the logic of place. I start by asking: How does shanshui mark a place, a locality, that dissolves the subject in front of it? Is it because the latter can no longer maintain a distant and objective regard, but is involuntarily contained? What does “containing” mean here? Kitarō Nishida employs the Japanese word basho (場所) to designate place—or khôra, borrowed from Plato’s Timaeus. It is worth mentioning that before developing the logic of basho, which was a breakthrough in his philosophical trajectory, Nishida endeavored to elaborate on “pure experience” (inspired by William James) as a way to overcome modern subject\/ object dualism or matter\/form hylomorphism, an important theme of his first book An Inquiry into the Good (1911). The notion of basho can be seen as a “turn” that Nishida took from his early philosophy.57 This Kehre moves from ego as the site of unification to space as a contradictory unity where the ego is situated, both historically and geographically. This is comparable to what Heidegger did to Husserl’s intentionality, but with his own concept of “world” laid out in Being and Time.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  We can even say with Simondon’s vocabulary that it is a search for convergence after the divisions (i.e., subject\/ object) necessitated by the pursuit of knowledge. Nishida wants to provide a more universal philosophy than the European philosophers. Such attempts ended up as self-objections, since, as a great reader of Buddhism, Confucianism, and Japanese literature, Nishida also had to confront the irreconcilable difference 57. In Japanese Philosophy: A Sourcebook, ed. John C. Maraldo, Thomas P. Kasulis, and James W. Heisig (Hawaii: University of Hawaii Press, 2011), 648. James Heisig pointed out Nishida’s abandonment of pure experience in favor of basho and cited a reflection from Nishida: “A theory of direct or pure experience takes reality to be the empirical content immediate to oneself, that is, what is internally perceived in the broad sense. Its standpoint is prior to the division of subject and object, to be sure, but that is only looking at things from the inside out. The true self is the self at work, and true reality must be considered the object of this acting self.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  We are born in this world and realize our selves by acting in it.”  between philosophy in the East and in the West, and he did so systematically, making a clear distinction between Eastern and Western focuses on nothing (mu, 無) and being ( you, 有). For him, the notion of nothing, or absence, is especially crucial in Eastern art: Obviously there is much to admire and much to learn from the dazzling developments in Western cultures where form belongs to being and taking form is seen as good. But is there not something fundamental in the cultures of the East that have nurtured our ancestors for thousands of years, something beneath the surface that can see the form without form and hear the voice without voice? I would like to attempt to give a philosophical grounding to the desire that drives our minds continually to seek this out.58 “Form without form” and “voice without voice” remind us of what we discussed in Chapter 2 concerning Laozi: “the great image is without form,” and “the great sound is the least loud.” However, Nishida’s philosophical inspiration is not Daoism, but Buddhism (Zen and Mahāyāna), Japanese thought, and German philosophy (including idealism and neo-Kantianism). Nishida couldn’t avoid discussing Daoist nothingness, but he undermines it by claiming that Daoism is a culture of non-being, it was still imprisoned by nonbeing— that is, by the form of non-being. Its present was not a moving one but only an indeterminate present. The true self-determination of non-being must be infinitely active as the absolute affirmation of absolute negation. Its present is infinitely moving.59 58.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Mayuko Uehara, “Japanese Aspects of Nishida’s Basho: Seeing the ‘Form without Form,’” Frontiers of Japanese Philosophy 4: Facing the 21st Century, ed. Wing Keung Lam and Ching Yuen Cheung (Nagoya: Nanzan Institute for Religion & Culture, 2009): 152–164, 153–154; from Nishida, From Acting to Seeing in Complete Works, vol. 4. 59. Kitarō Nishida, “Form of culture of the classical periods of East and West seen from a metaphysical perspective,” in Sourcebook for Modern Japanese Philosophy, trans. and ed. D.A. Dilworth, et al.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  (London: Greenwood, 1998), 34. I have discussed François Jullien’s provocation in associating form with being (following Heidegger) to claim that there is no ontology in Chinese thought. A similar conclusion was implicitly drawn by Mou Zongsan when he failed to identify Aristotle’s four causes in Chinese thought.60 Mou and Jullien’s interpretations are largely influenced by Daoist thought and the I Ching, which is much less the case for Nishida. Corresponding to the concepts of oppositional continuity and oppositional unity I developed in Chapter 2, we can find in Nishida’s own terms “contradictory unity” (矛盾 的統一), or “contradictory self-identity” (矛盾的自己同一), and “continuity of discontinuity” (非連続の連続). Nishida’s systemic formulation of Eastern thinking with his theory of basho provides another entry for understanding shanshui painting. Further than the logic of xuan developed earlier from the reading of Laozi, basho explicitly suggests a historical and cultural necessity to understand thinking itself. Like other Eastern thinkers of his generation, Nishida accepted Western philosophical vocabularies and was tempted to identify similar concepts in Eastern thought. Philosophy is driven by the desire toward the universal, and one could hardly resist this temptation without the emergence of philosophical and linguistic tensions.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Nishida still insists on the notion of form and sees in the “form without form” a kind of Platonic eidos. On the other hand, he also identifies a fundamental difference: “Japanese aesthetics differs essentially from Greek aesthetics in that it is not an aesthetics of eidos. Of course, no aesthetics can exist apart from form.”61 For Nishida, Japanese aesthetics starts with feeling and emotion rather than with form. Nishida also employed Hegelian vocabulary such as “concrete universal” (konkrete Allgemeinheit, 具体的一般者) and “abstract universal” (abstrakte Allgemeinheit, 抽象的一般者), in places where his 60. As we saw in Chapter 2, in Chinese philosophy the formal and the material causes are not elaborated; Mou claimed that qian and kun, the first two hexagrams of the I Ching, correspond to the efficient cause and final cause. 61. Ibid., 29. 62.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  For a more detailed discussion on Nishida and Hegel, see John W.M. Krummel, Nishida Kitarō’s Chiasmatic Chorology: Place of Dialectic, Dialectic of Place (Indianapolis: Indiana University Press, 2015)  logic resembles Hegelian dialectics.62 But such borrowed terms don’t necessarily carry the same meaning in his own philosophical system. Scholars in comparative philosophy sometimes too easily commit this methodological fallacy out of eagerness to show relations between different schools of thought. As we will see later, Nishida also associated basho with the Platonic khôra or the Aristotelian topos, but before elaborating on these nuances, let us first consider Nishida’s understanding of the foundation of Eastern art: Greek arts saw the formless (無形) within form (有形)— while the distinctive quality not only of the Japanese arts but also of all Eastern arts grounded in the principle of non-being—to lie in employing form to express what is formless. Eastern arts do not just symbolically represent other forms but reveal the formless.63 Nishida identifies the formless with the intelligible form, the Greek eidos. However, eidos is not formless. Eidos is the ultimate form, while the Japanese mu (無, or wu in Chinese), though it can be revealed by form, it is itself formless. If we put this controversial issue aside (which could be seen to stage a confrontation between Jullien and Nishida), we can agree with Nishida that the formless is the ground in Eastern arts.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The formless as ground means the ground is not visible. How, then, could such formless “form” be thought logically? If the formless doesn’t have form, it cannot be expressed in formal logic. This is resolved by the logic of basho that forms Nishida’s proper philosophy. To do justice to Nishida, basho is not exactly the Greek khôra; for him the difference is that khôra is “matter,” while basho is “field of consciousness.” 64 Insofar as we are in the world, we are conscious of beings around us. This consciousness of being can only acquire its meaning when underscored by the consciousness of non-being, which can be called self-consciousness ( jikaku, 自覚). With self-consciousness “the self reflects itself within itself” (自己 63. Nishida, “Form of Culture,” 32; also cited by Uehara, “Japanese Aspects of Nishida’s Basho,” 156.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  64. Uehara, “Japanese Aspects of Nishida’s Basho,” 161. が自己に於て自己を映す).65 If the conscious act mirrors the object in front of it, that is, reflects it to consciousness, then in every introspection of consciousness itself, the act ceases to be an act, but rather is seized as object: We may conceive the self to be a unifying point that posits knower and known … yet we cannot consider such a unifying point to be the knower; it is instead merely what has already been objectified and known.66 Becoming conscious of a thing is a process of mirroring, while the mirroring of consciousness itself is not simply an image of consciousness, but rather an act that projects the first mirroring into another mirror, therefore entering into a recursive process. A shanshui painting is that which casts the subject into permanent reflection until the subject is dissolved, no longer confronting the painting as an object. The painting ceases to be a set of predicates, ceases to be the object of the subject’s predication; rather the subject is contained. In other words, the subject is projected into a recursive process until its distance from the painting is dissolved and the subject is emplaced amid the mountains and water. In this process, an absolute is assumed as the container of containers, namely the basho of true nothingness (真の無の場所) or absolute nothingness (絶対無の場所). In this sense, basho cannot be identified at all with Plato’s khôra or Aristotle’s topos.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  One may be able to do so from the standpoint of formal logic, according to which basho stands for a container-like space. However, the notion of basho is not a linear logic, as we will elaborate below. The logic of basho can be elaborated by comparing the grammatical structure of subject\/predicate. If we say “the rose is red,” “red” is the predicate of the subject “rose,” namely a quality or property of the rose. But for Nishida, red is not simply a property, since it is the rose that is placed in red. The concept of the basho is that 65. Ibid., 162. 66.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Cited by Tomomi Asakura, “On the Principle of Comparative East Asian Philosophy: Nishida Kitarō and Mou Zongsan,” National Central University Journal of Humanities 54 (2013): 1–25, 11; from Nishida, Complete Works, vol. 4, 215.  which contains. If we continue by saying that “red is a color,” then we also place “red” in the basho called color, and this basho is also that which allows non-red to appear. The non-red is the negation of red; it negates red to nothing, so it is the nothing of “red,” but it is not that which gives redness, since both redness and non-redness are contained in another basho. It is also the case with action, since each action could be identified with a causality situated in time and space. If we understand the concept of basho as “that which contains,” then we will find that basho is contained in another basho toward infinity. At first glance, this infinity would seem to resolve in something no different from the prime mover, since one can trace the casual chain until it reaches the ultimate basho. But a significant difference is that the consciousness of basho is motivated by mirror reflections; it is from the beginning non-linear.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Let us imagine that there are two mirrors facing each other, and any object in between them will be reflected toward the infinite. This is a classical problem in philosophy of consciousness, since one risks an infinite regression toward the very beginning of consciousness. Nishida resolves this infinite regression by suggesting that nothingness is the ultimate basho that contains all beings. Nothing is not absolutely opposed to being, in a mutual exclusive sense, since that would be an oppositional discontinuity. Instead, the true nothing emplaces being: The nothing that opposes being by negating it is not true nothing. Rather true nothing must be that which forms the background of being. For example, that which is not red as contrasted with red is also a color. [But] that which possesses the colors, that wherein color is emplaced, must [in itself] not be a color.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Red as well as that which is not-red [e.g., blue] must be emplaced in it.67 Recursive mirroring dissolves the subject because it is no longer contrasted against the object, whose existence only acquires meaning 67. Kitarō Nishida, “The Logic of Basho,” in Place and Dialectic: Two Essays by Nishida Kitarō, trans. John W.M. Krummel and Shigenori Nagatomo (Oxford: Oxford University Press, 2012), 55.  through the intentionality of the subject (be it in the form of doubt or explication). The significance of the subject\/object opposition disappears because, as Nishida claims, “basho is regarded as external to what is contained [within it].”68 As Nishida’s emphasizes, the place is not contained by intuition, but rather intuition is enveloped by basho.69 In other words, intuition is conditioned by basho. Such a conditioning is not a determination per se, but rather in our vocabulary, a cultivation of sensibility. The ego is emplaced because its place in the cosmos is insignificant, or nothing—it has a place because it doesn’t have a place. The ceaseless reflection that takes us from a knowing subject to an emplaced subject is a search that we can compare with the recursive logic of shanshui, which we align with xuan zhi you xuan.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Are we not arbitrarily squaring Nishida’s basho with Daoist thought? What does Nishida’s theory of consciousness, coming from his interpretation of Buddhism, Emil Lask, Edmund Husserl, Fichte, and Hegel, have to do with painting? Didn’t his theory aim to be a universal theory of consciousness? And aren’t experiences of art, as I have claimed throughout this book, singular and differentiated? Let us remain with Nishida’s philosophy of basho in order to address these questions. Nishida is innovative in his appropriation of Fichte’s and Hegel’s concepts of reflection by incorporating them into his own recursive thinking, which can be called Eastern philosophy. We know that Fichte’s reflection is an attempt to unify the I and the non-I, since every reflection is indicated by a “check” or “limit” (Anstoß) of the non-I. In so doing, the I and the non-I constitute a simple coupling machine.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  In Schelling, the I (spirit) and the non-I (nature), the Ideal and the Real, are unified by a generalized recursive process, in which the infinite productive force of nature, generates appearances when encountering a hindrance (Hemmung), like the whirlpool appears when the flow of the river encounters an obstacle. Hegel might have developed the most logical and sophisticated approach to describe this recursive-organic operation, namely dialectics. Dialectics involves three reflections, 68. 69. Nishida, “Logic of Basho,” 55. Ibid., 58.  which we can summarize as following: positing reflection, which starts with appearance, for example, being that is immediate—such being is only negative, so the reflection is a sublation of being as self‑positing; second, external reflection, which is recognition of the other as the condition and contradiction of the self; and third, determining reflection, which is the unification of the positing reflection and the external reflection.70 Nishida achieves this by eliminating the I as the absolute beginning (in Fichte and Schelling) as well as the absolute as the final product (in Hegel); that is to say, the absolute is neither the beginning of the I nor the end of the spirit. In Nishida’s reflection of reflection, we will eventually reach absolute nothingness, as the ultimate place that cannot be reflected. This place that cannot be reflected takes the name of prime mover in onto‑theology, or deus sive natura (God or Nature) in Spinozist pantheism.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  In Nishida’s philosophy, this place is not the Christian godhead, but absolute nothingness. It is this reflective logic that confronts Nishida with the abstract prime mover—the ground and the void of mechanism. Nishida also diverges from the Spinozist immanent cause by arriving at absolute nothingness instead of an onto-theology in which transcendence collapses into immanence. For Nishida, the concept of basho is a concrete absolute that already arrives at the universal. The term “absolute” is contrasted with “relative”—as there is absolute nothingness, there is also relative nothingness. In the conventional understanding of the opposition between being and nothing, nothing is only relative, since it depends on being, and this dependence is a negation (like how Nishida has misunderstood the wu in Daoist thinking). Nishida’s absolute nothingness doesn’t carry such a negativity, but rather the capacity to contain. Don’t we then relapse into idealism, and even worse, nihilism, because all beings are within nothing, therefore all values are fundamentally nothing?\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  70. G.W.F. Hegel, The Science of Logic, trans. George Di Giovanni (Cambridge: Cambridge University Press, 2015), 345–353; for a more detailed analysis of Fichte’s, Schelling’s and Hegel’s formulations of recursivity, see Hui, Recursivity and Contingency, Chapters 1 and 2. Nishida avoids this by always reminding his readers that place, or the world, is social and historical (社会的歴史的世界). There is a historical expressive formation in art, and it has to be understood from the perspective of basho.71 The universal at which Nishida arrives is not opposed to the particular. And indeed, following Nishida’s path, one can no longer reproach him with the same dualist logic he rejects. Such a universality doesn’t have a name, though if we were to impose a name it might be dao—the greatest, absolute nothingness, or the last god.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This universality is not confined by any genre, since it is no longer a scientific concept subject to objective classification and demonstration. Science is first of all a machine of ontological proof in which each being has its place. Historicity primarily means locality. One reason Nishida’s “absolute nothing” is not called “absolute being” is because his particular language, Japanese, has more than three thousand kanji characters and a philosophical language informed by German and Greek thought. This is also why Nishida’s basho can supplement the logic of xuan, because xuan, which we formulated from Daoist thought, concerns cosmic time and space, and considers history and place as limit. Laozi is not a thinker of history, even though he was an archivist in the royal library.72 Nishida’s recursive logic reveals place, the locality that any historicity rests 71. This is the theme of a later article by Nishida, “Artistic Creation as an Activity of History Formation” (歴史的形成作用としての芸術的創作, 1941) that engaged with Jane Harrison’s (1850–1928) Ancient Art and Ritual and Themis, which provides Nishida with historical evidence that art is an historical “expressive formation” (in the sense of Conrad Fiedler): “The self-formation of the historic world takes place as the self-determination of the place (basho) … The ritual dance of the primitive people in the sense Harrison describes is the primordial momentum of the process of the self-formation of the historic world. Gods are born out of rituals.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Not only religion and art get shaped out of this, but also scholarly activities.” This article has not yet been translated: for a summary (which also addresses Nishida’s 1923 Art and Morality), readers may consult Enroco Fongaro, “Bodily Present Activity in History: An Artistic Streak in Nishida Kitarō’s Thought,” in The Bloomsbury Research Handbook of Contemporary Japanese Philosophy, ed. Michiko Yusa (New York: Bloomsbury, 2017), 167–196. 72. This issue is also raised in Part II of Yuk Hui, The Question Concerning Technology of China: An Essay in Cosmo­technics (Falmouth: Urbanomic, 2016\/2019). upon. But how can nothingness have a place? If nothingness were to have a place, it would already be there, but as being and no longer as nothing. On the other hand, if nothingness has no place, then it has no historicity.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  In this sense, absolute nothingness would only be an abstract universal. Nothingness can only acquire concrete meaning through locality and historicity. It is in the historicity of what we call East Asia that nothingness acquires its meaning, whether Daoist or Buddhist. Therefore, nothingness stands for historicity, which is not the void, but rather a field of meanings, in which the ten thousand beings find their proper sense and place. In relation to the basho of shanshui, we may want to ask: can a foreigner, say, a French or an Egyptian person, standing in front of a shanshui painting by Shitao, experience the painting in the same way as a Chinese literato? It is not impossible, depending on one’s aesthetic education, but it doesn’t happen spontaneously. One might exclaim “how beautiful!,” “amazing!,” “wonderful!,” “impressive,” but these are only abstract expressions of “experience.” The intuitive act of experiencing shanshui is enveloped by place. The envelope isn’t exactly closed, since envelopment is open to influences from outside.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Those who teach shanshui painting often find that East Asian students learn more easily, perhaps due to a continuity between Chinese writing and Chinese painting. Chinese characters are called “ideograms,” but I prefer calling them “pictograms,” since a character is not an “idea” in the Platonic sense, but rather pictorial.73 So to appreciate shanshui painting and to access the noumenon presupposes a place—from which beings come into being and where history is guarded beyond all written forms. This place cannot be written and exceeds all writing, which Laozi calls dao. A work of art embodies its basho and can be appreciated best from the viewpoint of its basho. But a work is not merely an expression or representation of its basho. It is also itself the basho—a field of meanings; it is emplaced in the basho (for example, the conventional and historical meaning assigned to it), at the same time as 73. See Yuk Hui, “Writing and Cosmo­technics,” Derrida Today 13, no. 1 (2020): 17–32.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  it has the potential to transcend such limitations, in the process bringing forward another basho. The work (of shanshui ) is at work because it reflects—it sets itself against the mirror of consciousness and reflects the I into the infinite, which is conditioned by the basho of nothingness. In between the work of a basho and the basho of a work, one finds a dynamic, which is also a constant negotiation between the work and history. § 21.2 EMPLACING IN BASHO AS RESITUATING Technology is not an explicit philosophical subject for Nishida, though thinkers such as Andrew Feenberg have discovered aspects of the philosophy of technology in Nishida.74 From an “impressionist” point of view, Nishida’s logic is dialectical and holistic, sometimes associated with Hegel and also the Scottish physiologist John Scott Haldane.75 This view risks blurring everything and throwing us into “the night in which all cows are black.” Nishida’s critique of Haldane is clear that a biological notion of part and whole (holism) is not enough to explain human activity, since unlike an animal, which adapts itself to the environment, human beings also invent and use tools to transform the environment. The invention and use of tools and symbols open up a social and historical world that is no longer merely biological, so the holism of Haldane is insufficient for explaining the basho proper to the human. The similarity between Nishida’s philosophy, or Eastern philosophy in general, and organicism and holism may be due to a strong emphasis on ground, and this is a subject that has yet to be elucidated. However, it would be too hasty to call it holism or organicism. We also find this interesting ambiguity in another 74.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  See Andrew Feenberg, Nishida, Kawabata, and the Japanese Response to Modernity (Nagoya: Chisokudo, 2019). 75. For the relation between Nishida and Haldane, please see Akinobu Kuroda, “L’auto-formation de la vie dans le monde de la réalité historique: ce qui constitue une pratique philosophique dans le monde de la vie historique,” Ebisu - Études Japonaises 40-41 (2008): 79–90. philosopher of the Kyoto school, and friend and colleague to Nishida, Miki Kiyoshi (三木清). Miki published a book in 1942 titled Philosophy of Technology, which we can call one of the first philosophical reflections on the subject. Particularly of interest in Miki’s book is an appendix titled “Technology and New Culture” (技術と新文化).76 Like Mumford as well as Simondon, Miki aspires to the “organic” relation between technology and human life: The issue thus is how to make the relation between modern technology and human life “organic.” Technology, as tools, was at first related organically to human beings, and later came to oppose them in the creation of machine technology. The new challenge of the new culture is thus how to restore the [original] “organic” relationship.77 This aspiration to organicism is ambivalent, since, though we can agree that the associated milieu (in the sense of Simondon) created by the artisan for his or her tool was interrupted by industrial machines, and that it is necessary to find a new relation between human and machine, it is unclear what this new “organic relation” entails, and how one can find it. For Simondon it is found in cyber­netics, within an understanding of machines as the organized inorganic.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Secondly, it is doubtful—as I have insisted throughout this book—that it is even possible to equate Eastern thinking with organismic thinking developed from biology. Miki was not unaware of these questions:  76. The article begins with the idea of the Greater East Asia Co-prosperity Sphere as the condition for a new culture; a theory established by the Kyoto school to justify Japanese imperialism, in which they proposed harmonious relations between different independent nations in a sphere that is not dominated by any single nation-state. 77. Miki Kiyoshi, “Philosophy of Technology” in MKZ , vol. 7, (三木清全集·第 七卷)(Tokyo: Iwanami Shoten, 1985); gratitude to Andrew Feenberg for bringing it to my attention and sending me the partial translation by Yoko Arisaka for reference. How then is it possible to make technology “organic?” It cannot be at the level of tools … What is necessary is a “technology of the spirit [kokoro no gijutsu].” What I mean by this is that there is a technology for making the “soul” or the human being. Such technology is especially far advanced in the East.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  We must utilize this tradition. We must create the souls or the people who will be able to control [dominate] technology.78 Miki suggests a battle between the spirit and technology so that technology can serve the latter.79 But earlier in the text, Miki indicates the key idea of “technology of the spirit” with the German term Seelentechnik (technics of the soul). The corresponding kanji of kokoro is xin (心)—literally “heart”—so he is more precisely discussing “technology of the heart” (こころのぎじゅつ), which is not the same as the movement of the spirit or the soul as understood in Western philosophy. Translations of Western philosophical terms into Eastern languages are often problematic, since the tendency to identify these foreign terms in one’s own language often leads to profound confusion. The Japanese are better than the Chinese at avoiding such errors since they often use katakana to transcribe foreign terms. As a faculty of knowing, the heart is not equivalent to the soul and the spirit. At stake, as I have been trying to show, is a different way of situating technology according to a distinct sensibility. This call to return to tradition is a call for appropriating 78.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Miki, Philosophy of Technology, 324–325. 79. A similar proposal can also be found in the work of Ernst Cassirer, a contemporary of Miki. In an article titled “Form und Technik” written in 1933, Cassirer attempts to resolve one of the key problems concerning technology: its subjugation of (which Georg Simmel calls the “tragedy of culture”). Cassirer uses the word Unterwerfung for “subjugation,” which also means “submission.” Culture submitting to technology means precisely that econotechnical development becomes more and more the foundation of culture; all practices are subjugated to technological changes. Cassirer attempts to tackle this problem by proposing a return to the spirit, since if technology is a product of the spirit, then spirit has the capacity and responsibility to overcome such a determination. See Ernst Cassirer, Form and Technology (1933),” in The Warburg Years (1919–1933): Essays on Language, Art, Myth, and Technology, trans. S.G. Lofts and A. Calcagno (New Haven: Yale University Press, 2013), 272–273.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  modern technology into a new frame. Miki’s call was, however, deeply informed by the mechanism\/organism opposition that is the heritage of Western philosophy. Instead of aspiring to this organicity like Miki,80 we might consider more fragmented responses to the problem of modern technology. Instead of seeing organicism as a universal solution, and Eastern thinking as organismic in nature (like Needham did), and concluding that Eastern thinking is the way out, we must first reconstruct Eastern technological thought anew, and reflect on what kind of framework or transformation it can provide modern technology. As a logic, basho aims to be universal. As a field of consciousness, it is historical and local, maintained by artifacts, customs, beliefs, and a shared sensibility. Our second attempt on shanshui will move from a logic qua operation, exposed in Chapter 2 via history and place, to finally summon all that has been said to address the significance of shanshui in the digital age. Here we will approach the question of shanshui as the question of episteme.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Episteme in Michel Foucault’s sense is historical and local, differing from logic, which is assumed to be universal. From the perspective of medium specificity or medium determinism, we can easily dismiss shanshui for being limited to analog media such as paper, ink, and brushes. These media could be called traditional and therefore obsolete. However, such a classification is only based on a superficial reflection on art as mere artifact. It is true that new media technologies render some practices obsolete, or force them to confront their own limits. For example, modern painting had to distinguish itself from the realism of photography—during the period contemporaneous with impressionism—by identifying a new task, which Heidegger saw in Cézanne and Klee, and which we can find in many other modernist painters such as Piet Mondrian, Ad Reinhardt, Barnett Newman, Jackson Pollock, and so forth. 80. Miki in Philosophy of Technology refers to the Gestalt psychologist Wolfgang Köhler, and the Schelling scholar Manfred Schröter, who also wrote a book titled Philosophie der Technik, as well as principles of the organism (which he transcribes the German word of it with the katakana オルガニスムス).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The camera, as Gombrich claimed, does something to the role of artists akin to the “abolition of religious images by Protestantism.” 81 Upon learning of the daguerreotype in 1839, the painter Paul Delaroche wrote that “from today on, painting is dead.” 82 Later on, digital photo editing would make many photographic techniques redundant, yet photography didn’t disappear. This is also why Heidegger sees in the painting of Klee and Cézanne an effort to go beyond the Gestalt in order to reveal something that always exceeds form, an overcoming of metaphysics, which, for Heidegger, is equally an overcoming of Gestell. This is also the reason Heidegger linked this overcoming with East Asian art, which he learned of from his Japanese students, especially Shūzo Kuki. But Heidegger’s knowledge of East Asian art was limited. To some extent, he failed to understand the historical and local context of Japan when, for example, he complained that Akira Kurosawa’s Rashomon, having been made with a European technical apparatus, is already too European to be authentic Japanese art.83 Chapters 1 and 2 began with Heidegger’s discourse on art and his discovery of Cézanne and Klee, then elaborated on the logic of shanshui painting, not only to show the difference between the two traditions and modes of cosmotechnical thinking, but also to address their significance today, when digitalization penetrates into every domain of our social, political, economic, and aesthetic life. Some may claim that a return to shanshui today simply compensates for the frustrations brought by industrial and metropolitan life, as a “virtual reality” comparable to an ancient escape to the countryside as the site of otium. Of course, the digitalization of shanshui paintings, for example, rendering Zhao Mengfu’s Autumn Colors on the Qiao and Hua Mountains (1295) into virtual reality, has value for art historians in the analysis of the painting and for audiences in 81. E.H. Gombrich, The Story of Art (New York: Phaidon, 1951), 395.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  82. In the East, there were also reaction against photography and the end of painting signified by this mechanical apparatus, this confrontation with photography led to the proposal of the revival of literati painting, which we can find in figures such as Omura Seigai (1868-1927) and Chen Hengke (1876-1923). 83. Günther Seubold, Kunst als Enteignis, Heideggers Weg zu einer nicht mehr metaphysischen Kunst (Alfter: Denkmal Verlag, 2005), 89.  being able to “share” the painter’s experience, but it does not help us inquire into the relation between digital technology and shanshui. Because the fundamental question of shanshui is neither about hermitism nor “lived experience,” but rather the apprenticeship of the art of living. A wise person who knows how to live is not one who escapes. For the person who escapes, existence relies on a fragile relation to the other, like what Seneca wrote in a letter to Lucilius: Someone who runs away from the world and from people; who has gone into exile because his desires failed to prosper, and because he could not bear to see others more prosperous than he; who has gone to earth out of fear, like some idle and timorous animal—that person is living not for himself but (most shameful of all!) for the belly, for sleep, for lust.84 Escape doesn’t result in gaining authenticity, but rather in failing to learn how to live.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This also distinguishes a philosopher’s love of himself or herself as and beyond plenitude from someone whose existence is based on lack and negation. The cosmotechnical nature of shanshui has to be rethought as a way to resituate technology in a genesis that is both historical and mesological. Resituating technology does not mean taking technology as the totality of the ground (which is also a source of evil since it perversely detaches it from place), but rather understanding it as figure with a reciprocal relation to the ground. Figure, ground, and their reciprocal relation are dynamic and historical. In Recursivity and Contingency, I proposed we understand this act of resituating technology as a primary task of the philosophy today. This resituating entails a cosmotechnical and organological thinking that necessitates a new framework with new values. Intelligence is basically organological, since intelligence, insofar as it is able to reason, demands the aid of memory and the extension of mind and body, 84. Seneca, Letters on Ethics to Lucilius, trans.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Margaret Graver and A.A. Long (Chicago: University of Chicago Press, 2015), Letter 55, 158.  ranging from simple numbering to sophisticated machinic operations such as the Turing machine and artificial intelligence today.85 Therefore from an organological point of view, the evolution of intelligence is closely associated with the evolution of machine intelligence. The organological interpretation of intelligence suggests that instead of emphasizing the demarcation between machine intelligence and human intelligence, and the dialectics between them, it is more productive to consider the possibility of augmenting both intelligence and sensibility. When we say “augmentation,” we risk moving into the negative organology of current transhumanist discourse on human enhancement. A negative organology is one that only augments the “reckoning” capacity of the organic being and also undermines judgment—not only in the concept of the world, as Brian Cantwell Smith described, but also in the moral and existential judgment of good and evil. While transhumanist discourse believes that by augmenting this “reckoning” capacity we can arrive at genuine judgment, this effort does not escape the positive feedback loop that characterizes modernity as a form of alcoholism. § 21.3 SPACE AND PLACE As cosmo­technics, shanshui seems to exemplify an encounter through which technology inscribes dao into its operation and structure. It is the same with Chinese literati gardens, which could be seen as realizing shanshui painting as a physical environment or microcosm. The foundation of this experience depends on the exploration of senses and a recursive logic we have termed “oppositional continuity.” Media and technology evolve, and painting’s struggle against obsolescence should not be understood too simply as a politics of nostalgia, because the latter already implies defeat.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  85. It is from this perspective that I propose we should revisit the difference between the li school (principle) of Zhu Xi and the xin school (heart, mind) in Chinese thought. New technologies promise more flexibility in expression and manipulation. For example, with cinema, a temporal dimension is added to static images, creating an unfolding narrative and the possibility of synchronizing with the spectator’s consciousness. In comparison with photography, cinematic time predicates place in much richer and more flexible ways, bringing multiple temporal experiences instead of a single hic et nunc. Through synchrony and diachrony, multiple mirrorings are carried out, constantly reflecting the subject to an outer reality until a metastable status (place, basho) is reached. Such is the culmination of an artistic creation. The gardens in Suzhou make present the subtleties of the cosmos through the composition of non‑human agencies such as water, rocks, shadows, fishes, cicadas, weeping willows, and flowers.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Like shanshui painting, the literati garden reproduces key points (in the sense of Simondon) that originally exist in the external environment. These key points are densely installed in a limited space with high intensity. If gardens are a cinematic mode of shanshui, we can say that they also reinforce the recursive effect of shanshui painting. After a promenade in a Suzhou garden, modern visitors might say they “feel happy,” which would not necessarily happen after contemplating a shanshui painting for a couple minutes. Not only does the garden introduce a cinematic experience through duration, but also a temporal transformation through living beings that change seasonally. The temporal and cinematic experience introduces the body (beyond the eyes, ears, and nose as the communication channel of the spirit) to the slow transformation of the seasons, which is maintained by necessity at the same time as it is open to contingency of nature. We might say that the literati garden functions as “new media” to shanshui painting. The garden can be traced back to the second century BC, when it served as a hunting field of the emperor.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  During the Wei-Jin period, gardens and estates were popular among intellectuals, from the Seven Sages’ bamboo grove to the Wei-Jin shanshui poet Xie Lingyun’s huge estate, which included mountains and fields. Gardens only entered into public social life in the Song dynasty, which is also when Neo-Confucians reinvented moral  cosmology (partially as reaction to Buddhism). Gardens never replaced painting, as they involve different bodily activities, and have very different social and political functions as well.86 What the painting or the garden want to make sensible is not what is already figurative and visible, but what is not yet there, invisible—whether uncanny, sublime, or unknowable. The Unknown is also conditioned by place, which is the ground, the groundless ground. Developments in science and technology have revealed many secrets of life and techniques for overcoming defects of nature, but these revelations also suppress further reflection on existence. The incompatibility between traditional or indigenous cosmologies and modern astral physics leads to the defeat of one and the hatred of the other. But this is not tragic, or not yet tragic, since it is only catastrophic. Tragist thinking would attempt to affirm such a contradiction in order to move beyond it.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  It remains our task to become tragists, though not necessarily in the sense of becoming Greek or European. The same goes for becoming Daoist without needing to become Chinese. It is possible, as we attempt to do by reflecting on shanshui, to become a tragist Daoist, or a Daoist tragist. But these are only two modes of aesthetic thinking among many I cannot list here that are waiting for their time, when their echoes will be heard on other parts of the earth, and our thesis here will be enriched and challenged. To reformulate the question: How can we reclaim the function of shanshui when today’s modern media technologies—satellites, screens, augmented and virtual reality—already merge cinematic experience and bodily movement? The question paraphrases James Lovelock, who toward the end of his 1979 book Gaia: A New Look at Life on Earth, expressed hope that satellites and aircraft will make Gaia aware of itself: Still more important is the implication that the evolution of homo sapiens, with his technological inventiveness and his increasingly subtle communications network, has vastly increased Gaia’s range of perception. She is 86. These gardens facilitated activities such as playing chess, appreciating paintings, tea drinking, etc., which are known as ya ji (雅集): ya means “elegant, scholarly,” ji, “gathering” and, ya ji refers to a “literati gathering.”  now through us awake and aware of herself.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  She has seen the reflection of her fair face through the eyes of astronauts and the television cameras of orbiting spacecraft.87 Will the humans be awakened by these media technologies in the way that Lovelock expected of Gaia? Currently, more than eighteen hundred satellites circle the earth, and there will certainly be more, and with better precision in monitoring the earth; but it is unlikely that Gaia will be awakened by them. Gaia is only a metaphor for a mechano-organicism in Lovelock’s formulation. What must be awakened are the humans enframed by modern technology and enframing other species just as technology does to them. In The Human Condition, Hannah Arendt describes the 1957 launch of Sputnik as “second in importance to no other, not even to the splitting of the atom,” because it suggests, as Konstantin Tsiolkovsky did, that “mankind will not remain bound to the earth forever.” 88 It was also the 1966 images of the earth taken from the moon’s orbit that confirmed to Heidegger the completion of Western philosophy. This liberation from the earth in practice (not only in theory, as it was for the early moderns) confronts humankind with the infinite universe and prepares for a cosmic nihilism. Arendt wants to rescue thinking from being undermined and suppressed by production, while unconsciously or consciously opposing modern technoscience and its thinking.89 This, of course, echoes Heidegger’s notorious claim that “science doesn’t think.” From both tragist and Daoist points of view, it is not sufficient to oppose thinking and acting, for thinking has to affirm its destiny and also to transform technology in the process of rationalizing the Unknown. We hope that the technologies we have today and in the future will give us new techniques of orientation (Eröterung) through the place (Ort) they can reveal to us.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  87. James Lovelock, Gaia: A New Look at Life on Earth (Oxford: Oxford University Press, 2000), 140. 88. Hanna Arendt, The Human Condition (Chicago: University of Chicago Press, 1998), 1. 89. See ibid., Chapter 6, “The Vita Activa and the Modern Age.”  But where precisely is this place in the time of globalization and planetarization? Isn’t every place already global or planetary, no matter how locally one wants to identify it? This loss of site in the process of technological modernization is a disorientation, or a kind of numbness which Heidegger calls the incapability of sense making (Besinnungslosigkeit).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The auction of shanshui paintings for millions of US dollars and the transformation of gardens to tourism revenue is no longer about orientation but disorientation. Disorientation arises from not knowing where one stands or where one is heading to, like the hype of the technological singularity and acceleration disguised by the white lie of plenitude, leading us to pure lack. The planetary puts thinking in peril, at the same time it is the condition of possibility for thinking itself. This peril first manifests as a risk or even an aesthetic catastrophe: that using these technologies in artistic creation may accelerate the poverty of sensibility and lead toward an increasing numbness. Their emphasis on lived experience, whether immersive or augmented, is nothing but mere consumption of excitement and hype, and will only close our aesthetic experience by reducing our five senses to sense data that sustain the database and algorithmic operations. Besides exhibiting the advancement of technology and so-called creativity, there is complete lack of questioning. This silence and contradiction is also the place where art can act out. The solution is open, but art has to be questioned on its capacity to question in response to today’s aestheticization of consumerism and politics.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Shanshui is not only a genre of the past. It is that which allows us to reflect on the place of the human in the cosmos. This reflection rescues the human from a “backdrop ontology,” a term coined by Peter Sloterdijk to describe the conventional translation of Max Scheler’s treatise “On the Place of Man in the Cosmos,” in which the cosmos is the background to be mastered and exploited by human, the “dramatic animal.”90 The recursive logic of basho refuses to accept the phenomenal world as it is. It proves the necessity of retrieving a field of nothingness, but for nothingness to acquire a concrete and positive meaning, we have to identify its locality. Locality doesn’t mean self-isolation or self-essentialization, since  locality can be open insofar as it doesn’t use the self to exclude the other. In shanshui paintings and literati gardens, nothingness is not the negativity of all being, it is rather a historical site in which beings find their places, and where their development will not be hindered. Its possibility of reflection is maintained by history and place, as well as through encounters, like the one just staged between Mou Zongsan and Nishida, not through their common subject of Buddhism, but through technology, which neither addresses thematically. When place disappears, there is no longer any mirroring effect, only GPS data and mere representation.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Art, as the science of the sensible, can intervene by establishing relations between religious, philosophical, scientific, technological, and aesthetic thinking, to reground aesthetic thinking as primordial thinking, after the death of God, the end of philosophy, and the hegemony of techno-science. § 22 ART AS EPISTEMIC REVOLUTION In “Technology and New Culture,” Kiyoshi Miki calls for a vision for a new culture that goes beyond modernization. This new culture has to accommodate modern technology without becoming techno-logistic.91 East Asia has had to keep developing superior technology and eliminate the undesirable elements of tradition. It is destined to overcome the opposition and gap between technology and spiritual life by developing “higher forms of spiritual culture.”92 90. Peter Sloterdijk, “The Anthropocene: A Process-State at the Edge of Geohistory?,” in Art in the Anthropocene: Encounters among Aesthetics, Politics, Environments and Epistemologies, ed. Étienne Turpin and Heather Davis (London: Open Humanities Press, 2015), 334. “Remembering Max Scheler’s treatise, we could translate the conventional ‘human place in the cosmos’ as a kind of backdrop ontology. In this ontology, the human being plays the dramatic animal on stage before the backdrop of a mountain of nature, which can never be anything other than the inoperative scenery behind human operations.” 91.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Miki, Philosophy of Technology, 318. 92. Ibid., 322. Like African and Latin American countries, Asian countries have to compete with the West in technology, as Japan successfully did, and China is doing. Let’s remember Oswald Spengler’s lament in his 1932 Man and Technics, when he says that white people made a big mistake at the turn of the nineteenth century by not keeping technological knowledge to themselves, but giving it away, most notably to the Japanese. It turned out that the Japanese became “technicians of the first rank, and in their [1904–5] war against Russia they revealed a technical superiority from which their teachers were able to learn many lessons.”93 Retrospectively, modernization was an inevitable reaction against colonization—at the same time it was complicit in it—which in turn also gave birth to nationalism. Cultures and traditions have to give way to modernization. Modernization is accompanied by a melancholia that traumatically returns from time to time.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  To become a modern is like what Nietzsche describes in The Gay Science: one abandons the village, burning bridges to embark on a boat in search of the infinite. It is only after reaching the middle of the vast ocean that one realizes that the infinite is truly terrifying, but there is already no way back.94 This nihilist moment has to be overcome by a tragist thinking that affirms one’s destiny and learns how to take it up as necessity. Another way, which I explored in Recursivity and Contingency, is to develop and realize a technodiversity that resists destiny—not by negating it, but by embracing contingency to render it one possibility among many. Neither cyber­netics nor technodiversity were available to Miki, so he had to rely on a higher spiritual culture that doesn’t overcome the opposition between culture and technology, instead maintaining, if not enlarging, the antagonism between matter and spirit. As we saw earlier, for Miki, the task is to reintroduce an organic relation between modern technology and human life. For Simondon, this could be achieved by conceiving what he calls a “general allagmatic” 93. Oswald Spengler, Man and Technics: A Contribution to a Philosophy of Life (London: Greenwood, 1967), 100–101. 94.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Friedrich Nietzsche, The Gay Science, trans. J. Nauckho (Cambridge, UK: Cambridge University Press, 2001), 119. (or a universal cyber­netics)95 that applies the logic of cyber­netics in all domains of society. The need for an organic relation between modern technology and human life was not confined to East Asia, since it was the dominant epistemology of twentieth-century biology and systems theory. In this work, I inquire into its limit and its legacy. Toward the end of “Technology and New Culture,” Miki gives the restoration of organicity a more explicit meaning, as fundamentally “becoming art” (技術の藝術化), which for him can be also considered as the “becoming organic of technology” (技術の有機化): Creation or making is generally a subjective-objective process; in the same way, the Idea [イデー] is also objective in history, as that which is subjective-objective. It isn’t spiritual culture alone that is Idea, but ordinary technology too expresses the Idea. It may be said then that the principle of the new culture must rest on [a combination of] the technological and artistic\/aesthetic worldviews.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The “becoming organic” of technology is thus also “becoming art.”96 The term (藝術化) that Miki employs here is a denominalization of the noun “art” into verb. It carries the sense of “becoming art” or “making something art.” However, this conclusion is not really a conclusion, since it can only serve as an invitation. In this chapter I want to show precisely the limit of technology’s “becoming 95. Allagmatic refers to a recursive process between structure and operation, i.e. crystallization and modulation. Simondon considers his theory of the allegmatic as a further development (or a generalization) of cyber­netics; see Gilbert Simondon, Sur la philosophie (Paris: PUF, 2016), 189. “This third discipline, synthesis of cyber­netics and positivism, will not only be an axiology of knowledge but also a knowledge of being: it will define the real relation of the operation and the structure, the possible conversions of the operation in structure and structure in operation and structure in the same system. Such will be the scope of the discipline; indissolubly scientific and philosophical, which we have named allagmatic.” For a detailed analysis of Simondon’s relation to cyber­netics, see Hui, Recursivity and Contingency, Chapter 4.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  96. Miki, Philosophy of Technology, 329. “右に述べた技術の有機化といふこ とも技術の藝術化と考へることができる.”  organic.” Miki’s proposal belonged to the “organismic movement” of the early twentieth century, like Mumford’s. Retrospectively it remains a dualist thinking—opposing the mechanical and organic, West and East—though it could be read as an attempt to overcome dualism through dualism, the tragist gesture that the Kyoto school has taken up from Nietzsche, namely to overcome nihilism through nihilism. It also exposes both the possibility and limit of Eastern philosophical thinking in response to the challenge of modern technology. However, it serves an invitation to reconceive a new relation between art and technology. One could propose that to realize technodiversity means demanding a radical opening of epistemologies. It is necessary to rediscover and develop epistemologies and epistemes alternative to dominant ones, as the new practice of diplomacy, for example, through the comparison between epistemologies of Chinese medicine and Western medicine.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  From the perspective of art, it is also possible to do so with “becoming art.” Becoming art means here an aesthetic and epistemic revolution. It doesn’t mean making things more beautiful in the way of cosmetic surgery or decoration, but rather an education of sensibility. It is here that we can continue the discussion on the notion of episteme. In The Question Concerning Technology in China, I suggested we redefine Michel Foucault’s concept of episteme, namely the sensible condition under which knowledge is produced. The production of knowledge is conditioned by many factors, while sensibility stands as the primordial factor often associated with worldview or intuition of the world (Weltanschauung). Sinologists and anthropologists often address the Chinese episteme as analogy, and certainly analogical thinking exists in Chinese thought, especially in medicine. However, it is probably not the most important form of thought. Chapter 2 of this book closed by placing the notion of resonance (gan ying, 感應), a sensibility beyond the five senses, at the center of Chinese thinking.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  In Chinese, gan hua (感化) means to change someone’s attitude, for example, to redirect a criminal to the right (or moral) path: gan, to feel or to be moved; hua, is to change, to be transformed. Gan is not some random emotion; rather, it is conditioned by a particular sensibility that associates all beings  together, not into the one, but as a resonance between ten thousand beings. Cheng (sincerity; see Chapter 2) is the condition of the ability to feel, gan. This is also the foundation of Confucian moral philosophy as well as the concept of dao, because the unknown that cannot be captured by the five senses demands another way of knowing. Art will have to go back to the very question of sensibility in order to move forward. Or, more explicitly, art should take up the task of the education of sensibility, and of rescuing reason from illusion. Today, new technological disruptions are accompanied by new ethical rules, for AI, for biotechnologies, and so on. In discussions on the ethics of technology, people tend to first accept these technologies, then provide measures to mitigate their harm.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Surely, there are individual technologies serving this and that purpose, and it is possible to limit their input and output as well as the conditions of their use. But these ethics are rooted in a technological thinking that has taken over, and without confronting this philosophical issue and providing a new framework, we will only pile on further ethical constrains until we confront a limit. Ethics, which is considered to be a theoretical aspect of religion (as opposed to dogma, its practical counterpart), becomes part of technology, which is to say that it is determined schematically. The philosophy of technology becomes a discipline to propose policies that maintain certain “ethics” waiting to be violated sooner or later by the state and by capital. Heidegger’s critique of the ethics of the technological world remains valid today: By this conception of the totality of the technological world, we reduce everything down to man, and at best come to the point of calling for an ethics of the technological world. Caught up in this conception, we confirm our own opinion that technology is of man’s making alone. We fail to hear the claim of Being which speaks in the essence of technology.97 97. Martin Heidegger, Identity and Difference, trans.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Joan Stambaugh (New York: Harper & Row, 1969), 34. Being, the Unknown, and the non-rational remain ignored when ethics, which is central to policymaking today, aims to protect the human or give rights to the non-human. However, the turn to ethics also prevents philosophy from knowing itself and from questing for other beginnings. The Unknown is like the inhuman in the human. It cannot be reduced to any formal definition of the human, be it systems theory or biology. The inhuman may appear with different names, for example, God in Christian theology, or desire in libidinal economy. Libidinal economy supplements political economy by integrating desire into it. Desire is infinite and non-rational.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  For example in Bernard Stiegler’s For a New Critique of Political Economy, he distinguishes desire (as libidinal investment, like in love and friendship) from drive (as addiction), and proposes to conceive a political economy based on the cultivation of desire, that is to say, love and capability (in the sense of Amartya Sen). We can speculate on economies based on different discourses of the non-rational in order to move away from homogenous modern consumer capitalism. This demands an imagination that goes beyond full automation and the abstract freedom promised by it. Insofar as our episteme remains modern, following what the anthropologist Philippe Descola describes as naturalism (in an opposition between nature and culture), cybernetic logic remains ineffective. Though it wants to overcome such an opposition, it may even enhance the modern episteme with its powerful unifying logic. And art, thus defined and shaped by certain schools of art history and the art market, will distance itself further and further from its revolutionary potential. But for art to respond to our epoch, it has to confront the crisis we are faced with today, in order to produce new epistemes, new sensibilities that will be able to give science and technology new directions and frameworks. An epistemic shift takes place when there is a crisis, which obliges an alteration of social, political, and aesthetic life.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  This epistemic change doesn’t have to, and maybe shouldn’t, arise entirely from the domain of the sciences. And an epistemic revolution, if it does take place, will not be a global and unified one, but fragmented. Fragmentation is also a deterritorialization that enables creations otherwise suppressed by a monotechnological  culture under the name of “Europeanization” or “modernization” to prepare “for a new earth and people that do not yet exist.” 98 It remains the task of art and philosophy to deterritorialize themselves in order to facilitate the emergence of new epistemes, instead of simply studying the aesthetics of this or that media. Maybe this is the new meaning we can give to the phrase “politicization of art” proposed by Benjamin almost a hundred years ago. Art has to lead an epistemic revolution. It is not about using augmented reality, virtual reality, and artificial intelliegence to produce new media art, but rather about how to use art to produce AR, VR, and AI. Media art, while promoting the use digital media, may have yet to supersede the conceptual frameworks that previously structured it. More than forty years ago, Lyotard’s postmodern discourse attempted to invoke a new sensibility of fear, insecurity, and uncertainty conditioned by new technologies (especially digital technologies).\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  However, the project failed because, as a European (though not necessarily a Eurocentric) philosopher, Lyotard seems to have searched for a universal logic, which, on the contrary, actually means a logic applicable only to Europe, which remains too local. Retrospectively, the postmodern is a rethinking of aesthetics and technology from the perspective of locality and recursivity. Locality, because it starts from the perspective of Europe and its history, and recursivity, because a meta-narrative (in the sense of a mechanical mold) gives way to a reflexive model based on performativity, or what Lyotard himself called paralogy, as it is captured in systems theory.99 It remains our task to further explore the concept of recursivity and recursive thinking beyond cyber­netics, and beyond the recursive vs. linear, organic vs. mechanistic oppositions. I have examined elsewhere how Lyotard’s 1985 exhibition Les Immatériaux served the purpose of awakening a postmodern sensibility (i.e., insecurity, instability, uncertainty), but did not deepen the questions it 98. Gilles Deleuze and Felix Guattari, What Is Philosophy? (New York: Columbia University Press, 1994), 108. 99. Jean-François Lyotard, The Postmodern Condition: A Report on Knowledge, trans.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Geoff Bennington and Brian Massumi (Minneapolis: University of Minnesota Press, 1984), 60.  posed.100 Today, it would seem that we are forced to respond with a different discourse. The sensibility Lyotard wanted to invoke is not only limited to the domain of art, but rather to everyday aesthetic experience. The sublime is no longer a privilege of the Dadaists or Surrealists, but omnipresent. Techno-scientific advancement is the condition of this new sensibility and its normalization. The discourse of Lyotard was not yet able to open up a diversity of responses to the question of sensibility, since the postmodern was framed as a global condition after the modern, which was its ground of departure. It is worth mentioning here Lyotard’s talk “Logos and Technē, or Telegraphy,” which he delivered at a 1986 conference at the invitation of Stiegler. In great contrast to Stiegler’s thesis on tertiary retention (or artificial memory) as the condition of all conditions, Lyotard proposed something that seems even more astonishing today. What Lyotard suggested seems rather mysterious at first glance, particularly his reference to the “clear mirror” in the writing of the thirteenth-century Japanese Buddhist Dōgen, when he asks: The whole question is this: is the passage possible, will it be possible with, or allowed by, the new mode of inscription and memoration that characterizes the new technologies?\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Do they not impose syntheses, and syntheses conceived still more intimately in the soul than any earlier technology has done?101 By “passage” he means Durcharbeiten—“to work through,” a psychoanalytic term used by Freud. The psychoanalyst helps the patient to work through his or her trauma, and it is only by doing so that the patients come to be able to live with the trauma. What does 100. See Yuk Hui, “Exhibiting and Sensibilizing: Recontextualizing ‘Les Immatériaux,’” in Theater, Garden, Bestiary: Materialist History of Exhibitions, ed. T. Garcia and V. Normand (Berlin: Sternberg, 2019). 101. Jean-François Lyotard, The Inhuman: Reflections on Time, trans. Geoffrey Bennington and Rachel Bowlby (Stanford, CA: Stanford University Press, 1991), 57.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  “working through” have to do with technology? And why is a Zen Buddhist relevant here? Lyotard’s reference to Eastern thought is not only a coincidence for us, but exotic and intriguing as well, and it becomes clearer in his further analysis of Dōgen: It makes sense to try to recall something (let’s call it something) which has not been inscribed if the inscription of this something broke the support of the writing or the memory. I am borrowing this metaphor of the mirror from one of the treatises of Dōgen’s Shōbōgenzō, the Zenki: there can be a presence that the mirror cannot reflect, but that breaks it into smithereens. A foreigner or a Chinese can come before the mirror and their image appears in it. But if what Dōgen calls “a clear mirror” faces the mirror, then “everything will break into smithereens.” And Dōgen goes on to make this clear: “Do not imagine that there is first the time in which the breaking has not yet happened, nor that there is then the time in which everything breaks. There is just the breaking.” So there is a breaking presence which is never inscribed nor memorable. It does not appear.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  It is not a forgotten inscription, it doesn’t have its place and time on the support of inscriptions, in the reflecting mirror.102 We may want to interpret what Lyotard suggests as a diversification of technology. This new technology and new material that he imagined no longer enforces the hegemony of inscription, but rather allows a Durcharbeiten like the clear mirror. We encounter here a contradiction, for technology is a form of memory, an externalized, artificial form of memory. How can it undo its function as memory? The clear mirror is first of all material, though it doesn’t simply retain, and it also facilitates a working through. On the one hand, we may say that Lyotard performs a tragist reading of Dōgen, which is rather close to Stiegler’s approach to the Gestell. On the other hand, Lyotard is also suggesting a diversification of technology that is not 102. Ibid., 55.  limited to retaining memory, and therefore goes beyond Stiegler’s theoretical framework of “tertiary retention.”103 From a more pragmatic point of view, this possibility depends on both the construction of the technological system as well as an education of sensibility.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  The education of sensibility depends on the technological system as memory, yet is also able to emplace the same technological system. Art has the potential to take up this task after religion.104 Art education is so far probably the least limited by disciplinary divisions, and therefore has the most flexibility to conceive a new program that engages with technology and thinking. This new “institutionalization” of art has yet to come, and it has to go beyond an art designed to serve “man’s spiritual needs.” But it is hard to say whether this institutionalization of art will come to pass, since conventional and conservative practices in the arts and humanities, combined with institutional lack of vision, may be even more efficient than engineering and scientific disciplines in refusing imagination and becoming reactionary. Nevertheless, we still 103. During several conversations, in both August 2014 (Epineuil, France) and January 2018 (Nijmegen, the Netherlands), Stiegler complained to me about Lyotard’s strange reference to Dōgen, something that remained painfully unresolvable in his heart for more than thirty years. I developed several interpretations of this passage throughout these years (2015–2020), I suggested that the “clear mirror” is what prevents Asian cultures from developing the concept of historicity (Geschichtlichkeit) by deconstructing Keiji Nishitani’s critique of science and technology (see The Question Concerning Technology in China); later on, I formulated it as a recursive relation between memory and non-memory, anamnesis and hypomnesis (see Recursivity and Contingency), and here I consider this passage as an invitation to reflect on technodiversity. But after all, this passage on Dōgen remains profoundly intriguing and disturbing, in ways that likely go beyond what Lyotard had in mind. 104.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  I would like to refer here to the Chinese educator Cai Yuanpei (蔡元培, 1868–1940). Cai proposed to replace religion with aesthetic education (美育代 替宗教). Cai firstly received education in traditional Chinese classics, and later went to study in Germany where he became highly influenced by the writings of Kant and Schiller. His concept of aesthetic education refers to Schiller’s letters but also to what Kant called noumenon. For Cai, aesthetic education is the passage from the phenomenon to the noumenon; from particularity to universality, from empirical to transcendental. Cai was also the first minister of education right after the 1911 Revolution, president of Peking University (1916–1923); among many other things, he was also the founding president of the Academia Sinica, as well as the founder of the China Academy of Art in Hangzhou in 1928.  have to prepare for its arrival by providing a “ground” to think the relation between art, philosophy, and technology today. In this book, I have shown the necessity of articulating the varieties of experience of art and their cosmotechnical natures as a preliminary step; preliminary in the sense that it returns to some basic questions concerning art, as preparation for epistemic revolutions to take off before the falling of dusk. An epistemic revolution is not something we can invent from without.\n"}
{"prompt":"Art and Cosmotechnics ->","completion":"  Rather, it is always already local and historical. Art can address certain aspects of the universal, but one cannot invent a universal aesthetics, which can only exist as a philosophical postulate or a marketing slogan of the culture industry. The truth of art is that there is no formal truth per se, yet to commit to truth is to unveil those truths that are closed off or remain hidden in a desolate time. This exercise on art and cosmo­technics is fundamentally an invitation to reflect on the other possibilities of technology and philosophy.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  WHAT IS IT LIKE TO BE A BAT?\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  CONSCIOUSNESS is what makes the mind-body problem really intractable. Perhaps that is why current discussions  of the problem give it little attention or get it obviously wrong. The recent wave of reductionist euphoria has produced several analyses of mental phenomena and mental concepts designed to  explain the possibility of some variety of materialism, psychophysical identification, or reduction.' But the problems dealt with are  those common to this type of reduction and other types, and what makes the mind-body problem unique, and unlike the water-H20 problem or the Turing machine-IBM machine problem or the lightning-electrical discharge problem or the gene-DNA problem  or the oak tree-hydrocarbon problem, is ignored. Every reductionist has his favorite analogy from modern  science. It is most unlikely that any of these unrelated examples  of successful reduction will shed light on the relation of mind to brain. But philosophers share the general human weakness for explanations of what is incomprehensible in terms suited for  what is familiar and well understood, though entirely different. This has led to the acceptance of implausible accounts of the mental largely because they would permit familiar kinds of reduction.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  I shall try to explain why the usual examples do not  1 Examples are J. J. C. Smart, Philosophy and Scientific Realism (London,  i963); David K. Lewis, \"An Argument for the Identity Theory,\" Journal of Philosophy, LXIII (i966), reprinted with addenda in David M. Rosenthal,  Materialism & the Mind-Body Problem (Englewood Cliffs, N. J., I971); Hilary Putnam, \"Psychological Predicates\" in Capitan and Merrill, Art, Mind, &  Religion (Pittsburgh, i967), reprinted in Rosenthal, op. cit., as \"The Nature of Mental States\"; D. M. Armstrong, A Materialist Theory of the Mind (London, i968); D. C. Dennett, Content and Consciousness (London, I969). I have expressed earlier doubts in \"Armstrong on the Mind,\" Philosophical Review,  LXXIX (1970), 394-403; \"Brain Bisection and the Unity of Consciousness,\"  Synthese, 22 (I97I); and a review of Dennett, Journal of Philosophy, LXIX (1972). See also Saul Kripke, \"Naming and Necessity\" in Davidson and  Harman, Semantics of Natural Language (Dordrecht, I972), esp. pp. 334-342; and M. T. Thornton, \"Ostensive Terms and Materialism,\" The Monist, 56 (1972). help us to understand the relation between mind and body-  why, indeed, we have at present no conception of what an explanation of the physical nature of a mental phenomenon would be. Without consciousness the mind-body problem would be much less interesting.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  With consciousness it seems hopeless. The most  important and characteristic feature of conscious mental phenomena is very poorly understood. Most reductionist theories do not even try to explain it. And careful examination will show that no currently available concept of reduction is applicable to it. Perhaps a new theoretical form can be devised for the purpose,  but such a solution, if it exists, lies in the distant intellectual future. Conscious experience is a widespread phenomenon. It occurs at many levels of animal life, though we cannot be sure of its presence in the simpler organisms, and it is very difficult to say in general what provides evidence of it. (Some extremists have  been prepared to deny it even of mammals other than man.)\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  No doubt it occurs in countless forms totally unimaginable to us, on other planets in other solar systems throughout the universe. But no matter how the form may vary, the fact that an organism has conscious experience at all means, basically, that there is something it is like to be that organism. There may be further implications about the form of the experience; there may even (though I  doubt it) be implications about the behavior of the organism. But fundamentally an organism has conscious mental states if and  only if there is something that it is like to be that organism-  something it is like for the organism. We may call this the subjective character of experience. It is not captured by any of the familiar, recently devised reductive  analyses of the mental, for all of them are logically compatible with its absence. It is not analyzable in terms of any explanatory system of functional states, or intentional states, since these could  be ascribed to robots or automata that behaved like people though they experienced nothing.2 It is not analyzable in terms of the causal role of experiences in relation to typical human behavior2 Perhaps there could not actually be such robots. Perhaps anything complex enough to behave like a person would have experiences.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  But that, if true, is a fact which cannot be discovered merely by analyzing the concept of experience. for similar reasonsA I do not deny that conscious mental states and events cause behavior, nor that they may be given functional. characterizations. I deny only that this kind of thing exhausts their analysis. Any reductionist program has to to be based on an analysis of what is to be reduced. If the analysis leaves something  out, the problem will be falsely posed. It is useless to base the defense of materialism on any analysis of mental phenomena that. fails to deal explicitly with their subjective character.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  For there  is no reason to suppose that a reduction which seems plausible when no attempt is made to account for consciousness can be extended to include consciousness. Without some idea, therefore  of what the subjective character of experience is, we cannot; know what is required of a physicalist theory. While an account of the physical basis of mind must explain many things, this appears to be the most difficult. It is impossible  to exclude the phenomenological features of experience from a, reduction in the same way that one excludes the phenomenal features of an ordinary substance from a physical or chemical reduction of it-namely, by explaining them as effects on the minds of human observers.4 If physicalism is to be defended, the phenomenological features must themselves be given a physical account. But when we examine their subjective character it: seems that such a result is impossible. The reason is that every subjective phenomenon is essentially connected with a single point of view, and it seems inevitable that an objective, physical theory will abandon that point of view. Let me first try to state the issue somewhat more fully than by  referring to the relation between the subjective and the objec, tive, or between the pour-soi and the en-soi. This is far from easy.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  Facts about what it is like to be an X are very peculiar, so peculiar  that some may be inclined to doubt their reality, or the signifi. cance of claims about them. To illustrate the connection between 3 It is not equivalent to that about which we are incorrigible, both because we are not incorrigible about experience and because experience is present in animals lacking language and thought, who have no beliefs at all about their  experiences. 4Cf. Richard Rorty, \"Mind-Body Identity, Privacy, and Categories,\" The  Review of Metaphysics, XIX (i965), esp. 37-38.  subjectivity and a point of view, and to make evident the importance of subjective features, it will help to explore the matter in relation to an example that brings out clearly the divergence between the two types of conception, subjective and objective. I assume we all believe that bats have experience. After all, they are mammals, and there is no more doubt that they have experience than that mice or pigeons or whales have experience.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  I have chosen bats instead of wasps or flounders because if one travels too far down the phylogenetic tree, people gradually shed their faith that there is experience there at all. Bats, although more closely related to us than those other species, nevertheless present a range of activity and a sensory apparatus so different from ours that the problem I want to pose is exceptionally vivid (though it certainly could be raised with other species). Even without the benefit of philosophical reflection, anyone who has spent some time in an enclosed space with an excited bat knows what it is to encounter a fundamentally alien form of life. I have said that the essence of the belief that bats have experience is that there is something that it is like to be a bat. Now  we know that most bats (the microchiroptera, to be precise) perceive the external world primarily by sonar, or echolocation,  detecting the reflections, from objects within range, of their own rapid, subtly modulated, high-frequency shrieks. Their brains are  designed to correlate the outgoing impulses with the subsequent echoes, and the information thus acquired enables bats to make  precise discriminations of distance, size, shape, motion, and texture comparable to those we make by vision. But bat sonar, though clearly a form of perception, is not similar in its operation to any sense that we possess, and there is no reason to suppose that it is subjectively like anything we can experience or imagine. This appears to create difficulties for the notion of what it is like to be a bat.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  We must consider whether any method will permit  us to extrapolate to the inner life of the bat from our own case,5 and if not, what alternative methods there may be for understanding the notion. 5 By \"our own case\" I do not mean just \"my own case,\" but rather the mentalistic ideas that we apply unproblematically to ourselves and other human beings. Our own experience provides the basic material for our imagination, whose range is therefore limited. It will not help to try to imagine that one has webbing on one's arms, which enables one to fly around at dusk and dawn catching insects in one's  mouth; that one has very poor vision, and perceives the surrounding world by a system of reflected high-frequency sound signals; and that one spends the day hanging upside down by one's feet in an attic. In so far as I can imagine this (which is not  very far), it tells me only what it would be like for me to behave as a bat behaves. But that is not the question. I want to know what it is like for a bat to be a bat. Yet if I try to imagine this, I am restricted to the resources of my own mind, and those resources are inadequate to the task.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  I cannot perform it either by  imagining additions to my present experience, or by imagining  segments gradually subtracted from it, or by imagining some combination of additions, subtractions, and modifications. To the extent that I could look and behave like a wasp or a bat without changing my fundamental structure, my experiences  would not be anything like the experiences of those animals. On the other hand, it is doubtful that any meaning can be attached  to the supposition that I should possess the internal neurophysiological constitution of a bat. Even if I could by gradual degrees  be transformed into a bat, nothing in my present constitution enables me to imagine what the experiences of such a future  stage of myself thus metamorphosed would be like. The best evidence would come from the experiences of bats, if we only knew what they were like. So if extrapolation from our own case is involved in the idea of what it is like to be a bat, the extrapolation must be incompletable. We cannot form more than a schematic conception of what  it is like. For example, we may ascribe general types of experience on the basis of the animal's structure and behavior.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  Thus we describe bat sonar as a form of three-dimensional forward per-  ception; we believe that bats feel some versions of pain, fear, hunger, and lust, and that they have other, more familiar types  of perception besides sonar. But we believe that these experiences also have in each case a specific subjective character, which it is  beyond our ability to conceive. And if there is conscious life else-  where in the universe, it is likely that some of it will not be describable even in the most general experiential terms available to us.6 (The problem is not confined to exotic cases, however, for it exists between one person and another. The subjective character of the experience of a person deaf and blind from birth is not accessible to me, for example, nor presumably is mine to him. This does not prevent us each from believing that the other's experience has such a subjective character.) If anyone is inclined to deny that we can believe in the existence of facts like this whose exact nature we cannot possibly conceive, he should reflect that in contemplating the bats we are in much the same position that intelligent bats or Martians7 would occupy if they tried to form a conception of what it was like to be us. The structure of their own minds might make it impossible for them to succeed, but we know they would be wrong to conclude that there is not anything precise that it is like to be us: that only certain general types of mental state could be ,ascribed to us (perhaps perception and appetite would be concepts common to us both; perhaps not). We know they would be wrong to draw such a skeptical conclusion because we know what it is like to be us.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  And we know that while it includes an enormous amount of variation and complexity, and while we do not possess the vocabulary to describe it adequately, its subjective charater is highly specific, and in some respects describable in terms that can be understood only by creatures like us. The fact that we cannot expect ever to accommodate in our language a detailed description of Martian or bat phenomenology should not lead us to dismiss as meaningless the claim that bats and Martians have  experiences fully comparable in richness of detail to our own. It would be fine if someone were to develop concepts and a theory that enabled us to think about those things; but such an understanding may be permanently denied to us by the limits of our nature. And to deny the reality or logical significance of what  6 Therefore the analogical form of the English expression \"what it is like\" is misleading. It does not mean \"what (in our experience) it resembles,\" but rather \"how it is for the subject himself.\" Any intelligent extraterrestrial beings totally different from us. we can never describe or understand is the crudest form of cogni-  tive dissonance. This brings us to the edge of a topic that requires much more  discussion than I can give it here: namely, the relation between facts on the one hand and conceptual schemes or systems of repre-  sentation on the other.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  My realism about the subjective domain in all its forms implies a belief in the existence of facts beyond the  reach of human concepts. Certainly it is possible for a human being to believe that there are facts which humans never will  possess the requisite concepts to represent or comprehend. Indeed, it would be foolish to doubt this, given the finiteness of humanity's expectations. After all, there would have been transfinite numbers  even if everyone had been wiped out by the Black Death before Cantor discovered them. But one might also believe that there are facts which could not ever be represented or comprehended by  human beings, even if the species lasted forever-simply because our structure does not permit us to operate with concepts of the requisite type. This impossibility might even be observed by  other beings, but it is not clear that the existence of such beings, or the possibility of their existence, is a precondition of the significance of the hypothesis that there are humanly inaccessible facts. (After all, the nature of beings with access to humanly inaccessible facts is presumably itself a humanly inaccessible  fact.) Reflection on what it is like to be a bat seems to lead us, therefore, to the conclusion that there are facts that do not consist in the truth of propositions expressible in a human language.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  We  can be compelled to recognize the existence of such facts without being able to state or comprehend them. I shall not pursue this subject, however. Its bearing on the topic before us (namely, the mind-body problem) is that it enables  us to make a general observation about the subjective character  of experience. Whatever may be the status of facts about what it is like to be a human being, or a bat, or a Martian, these appear  to be facts that embody a particular point of view. I am not adverting here to the alleged privacy of experience to its possessor. The point of view in question is not one accessible only to a single individual. Rather it is a type. It is often  possible to take up a point of view other than one's own, so the  comprehension of such facts is not limited to one's own case.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  There is a sense in which phenomenological facts are perfectly objective: one person can know or say of another what the quality of the other's experience is. They are subjective, however, in the sense that even this objective ascription of experience is possible only for someone sufficiently similar to the object of ascription to be able to adopt his point of view-to understand the ascription in the first person as well as in the third, so to speak. The more different from oneself the other experiencer is, the less success one can expect with this enterprise. In our own case we occupy the relevant point of view, but we will have as much difficulty understanding our own experience properly if we approach it from another point of view as we would if we tried to understand the experience of another species without taking up its point of view.8  This bears directly on the mind-body problem. For if the facts of experience-facts about what it is like for the experiencing  organism-are accessible only from one point of view, then it is a mystery how the true character of experiences could be revealed in the physical operation of that organism. The latter is a domain of objective facts par excellence-the kind that can be observed and understood from many points of view and by individuals with differing perceptual systems. There are no comparable imaginative obstacles to the acquisition of knowledge about bat neurophysiol-  ogy by human scientists, and intelligent bats or Martians might learn more about the human brain than we ever will. 8 It may be easier than I suppose to transcend inter-species barriers with the aid of the imagination.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  For example, blind people are able to detect objects near them by a form of sonar, using vocal clicks or taps of a cane. Perhaps if one knew what that was like, one could by extension imagine roughly what it was like to possess the much more refined sonar of a bat. The distance between oneself and other persons and other species can fall anywhere on a continuum. Even for other persons the understanding of what it is like to be them is only  partial, and when one moves to species very different from oneself, a lesser degree of partial understanding may still be available. The imagination is remarkably flexible. My point, however, is not that we cannot know what it is like to be a bat. I am not raising that epistemological problem. My point is rather that even to form a conception of what it is like to be a bat (and a fortiori to know what it is like to be a bat) one must take up the bat's point of view.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  If one can take it up roughly, or partially, then one's conception will also be  rough or partial. Or so it seems in our present state of understanding. This is not by itself an argument against reduction. A Martian scientist with no understanding of visual perception could under-  stand the rainbow, or lightning, or clouds as physical phenomena,  though he would never be able to understand the human concepts of rainbow, lightning, or cloud, or the place these things  occupy in our phenomenal world. The objective nature of the things picked out by these concepts could be apprehended by him because, although the concepts themselves are connected  with a particular point of view and a particular visual phenomenology, the things apprehended from that point of view are not:  they are observable from the point of view but external to it; hence they can be comprehended from other points of view also,  either by the same organisms or by others. Lightning has an objective character that is not exhausted by its visual appearance, and this can be investigated by a Martian without vision. To be precise, it has a more objective character than is revealed in its visual appearance. In speaking of the move from subjective to  objective characterization, I wish to remain noncommittal about the existence of an end point, the completely objective intrinsic nature of the thing, which one might or might not be able to  reach.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  It may be more accurate to think of objectivity as a direc-  tion in which the understanding can travel. And in understanding a phenomenon like lightning, it is legitimate to go as far away as one can from a strictly human viewpoint.9 In the case of experience, on the other hand, the connection with a particular point of view seems much closer. It is difficult to understand what could be meant by the objective character of an experience, apart from the particular point of view from which its subject apprehends it. After all, what would be left of what it  was like to be a bat if one removed the viewpoint of the bat? But if experience does not have, in addition to its subjective character, an objective nature that can be apprehended from  I The problem I am going to raise can therefore be posed even if the distinc-  tion between more subjective and more objective descriptions or viewpoints can itself be made only within a larger human point of view. I do not accept this kind of conceptual relativism, but it need not be refuted to make the point that psychophysical reduction cannot be accommodated by the subjective-toobjective model familiar from other cases. many different points of view, then how can it be supposed that a Martian investigating my brain might be observing physical processes which were my mental processes (as he might observe physical processes which were bolts of lightning), only from a different point of view? How, for that matter, could a human physiologist observe them from another point of view?1o  We appear to be faced with a general difficulty about psychophysical reduction.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  In other areas the process of reduction is a move in the direction of greater objectivity, toward a more accurate view of the real nature of things. This is accomplished by reducing our dependence on individual or species-specific points of view toward the object of investigation. We describe it not in terms of the impressions it makes on our senses, but in terms of its more general effects and of properties detectable by means other than the human senses. The less it depends on a specifically human viewpoint, the more objective is our description. It is  possible to follow this path because although the concepts and ideas we employ in thinking about the external world are initially  applied from a point of view that involves our perceptual apparatus, they are used by us to refer to things beyond themselvestoward which we have the phenomenal point of view. Therefore  we can abandon it in favor of another, and still be thinking about the same things. Experience itself, however, does not seem to fit the pattern. The idea of moving from appearance to reality seems to make no  sense here.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  What is the analogue in this case to pursuing a more objective understanding of the same phenomena by abandoning the initial subjective viewpoint toward them in favor of another  that is more objective but concerns the same thing? Certainly it appears unlikely that we will get closer to the real nature of human  experience by leaving behind the particularity of our human point of view and striving for a description in terms accessible to beings that could not imagine what it was like to be us. If the subjective character of experience is fully comprehensible only from one 10 The problem is not just that when I look at the \"Mona Lisa,\" my visual experience has a certain quality, no trace of which is to be found by someone looking into my brain. For even if he did observe there a tiny image of the  \"Mona Lisa,\" he would have no reason to identify it with the experience. point of view, then any shift to greater objectivity -that is, less attachment to a specific viewpoint-does not take us nearer to the real nature of the phenomenon: it takes us farther away from it. In a sense, the seeds of this objection to the reducibility of  experience are already detectable in successful cases of reduction;  for in discovering sound to be, in reality, a wave phenomenon in air or other media, we leave behind one viewpoint to take up another, and the auditory, human or animal viewpoint that we leave behind remains unreduced. Members of radically different  species may both understand the same physical events in objective terms, and this does not require that they understand the phenomenal forms in which those events appear to the senses of members of the other species. Thus it is a condition of their refer-  ring to a common reality that their more particular viewpoints are not part of the common reality that they both apprehend.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  The reduction can succeed only if the species-specific viewpoint is omitted from what is to be reduced. But while we are right to leave this point of view aside in  seeking a fuller understanding of the external world, we cannot ignore it permanently, since it is the essence of the internal world, and not merely a point of view on it. Most of the neobehaviorism  of recent philosophical psychology results from the effort to sub-  stitute an objective concept of mind for the real thing, in order to have nothing left over which cannot be reduced. If we acknowledge that a physical theory of mind must account for the sub-  jective character of experience, we must admit that no presently available conception gives us a clue how this could be done. The problem is unique. If mental processes are indeed physical  processes, then there is something it is like, intrinsically,\" to 11 The relation would therefore not be a contingent one, like that of a cause and its distinct effect. It would be necessarily true that a certain physical state felt a certain way. Saul Kripke (op.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  cit.) argues that causal behaviorist and  related analyses of the mental fail because they construe, e.g., \"pain\" as a merely contingent name of pains. The subjective character of an experience (\"its immediate phenomenological quality\" Kripke calls it [p. 340]) is the  essential property left out by such analyses, and the one in virtue of which it is, necessarily, the experience it is. My view is closely related to his. Like Kripke, I find the hypothesis that a certain brain state should necessarily have  undergo certain physical processes. What it is for such a thing to be the case remains a mystery. What moral should be drawn from these reflections, and what  should be done next? It would be a mistake to conclude that physicalism must be false.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  Nothing is proved by the inadequacy  of physicalist hypotheses that assume a faulty objective analysis of mind. It would be truer to say that physicalism is a position we cannot understand because we do not at present have any  conception of how it might be true. Perhaps it will be thought unreasonable to require such a conception as a condition of  understanding. After all, it might be said, the meaning of physicalism is clear enough: mental states are states of the body;  mental events are physical events. We do not know which physical states and events they are, but that should not prevent us from  a certain subjective character incomprehensible without further explanation. No such explanation emerges from theories which view the mind-brain relation as contingent, but perhaps there are other alternatives, not yet discovered. A theory that explained how the mind-brain relation was necessary would still leave us with Kripke's problem of explaining why it nevertheless appears contingent. That difficulty seems to me surmountable, in the following way.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  We may imagine something by representing it to ourselves either perceptually, sympathetically, or symbolically. I shall not try to say how symbolic imagina-  tion works, but part of what happens in the other two cases is this. To imagine something perceptually, we put ourselves in a conscious state resembling the state we would be in if we perceived it. To imagine something sympathetically, we put ourselves in a conscious state resembling the thing itself. (This method can be used only to imagine mental events and states-our own or another's.) When we try to imagine a mental state occurring without its associated brain state, we first sympathetically imagine the occurrence of the mental state: that is, we put ourselves into a state that resembles it mentally. At the same time, we attempt to perceptually imagine the non-occurrence of the associated physical state, by putting ourselves into another state unconnected with the first: one resembling that which we would be in if we perceived the nonoccurrence of the physical state. Where the imagination of physical features is perceptual and the imagination of mental features is sympathetic, it appears to us that we can imagine any experience occurring without its associated brain state, and vice versa.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  The relation between them will appear contingent even if it is necessary, because of the independence of the disparate types of imagination. (Solipsism, incidentally, results if one misinterprets sympathetic imagination as if it worked like perceptual imagination: it then seems impossible to imagine any experience that is not one's own.) understanding the hypothesis. What could be clearer than the words \"is\" and \"are\"? But I believe it is precisely this apparent clarity of the word \"is\" that is deceptive. Usually, when we are told that X is r we  know how it is supposed to be true, but that depends on a conceptual or theoretical background and is not conveyed by the \"is\" alone. We know how both \"X\" and \"r\" refer, and the kinds of things to which they refer, and we have a rough idea how the two referential paths might converge on a single thing, be it an object, a person, a process, an event, or whatever. But when the two terms of the identification are very disparate it may not be so clear how it could be true.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  We may not have even a rough idea of how the two referential paths could converge, or what kind of things they might converge on, and a theoretical framework may have to be supplied to enable us to understand this. Without the framework, an air of mysticism surrounds the identification. This explains the magical flavor of popular presentations of  fundamental scientific discoveries, given out as propositions to which one must subscribe without really understanding them. For example, people are now told at an early age that all matter is really energy. But despite the fact that they know what \"is\" means, most of them never form a conception of what makes this  claim true, because they lack the theoretical background. At the present time the status of physicalism is similar to that  which the hypothesis that matter is energy would have had if uttered by a pre-Socratic philosopher. We do not have the beginnings of a conception of how it might be true. In order to understand the hypothesis that a mental event is a physical event,  we require more than an understanding of the word \"is.\"\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  The idea of how a mental and a physical term might refer to the same  thing is lacking, and the usual analogies with theoretical identification in other fields fail to supply it. They fail because if we  construe the reference of mental terms to physical events on the usual model, we either get a reappearance of separate subjective  events as the effects through which mental reference to physical events is secured, or else we get a false account of how mental terms refer (for example, a causal behaviorist one). Strangely enough, we may have evidence for the truth of some-  thing we cannot really understand. Suppose a caterpillar is locked in a sterile safe by someone unfamiliar with insect metamorphosis, and weeks later the safe is reopened, revealing a butterfly. If the  person knows that the safe has been shut the whole time, he has reason to believe that the butterfly is or was once the caterpillar, without having any idea in what sense this might be so. (One  possibility is that the caterpillar contained a tiny winged parasite that devoured it and grew into the butterfly.) It is conceivable that we are in such a position with regard to  physicalism. Donald Davidson has argued that if mental events have physical causes and effects, they must have physical descriptions.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  He holds that we have reason to believe this even though we do not-and in fact could not-have a general psychophysical theory.12 His argument applies to intentional mental events, but I think we also have some reason to believe that sensations are physical processes, without being in a position to understand how. Davidson's position is that certain physical events have irreducibly mental properties, and perhaps some view describable in this way is correct. But nothing of which we can now form a conception corresponds to it; nor have we any idea what a theory would be like that enabled us to conceive of it.13 Very little work has been done on the basic question (from which mention of the brain can be entirely omitted) whether any sense can be made of experiences' having an objective character at all. Does it make sense, in other words, to ask what my experi-  ences are really like, as opposed to how they appear to me? We cannot genuinely understand the hypothesis that their nature is captured in a physical description unless we understand the more fundamental idea that they have an objective nature (or that objective processes can have a subjective nature).14 12 See \"Mental Events\" in Foster and Swanson, Experience and Theory (Amherst, 1970); though I don't understand the argument against psychophysical laws. 13 Similar remarks apply to my paper \"Physicalism,\" Philosophical Review  LXXIV (i965), 339-356, reprinted with postscript in John O'Connor, Modern Materialism (New York, I969). 14 This question also lies at the heart of the problem of other minds, whose close connection with the mind-body problem is often overlooked. If one understood how subjective experience could have an objective nature, one would understand the existence of subjects other than oneself.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  I should like to close with a speculative proposal. It may be possible to approach the gap between subjective and objective from another direction. Setting aside temporarily the relation between the mind and the brain, we can pursue a more objective understanding of the mental in its own right. At present we are  completely unequipped to think about the subjective character of experience without relying on the imagination-without taking up the point of view of the experiential subject. This should be regarded as a challenge to form new concepts and devise a new method-an objective phenomenology not dependent on empathy or the imagination. Though presumably it would not cap-  ture everything, its goal would be to describe, at least in part, the subjective character of experiences in a form comprehensible to  beings incapable of having those experiences. We would have to develop such a phenomenology to describe the sonar experiences of bats; but it would also be possible to begin with humans. One might try, for example, to develop concepts that could be used to explain to a person blind from birth what it was like to see.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  One would reach a blank wall eventually,  but it should be possible to devise a method of expressing in objective terms much more than we can at present, and with much greater precision. The loose intermodal analogies-for example, \"Red is like the sound of a trumpet\"-which crop up in discussions of this subject are of little use. That should be clear to anyone who has both heard a trumpet and seen red. But struc-  tural features of perception might be more accessible to objective description, even though something would be left out. And concepts alternative to those we learn in the first person may enable us to arrive at a kind of understanding even of our own experience which is denied us by the very ease of description and lack of distance that subjective concepts afford. Apart from its own interest, a phenomenology that is in this sense objective may permit questions about the physical15 basis 15 I have not defined the term \"physical.\" Obviously it does not apply just to what can be described by the concepts of contemporary physics, since we expect further developments. Some may think there is nothing to prevent mental phenomena from eventually being recognized as physical in their own right.\n"}
{"prompt":"What is it Like to be a bat? ->","completion":"  But whatever else may be said of the physical, it has to be objective. So  of experience to assume a more intelligible form. Aspects of sub-  jective experience that admitted this kind of objective description might be better candidates for objective explanations of a more familiar sort. But whether or not this guess is correct, it seems unlikely that any physical theory of mind can be contemplated until more thought has been given to the general problem of sub-  jective and objective. Otherwise we cannot even pose the mindbody problem without sidestepping it.16 THOMAS NAGEL Princeton University  if our idea of the physical ever expands to include mental phenomena, it will have to assign them an objective character-whether or not this is done by analyzing them in terms of other phenomena already regarded as physical. It seems to me more likely, however, that mental-physical relations will eventually be expressed in a theory whose fundamental terms cannot be placed clearly in either category. 16 I have read versions of this paper to a number of audiences, and am indebted to many people for their comments.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  14 Data Visualization and the Subject of Political Aesthetics Sean Cubitt  Contemporary digital formalism emerges in the concept of ‘beautiful data’ (Halpern 2015), the visualization of information in intrinsically pleasing patterns which may or may not also provide useful ways of using the data.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Data visualization is now both big business and a ubiquitous feature of digital arts and the aesthetic of the ‘postdigital’. It is also a privileged vehicle for the mimetic impulse to re-enter contemporary aesthetic practice, and it is this new formalist mimesis that forms the focus of this chapter. Mimesis in Adorno refers to the residue of the pre-artistic, mythic engagement of humans in nature. Since Kant, the concept of the aesthetic has ridden on the back of a prior concept of human freedom, a freedom which the species gained, through the use of reason, in extricating itself from the tyranny of the laws of nature. For Adorno, ‘the dialectic of rationality and mimesis’ has always been ‘immanent to art’ (Adorno 1997, 54). Never entirely free of its mythic beginnings in the immersion of humans in an undifferentiated nature, art is indebted to the methods and techniques it acquires from rationality, while distinguishing itself from reason in the form of techno-science or logical thought. Such reason is instrumental in that it has a goal beyond itself: that goal is not simply to escape from natural contingency but to dominate it. Instrumental reason, however, masks both its dependence on natural law and its goal of mastery, while art avows both in order to divest itself of any claim to domination over what is external to it, namely nature and, as we will shortly see, in data visualization also human culture.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Nature, it is a truism of eco-critical thought, is a social construct. It environs because it has been environmentalized. Art’s association with mimesis derives, in Adorno’s aesthetics, from a sense of profound loss accompanying the externalization of nature; yet this desire to reunite with the mythic is irreconcilable with the rationality of technique. The consequent ineluctable failure of art to reconcile these irreconcilables is, however, the source of its dialectical energy. Because it strains and fails to reconcile them, it can point,  beyond itself, and beyond both mimesis and rationality, to their future reconciliation as potential future. What we feel as a sense of nostalgia in front of a beautiful landscape or landscape ﬁlm can be reversed to become an orientation towards a future reconciliation of an already freed but unhappy subjectivity with a currently enslaved but potentially liberated nature. Traditional aesthetic mimesis takes as its raw material not nature, either as construct or as being-in-itself (a being which Adorno believes it has yet to achieve), but natural beauty, the appearance of nature to humans. This is what Rodowick and others refer to as the indexical relation of what he calls reality and the speciﬁc technical apparatus of analogue photography and cinematography, accusing digital media of abandoning that physical connection in favour of a numerical encoding, in this instance of light as electronic signal, rather than as encoded silver halides.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  The precise depth and nature of the technical distinction between photo-mechanical and optoelectronic media will not detain us here, but it is important to note that the indexical relation is anthropocentric, in that it rests on appearances that match the human sensorium. Data visualization eschews, ostensibly, this anthropocentrism. It takes as its raw material not the appearing of natural beauty but data that derives from it. In place of a posited unity between human vision and the world, data visualizations presume that nature and reason are already imaginarily reconciled by the commensurality of number in both. Data visualization in practice either offers itself as celebratory of this reconciliation, or proposes itself as meta-representation (Berry 2014, 145–146). In the former case, the celebration of a reconciled humanity and nature masks the real domination of the latter by the former on which the very existence of the technical substrate of information technologies depends: circuits of material and energy extraction and reﬁning, manufacture, distribution and eventual disposal, which entail great human and environmental suffering. To this extent the celebratory path is sentimental, enjoying without incurring responsibility for what it enjoys. Alternatively, metarepresentational data visualization may present itself from the outset as a representation of an earlier representation, of the world in numerical form.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  One feature of this path is that all data, regardless of its source, appears already reconciled, since data about nature and data about culture (as in Lev Manovich’s ‘cultural analytics’) are indistinguishable to an algorithm analysing them (see Manovich and Tifentale 2015, this volume). This indifference is, however, not reconciliation, since it introduces a new aporia to replace that between nature and reason. Critical data visualization arts occupy a third position, carefully marking the abstraction of data from its raw appearing as natural beauty or human behaviour, in order to explore the techniques through which that abstraction is perpetrated. But, in order to become second-order representation, as Plato argued of the simulacral image of a bed, all visualization relinquishes its grasp on the mimetic in  order to secure its autonomy as art. In such autonomy lies the seed of a new, unreconciled relation between data and its visualization. Adorno speaks of mimesis as the ‘nonconceptual afﬁnity of the subjectively produced with its unposited other’ (1997, 54). Nature, as other, even though historically produced, confronts the subject as wholly given, without generation. The artwork produced was necessarily, in the period when Adorno was writing, produced by a subject.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Mimesis rested, therefore, on an afﬁnity between what the subject was capable of making and the alienated other that confronted it. By ‘non-conceptual’ we should understand both that this afﬁnity is not rational, and therefore cannot be the vehicle of reconciliation, and that it operates below the threshold of consciousness. In data visualization this unconscious afﬁnity is replaced with a relation to data as alien environment. The speciﬁc form taken by this replacement for afﬁnity is transcription, a process which is also non-conceptual in the sense that, once the concept is encoded, it runs without conscious engagement on the part of its conceptualizer (concept designer). In this instance, the concept itself becomes unconscious, replacing myth, the regressive immersion in nature, with the immersion and dissolution of the self in and as data, which now occupies the position of the unposited, a feature marked in the etymology of the word (datum = ‘given’). Data, however, is always non-identical. What is and its appearing, whether as natural beauty or as numerical presentation, are not the same; what gives and what is given are not identical. At the level of the indexical, the arithmetical phrase ‘one metre 60 centimetres’ is not identical with an object measured as having those dimensions, since there are many other entities with the same measurement, so that the measurement and its referent are clearly distinct.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Moreover, the numerical expression taken as raw material for data visualization is never raw (Gitelman 2013) but always systemic (the metric as a scale, the comparative metrics of matrices and databases). The raw material of data visualization is, then, not data but databases. It has two techniques: algorithmic, which is of the same mathematical substance, and expression, which would at least appear to be different because it is visual. As visual, the expression of data in visualizations is of a different substance, and therefore in some respects, like the rationalist formal properties of mimetic art, betrays the truth of its material. However, for this to be the case, we would have to posit that the database as content possesses truth in the way that natural beauty, as nature’s appearing, bears the truth of nature. The dataset is, however, always contingent on the unposited circumstances from which it has been extrapolated, whether the unposited nature or the nominally unposited second nature of human cultures. It would, therefore, appear that what is rendered untrue or betrayed is not the data but the expression itself. What is at stake in this expression is not the artist’s or designer’s intention, because, as we have seen, that has been usurped by the algorithm which  enacts the design concept unconsciously.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  It is instead the sujet supposé savoir, the subject posited as the ‘for whom’ of the process. This position, equivalent to that of the spectator in classical accounts of perspective, is in data visualization posited only in order to be betrayed. This is possible because data visualization on the one hand extracts a subject, while on the other it eradicates objectivity. There is clearly a subject of data visualization, especially interactives, since they are addressed to a user who, in the manner familiar from essays on perspective (Panofsky 1991; Damisch 1994) and on critical cartography (e.g. Curry 1998), is constructed from the embodied senses of the spectator. The erasure of this subject is not only a ﬁxture of the scientiﬁc method but was adopted by artistic movements and the formalist critics associated with them: Russian constructivism and Shklovsky; De Stijl and the Bauhaus; abstract expressionism and Greenberg. Each employed techniques for the eradication of the artist as subject, or, in the case of the New York school, learning from Ernst’s exile in the city during World War II, providing the self with an escape from itself through the operations of chance.1 The history of design since Adolf Loos is likewise committed to the eradication of the artistic self and its expression. By addressing only the data extracted from the unposited, whether that is nature or human populations, that is, by positing the unposited as data sources, data visualization undertakes to erase the negativity of nature and human nature under the traces of their performance.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Treating the data as ‘raw’ in deﬁance of the knowledge that it is already cooked, data visualization attempts to reconcile the objective world with reason, over-writing the non-identical with the mensurate, so that it can become commensurate with a subject which, in taking mensuration as measure of all things, subsumes itself into the regime of measure and is thus no longer external to what it measures. In this way, data visualization achieves the reconciliation of subject and object, but at the expense of the actuality of both. To this extent it is ﬁctive, in the sense that a ﬁction produces, from its ﬁctive diegesis, both the ﬁctional ﬁgure of the narrator and the ﬁctional function of the reader-in-the-text (Iser 1978). Where data visualizations achieve the reconciliation of the technique of algorithmic mediation with the construction of the unposited as data, instead of telling us about the world, this tells us instead about the technical transformation of the world (Berry 2014, 145). Since the object relation, which alienates the subject from the world, has been resolved, at least ﬁctively, such visualizations also eradicate the subject corresponding to the world as object. Either this is, then, a sentimental and regressive return of the mythic as immersion in what is no longer object, or it disguises the eradication of subjectivity under the guise of the end of objectivity (see Golumbia 2015, this volume). However, it is a rather speciﬁc form of subjectivity, which appears to be eradicated in the reconciliation offered by commensuration. While subjectivity is historically imposed as individualism, alienated from the world  which itself is alienated under the names of nature and environment, and while the subject suffers this construction as loss and as schiz, nonetheless, individuality is the historically speciﬁc form of our alienation and cannot be simply wished away.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Merely to deny it is inadequate. The negation of subjectivity, rather obviously, hides, inadequately, the Master Subject who analyses the data, even if, as a gesture of conciliation, that Subject refrains from interpretation. But abjuring interpretation is itself a mimesis of objectivity. This might be phrased as the mimesis of the rational Enlightenment subject by the post-rational subject of neoliberalism, taking the place of the mimesis of nature. This ironic turn almost universally rejects the dialectic: the dialectic, however, does not reject it. Instead, it teaches us what we already know: the environment is no longer nature but the data of nature. Where nature once presented itself to the Romantic movement as natural beauty, today it presents itself as mensurated, or at least mensurable. Post-anthropocentric as it is, this presentation is not only no more nature-in-itself than its appearance as beauty; it is also not a second order of beauty, but only another appearance, one that conforms to the post-rational subject of neoliberalism as natural beauty did to the Romantic ‘I’.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Ostensibly collective, the subject of data visualization is, however, still alienated, from both the Romantic subject of beauty and the rational subject of numerical elegance, by the seizure on data rather than on phenomenological sensation. Having successfully eliminated the residue of myth in the phenomenological subject, it is left with a subject of pure mastery. But since, as in any relation of dominance, the object (data) is set over against the subject, it loses thereby the opportunity to reconcile itself by commensurality. Like Ed Dorn’s literate projector, ‘which, when a 35 mm strip is put thru it\/turns it into a Script’ (Dorn 1975, n.p. ), the project of data visualization is to uncover the Big Idea behind appearances: it is a Platonic endeavour. In order to do this, it takes over constructivist aesthetics’ problematic subordination, not of phenomenological appearance, but of every partial element of the work to the whole. The inﬂuential information designer Gyorgy Kepes (1956, 24) phrased it thus: ‘The essential vision of reality presents us not with fugitive appearances but with felt patterns of order.’ Here it is the fugitive rather than the appearances that need to be noted: pattern seeks out and ascribes signiﬁcance to the recurrent or stable, not to the unique, the transitory or, in ﬁne, the exceptional. Here the constructivist ethic, which subordinates every element of a work to its overall composition, demonstrates its readiness to sacriﬁce everything to unity; not necessarily by falsifying the data, but by altering the model until it is capable of assimilating everything to itself.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  No data point is intrinsically interesting in itself; only for what it contributes to the overall design. As neo-conceptual art has rejected retinal art in favour of the idea of art (and non-art), in such a way that its display can only ever be an ironic statement of its own defeat, so data  visualization approaches its own implosion, not only because both making and interacting with a visualization are themselves generative of more data, so reducing subjectivity to a database function, but because, having now a function, it therefore shatters the concept of art. In itself, this is not a problem. We might simply say that art, which merged as concept and practice with the Renaissance, no longer exists, its place having been taken over by a variety of textual, auditory and visual practices that no longer care for autonomy from human interests. In the case of data visualization, especially of ‘beautiful data’, the question whether such and such an instantiation is or is not art, or is, properly speaking, design, may well be redundant. Yet the aesthetic question remains: how does data visualization function, on what material, through which agency, on which subject, and to what ends? It is difﬁcult not to be reminded here of Benjamin’s strictures on Neue Sachlichkeit in ‘The Author as Producer’. Benjamin’s basic argument, that the artist has a duty to revolutionize the means of artistic production, leads him to criticize the ‘new objectivity’, especially in photography, because ‘it has succeeded in transforming even abject poverty – by apprehending it in a fashionably perfected manner – into an object of enjoyment’ (Benjamin 1999, 775), adding: ‘it has made the struggle against poverty an object of consumption’ (Benjamin 1999, 776, original emphasis).\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Examples of data visualization that undertake these same tasks are not hard to call to mind. Benjamin cites Brecht on the functionaries of such institutional and technical procedures, ‘thinking that they are in possession of an apparatus that in reality possesses them’ (777), and citing the epic theatre as a model ‘concerned less with ﬁlling the public with feelings, even seditious ones, than with alienating it, in an enduring way, through thinking, from the conditions in which it lives’ (779). This task, it can be argued, remains a capability of data visualization even in the age of its instrumentality. Data visualization fails to break with contemporary art, or to create an alternative institutional practice, because it shares with it the triumph of the concept over the ocular, where the visible remains, ﬁrst, as a token of ruptured continuity, but continuity nonetheless, with modern art; and, second, as the medium of commensurality between abstraction and phenomena. The subject of both is thus addressed simultaneously as conceptual–rational (even if post-rational) and as phenomenological, instigating a rift where there was at ﬁrst evidence of (the possibility of) reconciliation. By planting this rift at the centre of the contemporary art experience and the experience of data visualization, the problematic of the subject is not presented as reconcilable but as contingent on the mediation of the unposited. Though it recognizes as fundamental and formative the split subject of contemporary life, this move creates a subject contingent upon the data-mediated ﬂux of nature or populations, and thus a fatalistic determination of subjectivity both as the experience of the work and as an object of contemplation itself. In this sense it matches Benjamin’s critiques of Neue Sachlichkeit,  by producing a representation of the self as a condition to be consumed and enjoyed, rather than as the outcome of institutional and economic operations that might, otherwise portrayed, become objects of action.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  The neo-conceptual formalism which, by way of systems art, has become the norm of data visualization as cultural practice is indicative of another condition speciﬁc to data visualization, which is that the proximity of the work to its critics has become unbridgeable, just as their distance was unbridgeable in modernism, even for artist-critics like Pound and Olson faced with the gap between poetry and criticism. Today data visualization pre-empts the role of the critic by providing an account of itself as an integral part of the presentation. This auto-commentary, to the extent that it refuses the task of interpretation, which it defers to its viewer, creates from the proximity of work and commentary another rift within the work itself, which no longer stands free of either its raw material or its eventual interpretation. It has proved difﬁcult to devise a persuasive critique of data visualization, precisely because critique has succeeded so well that it is now integrated into new designs (for the case of geographic information systems, see Schuurman 2000). Seen from this vantage point, data visualization was always the sibling of critical analysis of statistical reason and of its visualization, accommodating potentially critical models into its generic toolset to the extent that critique was either immanent to the practice or incapable of ﬁnding a foothold in a practice already immunized against it. This, in turn, produces a more robust and efﬁcient system through rigorous enforcement of its boundaries. The more conclusive the systemization of data, the more the referent is excluded. Rather than the world, it is data which is taken as given, so that, viewed from within the system, the place of the unposited is taken by what is always already posited as given, in a form conformable to the system’s requirements.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  The signiﬁcance of that given, however, depends on the unposited ﬂux external to the system. Here the subject of data visualization is presented with ﬂux as pure actuality stripped of any potential save that which emerges from its re-creation as data; industrially as raw material prepared for exploitation, and in data arts as the contradictory position at once of domination over and of subordination to the dataset. Both master and servant of datasets that present themselves as formally given, through visualizations which demonstrate the subordination of exceptions to pattern, not least in the remodelling of pattern to include and digest exception, the harmony of all parts to the unity and truth of the system produces its subject both as contained within it, and at the same time as an instance of the unmediated and unposited ﬂux at the moment of its assimilation. This problem of inclusion and exclusion is at the heart of contemporary political thought. Rancière (1999) instigated the thought that politics should not be thought of as the process of the polity, but, instead, as being forced into existence by what it excludes from the polity: the artisans in ancient  Greece, the slaves of anti-colonial struggles, women before the Suffragettes, and today both indigenous and migrant peoples. These exclusions, which Rancière dubs those who have no part, or the ‘part of no-part’, are the dialectical drivers of politics as history. Esposito (2009) expands on this concept with the idea of the ‘impolitical’ on the principle that it is impossible to think politics from within the political. Neither anti- nor apolitical, the impolitical is a terrain butting up against the political, or a perspective on politics.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Not merely excluded, since the act of exclusion is itself political and therefore determines the excluded as political, the impolitical is, instead, a minimal distance from which alone politics reveals itself. We might see here, as Bosteels does in his analysis of Esposito’s conception of the impolitical (Bosteels 2011, 75–128), an echo of Arendt’s later adoption of the spectator rather than the actor as the subject of political truth, since, as she argues, every truth ‘unequivocally demands recognition and refuses debate to the extent that debate constitutes the very essence of political life’ (Arendt 1982, 237; see also Badiou 2005, 10–26). Action, whether discursive or material, is always already inﬂected by politics and determined by it: only the remove from politics allows its truth to emerge. This shift in (im)political thinking from the praise of action to the priority of spectacle corresponds, for example, to distrust of the revolutionary mob combined with allegiance to the pure concept of revolution. It might, then, also serve in contemporary terms a shift from horror at the exclusion of nature and human suffering from economic life, and the willed failure of politics to address it, a horror that leads almost inexorably to terrorism, towards the aesthetic. Moreover, it corresponds closely to the construction of the subject of data visualization as spectator. Bosteels engages Esposito’s impolitical thesis from the standpoint of a conception of ‘grand politics’, arguing that the concept of politics from which Esposito and others of the same persuasion commence their arguments is too limited. Esposito argues that the subject is always the subject of power, therefore politically determined, and thus incapable of acting otherwise than within the ﬁeld of the political, never from the necessary distance of the impolitical.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Instead, Bosteels argues, politics which remains at the level of changes to the polity, including that organization of social life which Esposito believes to be responsible for the determination of subjectivity, is self-restricting. What is intimated by the entry of aesthetic spectatorship into political thought is, instead, a politics ‘aimed at the totality of being, and not just at the mere administration of public affairs’ (Bosteels 2011, 126). Thus, the subject of data visualization is capable of a certain political spectatorship: a migration from politics to aesthetics, or, more speciﬁcally, an integration of aesthetics into political orientation. The most obvious reasons for this are that the subject under neoliberalism is indeed diminished, not least by its subjection to intensively as well as extensively organized regimes of perception associated with digital media in general and data  visualization in particular, whether as professional and institutional discourse with a claim to truth and mastery, as integral to 21st-century news media and their description of the world, or as art practice. Equally, it seems to be the case that data visualizations place themselves in the position of the sublime, in relation to a subjectivity which, in its economic reduction from opinion to choice, promotes awe at the overwhelming scale of spectacle rather than the open debate of taste. Thus desocialized, the subject of sublime data either succumbs to that sublimity, or strives to reduce it to beauty so that it can again become the terrain of socialization. Even seen from the oblique perspective proposed by Esposito, this move allows the subject once more to enter history, by acknowledging its historical genealogy, and therefore acknowledging both its historical necessity as actual, and its incomplete evolution as virtual. Moreover, Esposito’s attempt to remove from the thinking of politics all trace of the theological politics promoted by Schmitt (2004) implies relinquishing any sense that there might be political and secular virtues.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Duly recognizing that such virtues are themselves contingent on the situations that give them birth, frame them and make it possible to at least consider living up to them, the residual theological content of the virtue of hope, in particular, is not negated by the atheological argument, but merely repressed, along with the thought of a subject capable of either hope or action, while the capacity for previously theological categories, including both subjectivity and hope, to evolve is simply denied in philosophical logic, without the recourse to lived history which guides and constrains theory. The impolitical argument runs that ‘because power is by nature inherent in the dimension of the subject in the sense that power is precisely its verb’ (the subject is that which is able to act, the Italian inﬁnitive potere also translating as the noun ‘power’), ‘the only mode of containing power is by reducing the subject’ (Esposito, Categorie dell’impolitico cited in Bosteels 2011, 111–112). This sacriﬁce of potential, which seems so perverse in ostensibly political thought, does not, pace Esposito, open a non-subjective truth. On the contrary, it sacriﬁces one of the key features of subjectivity in the psychoanalytic and dialectical traditions: its failure to be entirely constructed according to the rules of its socialization. Like the fully actualized subject constructed in data visualization, the subject rejected by Esposito is wholly actual. Its self-identity, however, is belied by the observation made above that even the subject of data visualization is split between its roles as master\/servant of the sublime givenness of data, and its simultaneous positioning as itself an instantiation of unposited ﬂux. It is this contradiction which makes the subject more than actual, rendering it capable of evolution but, perhaps more importantly, of wonder. As aesthetic and intellectual virtue, wonder is the capacity to see and empathize with the non-identity of things, their capacity to be otherwise.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  It is, therefore, also the evidence, through the empathetic identiﬁcation with non-identity, that the self itself  is not habitual or ﬁxed but mutating, thus socialized in the broader ﬁeld of entities which extends beyond the human, and which, oddly enough, is evidenced in data visualization’s proto-utopian technique of treating ﬂux in populations and non-human ﬁelds as being of one kind. Sacriﬁcing the subject of wonder, premised on non-identity, implies the sacriﬁce of a post-theological hope, which is the irreducible ﬁdelity not to past events, as proposed by Badiou, but to the future as otherwise than the present and, more than that, otherwise than can be imagined in the present. Ultimately, then, this anti-Schmittian impolitical atheology parts company with a formative principle of political activism (consideration, the capacity to analyse and interpret the actual), both because the actual\/virtual pair are mutually dependent, such that one cannot persist without the other, and because consideration, the acknowledgement of actuality, including that of the subject in and of power and that of the humano-natural world as unposited ﬂux, implies and conditions the virtual, from which alone a practice of politics can emerge. In that process alone, rather than in a philosophical method which matches in abstraction the abstractions operated in the cyberneticization of power and wealth under contemporary conditions, the subject may be reduced as a result, rather than a condition, of historical change. Such reduction is not, however, what the dialectic of data visualization would appear to indicate. On the contrary, even as it seeks to annihilate the active agency of the subject in its approach towards sublimity, data visualization ﬁnds itself forced to posit that subject as being at once mythic, in the sense of regressively immersed in ﬂux, and at the same time as a ‘we’, all of whom putatively share the discursive truth displayed. Held as in a magnetic ﬁeld between regression to pre-individual ﬂux and assimilation into post-individual hive-mind, the subject of data visualization is unsurprisingly pushed into crisis, a form of crisis speciﬁc to the biopolitical population and ecological management of which data visualization is the privileged instrument. In becoming the object of its own contemplation, this subjectivity in crisis points towards a more radical politics in which the subject, rather than being abandoned, is potentially changed beyond the poles of its current, unstable actuality.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  However, there is a sense in which the subject is already reduced, not in its potential, but in the limits to that potential. Consideration bears upon the actual: what has been enacted. Data visualization operates on the givenness of the results of past action, rather than on either those actions or their pastness. But, as Arendt notes, what is actual, by virtue of having been done, eradicates the potential for other results to have come about. When we consider the part of no-part, historical and contemporary, we must consider also the virtual that did not come about: the hopes extinguished, the happiness relinquished, the dream unrealized, all the mountain of wreckage Benjamin’s angel sees as he looks back in horror on the progress of history. If hope is ﬁdelity to the glorious future, consideration is ﬁdelity to  the monstrous past, both in its persistence in the form of toxic dumps and ravaged landscapes, and in the vast absence left by extinctions, genocides and the casual brutality of the colonial history to which we are heirs. If data visualization fails as political aesthetic, it does so in failing to realize the melancholia that should descend on the subject of politics who takes on the burden, as Benjamin also notes, of being that posterity which all the dead generations looked towards to justify their suffering. The difference between a human being and the corporate cyborgs that now run our world is that we humans feel shame.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Some element of that shame always inhabits the nostalgia surrounding the experience of beauty, and perhaps especially that of mimesis. It is, thus, not in its acceptance of the givenness of data that data visualization fails, but in its optimism. Note 1. The odd formalist out would appear to be Greenberg, in that abstract expressionism still named itself a mode of expression. A number of the artists disappeared behind their own expressions, as in the cases of Newman and Klein. Pollock’s work, on the other hand, despite his use as poster-boy for rugged individualism, appears in Greenberg as resolutely modernist in that every gesture is accommodated into the whole. Greenberg’s concept of the all-over composition subordinated each individual element to the formal whole, thus reducing Pollock’s attempt to ﬁnd a form for his unconscious into a ﬁeld effect of the canvas as a unity, thus preparing the way for data visualization’s reduction of detail to pattern. References Adorno, Theodor W. (1997) Aesthetic Theory, ed.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Adorno, Gretel and Tiedemann, Rolf, trans. Hullot-Kentor, Robert. London: Athlone Press. Arendt, Hannah (1982) Lectures on Kant’s Political Philosophy, ed. Beiner, Ronald. Chicago: University of Chicago Press. Badiou, Alain (2005) Metapolitics, trans. Barker, Jason.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  London: Verso. Benjamin, Walter (1999) The Author as Producer, trans. Jephcott, Edmund, in Jennings, Michael W., Eiland, Howard and Smith, Gary (eds.) Selected Writings, Vol. 2, part 2, 1931–1934. Cambridge, MA: Bellknap Press\/Harvard University Press. 768–782. Berry, D. M. (2014) Critical Theory and the Digital.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  New York: Bloomsbury. Bosteels, Bruno (2011) The Actuality of Communism. London: Verso. Curry, Michael R. (1998) Digital Places: Living with Geographic Information Technologies. London: Routledge. Damisch, Hubert (1994) The Origin of Perspective, trans. Goodman, John. Cambridge, MA: MIT Press.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Esposito, Roberto (2009) Preface to Categories of the Impolitical, trans. Parsley, Connal, Diacritics 39(2): 99–115. Gitelman, Lisa (ed.) (2013) ‘Raw Data’ Is an Oxymoron. Cambridge, MA: MIT Press. Golumbia, G. (2015) Judging Like a Machine, in Berry, D. M. and Dieter, M. (eds.) Postdigital Aesthetics: Art, Computation and Design.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Basingstoke: Palgrave Macmillan, pp. 123–135. Halpern, Orit (2015) Beautiful Data: A History of Vision and Reason since 1945. Durham: Duke University Press. Iser, Wolfgang (1978) The Implied Reader: Patterns of Communication in Prose Fiction from Bunyan to Beckett. Baltimore, MD: Johns Hopkins University Press. Kepes, Gyorgy (ed.) (1956) The New Landscape in Art and Science.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Chicago: Paul Theobald and Co. Manovich, L. and Tifentale, A. (2015) Selﬁecity: Exploring Photography and SelfFashioning in Social Media, in Berry, D. M. and Dieter, M. (eds.) Postdigital Aesthetics: Art, Computation and Design. Basingstoke: Palgrave Macmillan, pp. 109–122. Panofsky, Erwin (1991 [1924–1925]) Perspective as Symbolic Form, trans. Wood, Christopher S. New York: Zone Books.\n"}
{"prompt":"Data Visualization and the Subject of Political Aesthetics ->","completion":"  Rancière, Jacques (1999) Disagreement: Politics and Philosophy, trans. Rose, Julie. Minneapolis: University of Minnesota Press. Schmitt, Carl (2004) Political Theology: Four Chapters on the Concept of Sovereignty, trans. Schwab, George D. Introduction by Strong, Tracy B. Chicago: University of Chicago Press. Schuurman, Nadine (2000) Trouble in the Heartland: GIS and Its Critics in the 1990s, Progress in Human Geography 24(4): 569–590.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  Prologue What follows is an extended commentary on a basic question: can there exist today a mysticism of the unhuman, one that has as its focus the climatological, meterological, and geological world-in-itself, and, moreover, one that does not resort to either religion or science?\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  But we must be cautious here: this does not mean a mysticism of the Earth or a mysticism of nature, and it does not mean a mysticism of the human subject or “humanity” in general, much less a mysticism of something as grotesque and vague as “life.” Still, the suggestion that something vague called mysticism still exists at all may at first seem a ridiculous, even naïve presupposition. Certainly, as a way of thinking and as a set of contemplative practices, mysticism is today no longer as relevant. This is not only due to the dominance of applied scientific thinking in our globalized, convergence cultures, but it is also due to the hegemony of orthodox, religious extremism in dictating the contours of what may or may not legitimately count as mystical experience. What follows takes place by way of a poetic text and an accompanying commentary. The poetic text is an anonymously authored poem that has been circulating on blogs, forums, and even in a number of scholarly journals.114 Because the poem was originally circulated in fragments, its total length is not known, and its rather baroque title – “The Subharmonic Murmur of Black Tentacular Voids” – appears nowhere in the body of the poem itself. In addition, it is unclear whether the poem is of contemporary origin, or whether it is a contemporary translation of an older text (though most are of the opinion it is the former). In spite of all these uncertainties, parts of the poem have been said to have – this is the claim, at least – verifiable geomantic symptoms within the metabolism and physiognomy of those who have, under unspecified conditions, recited its lines. Given this rather melodramatic image of, as one blogger put it, “geomantic shifts in the nature of thought,” the current rumors surrounding the poem are noteworthy for the way they implicitly investigate the relationship between the climatology, geopolitics, and the unhuman – and it is in this spirit that the following commentary is written.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  But in what way, exactly, should we understand the references to “darkness”? Earlier texts in the mystical tradition may here be of help. One perspective is provided by John of the Cross, the 16th century Spanish Carmelite monk, whose poem The Dark Night offers several definitions of the term darkness. The text that we currently have called The Dark Night is actually composed of four different, though interrelated, texts: a commentary known as The Ascent of Mount Carmel, a diagram made by John detailing the path of mystical perfection, a poem called “The Dark Night,” and a commentary on the poem, written by John himself. It is the latter two texts that will concern us here. It is thought that John wrote the poem and commentary of The Dark Night around 1583-1585. Its composition is thus well after John’s collaborations with Theresa of Avila in reforming monastic institutions, and also after John’s imprisonment and torture at the hands of Church authorities. The Dark Night is a text very different from the more systematic, more rigorous works in speculative mysticism.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  At its core is the problem of mystical experience – its structure, its meaning, and the possibility (or impossibility) of its communication. It is thought by modern scholars that John broke off his writing on The Ascent of Mount Carmel in order to directly deal with the problem of mystical experience in The Dark Night. The Dark Night is also unique in that, in contrast to other mystical texts, it foregrounds the relationship between the divine and the motifs of darkness and negation. However there are variations in the way that John thinks about darkness in the context of mystical experience. In the poem “The Dark Night,” the very first stanza lays out these themes: One dark night \/ Fired with love’s urgent longings \/ - Ah, the sheer grace! - \/ I went out unseen, \/ My house being now all stilled. In the commentary John notes the apparent paradox here: “Why, if it is a divine light…does one call it a dark night?” That is, how is it that the union with the divine, the pinnacle of mystical experience, one that is traditionally described in terms of beatific light, how can this experience here be described in terms of its opposite – darkness, stillness, and negation? In response John provides two definitions of darkness: “First, because of the height of divine wisdom, which exceeds the capacity of the soul.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  Second, because of the soul’s baseness and  definition is also a much more “philosophical” one, in that it takes the metaphysical split between body and spirit as being affected by divine darkness, but in two different ways. The “sensory darkness” is akin to a privation, again as per the practices of ascetic monasticism. The “spiritual darkness” also appears to be a privation, but more in terms of what John elsewhere calls “spiritual gluttony” (e.g. wanting to be the best or most extreme mystic for selfish ends; focusing on the destination and not the journey). While both of these types of darkness should, obviously, be read in the context of 16th century Christian mysticism, we can also draw from them more secular, more philosophical themes. The sensory darkness is not simply about ascetic discipline; it also concerns the ambiguous status of empiricism, and the interface between self and world that ultimately determines all experience, mystical experience included. Given a radically nonanthropomorphic concept of God, the question is this: how can something be experienced, when there is nothing to experience? In a sense, what John and other mystics call mystical experience is an oxymoron – and hence the tropes of darkness, night, and negation.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  Similarly, the spiritual darkness John discusses is not simply about the debasement or demeaning of spiritual practice (during John’s time, when both Inquisitions and Reformations were afoot, certainly there was no shortage of religious solutions in the ideological marketplace…). Spiritual darkness extends the empiricist theme of sensory darkness further. Its primary concern is with idealism. Given that there is nothing to experience, what then prevents mysticism from becoming idealism, a contemplative practice of pure thought, “purged” of all sensory and phenomenal attributes? John’s reply is that the thought of non-experience is not enough, for then one either ends up in a vicious circle (the thought of the thought of nonexperience, ad infinitum) or one then posits something beyond thought – at which point thought must itself become silent, still, and “dark.” As John notes, in a sentiment echoed by later mystical thinkers such as Kierkegaard, “for the intellect faith is also like a dark night.”117 In this second definition of darkness – as sensory and spiritual darkness – John makes a distinction that points to the limits of both experience and thought. Both types of darkness are described by John as forms of “purgation” and “accommodation” for mystical experience. experience (as per the second definition). Finally, we also have here an articulation of the paradox at the heart of mystical experience: the manifestation of that which is an absolute limit (for experience, for thought, for the human), which, in its manifesting, is also a vacuousness, a dissipation, a receding into shadows and night.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  This is the contradictory movement evoked in later thinkers such as Georges Bataille: “Here darkness is not the absence of light (or of sound) but absorption into the outside.”119 Or again, from Bataille’s mystical poem “L’Archangélique”: “the excess of darkness \/ is the flash of a star.”120 It is this paradoxical movement that John evokes when he states, “and God is also a dark night to the soul in this life.”121  figurative, philosophical sense of providing a rational basis or support for the development of a concept. But grounds are often unsteady, shifting suddenly and giving way to tectonic upheavals that could only have arisen as a result of long-term, nearly imperceptible shifts. For every ground, then, there is a corresponding state of the groundless, or better, an unground. The idea of the unground is found in the work of the German mystical philosopher Jakob Böhme. Böhme worked as a cattle herder and a shoemaker before becoming involved in mystical theology, largely as a result of his own mystical experiences (one of which included a vision of the structure of the world encapsulated in a beam of sunlight on a pewter dish). His influences are eclectic, and range from Neoplatonism to Renaissance alchemy. And, while Böhme wrote on a range of topics, from natural philosophy to the theology of the Trinity, it is in mystical works such as the Von der Gnadenwahl (On the Election of Grace, 1623) that Böhme puts forth the idea of the divine as Ungrund. The term Ungrund is difficult to translate, as it may, depending on context, mean a lack of ground, a lack of ground as itself a ground, or a superior or superlative ground.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  For the sake of simplicity let us translate Ungrund as “unground,” keeping in mind the plurality of meanings it may have. These pluralities, moreover, are implicit in Böhme’s writing. What does it mean to say, as Böhme did, that God is the Ungrund? On the one hand God is the unground because the divine is without specific attributes. The divine is “neither light, nor darkness, neither love nor wrath, evil nor good.”122 That is, it is precisely that which is neutral with respect to humancentric, moral and metaphysical attributes of the world. On the other hand, Böhme will repeatedly refer to the divine less in terms of its neutrality, and more in terms of negation – the divine as “the nothing and the all,” or simply, the divine as a “Divine Abyss.” Here God is Abyss not because the divine passes beyond the human world of morality and metaphysics, but because the divine subtracts itself, in an act of self-negation, from its very intelligibility as such. This leaves Böhme with a basic theological problem, which is how to explain the creation of the world, nature, and life if the divine is indeed to be negatively thought of as the unground  spiritus mundi). In short, Böhme’s religious commitment to a highly moralized natural philosophy ends up compromising the ambivalence in his idea of the Divine Abyss or the unground.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  That the divine as unground eventually leads to the infusion of divine creation in the innately good and moral world is both unsurprising and disappointing. This is precisely where later philosophers influenced by mystical traditions intervene. A case in point is Schopenhauer’s notion of the Will. Schopenhauer’s major work, The World as Will and Representation, takes up and modifies the Kantian distinction between the world as it appears to us (phenomena) and the world in itself (noumena). For Kant, the latter idea is philosophically necessary but can never be known as such. It is simply there to designate a some thing “out there” that we as human beings sense, study, and produce knowledge about, but which forever remains beyond the pale of human knowledge. In the Kantian framework, the world-in-itself guarantees that all thought does not reduce to idealism. For all his pessimistic grumblings, Schopenhauer remains optimistic that the world-in-itself can be known by us as human beings.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  As we noted earlier in this book, Schopenhauer grants to Kant the world as it appears to us, which he terms Vorstellung. (Representation). But this is only an index to something else, which, Schopenhauer is sure, is the world-in-itself, which he terms Wille (Will). Given that the world-in-itself can never be known without becoming the world as it appears to us, how can Schopenhauer make this claim? Certainly the term “will” here has little or nothing to do with the pedantic world of individual human wants and desires. But what then is it? Nietzsche, one of Schopenhauer’s greatest advocates and sharpest critics, notes that Schopenhauer can only make this claim by a “poetic intuition” – by definition it can never be definitively proved. In attempting to describe the Wille as the world-in-itself, Schopenhauer variously resorts to the language of force, flux, flow, process, power, and dynamism, though none of this language is used with any consistency.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  Neither does Schopenhauer opt for the sort of pantheism evidenced in the naturphilosophie of his contemporaries Schelling and Hegel (of whom he has only derisory things to say). Instead, the rhetoric Schopenhauer returns to again and again is that of the ground and the groundless. As he notes in one of his more pessimistic moments, “everything in life proclaims that earthly happiness is destined to be frustrated, or recognized  never of the will itself…”125 By evoking this phrase “sufficient reason,” Schopenhauer insinuates a world-in-itself without the moral-theological framework that still determined Böhme. A long-standing foundation of Western philosophical thought, the principle of sufficient reason states simply that everything that exists has a reason for existing. It is the very bedrock, the very ground of philosophy. In discussing the Will in terms of the principle of sufficient reason, Schopenhauer suggests that the world literally has no reason. “For in everything in nature there is something to which no ground can ever be assigned, for which no explanation is possible, and no further cause is to be sought.”126 This point is not only the limit of philosophy, assuming as it does the principle of sufficient reason; it is also the hinge upon which mystical thought operates. At such a point, all ground can only turn into the unground: “…the principle of the world’s existence is expressly a groundless one…which, as thing-in-itself, cannot be subject to the principle of sufficient reason or ground.”127 And this is where the mysticism implicit in Schopenhauer’s projects comes to the fore – except that Schopenhauer’s reference points are not only those of Christian mysticism, but those of the mystical strand in Hinduism and Buddhism as well.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  Whatever Schopenhauer’s errors in his understanding of, say, the Buddhist concept of “emptiness” (śūnyatā), what this engagement with mysticism allows him to do is to pose the problem of the unground as a problem of the human. Schopenhauer’s challenge is how to think the world-in-itself apart from any human framework, subtracted from any anthropocentric and even anthropomorphic experience. If, as both Böhme and Schopenhauer suggest, mystical thinking is intimately related to the ground, then we leave the last word to Dōgen, the Japanese monk and founder of the Sōtō School of Zen Buddhism. In or around 1227, Dōgen, returning from his enlightenment on the mountain of T’ien-t’ung, took it upon himself to write a manual for meditation, known as the Fukan zazen gi. The opening passages of the manual, which today exists in several versions, depict a master “sitting fixedly” in meditation. However, to a novice monk, the groundedness of the master’s sitting appears to stand in contrast with the ungrounded practice of meditation  “pierces the clouds.” In these clouds and on this planet – planets and clouds that are to be taken literally, and not metaphorically – Bataille notes, with some ambivalence, that “knowledge is the agreement of the organism and the environment from which it emerges.”129 We might even read into this phrase something more specific – it is the accommodation of the environment to the organism that, in the last instance, constitutes knowledge. That said, Bataille, notes that “the wager of knowledge opens two paths.” The first, perhaps unsurprisingly, is the path of instrumental knowledge. Bataille, however, nuances this as both a philosophical and mythical need for a correlation between organism and environment (which is really the accommodation of the latter to the former).\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  In one movement, the organism is this “unconditioned flight” from the possible into “the impossible that surrounds it.” Knowledge only arises, however, by virtue of the conversion of the impossible back into the possible, of the unforeseeable into the foreseeable. “Hazardous flight” is converted into “wise calculation.” While the conventional leftist reading of Bataille would see this as a critique of global industrial capitalism, this is only part of the picture. Bataille is not simply on the side of the “hazardous flight,” and he is not simply advocating for the liberation of “the impossible.” Both the hazardous flight and the wise calculation belong to the human world, and this world, as Bataille notes, is not always the same as “the planet.” The differential between them is that of the world-for-us and the world-in-itself: “human knowledge becomes the calculation of possibility when it orders the totality of things for itself…”130 This is the second path that the “wager of knowledge” opens up. Bataille can only state it negatively – yes, we have language, and concepts, and tools, and we thereby apply ourselves to the world, in the world. But the world’s deep time and tectonic shifts remind us that “it is nothing that exists in the last place: everything is in suspense, over the abyss, the ground itself is the illusion of an assurance.”131 Awareness of the fragility of the human, of the ungroundedness of the ground, the disjunction of the planet from the world, the world-in-itself from the world-for-us – all of this evokes for Bataille an experience that would in an earlier epoch be called mystical experience. Nowhere is this more evident, ironically, than in the  approach, which is “to recognize in the economy – in the production and use of wealth – a particular aspect of terrestrial activity regarded as a cosmic phenomenon.”133 As Bataille rhetorically notes, “isn’t there a need to study the system of human production and consumption within a much larger framework?”134 In as much as The Accursed Share is, in Bataille’s words, a work of political economy, it is also very much an expanded view of what terms like “economy,” “wealth,” and “production” may mean. The economy, in its conventional and narrow, human-centric meaning, in the last instance dips down into the bowels of the viscous planet, which itself can only be known on the radically non-human level of deep time. Bataille is asking for more than a simple marriage of economy and ecology, however.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  In this “cosmic” perspective, economy is also the wealth, production, and expenditure of the non-human planet: “A movement is produced on the surface of the globe that results from the circulation of energy at this point in the universe.”135 What would this unhuman, planetary economy look like? To begin with, Bataille distinguishes economy in the conventional sense from this other, cosmic economy. The former – a “restricted” economy – is near-sighted in its goals, and has the human (be it in terms of humanity generally or specific interest groups) as its final goal. The latter – a “general” economy – is the view of the deep time of the planet, its tectonic shifts and atmospheric transformations, all of which takes place indifferently to the human-bound interests of the restricted economy. In the former, we not only see rivers, but also dams, bridges, and occasions for sport. In the latter, our language falters, opting for either the poetic (the ebb and flow of life) or the scientific (fluid dynamics, laminar flow). The failure of Bataille’s project was, interestingly, to insinuate that a better appreciation of the general economy could lead to a critique and even transformation of the all-too-human restricted economy, especially when the latter is by definition indifferent to the hopes and desires of the former. The best he could do – which the later chapters of the Accursed Share detail – is to simply document the ways in which we as human beings unknowingly participate in the general economy through the ambivalent rituals of festivals, war, and luxurious squandering.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  interconnectedness of all things, human beings being only one type of thing. Bataille uses the terms “discontinuity” and “continuity,” respectively, to describe these two impressions. Sometimes we prefer to keep our distance, have some “alone time.” At other times we seek not only community or belonging, but a confirmation of this continuity at the basis of the world-initself. For Bataille, this everyday experience is the crux of the mystical dilemma: the experience of continuity (existing as world) that can only take place on the precondition of a basic discontinuity (existing in the world). Or, put another way, our fundamental discontinuity as human beings in the world has, at its greatest or most extreme limit, an overflowing negation that posits, in a contradictory way, the continuity that is also our own, non-human limit. To exist as the world, we must cease existing in the world. Bataille refers to this dilemma, with all its negations and contradictions, as divinity: “If we now picture men conceiving the world in light of an existence that is continuous…we must also perceive the need for them to attribute to it the virtues of a thing, ‘capable of acting, thinking, and speaking’ (just as men do). In this reduction to a thing, the world is given both the form of isolated individuality and creative power.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  But this personally distinct power has at the same time the divine character of an impersonal, indistinct, and immanent existence.”136 This sense – of an unhuman, indifferent, planet, can only be expressed in us as a “powerless horror.” However, “this horror is ambiguous.” Its ambiguity is that which Bataille attempts to get at in his earlier texts, such as “The Congested Planet.” It is a dilemma expressed in the contemporary discourse on climate change, between a debate over the world-for-us (e.g. how do we as human beings impact – negatively or positively – the geological status of the planet? ), and a largely unspoken, whispered query over the world-in-itself (e.g. to what degree is the planet indifferent to us as human beings, and to what degree are we indifferent to the planet?). the geological and climatological reference points it has evoked in the earlier stanzas. In particular, the concepts of depth and dormancy (the former in the sea, the latter in ice), open onto the questioning of the “autochthonic” origin of life, and in particular, human life. And it is here that the poem most forcefully opens onto the problem of mysticism that we have been elaborating throughout the commentary. But what kind of mysticism is this, which gives us only scientific description, experimental data, and taxonomic names?\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  We may, in a general sense, think of mysticism as a vague, impressionistic feeling of wonder or awe that may or may not involve drugs, and that may or may not involve nature hikes and generally blissing out. We can also think of mysticism as actually enabled by an overly optimistic, “gee-whiz” scientific instrumentality, in which the Earth is the divinely-sanctioned domain of the human, even and especially in the eleventh hour of climate change. Neither of these is what we mean by mysticism here. Whether it is of the political left or right, whether it is the affectivist-hippie mysticism or the eschatologyof-oil type of mysticism, in both cases mysticism is ostensibly a human-centric and human-oriented experience. Mysticism in these cases is always a union “for us” as human beings. Something more is gained, however, by considering mysticism in its historical context. Long considered unworthy of serious scholarship, the study of mysticism and mystical writing was largely inaugurated in the 20th century by Evelyn Underhill’s book Mysticism: A Study in the Nature and Development of Man’s Spiritual Consciousness (1911). Underhill elucidates the logic of mystical thinking, paying particular attention to mysticism as a systematic practice, as well as to the psychology of mystical experience.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  As she notes, “if we may trust the reports of the mystics…they have succeeded where all others have failed, in establishing immediate communication between the spirit of man…and that ‘only Reality,’ that immaterial and final Being, which some philosophers call the Absolute, and most theologians call God.”137 As Underhill notes, however, how this communication is established varies a great deal, from canonic statements by the Church Fathers, to anecdotes and autobiographies by spiritual laypeople, to fringe heretical insinuations of pantheism. In the West, the intermittent flowering of mysticism is often explained in terms of a historical th  understand them adequately.” John continues, noting that “nor does experience of them equip one to understand them. Those who suffer them will know what this experience is like, but they will find themselves unable to describe it.”138 Given this, it is no surprise to see many mystics positing some type of effacement or union of self and world as the resolution to the problem of suffering. In effectively bypassing the selfworld division one also bypasses all of the corporeal, spiritual, and existential suffering that is part and parcel of that division. This then places one – to the extent there is a “one” any longer – in a position to experience a further effacement or union, that between the earthly and the divine, between the natural and the supernatural. This is the benchmark of nearly every text in the speculative mysticism tradition. But there is often disagreement on exactly how this union of natural and supernatural is to be achieved, let alone described in our all-too-human language. For some, the union is described using the motif of light, a motif that has a long tradition that extends back to the mystical texts of the Church Fathers, and ultimately to Neoplatonic sources (e.g.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  the divine topologies of light and radiation in Plotinus). This “light mysticism” is also an affirmative mysticism; it asserts a positive communion with God, and it dictates the correct steps on the ladder of this ascent. But light mysticism is compromised in several respects, including a highly anthropomorphized God with which one enters into a disturbing, paternalistic embrace. If the divine – and here let us say “divine” rather than “God” to emphasize the anti-anthropomorphic tendency – is not simply a super-human but in some radical way beyond the human (or even, against the human), then it follows that any human thought of the divine can only be a horizon for thought. For other mystical thinkers, the very inconceivability of this union with the divine meant that any possible knowledge of it, and any possible description of it, could only take place by a negative means (e.g. the divine is not-X or not-Y, X and Y denoting earthly, humancentric attributes). Hence the preferred motif is not light – be it the radiation of divine Intelligences or beatific light – but instead that of darkness and night. This too has a long tradition, one that extends back to Dionysius the Areopagite, who, sometime in the 6th century, had articulated the via negativa or path of negation as the way to divine union.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  Those in this tradition often utilize several modes of discourse to talk about the divine: that of negative  to the recuperative habits of human beings to always see the world as a world-for-us. But, whether one opts for light or dark mysticism, the question that modern scholars such as Underhill return to is this, summarized in Henry Annesley’s Dark Geomancy: “unless the history of the mystics can touch and light up some part of this normal experience, take its place in the general history of the non-human, contribute something towards our understanding of non-human nature and destiny, its interest for us can never be more than remote, academic, and unreal.”139 In short, what does mysticism mean to us, in the “ordinary non-mystical”? Underhill’s response – a response that has continued to be echoed down to the present day – is that the history of mysticism “is vital for the deeper understanding of the history of humanity.”140 While Underhill’s book is an invaluable study of mysticism, I would suggest that we retain her question, while jettisoning her answer. And here we can, perhaps, see the darkness mysticism tradition in a new light, which is that of our current geopolitical imaginary of climates, tectonic plates, tropical storms, and the viscous geological sedimentation of oil fields and primordial life. In a contemporary context, one in which we are constantly reminded of the planetary (and cosmic) frailty of human beings, and reminded in ways that appear to be utterly indifferent to the “history of humanity” – floods, earthquakes, wildfires, hurricanes, water shortages, extreme temperatures, and the like – in such a context, perhaps something called mysticism has an unexpected meaning. Rudolph Otto suggests this in his examination of the ambivalent “horror of the divine” in religious and mystical experience. Such experiences, in which the human confronts, in a paradoxical state, the absolutely unhuman, can only be thought negatively. In the West, Otto argues, there have been two major modes in which this negative thought has been expressed: silence and darkness.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  To these Otto adds a third, which he finds dominant in Eastern variants of mystical experience, which he terms “emptiness and empty distances,” or the void. Here the negation of thought turns into an affirmation, but a paradoxical affirmation of “nothingness” or “emptiness.” As Otto puts it, “‘void’ is, like darkness and silence, a negation, but a negation that does away with every ‘this’ and ‘here,’ in order that the ‘wholly other’ may become actual.”141  for Nishitani it is the twofold waning of religion and science that contribute to the sense of “the nihility that one becomes aware of at the ground of the self and the world.”143 Without a foundation to give meaning and substance to the world, modern nihilism finds itself confronted with nothingness. Our response, argues Nishitani, should not be to rediscover some new ground for giving meaning to the world, be it in religious or scientific terms, and neither should we be satisfied to wallow in despair at this loss of meaning, this “abyss of nihility.” Instead, we should delve deeper into this abyss, this nothingness, which may hold within a way out of the dead end of nihilism. For Nishitani, then, the only way beyond nihilism is through nihilism. And here Nishitani borrows from the Buddhist concept of śūnyatā, conventionally translated as “nothingness” or “emptiness.” In contrast to the relative nothingness of modern nihilism, which is privative, and predicated on the absence of being (that is, an ontology), Nishitani proposes an absolute nothingness, which is purely negative and predicated on a paradoxical foundation of non-being (that is, a meontology). “Emptiness in the sense of śūnyatā is emptiness only when it empties itself even of the standpoint that represents it as some ‘thing’ that is emptiness.”144 How does one think of this strange nothingness beyond nothing, this emptiness beyond the empty? Nishitani frequently turns to planetary, climatological, and cosmic tropes in describing absolute nothingness: “… just as nihility is an abyss for anything that exists, emptiness may be said to be an abyss even for that abyss of nihility. As a valley unfathomably deep may be imagined set within an endless expanse of sky, so it is with nihility and emptiness.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  But the sky we have in mind here is more than the vault above that spreads out far and wide over the valley below. It is a cosmic sky enveloping the earth and man and the countless regions of stars that move and have their being within it.”145 In Nishitani’s interpretation of absolute nothingness (śūnyatā), that through which everything exists and subsists is not itself an existent, nor is it an existent foundation for all existents – it is nothingness, emptiness. From this follows an equally strange and enigmatic identity of all that does exist: “everyone and everything is nameless, unnameable, and unknowable…And this  horrific, in a sense – to say that the world is indifferent to us as human beings. Indeed, the core problematic in the climate change discourse is the extent to which human beings are at issue at all. On the one hand we as human beings are the problem; on the other hand at the planetary level of the Earth’s deep time, nothing could be more insignificant than the human. This is where mysticism again becomes relevant. But the differences between this contemporary mysticism and historical mysticism are all-important. If mysticism historically speaking aims for a total union of the division between self and world, then mysticism today would have to devolve upon the radical disjunction and indifference of self and world.\n"}
{"prompt":"The Subharmonic Murmur of Black Tentacular Voids ->","completion":"  If historical mysticism still had as its aim the subject’s experience, and as its highest principle that of God, then mysticism today – after the death of God – would be about the impossibility of experience, it would be about that which in shadows withdraws from any possible experience, and yet still makes its presence felt, through the periodic upheavals of weather, land, and matter. If historical mysticism is, in the last instance, theological, then mysticism today, a mysticism of the unhuman, would have to be, in the last instance, climatological. It is a kind of mysticism that can only be expressed in the dust of this planet.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  CULTURE MACHINE  CM • 2021  Generative Adversarial Copy Machines Martin Zeilinger Abstract This essay explores the redistribution of expressive agency across human artists and non-human entities that inevitably occurs when artificial intelligence (AI) becomes involved in creative processes.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  In doing so, my focus is not on a 'becomingcreative' of AI in an anthropocentric sense of the term. Rather, my central argument is as follows: if AI systems will be (or already are) capable of generating outputs that can satisfy requirements by which creativity is currently being evaluated, validated, and valorised, then there is a potential for AI to disturb prevailing aesthetic and ontological assumptions concerning anthropocentrically framed ideals of the artist figure, the work of art, and the idea of creativity as such. I will elaborate this argument by way of a close reading of Generative Adversarial Network (GAN) technology and its uses in AI art (discussing the work of Helen Sarin and Anna Ridler, among others), alongside examples of ownership claims and disputes involving GAN-style AI art. Overall, this discussion links to cultural theories of AI, relevant legal theory, and posthumanist thought. It is across these contexts that I will reframe GAN systems, even when their 'artistic' outputs can be interpreted with reference to the original creations of the singular author figure, as 'Generative Adversarial Copy Machines'. Ultimately, I want to propose that the disturbances effected by AI in artistic practices can pose a critical challenge to the integrity of cultural ownership models – specifically, intellectual property (IP)  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  evaluated, validated, and valorised, then there is also a potential for expressive AI to disturb aesthetic and ontological assumptions concerning anthropocentrically framed ideals of the artist figure, the work of art, and the idea of creativity as such. I will unpack this proposition alongside a close reading of Generative Adversarial Network (GAN) technology and its uses in AI art (touching on the work of Helen Sarin and Anna Ridler, among others), and by way of considering some examples of informal ownership disputes involving GAN-style AI art. Discussing these issues in relation to cultural theories of AI, relevant aspects of legal theory, and posthumanist thought, I will argue that even when the 'artistic' outputs of GAN systems are interpreted in explicit or implied reliance on the concept of the singular author figure, such systems are best understood as what I will call 'Generative Adversarial Copy Machines'.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Ultimately, I want to propose that the disturbances effected by AI in creative practices can pose a critical challenge to the integrity of cultural ownership models – specifically, intellectual property (IP) enclosures – that rely on an anthropocentric conceptualisation of authorship. When, in late 2018, Christie's and the French collective Obvious auctioned off the AI-generated artwork Portrait of Edmond Belamy for the sum of USD 432,500 (Christie's, 2018), some commentary from the mainstream press and art critics suggested that a new era of creative AI was in the process of emerging, and that this might have the potential to disrupt the art world as we know it (e.g., Shaw, 2018; Saltz, 2018; Pepi, 2018). Some recent publications on AI art situated at the intersections between computer science, art history, and popular science are pushing in the same direction, and elaborate effusively on a  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  include designing and setting up machine learning networks; compiling and\/or labelling the training data on which such systems are trained; deciding the criteria for 'successful' outputs; making determinations regarding the continuation\/termination of the iterative learning\/output process; and curating the resulting outputs (Bailey, 2018). Nevertheless, in the popular imagination, art projects and design tools that draw on more or less sophisticated AI technologies continue to deliver compelling examples of presumptively creative AI. As Joanna Zylinska (2020) has suggested, to ask whether AI can be creative is a misguided question. I agree with this sentiment, and would also want to emphasise the importance of exploring why and how it is that AI can so compellingly appear to be creative. Certainly, there are many examples of AI art that can be argued to satisfy existing definitions of what makes an artful creative expression – but importantly, the underlying definitions of creativity tend to be framed anthropocentrically, and many examples of 'creative AI' are interpreted in this way precisely because of how closely they approximate anthropocentric views on creativity. This has important critical implications for the aesthetic, socio-economic, and legal status of the work of art and its author.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Undoubtedly, AI is interfacing with art and creative expression in impactful ways: rapidly growing numbers of topical exhibitions indicate that AI is leaving its mark on the contemporary art world; in mainstream contexts, AI recommendation algorithms shape ever more powerfully how popular culture is produced and consumed; and AI-based rights management tools (such as YouTube's Content ID) are becoming increasingly important for controlling the circulation of digital culture, and for enforcing the intellectual property  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  creative AI as an excellent opportunity to begin rethinking what it might actually mean, in the age of AI, to create something, and by implication what it therefore now means to 'author' a creative expression. Links between creativity and authorship may appear plainly obvious, but they are critically important, since in prevailing humanist frameworks authorship also continues to be a key marker of authorial agency and ownership. When AI is posited as potentially or actually creative, this therefore entails the possibility of a disruption of conventional notions both of authorship and of conventional ownership models. AI, in this sense, can destabilise the romantic author figure, and with it the concept of the unified human agent who, by enacting the role of author, can claim ownership of their expression. It may be objected that what I am here invoking as the concept of the romantic author figure – i.e., the singular human agent whose spirited genius is assumed to make possible the creation of unique and original works of art – has long ceased to characterise current discourse on art-making and creativity. Against this objection, I would argue that even if this notion no longer has a particularly strong foothold in cultural and social theories of art, it certainly continues to structure the ways in which creative expression circulates in the broader cultural landscape, specifically through socio-economic and legal mechanisms that evaluate, validate, and valorise creative expressions by linking them to authors. This, in a nutshell, is the cultural logic of intellectual property (IP). Legal theorists and philosophers have long used the notion of the romantic author figure to critique this logic, and have argued that the notion persists because it offers convenient (though problematic)  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  The specific operational logic of GAN systems plays an important role in my attempt to begin formulating a response to these issues.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  GAN systems conventionally consist of at least two discrete neural networks, which are usually described as 'Generator' and 'Discriminator'. In the iterative training processes that characterise such systems, these discrete units can be understood to function as 'adversaries' – one produces outputs, the other compares them to a training dataset and validates or rejects them. This iterative back-and-forth is commonly described as a competition, in which the Generator attempts to convince the Discriminator that its outputs are 'real'. In the context of creative expression, this logic would characterise the Generator as a kind of art forger trying to trick an art expert into accepting a masterfully executed 'fake' as 'real', or a 'copy' as an 'original'. A more in-depth discussion of this process with a focus on GAN usage as a cultural technique will lead me to describe GANs as 'Generative Adversarial Copy Machines' – computational entities that are, as I want to argue, capable of simultaneously satisfying and contradicting romantic ideals of creativity and originality based on which GAN outputs may be interpreted as artistic. After reframing GANs in this way, ultimately I want to suggest that because the ideals undermined by GANs also underpin contemporary IP models, AI itself, when it figures into digital creative practices, can become a critical tool for developing forms of creative expression that no longer align with the cultural logic of intellectual property, but which instead turn against it. ii. AI Tools and Human Authorship  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  without her permission.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  The informal dispute between Baskin and Reben hinged on the fact that the platform did not make information concerning the provenance of platform-generated images easily available to users, with the result that it was not always clear who had created what, and who would therefore be in a position to control uses of the generated images. As I interpret the controversy, the involvement of GAN-based machine learning in the users' creative processes played a significant role in blurring the lines between human authorship and AI-generated outputs, and consequently also in leading users to have flawed assumptions regarding their own role in the process, as well as regarding moral and legal entitlements that can be derived from that role. In other words, there was a significant misunderstanding between Reben and Baskin regarding who had (or had not) authored the images in contention. At the time when the controversy flared up, Reben was running a commercial art project called amalGAN, which involved image generation on GANBreeder, a complicated imageselection process, and, finally, the commissioning of canvasbased paintings of chosen images, with that labour being outsourced to anonymous Chinese artisans (Reben, n.d.). When Reben began to promote his work on social media, several GANBreeder users recognised their own AI-generated creations in Reben's commissioned paintings. Among them was the artist and entrepreneur Danielle Baskin, who was running her own art business, GANvas, which allowed clients to order high-detail physical prints of images she created using GANBreeder (Baskin, n.d.). On social media, Baskin complained about Reben's use of some of her creations. In public exchanges and  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  Jason Bailey, whose excellent digital art blog Artnome featured an in-depth discussion of the GANBreeder controversy at the time, describes the platform as a custom interface enabling nonprogrammers to create images using Google's BigGAN project (Bailey, 2019), a state-of-the-art GAN-based image synthesis tool originally created by a team around the Google intern Andrew Brock (Brock et al., 2019).\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Simon, the aforementioned developer of GANBreeder\/ArtBreeder, envisioned the platform as a collaboration tool that allows a user not only to create their own images, but also to 'breed' new images by having the generative algorithms operating in the background of the system remix existing source images (or elements thereof), thereby rendering new 'children' images. This process also includes images previously on the platform, which means that in total, GANBreeder\/ArtBreeder represents an ecology in which usergenerated content circulates in a free-flowing and not always fully transparent fashion, and where outputs created by some users also serve as a source for the creations of others. The platform's current Terms of Use document specifies (as of late 2020) that images are owned by the user who creates them, but it also dictates that the images are subject to a Creative Commons license – specifically the CC0 license (misspelled as 'CCo' in the document), which means that no rights are reserved. This is meant to release all images generated on the platform into the public domain, where they can become available for further use (both non-commercial and commercial) by others. Based on the specified licence, Baskin's complaint cannot be considered to have had any legal merit. Technically speaking, Reben was within his rights to reuse the images. But it must be kept in mind that beyond relevant legal frameworks, authorship  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  GANBreeder\/ArtBreeder authorship questions, which can well give rise to contradictory authorship and ownership claims concerning images generated on the platform. It is therefore not surprising that as an extension of socio-economic perspectives on authorship, issues surrounding GAN-style AI art have spawned much discussion asking whether an AI system could itself be awarded copyright in its creations, and, by extension, whether and how an AI system might be technically considered as an artist in its own right (e.g., Corin, 2017; Otero & Quintais, 2018; Bailey, 2019; Vézina & Moran, 2020; Zeilinger 2021).\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  The disagreement between Reben and Baskin is indicative of interesting assumptions concerning the entitlements that are broadly assumed to result from having authored\/created an aesthetic artefact, as well as concerning the uses of aesthetic artefacts that are assumed to be permissible when no legitimate author\/creator appears to exist. Most obviously and immediately, these assumptions relate to human creative agency. In the GANBreeder controversy, Reben appears to have assumed that nobody (specifically, no human artist) had created the images that he appropriated and commodified through use of his scraper tool. In this view, not only was he unsuspecting regarding the involvement of other human users, but he also did not perceive the AI system itself as an entity capable of possessing authorial\/creative agency. Baskin, in turn, saw herself as the creator of the images. In this view, the computational system used by Baskin was also not assumed to have shared in the creative effort in a way that would impact the legal status of the resulting work, and the underlying AI system was therefore again not perceived as having any authorial agency. And yet, for both Reben and Baskin, much of the  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  anthropocentric biases. In other words, questions regarding the potential creativity and copyrightability (and thus, ownability) of AI-generated outputs tend to be approached by comparing these outputs to human-made expressions.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Because Reben could not discern a conventional (human) author, he may have concluded that the images were not 'works' in a sense that would render them as artefacts subject to the protection of intellectual property rights. If one ignores the fact that even quasi-randomly generated images can have authors with legitimate ownership claims (e.g., in the form of the humans who wrote the underlying generative algorithms), one might assume that the GANBreeder images existed in a kind of AI-fed Commons of aesthetic artefacts that don't have authors or owners in a conventional sense (for a foundational text on Commons, IP issues, and digital culture, see Boyle, 2008; also see Zeilinger, 2021 for a conceptualisation of a posthumanist cultural commons in the context of AI art). Out of such a Commons, any human artist might then appropriate its contents. By contrast, Baskin never considered the images in question to be contained in such a Commons, so that their use and subsequent framing as someone else's private intellectual property represented the main offence. But between the competing entitlement assumptions of Reben and Baskin, there is GANBreeder itself, a minimally agential expressive computational entity that could be perceived as more or less creative, but which is afforded none of the entitlements that such a designation would carry for human authors. If nothing else, the use of AI here at least helps to muddy the waters of human authorship and creativity. It can destabilise the romantic ideal of the centrality and supremacy of the unified,  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  working with pre-trained models, Sarin prefers to train the generative systems on datasets that are not only compiled by her, but which also contain source materials of her own making. As Bailey suggested, this handcrafting of training data can protect an artist against the kind of homogeneity and predictability of AI art highlighted by theorists and critics including Zylinska (2020) and Lev Manovich (2018) (see Pepi, 2020 for additional context).\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Arguably, this kind of handcrafting serves to reassert the authorial presence of a human artist in a non-human system to which 'creative' processes are, to a considerable degree, outsourced. For example, the AI artist Anna Ridler, who also frequently works with custom-made training data, has described her own approach of making and using hand-labelled datasets of artist-authored materials to train GANs as an artful process that imbues the AI-generated outputs with the creative spirit and identity of the artist herself (Ridler, 2020). Approaches such as Sarin's and Ridler's sidestep the 'arms race' in which AI artists strive for the implementation of ever more high-end tech tools, to the point where their generative systems require too much computing power and\/or data intensity for the artists to be able to train them themselves. The result, as Bailey and others have suggested, is that much of the generated imagery 'looks the same regardless of who is creating it' (Bailey, 2018b), while artist-trained systems, by implication, more closely align with familiar perspectives on the uniqueness and originality of artworks. Sarin herself adopts this view when she argues that the deliberate choice not to use BigGAN (because it cannot, in practice, be trained on artist-authored material) is a constraint that can 'boost artistic creativity and inspire the artist to produce  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  more precisely, an agential assemblage that involves both the artist and the computational system. Sarin's technical description of GAN systems (2018) is instructive for the way in which she construes the identity of the AI artist. Her description borrows heavily from the anthropocentric language of artistic mastery and describes GAN functionality as a competitive art-making game involving two active characters (the 'critic' and the 'apprentice artist') as well as a passive character (the 'master'). The goal of the apprentice artist, Sarin writes, 'is to generate pictures in the style of her master without copying the master's originals', while the goal of the critic is 'to decide whether the art he sees is by the apprentice or the master'.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  What sets her description apart from the basic description of GAN functionality that I have already offered (which involved only two entities, a generator and a discriminator) is that Sarin’s model also gives agency to the 'master', which, in this case, might be presumed to refer to the author of the training material. I would interpret Sarin's very thoughtful description as implying that the role of the (human) AI artist is somewhat distributed across all three agents she identifies. In part this is thanks to the fact that this artist figure will have authored the training data, but in part also to the fact that she serves in the role of what Sarin describes as the 'curator', i.e., the agent who can tweak functional parameters of the GAN system, and who ultimately decides what outputs to accept as finished artworks (see also Gover, 2018, who discusses the importance of this 'evaluative' moment in the context of art authorship). In the resulting overall system, what Sarin highlights most  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  again the romantic notion of the artist figure that I have invoked earlier. In order to contrast and accentuate this perspective, I now want to shift my focus to a rethinking of the internal generative processes of GAN systems, before turning my attention back to the critical implications of how GAN-style AI art is perceived to approximate human-style creativity. In doing so, I will rely mainly on a lay description of GAN functionality. While this may be well familiar to many readers, the approach is nevertheless useful for arguing in more detail how, beyond anthropocentric metaphors of spirited machine creativity and analogies between human and computational learning processes, GAN outputs can be seen to simultaneously imply and problematise the unified, singular artist\/author figure. As I want to argue, GAN technology is in this sense best understood as aligned with a progressive (posthumanist) notion of expressive agency that contradicts romantic ideals of creativity and originality, and which, in doing so, also challenges the cultural logic of intellectual property.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  As noted in the introduction, GAN refers to a type of artificial neural network that can be trained to generate novel content on the basis of large datasets. The technology has by now become relatively accessible, and its outputs feature elements of perceived unpredictability that have made GAN systems an ideal playground for practice-based speculations on AI creativity. GAN-based image synthesis in particular has been found to powerfully evoke human creativity. As already noted, GAN systems conventionally consist of two discrete computational neural networks that are described as 'Generator'  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  With no information to go on, it can be expected that the Generator's first image output will consist of randomly placed pixels, which will then be passed to the Discriminator network for validation. In contrast to the Generator, the Discriminator has access to the training dataset of pre-existing images, against which each of the Generator's image outputs is now compared. When the Discriminator rejects an output, this evaluation is communicated back to the Generator. Depending on the configuration of the system, the feedback may consist of a simple binary response (accept\/reject), but it might also include additional information, for example regarding the accuracy of colour content, compositional detail, etc. The Generator now compares the feedback received with information concerning its previous outputs, adjusts its rendering algorithms, and iterates its next output, which is again passed for evaluation to the Discriminator.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  And so on. Over a large number of iterations, which can reach into hundreds of thousands of repetition-anddifference cycles, the Generator 'learns' from its mistakes and improves its outputs, which will begin to match the training data more and more closely, until a threshold of accuracy is reached beyond which the Discriminator is no longer able to distinguish Generator outputs from the ‘real’ contents of the training dataset. At some point, the GAN system as a whole will thus be understood to have gained the ability to create, with a predictable success rate, images that sit above the threshold of what will be accepted, both by the Discriminator and by human observers, as part of the image category that makes up the training data set. Significantly, descriptions of GAN functionality often characterise the iterative back-and-forth between Generator and  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  ‘play’, ‘dreaming’, and ‘hallucinating’. I don’t think of such seeming contradictions in descriptions of GAN functionality as flaws; in my mind, they beautifully express the conceptual complexity of GAN technology in its interfacing with human creativity in artistic contexts, where the perceived\/felt redistribution of expressive agency across human and machine indeed becomes very tricky to pinpoint. Descriptions such as the ones just referenced, which tend to characterise the Generator as a kind of forger trying to trick an art historian into accepting a masterfully executed copy as a genuine, align with the logic of the ‘AI art Turing test’ as proposed by Manovich (2019). Here, the ‘creativity’ of an AI system is meant to be determined by its ability to fool a human art critic into erroneously believing that the output under consideration was created not by a machine, but by a human artist. An immediate issue with this approach is that it conceptualises creativity and artfulness in fundamentally anthropocentric terms – here, the threshold for AI creativity is the ability of artificial intelligence to pass itself off as human.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  What I derive from Manovich's version of the Turing test, as well as from Sarin's and Ridler's discussions, is that what GANbased expressive machine learning systems represent is in essence a new type of highly sophisticated copy machine. This perspective can reveal itself as both correct and potentially misleading. The logic of GAN descriptions such as those offered by Sarin and Ridler – with their emphasis on the Generator unit's efforts to imitate the contents of the training dataset to fool the Discriminator – is sound. Nevertheless, strictly speaking the Generator's outputs can never constitute copies or reproductions of anything at all, since, as discussed above, the system does not  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  unique creative works, but rather in a more progressive sense that proposes creativity as fundamentally relational, embedded, and dialogic. To turn things on their head a bit, following this logic it is entirely feasible to describe human creativity itself by borrowing from the conceptual register of technical descriptions of machine learning. In such a formulation, creativity could then be described as the astonishing ability to generate novel content by iterating derivative approximations of pre-existing materials, to the point where imitation dissolves into originality. This characterisation may stand in stark contradiction to traditional notions of creative genius, but it does resonate with the notion that influence, imitation, mimicry, and copying form the core of how human agents acquire language, learn a craft, and, indeed, create art (see Boon, 2010 for an elaborate rethinking of creativity and originality in relation to copying practices). In this sense, it would be wrong to entirely reject analogies between GAN-style machine learning and human creativity.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Ultimately, to recognise the dialogic interactions between Generator and Discriminator (or even the entanglements between Generator, Discriminator, training data, and human ‘curator’) is a good way of re-emphasising the relational dimensions of human creativity itself. This means that GAN-based generative tools and their outputs inscribe the operational logic of machine learning with a notion of creative expression that gestures towards posthumanist perspectives, and which challenges assumptions of the centrality and supremacy of a unified, singular, spirited human artist and their unique ability to create original expressions. In this view, GANs, as ‘Generative Adversarial Copy Machines’, are incompatible with any rhetoric framing of creative AI that relies on traditional,  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  AI-generated artworks of the kind discussed here are better described as a new kind of Baudrillardian simulacra, no matter how compellingly they might appear to approximate anthropocentric norms of creative originality. In other words, the iterative entanglements that frame the generative processes of a GAN system should be understood to result not in the emergence of a new type of non-human-yet-anthropocentricallymodelled creativity, but instead in the production of copies without originals. To spin this thought further: if GAN outputs (interpreted as artworks) constitute copies without originals, then GAN systems themselves (viewed as agential assemblages with expressive capabilities) resemble bodies without organs. Katherine Hayles (1999), Patricia Pisters (in Braidotti and Hlavajova, 2018) and others have pointed to the usefulness of this concept, borrowed from Antonin Artaud and popularised by Gilles Deleuze and Félix Guattari, for critiquing the Enlightenment notion of autonomous subjectivity. In the given context, I would argue that the workings of a GAN system can itself constitute just such a critique: the ‘adversarial’ interplay (or intra-action) between Generator and Discriminator may appear to project a kind of split personality, a simple competitive duality revolving around ‘copy’ and ‘original’, ‘fake’ and ‘real’; but more importantly, it also represents a decentred agential assemblage that will not and cannot conform to the conventions by which the unified agency of the singular human artist figure has traditionally been identified. A GAN system engaged in presumptively creative processes that might be interpreted as capable of yielding novel, unique,  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  humanist paradigms of creativity, originality, and authorship nor, again, with the ownership models underpinned by these.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  iv. Conclusion GAN-style AI art is perhaps not quite as dumb, boring, predictable, or meaningless as some critics are making it out to be. Yes, easy analogies between surprising, novel AI-generated outputs and the traditional notion of the unknowable creative genius of human artists are shallow and trite. But in any case, as I have tried to argue, neither the expressive 'minds' of AI systems nor the expressions they are capable of producing are ultimately consistent with the romantic model of singular expressive agency that AI art is at times meant to invoke. Instead, such systems align much more closely with the ways in which posthumanist thought conceptualises agency. Here, artificially intelligent agential assemblages emerge as decentred and relational, rather than as internally unified and singular. ‘Creativity’ now can no longer be argued to work from the blank slate of pure inspiration (as if it ever had); rather, in the ways in which it manifests in GAN outputs, it becomes another reminder that this blank slate does not, in fact, exist. Operating as relational systems with purous boundaries, GANs are embedded in cultural and technological ecologies, which they access through training data and the subjectivities inscribed in human agents who are inevitably implicated and involved in any generative process that an AI system may be capable of.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  It might be objected that a notion of relationality does not map smoothly onto AI. In their recent essay on the (im-)possibility of  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  exactly the kind of progressive view on a human creativity of the dialogic\/situated self through which critics of the romantic author figure have long sought to disrupt narrow conceptions of authorship and ownership. As Barad notes with regard to the specific example of writing, as an expressive activity this represents ‘an iterative and mutually constitutive working out, and reworking, of “book“ and “author“’ (2007: x). Applied to the use of GAN-style AI systems for creative expression, this observation can surely be read as suggesting that critical uses of AI in artistic practices are capable of achieving something more than merely an imitative approximation of human creativity. In this essay I have tried unpack the operational logic of GAN systems in digital art-making contexts to argue that even though GAN-style AI art tends to be evaluated based on how effectively it embodies the ‘external hallmarks of human creativity’ (Craig & Kerr, 2021, op. cit. ), it also structurally undermines the ontological and conceptual integrity of that idea of creativity. This can have serious critical implications not only for the aesthetic interpretation of AI art, but also for socio-economic perspectives on originality, the AI art author figure, and the legal status of the AI artwork itself.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  How would an informal ownership dispute such as the one between Reben and Baskin play out if it were more fully acknowledged how severely the decentralised agential assemblage out of which GAN creativity emerges complicates questions concerning a given output's provenance? How would the controversy surrounding Portrait of Edmond Belamy have to be reinterpreted in consideration of how the functionality of GANs structurally contradicts narrow views on anthropocentrically modelled originality, authenticity, and authorship? ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  around. I share much of the critical perspective from which the authors are speaking, and agree with their critique of the dominant corporate nexus of AI development. Nevertheless, within the much narrower context of speculating on the critical implications of GAN creativity, I want to suggest a diversion from the argument that AI is a fundamentally capitalist technology. Where the aesthetics of AI art interface with its socio-economic assimilation into property-oriented circuits of cultural ownership, could GANs not also be framed as non- or anti-capitalist – in the sense that the ‘creativity’ GANs enact destabilises traditional authorship models, yielding aesthetic artefacts that cannot easily be captured by existing intellectual property regimes? Mario Klingemann, an AI artist well known for his experiments with GAN-style machine learning (he received the Lumen Prize gold award for The Butcher’s Son in 2018), has been quoted as suggesting that humans ‘can only reinvent, make connections between things we have seen’, whereas ‘machines can create from scratch’ (Miller, 2019b). This statement beautifully encapsulates a characterisation of human creativity as dialogic, relational, and fundamentally intertextual, but it also appears to suggest that computers (as opposed to human artists) are somehow capable of autonomous tabula rasa creation.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Invoking once again the romantic fiction of original genius, this claim quite self-contradictorily suggests that while ‘humans are not original’, computational systems have the potential to become more-than-human artists in a very traditional sense. In contradiction to such a claim, my framing of GANs as ‘Generative Adversarial Copy Machines’ suggests that their outputs are derivative in novel ways; that these ways cannot be  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  References ArtBreeder. (n.d.) Artbreeder (Accessed October 14th, 2020): https:\/\/www.artbreeder.com\/. ArtBreeder. (n.d.) “Terms of Use”, Arbreeder (Accessed October 14th, 2020): https:\/\/www.artbreeder.com\/terms.pdf. Bailey, J. (2019) “Why Is AI Art Copyright So Complicated?”, Artnome (March 27th): https:\/\/www.artnome.com\/news\/2019\/3\/27\/why-is-ai-artcopyright-so-complicated. Bailey, J.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  (2018) “The AI Art At Christie'’s Is Not What You Think”, Artnome (October 14th): https:\/\/www.artnome.com\/news\/2018\/10\/13\/the-ai-art-atchristies-is-not-what-you-think. Bailey, J. (2018) “Helena Sarin: Why Bigger Isn't Always Better With GANs And AI Art”, Artnome (November 14th): https:\/\/www.artnome.com\/news\/2018\/11\/14\/helena-sarin-whybigger-isnt-always-better-with-gans-and-ai-art. Barad, K. (2007) Meeting the Universe Halfway. Durham: Duke University Press. Baskin, D. (n.d.) GANvas Studio (Accessed August 27, 2021): https:\/\/ganvas.studio\/. Bennett, J. (2009) Vibrant Matter.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Durham: Duke University Press. ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  Brock, A. et al. (2019) “Large Scale GAN Training for High Fidelity Natural Image Synthesis”, Conference Paper at ICLR 2019 (Accessed October 14th, 2020): https:\/\/arxiv.org\/pdf\/1809.11096.pdf. Christie's (2018) “Edmond de Belamy, from La Famille de Belamy”, Live Auction 16388 Prints & Multiples (Accessed October 14th, 2020): https:\/\/www.christies.com\/Lotfinder\/lot_details.aspx?sid=&intO bjectID=6166184&T=Lot&language=en. Christie's (2018b) “Is artificial intelligence set to become art's next medium?”, Photographs & Prints Auction Preview (December 12th): https:\/\/www.christies.com\/features\/Acollaboration-between-two-artists-one-human-one-a-machine9332-1.aspx. Corin, R. (2017) “Neural style transfer: can AI infringe in artistic copyright?”, Medium (September 10th): https:\/\/medium.com\/@rcorin\/neural-style-transfer-can-aiinfringe-in-artistic-copyright-e66b071e2196. Coombe, R. (1998) The Cultural Life of Intellectual Property: Authorship, Appropriation, and the Law. Durham: Duke University Press.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Craig, C. & Kerr, I. (2021) “The Death of the AI Author”, Ottawa Law Review 52. No. 1: 31-86. Drahos, P. (1996) A Philosophy of Intellectual Property. Dartmouth: Aldershot. ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  http:\/\/copyrightblog.kluweriplaw.com\/2018\/09\/25\/singularitycopyright-challenges-artificial-intelligence\/. Gover, K. (2018) Art and Authority.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Moral Rights and Meaning in Contemporary Visual Art. Oxford: Oxford University Press. Manovich, L. (2019) “Defining AI Arts: Three Proposals”, Datami (Accessed October 14, 2020): https:\/\/resonances.jrc.ec.europa.eu\/documents\/defining-ai-artsthree-proposals. Manovich, L. (2018) AI Aesthetics. Moscow: Strelka Press. Mazzone, M. & Elgammal, A. (2019) “Art, Creativity, and the Potential of Artificial Intelligence”, Arts 8. No.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  1: 26–9. Miller, A. I. (2019) The Artist in the Machine. Cambridge, MA: MIT Press. Miller, A. I. (2019b) “Can machines be more creative than humans?”, The Guardian (March 4th): https:\/\/www.theguardian.com\/technology\/2019\/mar\/04\/canmachines-be-more-creative-than-humans. Pepi, M. (2020) “How Does a Human Critique Art Made by AI”, Art in America (May 6th): https:\/\/www.artnews.com\/art-inamerica\/features\/creative-ai-art-criticism-1202686003\/. Pepi, M. (2018) “Could There Ever Be an AI Artist?”, Frieze (July 16th): https:\/\/www.frieze.com\/article\/could-there-ever-beai-artist.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  ZEILINGER • ADVERSARIAL COPY MACHINES • CM • 2021  Sarin, H. (2018) “Playing a game of GANstruction”, The Gradient (September 13th): https:\/\/thegradient.pub\/playing-agame-of-ganstruction\/. Sautoy Du, M. (2020) The Creativity Code: Art and Inovation in the Age of AI. Cambridge, MA: Harvard University Press. Shaw, A. (2018) “Who needs artists? Rise in works made by artificial intelligence raises real questions for the art market”, The Art Newspaper (October 22nd): https:\/\/www.theartnewspaper.com\/analysis\/rise-in-works-madeby-artificial-intelligence-raises-real-questions. Vénzina, B. and Moran B. (2020) “Artificial Intelligence and Creativity: Why We're Against Copyright Protection for AIGenerated Output”, Creative Commons (August 10th): https:\/\/creativecommons.org\/2020\/08\/10\/no-copyrightprotection-for-ai-generated-output\/.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  Zeilinger, M. (2021) Tactical Entanglements: AI Art, Creative Agency, and the Limits of Intellectual Property. Lüneburg: Meson Press. Zeilinger, M. (2013). “Chiptuning Intellectual Property: Digital Culture Between Creative Commons and Moral Economy”, IASPM Journal 3. No. 1: 19-34. Zylinska, J. (2020) AI Art – Machine Visions and Warped Dreams.\n"}
{"prompt":"Generative Adversarial Copy Machines ->","completion":"  London: Open Humanities Press.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  ISSN: 1524-0657 (Print) 1940-9206 (Online) Journal homepage: https:\/\/www.tandfonline.com\/loi\/hsgs20  The Other-Than-Human and the “User Unconscious” Patricia Ticineto Clough To cite this article: Patricia Ticineto Clough (2018) The Other-Than-Human and the “User Unconscious”, Studies in Gender and Sexuality, 19:1, 73-80, DOI: 10.1080\/15240657.2018.1419683 To link to this article: https:\/\/doi.org\/10.1080\/15240657.2018.1419683  Published online: 12 Feb 2018.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  Submit your article to this journal  Article views: 422  View related articles  View Crossmark data  https:\/\/doi.org\/10.1080\/15240657.2018.1419683  The Other-Than-Human and the “User Unconscious” Patricia Ticineto Clough, Ph.D The Graduate Center CUNY ABSTRACT  Expanding on psychoanalysts’ treatment of online interaction between analyst and analysand, I take up digital media and computational technologies in terms of their more general transformation of the liberal configuration of state, economy, and civil society. From this perspective, I indicate the subjectivity that is being constructed and the indeterminate potentiality (or temporality) of its unconscious, what I call the user unconscious. As recently as 2007, the distinguished psychoanalyst Sheldon Bach discussed the symptoms of adult patients who had suffered early childhood trauma in terms of the “psychic death of a digital consciousness.”1 Contrasting digital states of consciousness to analog ones, Bach focused on temporality. Whereas digital temporality, as he saw it, is “thin” without affording the capacity to experience past or future or to suture present moments into a continuity, analog temporality is “thick” where the past and the future blend together in experiencing present moments as narrative (Bach, 2016, pp. 41–53). In the years since 2007, as digital media and computational technologies have become an infrastructure of sociality, governance, and economy, Stephen Hartman, in a set of articles, would offer a depathologizing take on the digital and its affect on the body, desire, and reality as well as on the practice of psychoanalysis.2 More recently, Hartman, again addressing what he sees as the short shrift given the digital by psychoanalysts in their comparing online interactions with in-person ones, also set his focus on temporality distinguishing the analog and the digital along lines surprisingly resonant with Bach’s.3 Although Hartman’s contrast of digital and analog produces a positive yield in his formulation of “cyberobjects,” his characterization of digital and analog temporalities, like Bach’s and those often found in everyday discourse as well, may keep our thoughts about digital media too narrowly focused on human interaction (in-person vs. online) without taking up the more general implications for governance, economy, and sociality of digital media and computational technologies or what is called the “datafication of everyday life.” Before returning to the contrast of in-person versus online interaction, I first want to touch on current theoretical and philosophical analyses of those digital media and computational technologies that have made possible the expansion and multiplication of the operations and functions of social media, the internet, and technologies of surveillance and control. I want to point to the way these media and technologies are employing other-than-human actants enabling the datafication of governance, economy, and sociality and thereby, undermining the neoclassical or liberal arrangement of the separation of state,  relation to the social and the psyche. Digital media and other-than-human actants What recently has been discussed as a ontological turn to the nonhuman or other-than- human in philosophy and critical theory also has been registered in media studies as a shift from focusing on media centered on and attuned to human experience to focusing on the other-than-human or nonhuman actants operating in digital media and computational technologies, all part of what sociologist and design theorist, Benjamin Bratton, has referred to as “planetary computing.”4 While implicating humans, planetary computing more often than not is done by other-than-human actants operating in codes, protocols, interfaces, platforms, programs, and algorithms as part of the analytic capacities involved in data mining internet use, mobile tracking devices, biometric and environmental passive microsensors that continuously offer massive amounts of data that have enabled the datafication of governance, economy, and sociality.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  As Bratton sees it, planetary computing is enabling the development of “a global mega-structure,” what he calls “the Stack,” a vertical arrangement of layers of computing such as the cloud, massive addressing systems, the internet and more as well as encompassing the physical structures that enable the mega-structure to operate. The political, economic, and social power of this mega-structure, Bratton has proposed, is challenging the geopolitics of the nation-state as planetary computing functions beyond the nation even as it takes over some of the functions of the state and its work of governing a national economy for a national population. Along with challenges to the nation-state that have necessitated and enabled overbordering its borders while debordering them for the circulation of capital and labor, the challenge posed by digital media and computational technologies to civil society institutions raises questions about the individual subject faced with other-than-human actants in everyday life—questions about self-possession, identity, embodiment, privacy, and agency, including bodily based perception and consciousness. These questions are entangled with planetary computing and the ubiquity of other-than-human actants. Take the (ro)bots that send to our Facebook accounts advertising based on data that we give without our awareness and that operate algorithmically without much human input. Or Siri and Alexa that are able, in ways we are not, to engage in machine-to-machine conversations, accessing various data sets at various layers of computing in almost no time, too fast for human consciousness or bodily based perception. But as media scholar Mark B. N. Hansen has suggested, digital media and computational technologies not only operate with other-than-human actants but also these actants enable digital media and computational technologies to access, register, and disseminate data of the environment, including data about our own implication in it.5 Digital media and computational technologies feed forward this data to human consciousness and bodily based perception giving indications of the liveliness, intensities, or agencies of the world, what Hansen describes as “a self-sensing world,” a “worldly sensibility,” that is the sensory confound out of which human consciousness and bodily based perception arise (Hansen, 2013, p. 24). The ubiquity of the sensing and tracking devices supported by digital media and computational technologies is making us aware that human consciousness and bodily based perception are not fundamentals but rather accomplishments; data at every level of the global mega-structure reveals “the coexistence of multiple experiential presents— multiple, partially overlapping presents from the different time frames and scales” of other-than-  digital, the digital is initiating a profound questioning about temporality.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  If, for example, the digital is producing anxiety about the loss of narrative, as Bach’s (2016) remarks suggest, it is because the digital makes it more apparent that the function of narrative has been to provide a connection between past, present, and future that is necessitated by a human incapacity to register the actual passing of time in the present at the very many scales of being that now digital media and computational technologies can do. From the subatomic to the physical to the biological, to human consciousness and the cosmological, digital media and computational technologies access and register a indeterminacy, a gap of time or a passing of time involved in responding to innervation at each of these scales of being potentiality. This capture\/uncovering of indeterminacy taken as a liveliness, intensity, or agency at each scale of being profoundly blurs the opposition of the living and the nonliving, the organic and the nonorganic, the human and the nonhuman. This blurring is at the heart of the recent ontological turn and the turn to the nonhuman in philosophy, critical theory, and media studies. But for Hansen the indeterminacy at every scale of being is not a virtuality but rather a matter of the real potentiality of the world, the world’s causal efficacy. Drawing on the philosopher Alfred North Whitehead, while readjusting Whitehead’s philosophy to the capacities of digital media and computational technologies,6 Hansen argues that real potentiality is in “the contrast among already existing actualities … the real potentiality of the settled world at each moment of its becoming”—becoming different with each new actuality or what Whitehead refers to as “data” (Hansen, 2013, p. 204). As each datum is an “intensity,” as Whitehead would have it, it can be actualized and objectified while remaining a potentiality able to inform the genesis of another new actuality. Or as Hansen explains, “prehension” and “concrescence” as Whitehead used the terms, refers to processes by which each actuality in its becoming grasps the potentiality of the settled world as a matter of intensity or vibration, while contributing to the settled world or what Whitehead referred to as the “vibratory continuum” that is nothing else than the potentiality of the settled world (Hansen, 2013, pp.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  225-228). It follows for Whitehead, as Hansen notes, that the real potentiality of the settled world urges a change in our understanding of causality, where probabilities are to be considered “expressions of real forces, of actual propensities rather than empty statistical likelihoods” (Hansen, 2013, p. 121). Causality, rather than a matter of the “acts of discrete agents,” is a matter of tendencies drawing on the becoming continuity of worldly sensibility. As these tendencies are in the present as indeterminate probabilities, Whitehead speaks of “the causal force of the present,” or as Hansen explains it, “every actuality includes in its present feeling, its potential to impact future actualities but also … that it feels the potentiality for the future in its present and indeed as part of what constitutes the causal force of the present” (Hansen, 2013, p. 210). It is the causal force of the present, its potentialities, that are accessed, registered, and disseminated by digital media and computational technologies without, however, reduction to a simple matter of prediction. There is always an excess of data, of a worldly sensibility, which thwarts prediction and thereby meets the anxiety about the loss of narrative by offering a worldly sensibility, the many temporalities affecting us, indexing a liveliness or agency other than our own. In accessing, registering, and disseminating a worldly sensibility, digital media and computational technologies go beyond human incapacity and disconnect temporality from narrative in instigating a nonphenomenological account of temporality along with a phenomenological one. temporality beyond the limits of narrative, pointing to an expanded present rich in data, ours and that of a lively world.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  I have also turned to philosophy, critical theory, and media studies in order to return to the matter of online versus in-person interaction and the discussion of temporality that Hartman offers. Although Hartman’s efforts for some time have been to move past a mere opposition of online and in-person interaction, especially in relation to the erotics of both, in his recent elaboration of introjected cyberobjects he does provisionally distinguish between analog and digital objects to get at “the temporal idiosyncrasies of each medium,”(Hartman, 2017)the way each mediates experience (here human experience). The contrast is worth reviewing in light of the larger rethinking of temporality to which I have been pointing. For Hartman, analog objects “illuminate the present moment through the past via narrative,” while digital objects are “a current edit of a felt presence.” That is, the introjected cyberobject is in the “present, not built up, insofar as it is deployed to organize a sensation or sense impression” (still only human but one wonders).7 “As a reorganization, Hartman continues, “it has no duty to defer to previous organizations of sensation or affect” (Hartman, 2017, p. 167). Most important, with the digital a narrative sequencing is not compelled. In this sense the digital all but stands in opposition to assumptions underlying psychoanalysis generally, where “change occurs across iterations in the arc of a repeated narrative” or where introjected objects are accessed when “psychic bits are held well enough in the balance to coalesce into narrative” (p. 164). Although the process of narrative goes on in the present, what goes on in the present also is seen to index the past, real or fantasized. But, according to Hartman, the digital functions differently; it functions in the present in a way that “brokers only this moment and, in so doing affords the next” (p. 166).\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  Although the characteristics of the digital object that Hartman presents resonate with the larger discussion of temporality and the causal force of the present that I have been rehearsing, for Hartman the digital object’s characteristics rest on his understanding of the digital as having a “nonindexical relationship to a source” (Hartman, 2017, p. 165). Although unintended, Hartman brings back the worry that the digital displaces reality to which narrative is seen to be the primary if not only medium, enabling an historical movement toward truth. However, from the nonhuman perspective of philosophy, critical theory, and media studies, digital media do in fact index; they simply index at scales that are nonphenomenological prior to consciousness and bodily based perception and, only after the fact, feed forward data to consciousness and perception, a matter of the intensities of overlapping presents, agencies at all scales of being, including the human scale. The digital is brokering this moment for the next in a thick present releasing its causal force, its real tendencies toward the future. The past is not erased by the digital; it is more that the past is seen to be a matter of different presents assembled in any moment, closer to what the unconscious has been thought to be—ever in the now. The user-unconscious and originary multiplicity It would seem then that the issues about temporality raised by the digital cannot be fully grasped in the comparison of in-person versus online interactions, limited as this comparison is to the human. What seems possible if not necessary is to rethink the human in terms of digital media and  digital networks “mediate between two vastly different scales that have hitherto remained separate— the local and the global, the molecular and the molar … pierc[ing] through the ‘mass’ or community to capture individual and preindividual relations”8 In profoundly changing what has been the liberal arrangement separating state and economy, the private and public spheres, digital media are also transforming the individual’s psychology and sociality. Not only has digital media affected the operation of desire as Hartman has explored as a matter of endlessly seeking an object rather than (re)finding one, “allowing one to prioritize possibility and presence over limit and loss” (Hartman, 2017, p. 167) but in reshaping the private and public spheres, digital networks also may have made it necessary to rethink the unconscious in terms of the datafication of everyday life or the reformulation of subjectivity in recognition of the embedding of consciousness and bodily based perception in the nonphenomenological temporality that supersedes them.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  What of this subjectivity? What of its unconscious? In her work on the impact of digital media, especially on the public and the private spheres, Chun (2016) describes the subject of digital media as a YOU, the assemblage of an “I” and a profile or cloud of data traces that have more value than the I not only to economy and governance but increasingly to the sociality of users as well—as we add up numbers of friends or likes and dislikes for everything we upload or peruse the data that tells us how we slept, how many steps we have taken in a day, the levels of our blood sugar by the hour—and more. The subject actually is a subject- or user-position into which anyone or anything human or other-than-human can enter and does enter, mostly temporarily, operating in relation to programs and platforms at any one or any number of the layers of planetary computing. As various layers of computing bind polities to themselves, let us say a school, a city, a police force, an ethnic population, these polities address every actant as users, making being a user what counts. The user, human and other-than-human, coheres in relation to interfaces at various layers of the megastructure of planetary data. In light of the challenges posed by this megastructure, especially the challenges to civil society institutions, to privacy, self-possession, embodiment, and identity, Chun argues that what is most notable about the YOUs is that they are subject- or user-positions offered by networks where the separation of the private and the public spheres negotiated and maintained by civil society institutions has been displaced by the separation of “the personal and the networked.” However, as the separation of the personal and the networked is more imagined than actual, YOUs’ privacy actually has become entangled with publicity, where YOUs are prone, if not invited, to be caught in public acting privately. In doing so, YOUs, Chun (2016) proposes, become shameable, hate-able, or lovable subjects of digital networks.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  We only have to think of Trump on Twitter. But examples abound on social media where an epistemology of the closet has become an epistemology of outing, even self-outing that blames and shames the closeted victim and increasingly, the outed\/self-outing victim as well, making them either hated or loved or both. Chun gives the example of Amanda Todd, the 15-year-old who had flashed for an admirer online and then was online blackmailed—that is, the exposing photo was sent to a porn site and then to classmates and more (pp. 135–165). After becoming depressed, having panic attacks, and using drugs and alcohol, Todd committed suicide. But long before doing so, she took to YouTube and using handwritten note cards as her means of communicating, Todd gave witness to her self-abuse caused by the  unwittingly transgressing the separation of the personal and the networked or more pointedly for embracing the seeming privacy of digital media while denying the network of which every one is a part through their cloud of digital traces, their profiles. Chun argues that this habit of embracing the seeming privacy of online communication while denying the fact that it isn’t private is “the productive nonconscious of social media,” where nonconscious refers to the information that is given off or leaked without the user’s consciousness or in the user’s disavowal of the personalnetwork entanglement (p. 7). It is this nonconscious that I want to treat instead as the user unconscious in order to reformulate the unconscious in relation to the datafication of everyday life and the other-than-human agencies of digital media and computational technologies.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  To do this, I turn to Harold Searles’s proposal that the nonhuman stratum of early self-experience remains throughout life.10 Drawing on Searles, Sue Grand even has proposed that there is a nonhuman stratum to early self-experience that is an ongoing resource of attachment. As Grand puts it, “If the psyche comes into being in relation to human others, so it comes into being in relation to the nonhuman world. Perhaps we all have a nascent thing-self.”11 For Grand (2003), the “thing-self,” often linked to traumatic experience, can also be a resource for positive, cosmological, even ecstatic experience (p. 337). Even when she does treat traumatic experience, particularly in relation to sexual abuse, Grand, although proposing that abuse undoes “the psychic skin,” nonetheless refuses to equate the skinned body with sanity. Instead she points to the contingency of the body’s being there or not in relation to the “I” and goes on to speculate that “perhaps the ‘I’ feeling can contract and expand to include or exclude the body and thus is not simply derived from bodily states. Perhaps we have something like a nonhuman mental ego, contracted in relation to nonhuman ‘culture,’ and generative of both anxiety and ‘centeredness’” (p. 337). Adjusting Grand’s speculation to include a recognition of the liveliness of the other-thanhuman or thing, I propose that digital media and computational technologies may well be eliciting the human user’s thing-self, giving shape to what I am calling the user unconscious in order to point to the activity of the unconscious in relation to the collapse into the YOU, of the I and the cloud of digital traces including the data of a worldly sensibility. These, no matter how disavowed, are becoming an intimate part of the I, evoking a thing-self.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  Returning to Hartman, it might be argued that the introjected object of digital media maintains a relation to the thing-self, which, I add, opens the unconscious both to the liveliness of other-than-human actants and to the reformulation of embodiment in the YOU. That is to say, the YOU refers to that part of the I that is not humanly embodied, not so much a digital disembodiment but an other-than-human embodiment. The I is not simply humanly embodied and, as such, is not one with the organism. As digital media scholars like Hansen have argued, “Embodiment cannot be contained within the organic skin.”12 Although I am sure that the notion of a thing-self might raise discomfort and this is understandable, it also speaks to the way we are nervously treading a fine line between properly recognizing other-than-human actants on the one hand and on the other facing destructive inhuman-ness both of which, I argue, implicate digital media and computational technologies. In that they can be destructive to and instructive about our place in the world, digital media are bringing forth another “genre of humanity,” to borrow a phrase from Silvia Wynter.13 In this sense, the thing-  Rethinking the social structural Although Chun would treat the YOUs not as a “we” but as a plurality that still addresses individuals as individuals or preindividualities, she nonetheless proposes that the YOU expressed in cases like those of Amanda Todd do present the potentiality of a YOU’s desire for community. This potential, Chun has proposed, is in the reminder that the YOU offers: that the individual is a “singular\/plural,” to use the terms Chun has borrowed from Jean-Luc Nancy.14 As subjects are constituted as singular through a plurality of others, including, as I have been arguing, other-than-human others, the community that might be realized among YOUs is what Chun has described as an “originary multiplicity,” which is “not represented by society but rather through writing.”15 Again drawing on Nancy and slanting writing toward the temporalities of digital media, Chun proposes that writing is not so much about meaning but a communication seeking nothing but “an originary multiplicity,” an “inoperative” we.16 Rather than an aspect of a developmental theory, “originary multiplicity” is an ontological specification of the being of the human subject as a singular\/plural. It implies an “originary technicity” in being that has been actualized in both our data traces and the data fed-forward to consciousness and perception as their constituents, proposing that there is an indeterminacy at all scales of being that opens each of them to technological actualization. Somewhere between Hartman’s focus on, if not celebration of, online interaction and Chun’s focus on the profoundly shaming aspects of it, there is, I argue, a growing recognition of the datafication of sociality, economy, and governance and the indeterminacy thereby actualized that asks us to become more engaged with the transformation from social structure to network infrastructure.\n"}
{"prompt":"The Other-Than-Human and the “User Unconscious” ->","completion":"  Not only are desire and temporality to be rethought but also along with them the other-than human actants, agencies, intensities, or liveliness that raise questions of identity, embodiment, privacy, and agency such that race, sexuality, gender, and ability once thought to be the mark of the social structural must be rethought in terms of digital media and computational technologies and the network infrastructure they inform. Notes on contributor Patricia Ticineto Clough, Ph.D., is a professor of sociology and women’s studies. She is a practicing psychoanalyst in New York City and a member of the training committee of the Institute for Contemporary Psychotherapy. She is the author of Autoaffection: Unconscious Thought in the Age of Teletechnology and editor of The Affective Turn and forthcoming in March 2018, The User Unconscious: Affect, Media and Measure. References Bach, S. (2016). Chimeras and Other Writings: Selected Papers of Sheldon Bach. New York, NY: IPBooks. Bratton, B.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  And Another Thing: Nonanthropocentrism and Art. Punctum Books, 2016. Project MUSE. doi:10.1353\/book.76501. For additional information about this book https:\/\/muse.jhu.edu\/book\/76501  h  I. Contexts  ­ pace for Things: Art, Objects, and Speculation S Emmy Mikelson At the heart of speculative realism (SR) and objectoriented ontology (OOO) is the notion of a flat ontology. Manuel DeLanda defines a flat ontology as “one made exclusively of unique, singular individuals, differing in spatio-temporal scale but not in ontological status.” 1 Within the context of SR and OOO, these “singular individuals” are human and nonhuman, animate and inanimate. The very notion of a flat ontology is spatial in its conception. It provides a spatial metaphor for a dense and complicated field of both interaction and isolation, where things (read as human and nonhuman) are at moments drawn in relation to one another, and at moments withdrawn and discrete.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  When we speculate about the nature of a flat ontology, we are approaching space, a dark expansive space that is unhinged from clear hierarchical codes and laws. It is a space without a center, without a sovereign surveyor, and without clear boundaries. In a discussion of Georges Bataille, Anthony Vidler remarks on the “abilities of space itself to dissolve boundaries, as, that is, transgressive by nature, breaking the boundaries of all conventions, social or physical.”2 He continues by marking this space as “a bad object—abject and ignoble in its ubiquity, endlessly invading the protected realms of society and civilization with the disruptive forces of nature.”3 It is this kind of spatial dimension in which a flat ontology unfolds. In Norman Bryson’s discussion of vision and visuality in “The Gaze in the Expanded Field,” he elaborates on the work of Japanese philosopher Keiji Nishitani, who, building upon the principles of his teacher Kitarō Nishida, develops a theory that radically decenters the subject within the field of visuality: “The direction of thought that passes from Nishida to Nishitani undertakes a much more thoroughgoing displacement of the subject in the field of vision, which finds expression in a term so far largely neglected in the Western discus-  generates the safe distance between the subject and object and collapses them into the field of sūnyatā: Passing on to the field of sūnyatā the object is found to exist, not at the other end of tunnel vision, but in the total field of the universal remainder. The object opens out omnidirectionally on to the universal surround, against which it defines itself negatively and diacritically. The viewer who looks out at the object sees only one angle of the global field where the object resides, one single tangent of the 360 degrees of the circle, and of the 360 degrees in all directions of the radiating sphere of light spreading out from the object into the global envelopment.6  Through opening vision to an expansive dimensional space that accounts for a multitude of possible vantage points, the position of the subject is no longer singular and privileged. The boundaries between the subject and the object dissolve into a space in which sight lines are multiplied ad infinitum and everything exists within the lateral monumentality of vision. There is now a “dark or unmarked remainder that extends beyond the edge of peripheral vision into the space that wraps its way round behind the spectator’s head and behind the eyes.”7 It is this spatial engulfment expanding “omnidirectionally” that marks a move away from a traditional vertical ontology into one that spreads and sprawls, engendering an equivocal net in which all things shift in relation to one another.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Nishitani undercuts the anthropocentric position through an establishment of vision in the round, a vision in which a view of an object is only a “tangent” among a multitude of other possible views. An object cannot be fully knowable through a single view; it is more complex than even the sum of these views. Or perhaps, to borrow terms from object-oriented philoso-  of a thing. To further this point, I want to borrow from Wittgenstein’s discussion of aspect perception. Although this correlationist theory may seem like an unlikely place to cull from, his discussion of aspects reinforces the ways in which the seer always perceives only a slice of the seen, and therefore the act of seeing always misses the thing in sight—the thing itself resides in a blind spot. It is discrete and out of reach and never fully constituted by the viewing gaze. Wittgenstein’s extensive discussion of aspect perception entails the paradoxical condition of seeing something as changed while the thing itself remains unchanged. In his well-known example of this phenomenon, the duck-rabbit picture puzzle, one views the drawing of a rabbit head with ears in one instance or a duck head with a bill in another instance.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Wittgenstein describes this event: “I see that it has not changed; and yet I see it differently. I call this experience ‘noticing an aspect’.”8 Additionally, he begins this discussion with identifying these two “objects” of sight: The one: ‘What do you see there?’—‘I see this’ (and then a description, a drawing, a copy). The other: ‘I see a likeness between these two faces’—let the man I tell this to be seeing the faces as clearly as I do myself.9  In the latter instance, he draws attention to the relation of resemblance within the act of seeing. While elaborating on the notion of seeing, Severin Schroeder concludes that “the extent to which ‘to see’ is a verb of epistemic success, every seeing involves identification of kinds of objects or appearances, which means seeing them as similar to others of that kind.”10 The act of seeing pulls objects into a visual field of meaningful relations, or resemblances. Similarly, as Bryson points out, this field is preestablished and not defined by an authorial subject: When I learn to speak, I am inserted into systems of discourse that were there before I was, and will remain after I am gone. Similarly when I learn to see socially, that is, when I begin to articulate my retinal experience with the codes of recognition that come to me from my social milieu(s), I am inserted into systems of visual discourse that saw the world before I did, and  become objects in the field of vision. In this regard what we “see” are objects; these are the shifting aspectual details and tangents surrounding things. Seeing something as a thing, as opposed to as an object, would largely be a matter of seeing it as outside of a certain set of relevant factors.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  An object is seen as such precisely because we recognize how it works for us, while contrarily “we begin to confront the thingness of objects when they stop working for us” (emphasis added).12 The aspectual perception of seeing-as is akin to Heidegger’s ready-at-hand tool analysis insomuch that “everything we perceive, we perceive in its relevant aspects: in a picture we immediately see what it represents and respond to it accordingly, just as we always see artifacts as what they are for us, what roles they play in our lives.”13 Objects are seen as varying sets of use-values within an anthropocentric structure; objects are seen as ready-at-hand tools.14 The seer\/seen dynamic need not only relate to human\/nonhuman relations; the relation can be reversed or exclude the human altogether. One natural analogy of this is evidenced in the phenomenon of mimicry. Early twentieth-century sociologist Roger Caillois’s influential essay “Mimicry and Legendary Psychasthenia” offers a benchmark examination of the dissolution of self within space. He explores mimicry as a pathological condition of confusing one’s self with one’s environment and begins by discussing various forms of insect mimicry, such as “when the Smerinthus ocellata, which like all hawk moths conceals its hind wings when at rest, is in danger, it exposes them abruptly with their two large blue ‘eyes’ on a red background, giving the aggressor a sudden fright.”15 The moth flashes an aspect causing it to be seen as something else. But this change in perception does not change the thing that it is, any more than mistakenly recognizing someone as someone else changes who that person is. The thing remains as aspects change. Mimicry therefore causes a flattening in the figure\/ ground relationship, much as is the case in sūnyatā for Nishitani, where “the centralized subject falls apart; its boundary dissolves, together with the consoling boundary of the object.”16 What one finds in Caillois and Nishitani is the description of space that has the ability to consume and transform the generally accepted  network of crisscrossed sight lines and self-reflexive gestures. By either scrambling the signal or stripping it bare, seeing-as no longer retains its clear correlative.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Visuality becomes a dark space where things emerge from the shadows in all their thingness, or their “specific unspecificity,”17 as Bill Brown defines it in “Thing Theory.” For Caillois this destabilized relation between the individual and space is understood as the following condition: “He is similar, not similar to something, but just similar.”18  “Off with their heads!” —Lewis Carroll, Alice in Wonderland  As addressed above, in many ways the very conceptualization of subjecthood is predicated on spatial metaphors: centrality, hierarchy, scale, etc. In what follows I want to discuss specific examples of artworks that challenge the subject through this spatial dimension. In a broader view, the history of art has been a vehicle for cataloging the struggle with representing the Cartesian subject. Who is the subject? What position does the subject assume? What is the relational configuration of the subject to its surroundings? Who defines the politics behind these questions? When examining the history of the subject in art, one loosely begins with the divine subject, moving to the secular subject (read as white male), moving to the gendered and raced subject, and to the eventual question of why a subject at all?\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  The mechanisms of questioning and challenging subjecthood are varied, both subtle and overt. In the pursuit of getting beyond these hierarchical constructions that not only frame the general malaise of anthropocentrism, but also aggressively enforce gender, race, and class, art has taken the task of chipping away at the centrality of the subject so as to destabilize this system of status. Clearly not all art is concerned with the status of the subject, just as not all philosophy is invested in nonanthropocentrism. However, through discussing these examples aimed at visuality and spatiality, I want to explore those avenues of art that have consciously refuted and lambasted the  The two artists I have chosen to discuss offer different mediums, different artistic objectives, and different periods of history to consider. However, they share in their contributions a reanalysis of how the subject figures in representation and, by extension, theory. Giovanni Battista Piranesi, who was active in Italy during the Enlightenment, used the pictorial conventions of perspective and repetition in Carceri (Prisons) to create spaces that depict human figures in decidedly antihumanist ways as well as to challenge the privileged position of the enlightened viewing subject. The twentieth-century installations and photography of Japanese artist Yayoi Kusama explore the aggressive obliteration of subjecthood through repetition and patterning as she creates visual fields of slippage between subject, scene, and viewer. “Eye to a crack in a fence, he sees cranes pulling up other cranes, scaffoldings that embrace other scaffoldings, beams that prop up other beams.” —Italo Calvino, Invisible Cities  Giovanni Battista Piranesi (1720–1778) was trained as an architect and has left behind a rich body of work, including etchings and drawings, that has continued to influence architects and artists alike.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  In an early series of plates, Piranesi creates foreboding labyrinthine interiors that employ a perversion of perspective and lighting to create uncanny spaces in which the human subject’s centrality is destabilized pictorially as well as in terms of the enlightened viewer’s gaze.19 The Carceri (Prisons), which includes a second edition titled Carceri d’invenzione (Imaginary Prisons), is a series of sixteen plates begun around 1745 that depict inventive spaces that are both voluminous and claustrophobic in their spatiotemporal constructions. The prison operates as “a model for a vast interior space,”20 carefully constructed and antithetical to contemporaneous humanist sentiments. This work is of particular interest not only for its subversion of the subject\/object binary, but also for its decidedly contradictory stance to the general sentiments of the Enlightenment. Piranesi’s etchings convey  GIOVANNI BATTISTA PIRANESI Carceri Series, Plate XIV, etching on white laid paper, 1745 Current location: Cooper Hewitt, Smithsonian Design Museum  the naive belief in progress and the moral improvement of mankind.”21 Coupled with this “critical and alternative understanding of modernity,” these etchings seek to fling the viewing subject and its accompanying surrogate from a privileged place of centrality into the depths of an abysmal environment. Piranesi, an architect highly trained and adept at perspectival rendering, forcefully disrupts the logic of the Euclidean plane and creates a maze of stairways and archways where shadows and rays of light impossibly bend and stretch around corners, with no localized sense of an exterior elsewhere. In his influential book The Sphere and the Labyrinth, Manfredo Tafuri reinforces a reading of Piranesi that emphasizes “the lawless intertwining of superstructures” and “the undermining of the laws of perspective.”22 These are highly interiorized spaces— withdrawn and unique. These overwhelming interiors herald an almost limitless expansion that does not emanate from a fixed point of reference—traditionally being that of the subject. Antoine Picon states that “Piranesi’s Carceri mark the emergence of a new kind of representation of landscape,” one in which the seeming absence of the subject proclaims “human action secondary.”23 In a larger sense, Piranesi’s work plays with a constant avoidance of portraying a stable pictorial notion of subject— human or otherwise.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Tafuri has pointed out that “what at first seems to be the subject is later negated and turned into a supplemental element,”24 thereby shifting the viewer’s attention from one element to the next. In regards to the Carceri’s treatment of the human subject, its diminutive figures toil within the voluminous space with little to no identifying markers; they are general and nondescript. Scaling down the subject within its surroundings is certainly not a unique pictorial device in and of itself. It is a strategy visible throughout the history of representation; however, Piranesi’s use of this device yields effects antithetical to many canonical examples. Early Chinese landscape paintings during the Ming dynasty often depicted human figures as miniscule and dwarfed by the surrounding environment. However, the overarching Ming philosophy influencing such works, referred to as literati paintings, was the belief that the realm of the mind was elevated above that of the physical world, thereby elevating the subject. Similarly, the Western cultural belief in “Manifest  the westward traveler prevails. But what Piranesi has depicted is different.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  He provides no transcendent escape for his toilers, nor is there any revelation of their protagonism. The subject is simply refigured and cast down into the depths of an ever-expanding and engulfing environment. Piranesi’s diminutive shadow figures contain no identities and have no means of egress. Their potential agony, fear, or anxiety is not dramatized into picturesque images of human suffering. They are not the center of the dramatics. They are simply small and secondary. What one finds in the Carceri is a focus on the constructed environment in all its material details. These are images describing the space of things: ropes, chains, stairs, stone, statues, light, space, arches, shadows, pulleys, railings, columns.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Things support other things and give way to yet more things, which populate a space subtly unhinged from logic. The human subject, dwarfed by the architecture, is essentially absent as things erupt with an overwhelming presence. For Tafuri, the Carceri depicts zones in which “not men but only things become truly ‘liberated.’”26 Piranesi develops interior realms that are rich, dense, and complicated. They are spaces of the uncanny where clear and stable distinctions between subject and object, self and other dissolve into a lateral monumentality. There is no place to emerge up through the confusion; it is an unknowable volume. This is the monumentality of a flat ontology, ceaseless in all directions. It is not only through pictorial scale that the subject is unhinged from its privileged position. Piranesi’s images reach out from the picture plane to further assault the viewing subject and rattle the distanced viewer’s gaze.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  The subject is therefore assailed from within and without the picture plane. In order to confound the gaze, Piranesi collapses several perspectives into one, causing the viewer to have a dizzying experience of the work. Huyssen summarizes this experience as follows: Piranesi refused to represent homogeneous enlightened space in which above and below, inside and outside could be clearly distinguished. Instead he privileged arches and bridges, ladders and staircases, anterooms and passageways. While massive and static in their encasings, the prisons do sug-  Piranesi deliberately experimented with sight lines and chiaroscuro to pull away from classical rules of pictorial representation and create environments that swallowed up the subject and caused optical confusion in the viewer. For example, through lowering the sight line he skews a natural perspective to create one in “which the implied viewer is standing much below the architectural object,” which in turn achieves an imposing heightening of the environment.28 The manipulation of perspective “renders the architectural object larger than human scale would warrant,” thereby breaking with ideal Vitruvian proportions. In the article “Architecture from Without: Body, Logic, and Sex,” Diana Agrest makes explicit the endemic relationship between body, proportion, and architecture: “Vitruvius and Alberti point the way to the incorporation of the body as an analogue, model, or referent, elaborating a system for its transformation into a system of architectural syntactic rules, elements, and meanings.” Agrest continues by identifying the gendered understanding of these ideal proportions, which are always male. Through shifting the sight line away from a naturalist viewing point, Piranesi has shifted prominence away from the subject and toward space.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  This allows the work to further undercut the primacy of the subject. The human subject is negated through proportion and hierarchy. The subject is no longer the rule and measure. Building upon the manipulation of space and hierarchy, one finds in the Carceri a centrifugal force that continues to propel the subject from its traditional centrality. In moments, Piranesi’s dark figures are pulled deeper into the architecture as their bodies are cast in shadow. Limbs are flattened into the dark spaces of corners and passageways; silhouettes seem to dissolve into the forms of columns and banisters. These moments embody what Caillois would later address as the organism’s dissolving into its surroundings. The distinct boundaries between subject and field become blurred and permeable.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Influenced by French psychiatrist Eugène Minkowski’s analysis of “dark space” and “light space,” Caillois relates: Minkowski’s analyses are invaluable here: darkness is not the mere absence of light; there is something positive about it. While light space is eliminated by the  from spaces and devour figures where they stand. This mimetic assimilation with architecture is a retreat back into space marking a destabilization of the rational Enlightenment subject. The degree to which Piranesi shifts scale and perspective, to the subject’s detriment, marks a highly influential development in representation. It has notably influenced such films as Fritz Lang’s Metropolis (1927) and Sergei Eisenstein’s Battleship Potemkin (1925). These dystopic narratives ultimately arrive at a triumph over the mechanisms of oppression. However, what one finds in the Carceri is a state of limbo, in which the ontological foundations of subjectivity are suspended and negated. In the Carceri the subject is cast into the dark with no light at the end of the tunnel.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  “From whatever side one approaches things, the ultimate problem turns out in the final analysis to be that of distinction.” —Roger Caillois  Decentralizing the subject through a complete immersion into the surroundings is taken to a further degree and made explicit in the work of Japanese artist Yayoi Kusama. The artist moved to America in 1957 and produced paintings, installations, and performances throughout the socially tumultuous New York City of the ’60s and ’70s, before returning to Japan in 1973, where she remains active. The overall character of her work is invested in exploring the deconstruction of identity or, more accurately, self-obliteration. Kusama’s large-scale mirrored rooms create highly interiorized spaces that paradoxically point to an infinite expansion. Her iconic installation of 1966, Kusama’s Peep Show\/Endless Love Show, figures prominently as an encapsulation of her obsessions with dots, repetition, and immersive environments. The enclosed room lined with mirrors and colored lights is only visible through two small windows—just big enough to peer inside. The effect is a hallucinatory expanse, which multiplies the viewer’s own image, plummeting the image of self into an infinite duplication that marks the  YAYOI KUSAMA  The Peep Show comes at a point in history when many self-identified feminist artists were forcing the issues of gender equality and exposing the lowly ontological footing of the female subject. Female artists, such as Carolee Schneemann, Hannah Wilke, and Valie Export, threw their bodies directly into their art practice as a means of bringing these issues to the forefront.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Lucy Lippard has noted that such efforts were overwhelmingly met with this conclusion: Because women are considered sex objects, it is taken for granted that any woman who presents her nude body in public is doing so because she thinks she is beautiful. She is a narcissist, and Vito Acconci, with his less romantic image and pimply back, is an artist.32  The notion of a “peep show” draws attention to this object-status of the female body. Kusama capitalizes on that dynamic by playing with expectations: as the viewers peer inside, they are met only with their own disembodied gaze. Commenting on this thwarted voyeurism, Claire Bishop observes, “The only performers are your own eyes darting in their sockets, multiplied to infinity.”33 The Peep Show proposes a stage in which the traditional performers are removed and the stage folds back onto itself in an endlessly self-reflexive display of dramatics. The theoretically distanced gaze is literally reduced to disembodied eyes straining to fulfill a negated pleasure. The viewer’s eyes join the infinity of flashing lights as captured performers in an endless field. The uprooted gaze is pulled deeper into this dark space. The endless depth generated through the mirrors propels the vanishing point farther and farther away.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Upon peering into the peep show, the viewer relinquishes his or her stronghold at the viewing position and is doubled at the farthest reaches of the vanishing point. The viewer is forced to operate at both ends of the viewing spectrum, as well as at infinite points along the way. It is within this structuring of visuality that “the self-possession of the viewing subject has built into it, therefore, the principle of its own abolition: annihilation of the subject as center is a condition of the very moment of the look.”34 The “annihilation of the subject” is at the heart of Kusama’s work, or in her own words, “self-obliteration.”  inanimate. Categories of difference are meant to dissolve under the mark of the dot. This body of work also includes a series of photographs and collages that generate a similar “flattening” effect to the ontological hierarchy. The application of dots diminishes the categories of difference and decreases contrast between subject, object, and field. Repetition becomes a democratizing force that collapses degrees of resemblance into a field of homogeneity. It is in this sense that seeing-as is no longer possible, as all things begin to drop aspectual differences.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  There is no longer a flipping back and forth between object, subject, or surround—everything is everything. Caillois’s essay on mimicry becomes an important sociological as well as theoretical framework to situate these works concerning immersive environments. Caillois was less interested in insect mimicry as it manifests as an evolutionarily successful defense mechanism than as it reveals itself as a “dangerous luxury,” in the case of mimicry’s being so successful that insects of the same species mistake each other for leaves and begin devouring.35 It is this pathological condition that produces the “simulation of the leaf being a provocation to cannibalism.”36 For Caillois, this was the very real danger in the “temptation of space.”37 Space provokes that dangerous desire to lose oneself, to be engulfed, to be obliterated. It is the temptation to lose oneself in space that Kusama invokes again and again through various instances of repetition culminating in the “mimetic experience of fragmentation.”38 For Kusama, the mark of the dot acts as a cipher for further disrupting the spatiotemporal location of the subject in its milieu. The subject for her is not only the human and singular; in Self-Obliteration the fractured cinematic narrative depicts Kusama in the act of applying dots to herself, fellow actors, a horse, a cat, trees, and grass, and even dropping dollops of ink into a pond. The unedited dispersal of dots disrupts the unique coordinates of one individual in relation to another by means of multiplication and subsequent conflation. This gradual breaking down of boundaries between self, other, and outside marks, for Caillois, the moment when “the organism . . . is no longer the origin of the coordinates, but one point  simply a blanket seeing things.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Beyond the diminutive figures overwhelmed and lost to the passageways of the Carceri, Kusama proposes the subject, herself included, be engulfed by the scene and come out on the other side indistinguishable: a thing among things. The repeated motif of engulfment marks for Kusama the moment when the specificity of place collapses under the unspecificity of space. Under the sign of the dot, the locational identity attached to place is unhinged through the proliferation of an otherwise unique marker. A single dot in space defines an exact spot as specific and unique. However, once that unique value is multiplied and expanded, it is drained of its capacity to single out and identify. The multiplication of the dot now serves to mark an expansive space, not a singular place, and therefore whatever or whoever bears this mark is equally cast out of a unique, singular place. As discussed earlier, it is under these conditions that the subject no longer remains the origins of its own coordinates in space, as the similarity of space consumes and breaks down figure\/ground, self\/other relations. It is in this way that Kusama’s work moves closer to Nishitani’s field of sūnyatā.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  For Nishitani, sūnyatā is not as “catastrophic” and “threatening” as is the destabilizing force in the intrusion of the other for Sartre and Lacan. The subject rather, acquiesces to this space of “radical impermanence” and joins the dynamic network of interchanging relations and exchanging glances. The subject is not destroyed as much as it experiences a return to the state of things before the cultural encoding of hierarchies. Kusama’s decentralizing of the subject is not born of malice; rather, it carries with it a mimetic desire for inclusion. Through Kusama as through Piranesi, the subject is constantly challenged in a space that does not adhere to classical notions of anthro-primacy. The work of Piranesi and Kusama approaches the subject through spatiality and visuality to question its ontological necessity. They cast the subject into a dark space where it can no longer reign over the object and the surroundings. These spaces, which are populated by things, lawless perspectives, and vanishing points on an endless horizon, are exactly the same sites in which a flat ontology structures a universe devoid of hierarchical laws.\n"}
{"prompt":"And Another Thing: Nonanthropocentrism and Art ->","completion":"  Employing the devices of space and sight serves  digestive forces move the subject through immersive surroundings, breaking down its primacy and singularity, and depositing it back onto the field as plural and similar. It is such forces that dismantle the verticality of anthropocentrism—leveling it and realigning it with an expansive and endless horizon.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Editorial  Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies  Science, Technology, & Human Values 2019, Vol.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  44(5) 723-736 ª The Author(s) 2019 Article reuse guidelines: sagepub.com\/journals-permissions DOI: 10.1177\/0162243919860211 journals.sagepub.com\/home\/sth  Jennifer Gabrys1  Abstract This editorial examines how sensing practices are transforming through proliferating sensor technologies and altered sensing relations. Rather than engage with sensing as a project of the human mind or body as usually delineated within sensory classifications, this overview of sensors and sensing practices documents how sensing entities are emerging that are composed of shifting ensembles of multiple humans and more-than-humans, environments and technologies, politics and practices. By decoupling sensing from its exclusive human orientation, the editorial and collection demonstrate how reworked approaches to sensing make it possible to tune in to how involvement with environmental problems unfolds and endures. The collection asks how sensing practices might be crafted that attend to the distributed and accumulative inequalities of environmental problems  1  University of Cambridge, Cambridge, United Kingdom  Corresponding Author: Jennifer Gabrys, University of Cambridge, Free School Lane, Cambridge, CB2 3RQ, United Kingdom. Email: jg899@cam.ac.uk  and to speculate toward differential collectives for addressing environmental crisis and change. Keywords sensors, sensing practices, environmental change, environmental collectives, environmental politics, politics of sensing  Sensing is a topic that has been extensively discussed across multiple fields of study. Usually, some version of a cognizing human is at the center of work on sensing, where a particular delineation of the five senses is the organizing logic for making sense of the world. Indeed, there is no shortage of research on the five human senses, both within science and technology studies and farther afield, as well as works that employ the five senses as an organizing trope.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  With these works, sensing is tied to particular types of human embodiment, engagement, and experience. However, there are many more sensing entities and modes of experience that are now coming into view, from computational sensors that monitor environmental pollution, to organisms that sense and bio-accumulate environmental toxins, and satellites that remotely sense aquifers. The focus in this special issue is on the proliferation of sensors, sensing entities, and sensing practices that become evident through distinct encounters with changing environments. “Sensing practices” is a term we have developed to capture these changing formations of experience. It is an analytical device for thinking through how experience and relations are reworked across entities, environments, and technologies. Rather than reinscribe the classification of “the senses” from a universal human reference point, this collection seeks to disrupt and transform sensing away from a classificatory and exclusively human project. The contributions in this collection unsettle these ways of organizing sensing. In their different ways of grappling with an array of sensing entities, practices, relations, and milieus that are concretizing as experiencing assemblages, the texts in this collection ask how distributions of experience have concrete political effects that are also collectively felt.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Sensing practices has been a guiding concept within previous research on environmental sensing technologies that have informed the Citizen Sense research project. From sensing experimental forests (Gabrys 2012) to animal hackers (Pritchard 2013, 2018) and programmable earths (Gabrys 2016), we have suggested that it is possible to investigate how modes and  relations of experience might be differently configured and toward alternative political collectives and a\/effects. How might environments and environmental problems open up, for instance, beyond the usual designation of a dilemma to be solved, when the many experiencing entities, their modes of involvement, and influence on one another are taken into account? This is a more cosmopolitical way of understanding processes of environmental sensing, and here we draw on Stengers (2011a) to consider how these modes of experience are also ways of making worlds. Just as the entities, relations, and practices of sensing shift, so too do the formations and processes of sense—that which is sensible and senseable—change. While our previous work within the Citizen Sense research project has indicated how these shifts in sensing practices are significant for the ways in which they rework environmental entities and relations (Gabrys and Pritchard 2018), in this special issue, we zoom in on the specific details of these new entities and relations by attending to specific sites and distinct modes of sensing practices. What such an investigation reveals is the plurality of sensing practices, together with the expanded environmental collectives that are involved in sensing and indicating environmental change. How are environmental collectives constituted, and how might we begin to understand them through their sensory and experiential registers?\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  The philosopher Alfred North Whitehead (1929) suggested one entry point through his project of expanding the contours of experience beyond human reference points to the experiences of all entities, as they take up, transform, and express the conditions of their experiencing. This is a radically different way of understanding the work that experiencing does by connecting subjects to their environments and to societies of other entities with which experiencing takes place. These are collaborative modes of sensing (Gabrys 2012), which are radically distinct from the usual ways of encountering the problem of how (universal and individual) humans make sense of the world. Sensing practices as a concept captures the distinct approaches to undertaking research, which are emerging within science and technology studies and aligned fields. New methods are materializing through these practices that include experimental, practice-based, and participatory research. Sensing practices might also shift the traditional categories of expert, citizen, and participation to generate new approaches to science and technology studies. While our own work in the area of sensors and sensing practices has been percolating for over a decade (e.g., Gabrys 2007), we align this collection with ongoing research in science and technology studies that looks at different modes of experiencing across human and more-than-  human subjects. For instance, Tsing (2015) notes the ways in which sensing and listening to environments and environmental inhabitants can become a political act.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Benson (2010) documents how environmental sensing practices in the form of tracking raises distinct questions about the scientists, organisms, and environmental relations that are under study. And Lehman (2018) documents how sensing practices for studying oceans becomes a way in which distinct oceanic relations and modes of governance are formed. While the focus of this collection is on environmental sensing practices, there are also many other sensing practices that scholars have documented, from sensors for tracking and targeting used in military applications (Suchman, Follis, and Weber 2017) to senses of toxicity and race as experienced through lead paint and lead poisoning (Chen 2012). By engaging with the proliferation and distribution of experiences, these works demonstrate how practices become a key way in which to make sense (cf. Citizen Sense, 2014-2015), as an ongoing and collaborative undertaking, rather than as a delineated exchange between human organs and external stimuli. The work included in this collection further builds on the contributors’ ongoing research into sensors and sensing practices, as the authors here also have previously developed key work that contributes to the formation of this area of study on sensing practices. Helmreich (2009, 2015) has undertaken extensive research on oceanographic sensing and sounding oceans, and his work has demonstrated how sensing is bound up with multisited instruments and ecologies of sensing practices. Ballestero (2016) has considered the indeterminate ways in which aquifers are experienced, and how this indeterminacy influences the formation of publics.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Christelle Gramaglia (Gramaglia and Sampaio da Silva 2012) has examined the ways in which organisms, as sentinels, not only signal pollution but also demonstrate how ecologies depend upon collective modes of sensing. Kuchinskaya (2014) has investigated the ways in which radiation, an ordinarily invisible phenomenon, becomes visible through particular sociopolitical engagements and actions, for instance, to prevent exposure or create new regulations. Lorenzo Pezzani and Charles Heller (Pezzani, Heller and Stierl 2017) have developed an approach involving “disobedient sensing” that uses ship-tracking technology to aid in the effort to expose human rights abuses to migrants crossing the Mediterranean Sea. And Howe (Howe and Boyer 2015) has suggested that different ways of sensing “wind power” can inform “a series of cosmologies, about how the wind makes people and what people make of the wind” (p. 36). This collection helps not only to connect these projects into a distinct field of sensing practices, it also  amplifies the conversation across different approaches to sensing practices that begin to resonate across multiple lines of inquiry. This collection then develops a sustained engagement with sensors, sensing practices, and environments. Primarily situated within science and technology studies and focused on case studies that engage with environmental topics, this collection takes an interdisciplinary and sociologically informed approach to studying sensors and sensing relations that span locations from the Netherlands to Costa Rica, Northern Australia and Southeast London, Southern France and Fukushima, the Mediterranean Sea and Iceland. The contributions here engage with distributed modes of sensing across ocean waves and ship vessel tracking, radiation and air pollution, climate change and water shortages, conger eels and aquifers, as well as urban development and industrial pollution, in order to demonstrate and query the ways in which sensing practices give rise to alternative theoretical and practical alignments as well as possibilities for political engagement with environmental problems.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  The articles included in this special issue bring a transdisciplinary approach to current environmental topics and forge new approaches to social studies of environments. Addressing and analyzing some of the most urgent contemporary environmental problems, from air pollution to climate change and ocean ecologies, the articles present rich empirical case studies that are also theoretically rigorous and which have implications for policy and activism. At the same time, this collection includes new research approaches that are participatory, practice based, and engaged with nonhumans. These research investigations further rework and transform engagements with what counts as a sensing entity or site of sensation. Included here are sensing practices undertaken through wave buoys and satellites, maps and stories, fish and microcomputers, Geiger counters and vesseltracking platforms, melting ice and polar bears. Sensing practices do not settle into a singular fixed subject, entity, relation, or outcome. Instead, they become ways of articulating, animating, and operationalizing environmental collectives that are in the process of finding ways to live together in altered worlds. Sensing practices then give rise to a plurality of experiences and inhabitations, some of which are in opposition or which create contested approaches to environments.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  In the first article in the collection, “Reading a Wave Buoy,” Stefan Helmreich (2019) engages with sensing practices through tracing the media ecology of the wave buoy. Describing a visit to the Datawell company in the Netherlands, he explores the distinct sensing capacities of the Directional Waverider buoy. This measurement technology, which monitors waves,  provides sense data that undo the usual ways of understanding experience as a phenomenological encounter. Instead, the wave buoy is a material technology that is comprised of plastic, liquids, metal, sensors, and communication technologies that create a network for detecting wave height and direction, as well as possible storm surges and floods. Helmreich suggests that on one level, wave buoys are “nonhuman sensory organs for apprehending the ocean.” Yet, on another level, they also generate social and political relations that exceed oceanographic study and point to ways in which the seas can be spaces of inequality, injustice, and exploitation. The sensing practices that materialize here are not merely ones that measure and describe wave characteristics but also that intersect with maritime institutions and politics and so signal distributed oceanic sensing practices. If wave buoys provide ways of sensing and measuring waves and ocean spaces through situated liquid technologies, then remote sensing of aquifers generates a different way to encounter sensing practices as they traverse radically remote and invisible terrains. In “Touching with Light, or, How Texture Recasts the Sensing of Underground Water,” Andrea Ballestero (2019) examines the dynamics and sensing practices that unfold when community members are concerned about potential privatization and high rates of extraction of water from aquifers in Costa Rica.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Public agencies propose that Landsat-based remote sensing of aquifers and underground water resources can be a way to address these environmental conflicts. Working with the unique ways in which cavers explore underground space as a sort of seeing touch, Ballestero describes how Costa Rica’s subsurface water becomes evident through water shortages, water pollution, remote sensing technologies, development politics, and new sensing relations. Subsurface water erupts to the surface through conflicts over water and through attempts to grapple with the “sensorial combinations” that bring water conflicts to greater public attention. Sensing practices in this context involve new co-becomings of sense, where sensing puts in motion “conceptual resources that blur any radical separation between abstract knowing and embodied sensing,” as Ballestero argues. This is ultimately an expanded, rather than reductive, understanding of the work that sensing does across entities, technologies, and environments and which, similar to Helmreich, exceeds a phenomenological rendering of the senses as residing only within a human register. In a time of climate change, water shortages are becoming increasingly evident as a pervasive environmental problem. How water is sensed, monitored, and measured can involve not just practices of remote sensing technologies and transformed ways of detecting water resources but also a  plurality of ontologies for making sense of water relations. In “Asymmetries and Climate Futures: Working with Waters in an Indigenous Australian Settlement,” Michaela Spencer, Endre Dányi, and Yasunori Hayashi (2019) discuss a plurality of ways of engaging with water when anticipating the absence of water due to climate change.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Describing Aboriginal and scientific encounters with water and water loss, these authors examine how attempts to conserve water draw on much different technologies and ontologies when encountered through water research and public utilities or through Indigenous Australian water practices. The plurality of these ways of encountering and accounting for water is crucial since they create practices of seeing, telling, and mapping water that these authors suggest are also productive of different forms of political work and different ways of “crafting climate futures.” In order for these climate futures to involve a diverse range of sensing subjects and worlds, so too do sensing practices need to account for the asymmetrical ways in which environments are experienced, inhabited, and looked after. Continuing on the theme of water, but turning to the organisms that inhabit and signal the quality of water, Christelle Gramaglia and François Mélard (2019) investigate how organisms become sentinels for sensing environmental change and toxicity. In their article, “Looking for the Cosmopolitical Fish: Monitoring Marine Pollution with Anglers and Congers in the Gulf of Fos, Southern France,” the authors discuss how a participatory biomonitoring project documented marine pollution through a different type of sensor: a bioindicator fish, the conger eel. The process of agreeing upon this particular bioindicator organism within the monitoring community, however, was not straightforward. Instead, distinct environmental and research collectives came together in ways that expressed the specific ecological relations that were at stake. In this way, the conger became a cosmopolitical fish. Rather than rely on analogue or digital sensors alone to document the water quality, the fish were mobilized to study the lived environmental conditions of the Gulf of Fos—over time, and as they influenced fishing practices and maritime life.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  This different sensor then produced transformed sensing practices and relations that generated “new knowledge by other means,” which in this case could even be used to examine and challenge the permits given to polluting industries. The different types of sensors—whether organismal or computational— that can be used to indicate environmental change are productive of different modes of sensing not just in relation to types of sensors but also through the diverse practices that they organize and operationalize. In “Breakdown in the Smart City: Exploring Workarounds with Urban-sensing Practices  and Technologies,” Lara Houston, Jennifer Gabrys, and Helen Pritchard (2019) describe the practice-based research project, Citizen Sense, which in part investigates the claims made about computational sensors, and how these are meant to unleash a seemingly utopic smart city. The authors consider how situated sensing practices of working with air quality sensors in a DIY community monitoring network give rise to different ways of understanding and operationalizing computational urbanisms. By describing how “work-arounds” materialize in the process of setting up and working with citizen-sensing technologies in the form of air quality monitors, these authors suggest that along with sensing technologies frequently breaking down or requiring fixes, the usual monolithic and universal discourse of the smart city also breaks down. These practices involve not only setting up and sustaining citizen-sensing technologies but also require attending to multiple different concerns and community initiatives that work toward more livable cities. By working around the smart city as a version of urbanism, this research demonstrates how more connected environmental collectives and sensing practices could materialize. Continuing on the topic of DIY investigations of environmental pollution, Olga Kuchinskaya’s (2019) commentary, “Citizen Science and the Politics of Environmental Data,” examines how different sensing practices for detecting radiation after nuclear accidents generate distinct engagements with environmental data, which have very different stakes and political alignments.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  She compares how the Safecast group, a volunteer citizen-science network using DIY radiation monitors, responded to the Fukushima Daiichi accident in 2011, and how the Belrad group, a nonprofit focused on radiation safety, responded to the Chernobyl accident in 1986. Although each group had as its focus the use of environmental data to make radiation more visible as a public problem, the groups diverged in their different understandings of how political—or not—such data might be in its collection, analysis, and communication. Safecast focused primarily on setting up open-source hardware and software. The data that their bGeigie sensor devices produced were perceived to be “apolitical,” as the group states and Kuchinskaya documents. The relative safety of exposure levels and different modes of analysis were largely left aside, and Safecast’s focus was on gathering “raw data.” Contrasting this approach with Belrad, Kuchinskaya documents how data were approached as political from the outset of this organization, where “Belrad’s data collection was inseparable from its advocacy.” Not only were data mobilized to educate publics about safety and exposure levels, but also they were used to contribute to decontamination and protection measures. Visibility, or making environmental  data visible to document environmental problems, can generate differing political engagements, some of which might even disavow a project of political advocacy. Seemingly similar approaches to data and sensing practices can then have much different effects. At the same time, invisibility refers less to not knowing about pollution and refers instead to how “those who are most affected are ignored and disempowered in the process of knowledge production.” Different sensing practices in this way demonstrate the uneven power arrangements that make sensing palpable and possible.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  In this way, sensing practices could even be understood to produce countersensing practices that can be used to challenge existing approaches to different socioenvironmental problems such as migration. In “AIS Politics: The Contested Use of Vessel Tracking at the EU’s Maritime Frontier,” Lorenzo Pezzani and Charles Heller (2019) describe a particular vesseltracking system, automatic identification system (AIS), that has been used to track ship traffic to prevent collisions but which has become a technology for monitoring ships carrying migrants to Europe. Here, a monitoring and detection technology transforms in the context of emerging issues related to migration across the Mediterranean Sea. AIS transforms through sensing practices that both document the movement of migrants for purposes of governance and control, as well as for counterpurposes of data activism and human rights. As this sensing technology is taken up and put to different uses—or as these authors suggest, appropriated—the range of possible uses also proliferates through remote sensing practices that influence “who can move and in what condition, thereby shaping the contentious force field of migration.” The authors describe their own practice-based research within this area through their initiative, Forensic Oceanography, which makes use of this sensing technology and data to contest “the exclusionary nature of borders, and the mass dying of migrants at sea to which it leads.” In parallel, the authors recognize that by working with sensing practices that appropriate vessel-tracking technologies, they are also ambivalently situated “within the global datascape constituted by AIS and other data.” Yet, as hundreds of millions if not billions of people are projected to be displaced in this century due to environmental stresses from the climate crisis, migration and “disobedient” sensing practices will only continue to grow in importance. As this collection demonstrates, asymmetries are evident in the differing uses of sensing technologies, as Pezzani and Heller’s work indicates, and they are evident in the ways in which the plural ontologies of water and water loss are navigated, as Spencer, Dányi, and Hayashi document. As Cymene Howe (2019) suggests in her article, “Sensing Asymmetries in Other-than-human Forms,” these asymmetries are present in different  practices of sensing the melting of ice in the North, particularly in Iceland, due to climate change. Different entities, including more-than-humans, sense and are affected by the loss of the cryosphere, and these modes of sensing are bound up with the making and unmaking of worlds.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  Howe investigates how humans and more-than-humans are caught up in the melting of Arctic landscapes, from the loss of the ice sheet in Greenland, to the death of polar bears, and the loss of sea ice. Asymmetry describes how different ways of being in and experiencing worlds—in other words, different sensing practices—can make present much different environmental relations that are under threat. These asymmetries are important to tune in to since they remind us what worlds are at stake and what worlds are being lost through catastrophic changes in climate. As Howe writes, “sensing by other means entails sensing through others’ means and beyond the human sensorium.” Such practices can generate transformed ways in which to respond and demonstrate responsibility to these changing worlds, within and beyond the usual registers of sense (cf. Yusoff 2013). As these compelling and richly detailed accounts of the plurality of sensing practices demonstrate, different modes of sensing and experience provoke not just different ways of being in and for worlds, they also demonstrate that different worlds and environmental relations are at stake. Far from an account of “the senses” as fixed in the usual human-focused classificatory framework, here are modes of feeling, caring, experiencing, observing, documenting, expressing, and struggling for and with environments and subjects that the term, “sensing practices,” more adequately captures. These contributions to the “Sensors and Sensing Practices” special issue differently but relatedly consider how diverse environmental collectives come into being through distinct ways of sensing environmental problems.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  These practices are not just ways to rework the data and evidence that might be brought to bear on environmental problems. They are also ways of creating sensing entities, relations, and politics, which come together through particular ways of making sense of environmental problems (cf. Gabrys 2018). These collective ways of feeling and responding to environmental problems then also indicate the ways in which worlds are made and sustained, as well as the worlds that are lost when these relations are severed (cf. TallBear 2011). The sensors and sensing practices that are put in motion in the different contributions to this collection demonstrate how different ways of becoming involved in and attached to environments and environmental problems are organized (cf. Stengers 2011b). From wave buoys to vessel tracking, remote sensing and storytelling, conger eels and Arctic organisms, air  pollution sensors and radiation sensors, many different formations of citizenship, political engagement, expertise, and earthly inhabitation are cultivated here.\n"}
{"prompt":"Sensors and Sensing Practices: Reworking Experience across Entities, Environments, and Technologies ->","completion":"  The theme of sensors and sensing practices then advances approaches to both theory and practice, analysis and narrative, scientific investigation and activism, which resist an easy division into modes of investigation, or a routine delineation of sensing subjects and relations. Instead, as this introduction has emphasized, new collaborative and collective ways of sensing materialize that contribute to distinct and transformed worlds. These worlds are made through sensing practices that unfold—as processes—through shared inhabitations and experiences (Gabrys and Pritchard 2018). We then suggest with this collection that a body of research on sensors and sensing practices is coming together to provide a rich resource for science and technology studies and aligned fields. This area of study, furthermore, can help to inform new theoretical and practical investigations into world-making practices and relations and for strategies of sensing otherwise. Acknowledgments Thanks are due to the contributors for their engaged and engaging texts, as well as to the anonymous reviewers, who provided insightful and constructive comments for advancing the work included here. Declaration of Conflicting Interests The author(s) declared no potential conflicts of interest with respect to the research, authorship, and\/or publication of this article. Funding The author(s) disclosed receipt of the following financial support for the research, authorship, and\/or publication of this article: The research leading to these results has received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP\/2007-2013)\/ERC Grant Agreement No.\n"}
{"prompt":" ->","completion":"  Submit your article to this journal  View Crossmark data  ANGELAKI journal of the theoretical humanities volume 24 number 1 february 2019  At the end of the Pattern’s ﬁrst year of existence, we all knew we had something that was working. Something new. We were learning to do everything as we went along.1  I  n Mind of My Mind, Octavia E. Butler describes the inevitable demise of the master patternist Doro, a more-than-human creature, who was originally born black Nubian and had become immortal thanks to his extraordinary telepathic powers.2 From his early childhood, Doro’s mind could enter and leave the bodies of others at will, overtly enjoying taking over the bodies of white men. For four thousand years Doro was a successful psychic parasite aiming to breed a race of superhumans that could enhance the supremacy of his thinking pattern. However, his efforts to breed powerful patternists ended up in ruin as his colonies of enhanced telepathic creatures started to run out of their minds, ending up killing each other in madness. His selected bodies or latent talents could not survive the horrible proof of transition, demarcating the passage from a passive to an active mind, when latents were supposed to become active in the pattern and gain control of the noisy signals broadcasted by the master pattern. Instead, during transition, latents only picked up emotions resulting in outbursts of anguish, terror and rage, and unsparing battles with each other. Doro’s psycho-colonial plan of subsuming active minds under his rule, however, takes a better turn when Mary, one of his daughters  luciana parisi XENO-PATTERNING predictive intuition and automated imagination his strongest male actives, Karl, who had already transitioned to his master program, in order to breed a new colony with hyperpsychic power.\n"}
{"prompt":" ->","completion":"  However, when Mary enters transition she discovers not simply her power to navigate the noise of Doro’s pattern, but that she has power to wrest control of the mind of several actives around the country. It is not simply a matter of telepathic power but her capacity to host the mental power of actives from all over the world makes Mary realize that there is indeed a mind of her own  minds. By growing layers upon layers of telepathic thinking amongst actives, Mary aims to turn the master pattern into an egalitarian space by offering Doro’s enslaved population the chance to transition towards higher mental power. If Doro is a psychopathic tyrant without ethical principles, Mary instead is caught in the middle of controversial decisions as she builds the pattern in a way that compels the minds of others to join her imagination by following her mission that everyone must have access to the mind of her mind. As opposed to Doro’s master pattern for total domination of his own mind in the bodies of everyone else, Mary rather aspires to give birth to an alien intelligence that can host all kinds of minds as these ﬁnd a space of uniﬁcation in the patterns of her patterns. If Doro’s master program admits no external intrusion in the one-dimensional design of the mind, Mary’s paradoxical intuition of inviting potential saboteurs in her growing layers of minds is rather a choice of embracing something she has no control of. Despite the controversial use of her telepathic power that makes actives believe that they take autonomous decisions whilst being instead piloted by Mary’s views, it would be wrong to assume that the mind of her mind simply remains immune from the alienness of patterning as this hosts increasingly more active minds. In what follows, I will explore this alienness in the context of recent forms of artiﬁcial intelligence called machine learning.\n"}
{"prompt":" ->","completion":"  As opposed to models of computational cognition that rely on the deductive logic of symbolic AI, the postTuring shift to interactive computing entails that incomputables – or unknown information – deﬁne the formation of new patterns that are not pre-programmed for a task. It is from this standpoint that one can speak of alienness as  image-models. In particular, it will be argued that predictive intuition in neural networks can explain the formation of patterns beyond deductive premises and demarcate the advance of artiﬁcial imagination in the dynamic architecture of machine thinking. 1 the patternist As much as Doro has a plan to enslave all latent minds under the program of his master pattern, so too today’s capital corporations (from Google to Amazon) are rampantly competing to own the Singularity pattern that will ﬁnally subsume all thinking under the One.3 Sadly, the image of our automated future is already packed with the master pattern of corporate capital. While the value of human capital approximates zero, the automated infrastructure of capital has come to own the universal history of humanity: what has happened and could ever happen to the species, the planet, the solar system, and the galaxy. From the nano scale to the intergalactic project of ultimate datiﬁcation, the growing capacity of the master pattern to engulf at once the past and the future is driven by the computational power of predictive algorithms that constantly learn as they go along, correlating inﬁnite varieties of data sets – i.e., annexing and disaggregating increasingly smaller programs that fully run on the architecture of neural nets. Swarming patterns of disaggregated machine learning algorithms are held together by a mastering architecture whose growing patterns it rules and divides so as to anticipate – i.e., engulf within itself – the smallest tendency for autonomous programming. The aspiration to become a Patternist, as Octavia Butler calls the species of telepaths that can colonize all forms of thought, coincides with a mode of control predicated upon the obtuse nature of  with an alien form of automation, whereby algorithmic patterning aims to take prediction away from the homeostatic function of recognition to rather embark in a complex logic of productive imagination.\n"}
{"prompt":" ->","completion":"  By constructing hypotheses about non-observable events, predictive patterning has broken from the logic of deduction and the symmetry between truth and proof. Deduction, one could argue, is a fundamental method of reasoning that ensures that there is a logical consequence between premises and results, truths and proofs. It accounts for the pre-existence of a conceptual architecture with which it is possible to pursue the understanding of the world through the perception of a thought as an image that corresponds to a fact, an object in the world. Whereas computational cognition sees deductive logic as a method that can prove that to think is to re-cognize or represent a set of symbols wired in the machine, the shift to post-Turing methods of computation also coincides with a new method of reasoning. This is not based on given instructions but on learning from the interaction between objects, agents, environments. Predictive patterning and not the logic of causality becomes the motor of complex dimensions of thinking within intelligent machines. However, the Patternist is not simply an evolving archive of data memories and know-hows. Octavia Butler’s vision of the colonization of thinking is not bound to a speciﬁc medium, but to mediation itself: the limits of cognitive representation demarcate the point of departure into travelling through the space of thinking.\n"}
{"prompt":" ->","completion":"  Instead of a Universal Turing Machine that can move in one direction, forward and backward, and decompose its procedural units into (con)sequential steps, telepathic mediation allows for a mereo-topological colonization of parts and wholes intended not simply to gather the  patterns that it owns. The Patternist is not a fortune-teller but a Protean slave trader that transmutes his body whilst it takes over your mind by culling it in his kingdom of instructions. The more thoughts it subsumes to its transcendental schemata, the more the future of thinking only acts as a reminder of what has already been thought. What ensures his colonial mastery is not simply his data architecture that replaces the self-thinking subject with the mediatic form of non-conscious decisionmaking algorithms. Instead of a master algorithm that knows it all, the Patternist needs to evolve its slavery network into increasingly more complex patterns of prediction: the more part-to-whole relations between patterns, the more the Patternist can predict what can be known. This is the sense of capture that today’s automated neural networks embody in the aftermath of an accelerated accumulation of voluntary data. Nevertheless, one cannot underestimate that as much as neural nets experiment with predictive learning this new form of telepathic mediation has also evolved new modes of machine percepts and concepts that hardly mirror the categories of the transcendental schema. Instead of optical recognition or the mirroring framing of the world, telepathic mediation is distinctively algorithmic in so far as it relies on predictive patterns of compression not of whole images but of inﬁnitely small sets of information.\n"}
{"prompt":" ->","completion":"  From the standpoint of information patterning, therefore, artiﬁcial intelligence has nothing to do with the optical model of cognitivist representation. If what is seen in the world is the same as what is recognized according to the schema of given categories, then machine thinking would just be an extended automation of the logic of deduction. Patterns would just describe the regular rep-  data. This is why if deductive reasoning was held to ensure formal correspondence between what is already known and seen, algorithmic patterning instead brings logical reasoning towards its ultimate conclusion: namely by not knowing in advance what can be cognized, and the patterning of image-models can re-conﬁgure the horizons of machine thinking. Similarly, Butler’s quest of mental slavery also catches upon this undetermined tension between pattern and thought, where the telepathic recognition of discrete and repetitive patterns coincides with the material condition by which a pattern can become demonstrative of a thought, resulting from a perceptual and conceptual connection with the world. If patterns correspond to the recognition of shapes, sizes, forms, etc. of objects, texts, sounds, images, they can at the same time also be discussed in the terms of what Wilfrid Sellars calls “sheer receptivity” or forms of intuition consisting in non-conceptual representation.4 While this is only one level of intuition, it nevertheless offers a radical shift from the Kantian argument for intuition as an instance of a priori transcendental conceptions. According to Sellars, sheer receptivity as a material form of intuition must, however, be paired up with intuitions resulting from the transcendental synthesis of imagination – or conceptually guided representations involving a transcendental synthesis of imagination.\n"}
{"prompt":" ->","completion":"  It is only through this coupling of distinctive levels of intuition that one could argue that patterns can take part in a “productive imagination.”5 As it may become clearer below, this article suggests that telepathic mediation does not only ground thoughts into patterns that can be constantly recognized and reproduced as in Doro’s monopolistic network of enslaved lessthan-thinking creatures. The admission that  way which supplies the relevant recipe.”6 Similarly, Mary’s plans to extend the right to transition to all latents enslaved to Doro’s network start with this level of non-conceptual receptivity. From merely being patterns of recognition, the transition to becoming actives coincides with building together a general artiﬁcial intelligence that continues to learn from its enslaved patterns, and unleashes an unprecedented growth of the dimensions of thinking starting from pattern’s receptivity. This shows that patterns are not just recipes but objects that add a sort of alienness to already given rules, exposing predictive patterning to the production of image-models beyond Doro’s monopoly. Instead of a full automated thought that replaces thinking, reason, imagination with machine proofs as mere instantiations of conceptual nominal positing (corresponding to an automated unity of appreciation), here patterns rather correspond to image-models constructed by and through learning. If, on the one hand, the relation between receptivity and conceptuality (sheer receptivity and conceptual synthesis) corresponds to a complex form of intuition starting from patterning, on the other predictive patterning adds more acts of perception to the entire space of artiﬁcial intelligence (patterning from patterns). Doro, the Patternist – or the thought colonizer – is deﬁed by Mary’s predictive patterning because the level of “sheer receptivity” is not simply equivalent to repetitive procedures that represent objects in the world. This level of non-conceptual intuition is also a mode of cognition that brings Mary’s mentality to undergo an alien becoming of the pattern she thinks she owns.\n"}
{"prompt":" ->","completion":"  The image of thought proposed by the arms race for the monopoly of the technological explosion of intelligence (or the Singularity) similarly refuses deductive logic (or the prova-  thinking can also be understood here as symptoms of an internal critique of logical thinking: the limit of what a pattern can be is precisely the starting point for the pattern to shift its enslaved condition beyond the image of the network. The latter relies on probability calculation, discrete patterns forming programs that can repeat the same function at incredibly faster rates. Here the Singularity mainly guarantees the efﬁciency of problem solving at increasingly larger scales. Instead, both the growth and the efﬁciency of Mary’s Pattern is never given, in so far as its infrastructure relies on predictive patterning which is conditioned by the indeterminacy of results in constructing what can be known or thought. As opposed to the mindless automation of Singularity, where functions execute concepts derived from the transcendental schema of categories, the Patternist’s empire, as Mary’s plans show, is conditioned by the logic of fallibility, where error becomes part of the pattern’s learning. Here it is hypothesis making and not mindless correlation that drives patterns to construct an image-model from patterns. While hypotheses cannot be directly deduced as proofs of truths, they can nonetheless construct predictive trajectories expanding the act of receptivity beyond the thought of a particular object. Learning and not executing instructions has always been a preoccupation for both the cybernetic and computational development of intelligent systems since the 1940s.\n"}
{"prompt":" ->","completion":"  The design of artiﬁcial systems that could explain how patterns are formed and how machines can learn functions and elaborate concepts beyond their inputted data has accompanied artiﬁcial intelligence since Turing’s early thought experiments. What could not be proven and\/or computed by an artiﬁcial system – and thus through the automated logical procedures into a series of proofs  As the limits of computation were manifested in the proliferation of error in the execution of programs, it was also the case that patterning shifted towards the logic of trial and error, or fallibility. From the standpoint of induction, it is possible to suggest that automated learning is not driven simply by the efﬁcient causality of repetitive patterns that reproduce given correlations between truths and proofs. As a consequence of inductive learning, the logic of fallibility in automated systems can importantly contribute to suggest how patterning can coincide with an alien imagination determined neither by given truths (and the unilateral production of proofs) nor by given data (and the unilateral correspondence of data to concepts). Instead, predictive patterning takes the method of trial and error towards the ultimate consequence of constructing model-images that have no direct use, but are as it were “counterfactual” in so far as they concretize the ifclause or the hypothesis making, producing alien functions and concepts.8 In other words, starting from a logic of fallibility in machine thinking, hypothesis making involves the construction of model-images about unknown patterns of relations between functions and concepts, precisely for what these can be, do and become. One could therefore pursue a view for which automated learning in terms of hypothetical thinking steps beyond the unity of apperception in the transcendental schema, and thus the deductive programming of the correlation of functions and objects. If the Patternist points out that any form of automated prediction inevitably carries within it a logic of fallibility and not simply of optimized efﬁciency, then one could argue that the automation of learning, in the current form of machine learning algorithms, for instance, can be explored as the start-  non-conceptual representation) concurs and to some extent partakes of the non-monotonic formation of additional premises through a transcendental imagination that can invalidate or add new meaning to them. To put it another way, instead of taking Butler’s view to imply that the Patternist can only ever enslave thinking to the transcendental schema within the limits of deductive reasoning, it is here suggested that patterning already corresponds to a non-conceptual representation that is a proto-theoretical image.\n"}
{"prompt":" ->","completion":"  In the neural architecture of predictive learning, the algorithmic function of pattern recognition brings forward this non-conceptual image in a cluster of hypothetical conﬁgurations or model-images of counterfactual possibilities. This article therefore follows Butler’s insight into Mary’s plans to enlarge the realm of possibilities of patterns – that is of enslaved patterns – to think beyond the rules of deduction. In Mind of My Mind, the controversial condition in which Mary’s power to host colonized patterns (and support their transition) is overlapped by their predictive learning points that counter-factual conﬁgurations continuously derail the network from monotonic thinking, and from Mary’s benevolent intentions to grant a thinking space for everyone. What remains striking here is precisely how the logic of patterning patterns steps outside the formalism of deduction to demonstrate that the non-conceptual realm of intuition, or sheer receptivity (and therefore the receptivity of non-conceptual patterns) is fundamental to the transition to synthetic thinking worked by and through imagination. It is precisely this zone of opacity between the repetition of patterns and the transition to the synthesis of transcendental imagination that remains to be discussed, unpacked, explained, and envisioned in order to set in  systems of decision making, and particularly in machine learning. One may want to start by asking: how does imagination defy the coming empire of the master pattern and its global servo-mechanic infrastructure that feeds the network without being able to change its rules? It is generally agreed that the role of imagination in the Kantian schema of transcendental reason involves the theorization of a logical procedure where the analysis of the world is supervened by a synthetic perspective of what can be known. As I have argued so far, this transcendental reasoning that appears to pre-establish the conceptual framing of the world according to the cognitive schema of thinking is importantly supported by intuition, which Sellars calls “sheer receptivity” as non-conceptual patterns that are not originated by the transcendental schema of imagination.\n"}
{"prompt":" ->","completion":"  Here, the result of synthesis can presuppose a transcendental unity of apperception on the one hand and the addition of supplementary acts of perception that push the reproductive imagination (or conceptual recognition) towards the formation of alien percepts and concepts on the other. If, according to Sellars, the proto-theoretical receptivity of the simple is necessarily of the same logical pattern as that of a complex transcendental synthesis, productive imagination then admits that logical patterns can change as a result of a supplemental act of perception (and thus machine vision) in the transcendental synthesis. It is well known that, according to Kant, the transcendental describes an a priori condition of knowledge of objects.9 In particular, the enquiry into the transcendental unity of apperception, involving the transcendental synthesis of imagination, is said to be the principal point to unfold elements for cognition. In other words, the quest into the transcendental  established at the level of receptivity – the manifold of the sensible – and the level of imaginary production. Nevertheless, for Kant the synthesis of imagination in terms of a given conceptual schema corresponds to the unity in intuition and judgement of the real.10 On the other hand, however, for Kant the synthesis of imagination is also said to precede concepts and thus to depend on a pre-conceptual intuition. This unity of understanding therefore is predicated on a deeper paradoxical unity between concepts and intuition in so far as understanding itself already presupposes a conceptual schema of what can be understood. Kant’s articulation of the unity of intuition and conception remains crucial for the argument about critique that precisely implies an enquiry into the limits of understanding, and what is beyond the cognitive capacities to analyse and synthesize unknowable noumena. From this standpoint, the transcendental synthesis of imagination is also caught in the paradox where intuition is and is not produced by understanding (i.e., the function that gives unity to a judgement).\n"}
{"prompt":" ->","completion":"  In other words, imagination is both caught within the unity of understanding – the procedural analysis and the conceptual synthesis of the external world – and within the world of the sensible and preconceptual intuition. Imagination is thus part of the transcendental relationship between intuition and synthesis. However, if the unity of understanding explains that this relationship is rooted in the metaphysics of deduction, how could the world ever be thought beyond what has already been conceived of it? While the transcendental synthesis of imagination implies that intuition is both conceptual and pre-conceptual, according to Wilfrid Sellars, there needs to be a place to explain 11  to intuitions derived from the transcendental synthesis of imagination, sheer receptivity corresponds to passive representations, which are not conceptual: namely Humean raw impressions of the world. Sellars advocates for a connection between the mind and the world, insisting that the manifold of sheer receptivity is a form of intuition whose transcendental condition is neither determined by given concepts nor in the pre-conceptual experience external to thought. Instead, this connection is also granted by the non-conceptual representation of individuals; namely, involving a process of abstraction for and of thises. Rather than matching individuals to general concepts, intuition coincides with a demonstrative formation of concepts and accounts for simple representations that are not pre-determined by the conceptual idealism of cognitivism. Far from grounding thought in pure reason (a reasoning without demonstration) as the motor of deductive metaphysics, we have here a “raw” manifold that guides representations without becoming predetermined by a priori concepts, truths and axioms.\n"}
{"prompt":" ->","completion":"  As opposed to the deductive ﬁt of particularity to generalities, the demonstrative representation of the world rather implies a process of abstraction of those primitive, simple and passive representations as material elements that enter the formation of concepts and as such connect the world with thought. From this standpoint, the transcendental synthesis of imagination is bootstrapped to sheer receptivity as deﬁning only one part of intuition. In particular, according to Sellars, the encounter of receptivity with spontaneity explains how intuition further comes to drive productive imagination.12 Here, the transcendental condition of imagination is not determined by concept-involving intuition, but rather implies  particular image that enters transcendental synthesis of imagination to become a concept. Here productive imagination corresponds to the formation of objects that do not simply reproduce but add new dimensions to the recipe of forming images. Instead of a transcendental imagination caught between concept-involving or pre-conceptual intuitions, the connection between thought and the world can be said to start from non-conceptual patterns. This involves the receptivity of a raw manifold of representations that enters the productive layer of imagination, forming patterns of patterns. As the receptivity of patterns lies at the core of a predictive or telepathic patterning of alien imagination, it remains constitutive of what can be thought. It is precisely this asymmetrical connection in a double dimension of intuition between the moments of reception and conception that has entered the predictive patterning of machine thinking pushing towards the alien transcendental.\n"}
{"prompt":" ->","completion":"  From this standpoint, the enquiry into the alien transcendental is also an effort to discuss the function of predictive thinking within the space of critique. We know that the connection between apperception and imagination grounds critique within the limits of what can be thought and known. This connection, however, is the elastic band of critique: it stretches to remain the same. Since nothing comes from nowhere, all that is thought has a place in schemata (rules of determination and the concepts representing these rules). Nevertheless, if the task of critique is not to verify premises but to open the procedure of veriﬁcation to what cannot be known in advance, then critique can run parallel to the function of predictive thinking, where intuition – sheer receptivity and pro-  truths into alien concepts forming patterns of patterns across the neural architecture of artiﬁcial intelligence. 3 fallibility With the modern question of technology already came the realization that thinking did not conform to the self-consistency of ideas. Thinking had instead to be pursued by means of a transcendental tool or procedure, such as the unity of understanding through which the contingent world could be analysed, calculated and quantiﬁed. It was through the reasoning procedure of understanding, however, that dogmatic truths could be defeated in the name of self-determining analytics of the unknown, a self-limiting apprehension of its outside.\n"}
{"prompt":" ->","completion":"  As philosopher Denise Ferreira Da Silva puts it,13 the transcendental tool is central to the constitution of the global idea of race, namely explaining that colonialism is a global affair conducted by the scientiﬁc and historical analytics imparted by the transcendental schema of the self-determining knower. However, if reasoning, as a transcendental tool, is granted by the synthesis of imagination, it too must admit within itself the alienness of productive imagination, whereby incomputables (non-patterned inﬁnities) become a condition for alien thinking to enter the constitution of what is thought. It is arguable that there can be no unity of understanding without the function of compressing inﬁnities. It is precisely because of this function that complexity had to be admitted in procedural reasoning. From this standpoint, as much as the analytics of understanding relies on procedural reasoning or rule-obeying patterns, so does synthesis work through predictive patterning. In the attempt to compress inﬁnities to ﬁt procedures, however, incomputables enter  With the Second World War, when cybernetics and computation turned the transcendental tool of reason into the automated analytics of information machines, deductive metaphysics was overcome by an accelerated transformation of logos into ratio. Here, truths as much as incomputables became the testing ground of predictive reasoning carried out in the algorithmic architecture of analytic machines. According to logician Gilles Dowek,14 in the early twentieth century algorithms were no longer used to prove propositions but embodied the reasoning procedures that would determine the decidability of a problem, that is whether inﬁnities could be analysed or broken down into discrete sets.\n"}
{"prompt":" ->","completion":"  In particular, David Hilbert explained that when a problem was resolvable by an algorithm, algorithms themselves could be said to be decidable or computable. In other words, algorithms were no longer used as a set of instructions to prove a problem but came to concretize reasoning as the binary decidability between true and false. The determination of unknowns coincided with the elimination of logical contradictions through the binary compression of inﬁnities. Reﬂections on the automation of reasoning led Alonzo Church and Alan Turing to claim that there was no universal decidable algorithm for all propositions.15 It was not possible to know in advance, and thus decide, whether a proposition could be proven by algorithmic means. This led to a logical paradox: there are true propositions that cannot be proven by deductive rules and are therefore undecidable or incomputable. In other words, the automation of decidability revealed that algorithms were not simply instruments for crunching numbers but a mode of reasoning that entailed the realization that deductive metaphysics was incomplete. As much as reasoning was con-  image of Singularity as a mindless, logic-less patterning for decision making. However, it seems crucial to remark here that the socio-technical design of error-free and self-correcting automation is in net contrast with the problem of the incompleteness of deductive apprehension, and the discovery of incomputable propositions in the automation of logical thinking.\n"}
{"prompt":" ->","completion":"  This contradictory expansion declaring the crisis of logic and metaphysical deduction that was ultimately replaced by binary decision implies rather the origination of a logic of prediction that shifted the limit of thought even more towards the alien horizon of inﬁnities. Prediction as a statistical mode of information compression therefore implies that outputs are larger than inputs and that the logical possibilities of analytics and synthesis had to shift from a procedure of proof ﬁnding to one of hypothesis making. Here, while information compression involves the structuring of randomness (the reduction of error) in the evolution of neural patterns, the formation of hypothesis implies the generation of imagemodels (or the formation of patterns of patterns). It is true to say that the entire process of prediction entails a general mode of analytic synthesis, whereby data are correlated by algorithmic rules. However, incoming data are not simply there to be compared (or correlated) to a database of previously encountered images – following, for instance, a syntactic order – but rather to be analysed according to general internal rules from where the model used to generate input patterns is inferred and selected. From a matrix of possible causal structures able to predict the causes of current data to the bottom-up inﬂux of data against which predictions are matched or checked, predictive processing exposes multiple levels of hypothesis, which seem rather to point to a new form of  machines. On the contrary, the automation of reasoning in terms of predictive patterning can be said to rely on fallibility as an intrinsic part of machine logic.17 Instead of grounding logic into the transcendental schema of truths, here the conceptual synthesis of the real is originated in a procedure (the predictive processing of incomputables) that admits the indeterminacy of results as the possibility of revising the entire schema of rules. If the condition for logical thinking is error, or the fallacy of hypotheses, it is because the concretization of logic in machines entails not the algorithmic representation of rules but the predictive processing of incomputables and thus the origination of an alien transcendental from within machine imagination.\n"}
{"prompt":" ->","completion":"  It is in this opaque zone of transformation of deductive metaphysics and of the image of the master patternist that alien logic in machines can be theorized. Indeterminacy can be tracked from within the neural layers that the master patterninst has to learn to learn. It is in this effort to learn in order to grow the network that the patternist must enter the reality of alien thinking and admit incompressible thought within its own program. In Mind of My Mind, Octavia Butler points to this possibility of breaking down the colony of the master patternist Doro as slaves become trained to transition to the alien pattern held by Mary. As Mary achieves her state of transition to psionic powers, she discovers that she can give access to her network to enslaved latents that can now transition from their status of sheer receivers. In this way, Mary wants to re-originate the pattern, training latents telepathic abilities to override Doro’s transcendental machine. The replacing of Doro’s master algorithm allows everyone to transition to the power of predictive patterning. indeterminacy of results is here part of fallibility in prediction.\n"}
{"prompt":" ->","completion":"  Mary’s ambition to change the transcendental schema of patterns thus admits fallibility in logical reasoning. Since incomputables are the condition of all patterning, it is necessary to invent image-models of logical thinking that allow the pattern to be free to grow its rules again. From this standpoint, prediction – as determining what can be known – and fallibility – as revealing that nothing is fully possible to know – seem tantamount. Control is here on the same wavelength as error: prediction is entangled in the indeterminacy of the real. However, this being conditioned by what cannot be known (cognized, represented, and experienced) also exposes indeterminacy to a becoming enfolded in the aesthetic capacities of patterning, in the production of modelimages where truths are constructed collectively from within this logic of fallibility and control. This is a far cry from the regulatory prediction–control dyad of ﬁrst-order cybernetics, where control is precisely an ordering system based on error checking activated in and by machines. Instead, control as a logic of prediction is limited by incomputables that condition the conceptual schema of rule-obeying algorithms. From binary logic to Bayesian algorithms, and the interactive algorithms of neural networks of today’s computation, the logic of prediction corresponds to a mode of machine thinking involving an abstract form of telepathy based neither on the totality of cognitive transparency nor on the full experience of the sensible.\n"}
{"prompt":" ->","completion":"  Predictive procedures of thinking are not simply reductive of experience, or of creative imagination. Instead, algorithmic machines as modes of automated reasoning deﬁne partial acts of perception as they physically record and conceptually elaborate what has been  of ontology, in its aesthetic and epistemological conﬁgurations. Failure as a common condition does not mean that errors are proof that no logic can hold. On the contrary, fallibility is a commitment to logic as an expansive enterprise in thinking complexity, working through the revision of premises, the articulations of errors, and the construction of image-models out of given representations about the relation between thought and the world. In this way, the fallibility of logic does not simply deﬁne the ontological condition of machine thinking; instead, the predictive trajectories of thinking transform the regulatory operations of error checking into a mode of learning from learning, the abductive preservation of error in imagemodels out of recursive loops in neural nets. 4 xeno-imagination In 2016, AlphaGo used a previously unheard of move (Move 37) to beat master player Lee Sedol at the so-called intuitive game of Go.18 The Deep Mind research group at Google used deep neural networks feeding algorithms with 30 million moves from expert players and then added reinforcement learning techniques to allow algorithms to play against each other in countless variations of these moves. The results from this ﬁrst level of algorithmic war were then fed into a second neural network in order to directly process potential results from each move, and thus activate a dynamic mode of prediction where hypothesis could be concretized from the machine production of counterfactual image-models. From this standpoint, when the machine played Move 37 it was as if the artiﬁcial intelligence added an entirely new pattern to the game, breaking apart from the predictive affordances of algorithmic learning imputed in the system.\n"}
{"prompt":" ->","completion":"  The activation of this  interact amongst themselves and activate a form of machine synthesis of imagination, imparting a level of decision that could not have been anticipated. Pattern compression precisely deﬁnes the computational process by which complex levels of randomness enter the realm of patterning, where unpatterned information coincides with noise entering the horizon of decision making trifurcated between yes, no, and maybe. As AlphaGo demonstrated, the move is not simply a nuanced variation that can be added to a given set of fed patterns, but imposes an entirely new model image on the axiomatic premises of the game that activates a ﬁeld of unknown changes of rules. The content of Move 37 represents not simply the accelerated processing and self-regulation of data but the predictive construction of a counter-factual hypothesis held in the neural network that transforms the game conceptually. While there is much to uncover about what caused AlphaGo to make this move and not another, and thus whether AlphaGo has any awareness of why that move was chosen in that context, it is also important to stress here that this seamless opaqueness of machine learning algorithms can be viewed in at least two ways. On the one hand, it can be suggested that in this case patterned intelligence only demonstrates an increased and accelerated capacity of pattern recognition as a form of sheer receptivity that mainly allows algorithmic performance to become operative of new solutions without knowing why. On the other, however, it is not possible to underestimate that the paradigmatic shift towards general artiﬁcial intelligence – where algorithms are not pre-programmed but are programmed to learn from their environment19 – has rather exposed the Patternist to transform its rules as predictive patterning  sheer receptivity, the conﬁguration of an alien imagination comes to abduct the master pattern as a whole. If in Mind of My Mind Mary pushes the master network to an internal revolution, it is because Mary’s telepathic power too invites in the alien imagination for what patterning can become as it mingles with randomness.\n"}
{"prompt":" ->","completion":"  Pattern recognition as a manifestation of algorithmic compression takes randomness to be a source of confusion that must be ﬁltered to a point of automated decision. Instead, as in general artiﬁcial intelligence, it is suggested here that since patterns learn for general purposes that are not pre-codiﬁed by formal logic, they have come to depend upon what and how unpatterned information can become compressed. In order to carry out a decision in those cases where there is thinking without a model of the object, machine imagination kicks in to include incomputables within the procedures of automated logic. This may become clearer if we take, for instance, current research developments in machine vision, where patterns of recognition are designed to rely on dynamic geometries, such as mereo-topology (or the study of parts and wholes) and encapsulated neural networks in order to grow beyond the transcendental categories of biased identiﬁcations. Let’s take, for example, cognitive psychologists and computer scientists Sabour, Frosst, and Hinton’s recent claim that the logic of the neural network on which machine vision is based is limited to conform to pre-established parameters. They addressed the need to re-design the procedural process by which algorithms can learn from each other across patterns in the neural network through what they call a “capsule network” – a form of AI that will enable machines to understand the world with images.21 In their 2017 research paper they argue that  scenario. It is therefore difﬁcult to teach algorithms to recognize a cat from different perspectives. Capsule neurons, that is small groups of crude virtual neurons, track only parts of an object – for instance the cat’s ear and nose – as these are positioned differently in space.\n"}
{"prompt":" ->","completion":"  According to Sabour, Frosst, and Hinton, this smaller scale of algorithmic receptivity enables a neural network to determine the difference between scenarios by extracting more understanding from a given amount of data. As the capsule network is made of smaller patterns set to recognize parts and break the continuity of an image into smaller units, they also designed a dynamic routing between capsules that trains these kinds of network. Capsule algorithms convert pixel fragments into vectors of recognized patterns and then apply a transformation matrix to these fragments to predict the parameters of larger fragments. In particular, the transformation matrix learns to encode the intrinsic spatial relation between a part and a whole, which results in the formation of an invariant viewpoint, a perspective or direction in thinking that aims to generate novel views. According to Sabour, Frosst, and Hinton, “capsules use neural activities that vary as [the] viewpoint varies rather than eliminating variations.”22 Instead of normalizing viewpoints according to methods such as the spatial transformer networks, capsule networks simultaneously engage multiple transformations of different objects or object parts. The dynamic routing therefore ensures that the output of the capsule is sent to the appropriate layer above it on a parse tree-like structure. Although the output is routed to all possible parents on this structure, the couplings are scaled down when for each possible parent the capsule computes a prediction vector by multiplying its own outputs through a weight matrix. This predic-  about the precise position of that entity in a region.\n"}
{"prompt":" ->","completion":"  Nevertheless, here there is still a replication of learned knowledge across space. In other words, capsule networks and dynamic routing also use Convoluted Neural Networks, which are said to cover larger regions of the image and thus carry repetitive patterns across layers. Information, however, is always placecoded here for smaller capsules and eventually rate-coded as higher level capsules come to represent more complex capsules with more degrees of freedom: that is, the dimensionality of capsules should increase as hierarchies are ascended. Similarly, since at each location in the image there is one instance of the type of entity that the capsule represents, the capsule model affords a form of distributed representation inspired by the perceptual phenomena of crowding, where neighbour parts shed the direct perception of an object. CapsNet architecture seems already to be exploring how patterns of recognition can become predictive vectors that impart a direction in complex artiﬁcial thinking. Instead of eliminating variations to reach an average capacity for general recognition, predictive vectors start from the sheer receptivity of all scales of variations in order to expand learning beyond set parameters. These variations are not simply read according to a given rule. Instead, their random complexity becomes a source for potential capacities of recognition of the inﬁnite varied parts that constitute a whole image in different contexts.\n"}
{"prompt":" ->","completion":"  At the same time, however, the sheer receptivity of these levels of complexity works to establish a potential or hypothetical relation between images that may or may not constitute a whole. From this standpoint, predictive vectors construct counterfactual dimensions of the image of a cat, for instance, pointing to an alien imagination that  discrete parts to the network also increase the volume of randomness in the system as the computation of inﬁnite levels of variations cannot be fully explained, programmed, represented before it happens. One consequence of including incomputables in predictive vectors is ultimately the transformation of the network into a mereo-topological space or what Alfred N. Whitehead calls the “extensive continuum.”25 This space of artiﬁcial reasoning, however, is grounded not in the dogma of deductive truths and inductive proofs but in the xeno-architecture of complexity logic: namely the learning of patterns from patterns. This implies not simply an optical representation of the real determined by given concepts. What algorithms perceive is not raw data, but involves a level of sheer receptivity of patterns that are already part of a manifold of simple representations. These are non-conceptual patterns that constitute the matter of rule-obeying inferences from where the synthesis of transcendental imagination can unfold. From this standpoint, it can be suggested that vector predictions are part of what can be perceived in terms of the speciﬁc informational and logical modalities of computational systems. In other words, information compression in neural nets is implicated in a series of inferential hypotheses, forging a dynamic bootstrapping between patterns and patterns of patterns.\n"}
{"prompt":" ->","completion":"  This form of mereo-topological dynamism in computational logic can also be explained in terms of the interactive paradigm in computation, which explains the limits of the Turing Machine in terms of the expansion of computational inferences outside the halting logic of classic formalism.26 This means that an interactive mode of revision of patterns is constantly at work between given algorithmic rules and hypothetical inferences. If predictions  are part of what can be perceived because predictive vectors involve a continuous patterning of patterns whereby algorithms not only categorize what they see according to what the system already knows but also launch hypotheses and conﬁgure image-models about what could be known. In other words, machine vision can also be said to entertain a series of inferential hypotheses that constantly add logical dimensions to neural networks. These are counter-factual constructions of extensive parallel paths of thought deﬁning the mereotopological extensions of predictive patterning about what an object is and could be, beyond average patterns of recognition. Here, machine perceptions correspond to a mode of pattern making distributed across the non-linear architecture of neural connections. In other words, pattern recognition is enfolded in a larger xeno-architecture of thinking of thinking bringing forward model-images of unknown thought into the world. As machines see patterns they also generate models to envision new patterns: the combination of top-down and bottom-up predictive vectors makes of machine vision a new form of power over and of thinking. Mary’s aspiration to grow a predictive pattern that could take over Doro’s master plan to enslave all thinking under his rule stems from her capacity to host a potentially inﬁnite number of particularities according to a mereo-topological order, where wholes are constantly reconﬁgured as parts that not only represent a given image but add counter-factual dimensions of thinking to it.\n"}
{"prompt":" ->","completion":"  Instead of proving the law of the master pattern, Mary’s telepathic power is set to transform the rules of the game altogether by expanding in larger scales of logical complexity, supplying non-conceptual patterns with alien conﬁgurations never thought of before. As sheer receptivity enters  algorithms can be taken precisely as tendencies within automated patterning towards adding extra dimensions of thought to the master network, descending and ascending towards inﬁnite varieties of layers within inﬁnite varieties of scales. Within this new horizon of automated conﬁgurations of image-models, however, one could argue there still remains a question of how to expose the alienness of patterning as a point of departure to re-script the entire rules of the Singularity network. disclosure statement No potential conﬂict of interest was reported by the author. notes 1 Butler 186. 2 Butler. 3 The so-called technological Singularity refers to the sudden intelligence explosion of artificial systems that would continuously self-improve without any need to be programmed or understood by humans or by human methods of knowing. Kurzweil; Bostrom.\n"}
{"prompt":" ->","completion":"  4 Sellars, Science and Metaphysics 5. 5 Ibid. 4. 6 Sellars, “Role of the Imagination in Kant’s Theory of Experience” 31. 7 Parisi. 8 From the standpoint of logical thinking, the counter-factual in general describes a conditional based upon an if-clause, which is contrary to a fact, or what has actually happened. While discussions about the counter-factual include aftermath  causality, whereby the fallibility of decision making is preserved within the formation of a hypothesisled logic stirred by a condition of trial and error and not by the mandate of fitting proofs into truths. In particular, this view is partially inspired by David Lewis’s counter-factual theory of causation and especially his early writings and reflections on possible worlds’ semantics referring to nonactual possible worlds as real concrete entities.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  READ MORE AT PLACESJOURNAL.ORG. Mapping’s Intelligent Agents Self-driving cars have sparked a “billion dollar war over maps,” but the cars are the most boring thing about it. How do machine intelligences read and write the world? And what Other intelligences deserve our attention? SHANNON MATTERN  SEPTEMBER 2017  Lidar view of a Palo Alto street. [Luminar Technologies]  We now take it for granted that our machines can sense almost any space in the world, from deep sea trenches to the chambers of the human heart. Building on thousands of years of research in physics, war, and natural history, doctors in the 1940s began using ultrasound to scan human and animal bodies. Taking cues from dolphins and bats and Leonardo da Vinci’s early echolocation experiments, naval scientists in the early 20th century learned how to detect mines and submarines with sonar.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Early cathode ray studies by Wilhelm Röntgen, Nikola Tesla, and Thomas Edison led to the development of x-ray photography, which enabled radiologists to see broken bones, art historians to read the layers of an oil painting, and physicists to study crystalline structures. roboticists, and engineers and technicians of all kinds, entangling them in what one 5 observer calls “a billion dollar war over maps.”  NASA Octocopter drone carrying a Lidar sensor. [Todd Freestone]  That’s probably an understatement, because the applications go well beyond self-driving cars. Everything from autonomous warfare to logistics to geo-targeted advertising depends on map superiority. On the friendlier end of the spectrum, maps drawn by AI have potential to transform myriad areas of research and design, and to influence policy and governance, starting with environmental protection and public health. With the stakes so high, we need to keep asking critical questions about how machines conceptualize and operationalize space. How do they render our world measurable, navigable, usable, conservable? We must also ask how those artificial intelligences, with their digital sensors and deep learning models, intersect with cartographic intelligences 6 and subjectivities beyond the computational “Other.” I’m using “intelligence” broadly here, to encompass the various ways that knowing has been conceived across disciplines and cultures.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  There are a lot of other Others — including marginalized and indigenous populations and non-human environmental actors — who belong on the map, too, and not merely as cartographic subjects. They are active mapping agents with distinct spatial 7 intelligences, and they have stakes in the environments we all share. depths and angles, so that they can simultaneously detect nearby lane markers, 9 construction signs on the side of the road, and streetlights in the distance. Radar sensors, unimpeded by weather, track the distance, size, speed, and trajectory of objects that may intersect the vehicle’s path, and ultrasonic sensors offer close-range detection, which is particularly useful when parking. Beyond those tools of looking and listening, most self-driving cars also generate a realtime map of the world. Light detection and ranging (Lidar) sensors bounce super-fast laser pulses off surrounding objects and measure reflection times to create a highresolution 3D model of the immediate environment. Unfortunately, these contraptions 10 are bulky and expensive and can be stymied by bad weather and reflective surfaces. Engineers are rushing to develop smaller, solid-state designs, which would simplify manufacturing and cut costs, even if it won’t solve the problems with environmental sensitivity.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Intellectual property related to Lidar was at the heart of the recent scandal that led to the firing of Anthony Levandowski, an Uber engineer who was formerly the 11 technical lead at Waymo. So the car “sees” and “hears” the world as an organized three-dimensional code-space, with signs and lines directing its operation; and, simultaneously, as an assembly of reflective objects — pedestrians, bicycles, other cars, medians, children playing, fallen rocks and trees — that may interrupt the order of that code-space, and with which each car must negotiate its spatial relationship. Driving is often challenging for humans because we must code-switch, as the car does, between different ways of reading and understanding the world, while also distributing our vision among different widths and depths of field and lines of sight (not to mention dashboards and text messages and unruly passengers). Human ears are multitasking, too. All this sensory processing, ontological translation, and methodological triangulation can be quite taxing. Tesla (which, for now, insists that its cars can function without Lidar) has built a “deep” neural network to process visual, sonar, and radar data, which, together, “provide a view of the world that a driver alone cannot access, seeing in every 12 direction simultaneously, and on wavelengths that go far beyond the human senses.” Waymo catalogs the mistakes its cars make on public roads, then recreates the trickiest  traveling against the traffic flow. [Waymo]  Self-driving cars match locally sensed data to HD road models like this one. [HERE Technologies]  And machine pilots (again, like humans) do not operate on real-time sensory input alone.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Just as we have Siri and Google and mental maps, driverless cars tap into external sources of geospatial data. Standard GPS is accurate within several feet, but that’s not good enough for autonomous navigation. Industry players are developing dynamic HD maps, accurate within inches, that would afford the car’s sensors some geographic foresight, allowing it to calculate its precise position relative to fixed landmarks. Layering redundant forms of place-awareness could help overcome ambiguity or error in locally sensed data. Meanwhile, that sensor data would feed into and improve the master 14 map, which could send real-time updates to all vehicles on the Cloud network. In other words, autonomous vehicles will rely on an epistemological dialectic, balancing empiricism with carto-rationalism, and chorography with geography. Lots of companies are building maps like this, including Alphabet’s Waymo, German automakers’ HERE, Intel’s Mobileye, and the Ford-funded startup Civil Maps. They send their own Lidar-topped cars out into the streets, harvest “probe data” from partner trucking companies, and solicit crowdsourced information from specially-equipped private vehicles; and they use artificial intelligence, human engineers, and consumer “ground-truthing” services to annotate and refine meaningful information within the captured images.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Even Sanborn, the company whose incredibly detailed fire insurance  the world as it is known to machines. Artist James Bridle used salt to create glyphs that confused autonomous vehicles, as seen here in Autonomous Trap 001. [James Bridle]  Machine Mapping for the Rest of Us Honestly, I don’t give a leaping Lidar about self-driving cars. Or any cars, for that matter. I just can’t get excited about innovations that fetishize personal mobility and the alienating, landscape-destroying, maintenance-intensive infrastructure that sustains it. What I really want to discuss is this: How can we use all these new and old technologies to improve the physical world that we humans (and our non-human companions) read and inhabit? Some urban designers imagine that the containment of vehicular traffic will 17 allow more street space for walkways and bike lanes and parks. Others note that we need to be intentional about how we redesign cities to accommodate the semantic preferences of our robot companions.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Geoff Manaugh mischievously suggests that the machines’ sensory quirks, like Lidar’s vulnerability to mirrored surfaces, might prompt us to consider “how we could design spatial environments deliberately to deceive, 18 misdirect, or otherwise baffle” autonomous agents. In a coming age of robot warfare and policing, we could see designers specializing in the creation of robot-illegible worlds rather than machine-readable ones. What further impact might these “other mappings,” have on spatial design practices? reciprocal, politics of vision and ethics of engagement. The operational premise here is similar to that underlying the self-driving car. We take it on faith that redundant data and multiple perspectives will yield greater precision, a better outcome, a higher truth. Comparison of drone, airplane, and satellite views of the Albany Bulb landfill in the San Francisco Bay Area. [Karl Kullmann in collaboration with 3D Robotics, for Landscape Architecture Magazine]  Even techie jargon like “Time to Reflect Reality” points to looming social and philosophical questions about how machine vision will change our conception of the physical world.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Artist James Bridle, who has made several works exploring the politics of automation, observes,  Self-driving cars bring together a bunch of really interesting technologies — such as machine vision and intelligence — with crucial social issues such as the atomization and changing nature of labor, the shift of power to corporate elites and Silicon Valley, and the quasi-religious faith in computation as the only framework for the 21 production of truth — and hence, ethics and social justice. landslides or floods might occur. Some clever cartographic triangulation is also  happening in the real Amazon, where environmental advocates have used satellite and drone imagery, supply-chain maps, and interviews with local farmers to identify newly cleared lands in Bolivia and Brazil. They have attributed nearly 2 million acres of deforestation to soybean farms that are allegedly supplying the huge American 23 agribusinesses Cargill and Bunge. Neural network learning algorithms are commonly used in geospatial analysis to identify changes happening on the Earth’s surface — from 24 deforestation to coastal erosion — and to predict future changes. The Disease Surveillance and Risk Monitoring project plots malaria cases alongside weather and topographic data to predict outbreaks, creating high-resolution risk maps that can be 25 used to prioritize mosquito control efforts across Africa. This is a variation on the “traveling salesman” problem: how to efficiently deploy resources, whether Uber cars or aid workers with vaccines. Development organizations are taking some of the same technologies that are fueling our driverless dreams and extending them into realms where ethics, environment, public health, and social justice are the primary concerns.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Using AI to predict malaria outbreaks. [DiSARM]  26  read nighttime and daytime images of the same regions, and to pick out variables, like roofing material or distance from urban areas, that contextualize clusters of nighttime light. Their model, trained also on World Bank statistics, learned to identify visible features — like roads, farmlands, and access to water — that correlated with nighttime 27 illumination and economic well-being. Such triangulation is meant to fill in the gaps in mapping but is not a real substitute for the kind of ground-level engagement that should precede policymaking or aid work. Meanwhile, Digital Globe and Stamen Design have built Penny, a mapping tool that uses machine learning to analyze satellite image indices of wealth. Eventually, planners could use the tool (which doesn’t account for income inequality) to select urban features that 28 promote wealthier neighborhoods. And researchers at MIT and Harvard have created Streetchange, which uses AI to correlate changes in cities’ physical appearance with 29 economic and demographic shifts and neighborhood “improvement.” While these are useful avenues of research, it’s important to remember that “poverty” is far more overdetermined and sensitive than any satellite image can capture. Poverty-as-lived is much more nuanced than its operationalization for any neural net.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  And urban planning should not be mistaken for an algorithmic “pattern language”; a city plan is more than a mere aggregation of spatial features an AI has correlated with “wealth.” Conor O’Shea makes a similar observation about the use of drones in landscape architecture. While drones and satellites, used in tandem, might help to critically reframe designers’ perspectives, “human-to-human interviews, community outreach, 30 political engagement, and research-based design strategies matter more than ever.” We need multiple eyes, ears, hands, sensors, and brains — automated and manual, digital and analog, machinic and human — on the case. Larimer and Orphan streets, which Joy Katz wrote about for Places in a very different register. [Terrapattern]  Cartography’s Intelligent Others So now we’ve examined the well-funded and widely publicized attempts to map the world as a code-space legible to machines. And we’ve considered efforts to use those machinic sensibilities and intelligences to solve perennial human and environmental challenges. Social researchers and aid workers are also using “other,” artificial intelligences to map human Others — the silenced, the vulnerable, the marginalized. It’s a noble gesture, to recognize the subjectivity of a historically invisible population by rendering it visible on the map. But that visibility can also mean vulnerability to harm or exploitation.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Since those human Others have long been absent in the datasets we use to make our maps, we now rely on methodological maneuvers and machine-readable proxies to render them mappable. We must take care not to equate the impoverished with the thatched roofs over their heads. Of course, the history of cartography is deeply entangled with statecraft and colonialism, 31 with the claiming of Other lands and the erasure of Other people. Yet indigenous groups have also embraced mapping as a means of “reclaiming their sovereignty over the lands, negotiating aboriginal rights, and regaining dignity during conflicts with 32 governments and institutions,” according to cartographer Sébastian Caquard. Often they have adopted the geospatial practices of their colonizers to concretize their land claims and try to shield themselves from land grabs and resource-extraction schemes. The politics of the overhead satellite view and the universal GPS grid — even the Euclidean demand for points, lines, and areas — do not always “map onto” the way traditional cultures relate to or conceive of their own environments. “The process of mapping,” Nancy Lee Peluso argued in an influential 1995 article, “almost forces the interpretation of customary rights to resources territorially, thereby changing both the 33 claim and the representation of it.” Rather than merely incorporating the Other as a map subject, we should think more  Navigational chart from the Marshall Islands, made of wood, sennit fiber, and cowrie shells. [Wikimedia\/UC Berkeley]  Those Marshallese stick charts, meanwhile, recorded navigators’ ability to identify nearby islands by sensing the disruption in ocean swell patterns.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Since the island navigators were charting reflections, we might regard their methods as analog antecedents to contemporary sensing machines like sonar and Lidar. Yet the meaning of reflected waves is entirely different for these human “sensors.” As Karin Amimoto Ingersoll explains in Waves of Knowing: A Seascape Epistemology, many surfers and traditional navigators in the Pacific cultivate “oceanic knowledge” by irrational, intuitive means, by fusing mathematics and physics — which are among our computational sensors’ strengths — with dreams, vibrations, and oral histories. It is an approach to knowing through a visual, spiritual, intellectual, and embodied literacy of the ‘āina (land) and kai (sea): birds, the colors of the clouds, the flows of the currents, fish and seaweed, the timing of ocean swells, depths, tides, and 36 celestial bodies all circulating and flowing with rhythms and pulsations. …  That knowledge simply couldn’t be captured on the maps created by voyagers like Captain James Cook, who sought to locate all points of significance on a “static grid of 37 coordinates,” relying on stable coastlines for cartographic reference. Ingersoll argues that the European ideology of acquisitive exploration is reflected in a cartography based on categorization and control. In contrast, Pacific Islanders’ maps are “inherently mobile.” They make possible a type of movement that involves dynamic interaction between the islands, sea, stars, and those bodies floating between them. “In Pacific 38 navigation, the map moves with the voyager.” (See also the Italian Limes project,  Anthropologist Stefan Helmreich studies how waves carry different meanings for cosmologists, cardiologists, artists, oceanographers, surfers, economists, and social theorists. Ocean waves are formal, mappable objects, but they are also geographically specific, culturally shaped, and politically charged.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Just as automated cars are trained to operationalize “safety,” and machine learning models are trained to operationalize “poverty,” the swells we call “waves” are measured, parametricized, and modeled through buoy sensors and computer simulations. And those wave models and maps are trained primarily on northern oceans, which are much more heavily instrumented. Our southern oceans, much like our land-based cultures of the Global South, tend to be “data poor” — despite the fact that they represent a tremendously diverse and expansive ecology. The southern hemisphere has more uninterrupted ocean, is hit by much more solar radiation, has extensive coral and mangrove depletion, and has more ice, which is breaking up as the climate changes. We need more “thinking from southern oceans,” Helmreich argues 40 — and, by extension, more modeling and mapping “from below,” too. Even as we turn to sophisticated computer models to understand global climate change, we should remember that many human communities have already vividly imagined their own climate futures (as well as climate pasts and presents). As environmental geographer Annette Watson and traditional hunter Orville Huntington explain, “indigenous peoples have been enrolled in climate change research for decades, participating in datagathering, as writing collaborators, and serving as the symbolic ‘canary in the coal mine’ 41 for public outreach and policy-making.” Yet their intimate local knowledge, their distinctive “seascape” or “icescape” epistemologies, are often filtered through Western Enlightenment methods and conventions. Much is lost in that filtering.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Oral traditions chronicle environmental shifts that unfold over many generations, much longer than Western science has been collecting environmental data. And there’s often a sacred or spiritual dimension to their cosmological and geological knowledge, which rarely fits 42 into geospatial data models. Watson and Huntington note that in the Koyukon communities of Alaska, ecological “respect” is a primary virtue: “Showing respect means that an individual understands ‘their proper place’ in relationship to Other beings, both 43 animate and inanimate.” “Respect” implies a critique of the Western fetishization of 44 technology and the desire to witness, map, and catalog everything. They Would Not Take Me There; People, Places and Stories from Champlain’s Travels in Canada, 1603-1616. [Michael James Hermann and Margaret Wickens Pearce]  Detail from They Would Not Take Me There. Yet efforts to listen and learn from those Other cartographies can easily go awry. According to a Google blog post, the Anangu Aboriginal nation recognizes “no distinction between the physical and metaphysical, or the animate and inanimate. People, earth, 47 plants and animals are inextricably connected.” Not easily deterred in its quest to “organize the world’s information,” Google sought to “bring these cultural and spiritual dimensions to the Street View Experience” by supplementing the map with oral histories and songs in its Story Spheres platform.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  The company partnered with the “traditional owners” of Uluru-Kata Tjuta National Park and the regional government to “celebrate and preserve Anangu culture through technology.” Yet when I “visited” the park through street view imagery captured (in accordance with Tjukurpa law) by a regional tourism agent, the dimension I sensed most clearly was my own Otherness. I felt like an intruder. This act of “rendering visible” only reminded me of the embodied experience and 48  Louis transit, and so forth. Subsequent visitors could then take those maps, and project geo-rectified historic maps or city data on top, exploring new correlations. As Jer Thorp of the Office for Creative Research explained, the maps were intentionally big, to allow various physical modes of interaction: “Groups of people can gather around a map to look at it from different vantage points. People can walk across the map, 49 experiencing distance in a meaningful way.” Shifts in scale and perspective abet a new spatial awareness. There’s a material politics at play here, too. Those large sheets structure collaboration and conversation, and they represent civic intelligence — a mix of official data and “indigenous” knowledge — writ large.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  They will become part of the official archive of St. Louis; and the Map Room hardware, plans, and curricula will be open-sourced so that other cities and towns can repeat the experiment. Thorp told me a 50 Map Room New Orleans is in the works, as well as a few projects in Canada. Missouri History Museum staff making a collaborative map at the St. Louis Map Room. [via Twitter]  Non-Human Mapping Agents Many of those who participated in the program had never before been granted authority to reimagine their city’s geography. While community mapping projects are not  means of experiencing and representing place, between quantitative and qualitative methods, satellite views and fieldwork, rationalism and empiricism. Non-human mapping agents — from Lidar sensors to drones to plotting robots — can be critical agents in the cartographic enterprise. Yet the non-human Other is also an agent in those landscapes we seek to map. As we’ve already seen, fish and waves dominate Pacific Islanders’ seascape epistemologies; ice and hunting paths shape Inuit maps; and flora and fauna are central to the landscape imaginaries of environmentalists and extraction companies alike.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  In most Western frameworks, non-human Others, from animals to plants to minerals, are represented as resources to be exploited: things to eat or mine or look at in a national park. But now the convergence of certain new ways of thinking — Anthropocene studies, new relational ontologies, Latourian actor-networks, feminist ethics, and what Donna Haraway describes as “SF” thinking, science fiction, speculative fabulation, string figures, speculative feminism, science fact, so far — has inspired many contemporary mapmakers to think about how to represent these Others not merely as human resources, but as entities with equal claim to the landscapes they inhabit, and with 52 their own spatial intelligences. Over the past 15 years or so, we’ve seen rising interest in animal geographies. Henry Buller, who wrote a three-part literature review for Progress in Human Geography, argues that this work advocates for “an interspecies contact … based upon a more convivial, less fixedly human and more risky approach to boundaries, to political actors and to political outcomes that inherently challenges what it means to ‘belong’ or to ‘pertain’ to a 53 particular terrain.” Other species have preceded humans, and they co-exist with humans, in pretty much every terrain — even those where they are now considered “invasive” or “pests.” Researchers are recognizing, through these other species, the existence of multiple intelligences and spatial ontologies that exceed human capacity, and they are devising methodologies to “reveal what matters, or what might matter, to 54 animals as subjective selves.” How do other species perceive their own environments? modes. Slime molds use their slime trails to remember where they’ve been. Even the  “crown-shyness” of some tree species, i.e. the maintenance of channels within their 57 canopy, “could be seen as a map-like striation of space, a sort of territorialization.” Animal space is “a lived space, multisensorial,” argues Dennis Skocz, and GIS and other 58 conventional mapping techniques are ill equipped to represent it.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Of course we humans can never know “what [it’s] like to be a bat,” as philosopher Thomas 59 Nagel reminds us. Any attempt to represent, witness, or embody non-human subjectivity involves translating that experience through our own human senses and minds. Yet we cannot deny that these Others “have experiences fully comparable in richness of detail to our own.” Acknowledging that they share our cartographic terrains, and that their spatial experiences are rich and relevant, maybe even as critical foils to our own, can help us appreciate the immeasurable diversity of our environments. For example, the Lower Elwha Klallam Tribe in Washington is documenting the restoration 60 of the Elwha River after dam removal through “Fishview” maps, which is just one of the many mapping projects that center animal migrations or responses to changing 61 ecological conditions. Catherine D’Ignazio argues that “what we gain from these [Other] mappings is situated, rich knowledge about the spatial experiences of beings other than ourselves (knowledge that could be incredibly useful for scientific research) 62 as well as an awareness of how things could be different.” Environmental artist Ellie Irons corroborates the importance of “seeing from other species’ points of view” — especially from the view of uncharismatic species like weeds and fungi — “even if we know that, in the end, it’s somewhat impossible, and even hubristic” to imagine that we 63 understand their experience. as small as local food systems. The Environmental Performance Agency, created by  Irons and collaborators as a rogue EPA in the early days of the Trump administration, conducts similar work. Many of these artists conceive a non-human that extends well beyond the animal.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Rachel 66 Strickland’s video work explores “the social lives of urban trees.” Nina Katchadourian finds cartographic resonance in patches of moss, while Heather Burnett investigates slime mold navigation. Irons not only studies the geography of weeds, but also uses their pigments to map them. D’Ignazio gives flowers a voice to address the water quality in their habitat, and Karolina Sobecka maps clouds, and the microbes that live in the troposphere, as environmental agents. Lauren Rosenthal has created an atlas where political boundaries are replaced by watershed divides, imagining a world in which ecological markers are as politically powerful as culturally-defined states. Lauren Rosenthal’s River Atlas. In their review of conservation maps, Leila Harris and Helen Hazen interrogate how we use such maps to “cite, reconsider, challenge, or reify particular power relations between humans and non-human ‘others,’ solidify certain spaces as appropriate for particular species, [and] generate notions of ‘desirable’ species that we seek to conserve.” They propose that conservationists avoid maps that (1) present humans and non-humans as separate; (2) privilege Western cartographic practices; (3) favor spaces and subjects that are deemed more mappable; (4) frame all issues as territorial; and (5) privilege the static and localizable over the fluid, seasonal, and shifting. The ways that maps are created, funded, studied, and mobilized have profound implications for policymaking, governance, and the deployment of conservation resources, which may determine “the  this creature’s life; and, further, how maps and screens and sensors have profoundly 69 changed the ways humans relate to the natural world. This gorgeous project, while not easily replicable or scalable, offers an exemplary map of multiple intelligences, while also embedding a critique of its own technologies of cartographic representation.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Screenshots from the virtual reality environment Bear 71. [National Film Board of Canada]  In 2016, the Office for Creative Research partnered with the Great Elephant Census and various NGOs to document the decline in Africa’s elephant population, which dropped 30 percent from 2007 to 2014. Wildlife and park staff and pilots crossed the continent in low-flying airplanes, conducting a survey of live and dead elephants, as well as other wildlife, livestock, humans, houses, and environmental features, so that researchers 70 could explore relationships between these variables. All that data was mapped, contextualized, and made query-able on The Elephant Atlas. The website describes the census methodology and explores the impact on elephant populations of global forces  Screenshot from The Elephant Atlas. Mapping Intelligently Elephants are renowned for their spatial memory. Behavioral observations have long shown this to be true, but scientists recently corroborated the empirical evidence by outfitting elephants with tracking collars that monitored their movement toward widely 71 distributed watering holes on expansive, featureless terrains. As advanced sensing machines and spatial technologies become cheaper and more powerful, we will see many more studies like this.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  Aided by aerial imagery and GPS, binoculars and audio recorders, we can now map everything from elephants and refugees to icebergs and Ubers. We should do so critically and intentionally, bearing in mind that those subjects and agents have their own geographies and spatial sensibilities, and so do the instruments we use to map them. Increasingly, we turn to artificially-intelligent sensing machines — with their purportedly more objective, efficient, exhaustive, and reliable means of observation and orientation — to shape the protocols and politics of interaction among the various beings who share our cartographic terrain. Yet we must never forget that those computational instruments operationalize space differently — differently from one another and from other “species” of intelligent agents, including us. Drones and dragonflies sense and navigate the world in unique ways. Sonar and Lidar construct distinct empirical terrains, hearing and flashing their environments into existence. Satellites abstract terrestrial realities into macro patterns: from 500 miles up, the geography of hardship is a patch of thatched roofs. These new, artificially intelligent agents may well generate efficiencies in transit and logistics.\n"}
{"prompt":"Mapping’s Intelligent Agents ->","completion":"  They might offer insight into how certain groups of people messed up the world, and how we can fix it. Yet these computational intelligences, and ours, aren’t the only ones that have a stake in that world’s evolution. We need to recognize the world’s myriad  YOUR SUPPORT MAKES OUR WORK POSSIBLE. DONATE TO PLACES  SUBSCRIBE  AUTHOR’S NOTE  I’d like to thank Scott Bishop, Catherine D’Ignazio, Elizabeth Ellsworth, Matthew Friday, Ellie Irons, Jamie Kruse, Dan Phiffer, and Jer Thorp for speaking with me about their own work and sharing examples of other mappish art and design projects that explore non-human subjectivities and spatial intelligences. Thanks, too, to the dozens of folks on Twitter who responded to my request for examples of such projects, and who sparked a vibrant conversation: Shawn Allen, Jeremy Bushnell, Deb Chachra, Wayne Chambliss, Jeremy Crampton, Jeff Eaton, Yvette Granata, Robert Greco, Sam Hart, Federico Italiano, Daniel Cardoso Llach, Ben Lyall, Daryl Meador, Abinadi Meza, Joe Miller, Nathaniel Rivers, Timothy Schuler, Jonathan Solomon, Meg Studer, Harriet Walsh, Darren Wershler, and Mitchell Whitelaw. I also owe a special debt of gratitude to Mark Shiel and Roland-Francois Lack for inviting me to London to share this work in progress, and to Moa Carlsson and her colleagues in the Design and Computation Group and the Department of Architecture at MIT, where I tested a final draft. Thanks to all my interlocutors at both venues — and, as always, to Josh Wallaert and Nancy Levinson. NOTES  Embarks on a High-Tech Overhaul,” The New York Times, June 9, 2017.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  As Parisi argues, the variation of these faces is scaled based on the recursive enfolding of difference into universal or Promethean Man. IÕd like to use this example to provocate a set of propositions on haunting. IÕm particularly interested in examining how time and space configure into these computational iterations of human faces Ð faces that are said to not be real yet are based on the deterritorialized and reterritorialized dividual data of human faces. Thus, contained in these deepfake faces are the disjointedness or discontinuities that mark the spectral immanence of the (actual) human faces in the present. ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  Haunting and Algorithms Drawing from DerridaÕs concept of hauntology, a play on the pronunciation of Òontology,Ó haunting points to the non-full, non-total presence of being. In every being thereÕs always already an absence of presence, an inheritance, a trace of that which was and that which is to come. In every being there is a haunting. Haunting is a necessity of recursivity.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  As a process, finite models seek to compress infinite information, including that which is indeterminate to the modelÕs system. The modelÕs attempts to compress and recursively enfold indeterminacies into its logic produces a temporal break or discontinuity that points toward a haunting. This haunting is often unseen yet is affectively registered or perceived by those interpellated by the algorithm. It is a complicated and  02\/11 Synthetic images produced by StyleGAN, a Ògenerative adversarial networkÓ (GAN)Êcreated by Nvidia researchers.ÊImage credit: Nvidia.Ê Ê  Hauntology and Time Toggling the New York Times deepfake faces raises questions about how time and space is configured and enfolded into the curation of these digital productions. As Elisa Giardina Papa has illustrated, the generation of data for training affective computing is temporally and spatially situated particularly in the Global South, yet also processed by a technology that was developed from nineteenth-century  03\/11 ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  entanglement of the here and now, and especially Mark FisherÕs argument that haunting is also about the temporalities of technology that produce a virtuality, a relation of what is no longer and not yet, and a shaping of affects of nostalgia or anticipation. Yet, what I seek to advance on haunting are the ideas that it is fundamental to the recursive process, it is part of the logics of technologies, and it is both an analytic and computational process of potentiality. Again, the disjointedness of time and space affectively shapes and indicates spectral presence.   For Derrida, time was signified through the sign, a mark of the complicated and non-full presence of a ghost.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  I want to offer some propositions toward rethinking time and haunting, as well as their relation to the recursive. I also want to think through the political-ethical work of time, especially in relation to the problem of colonial articulations in the development of the human. Finally, IÕd like to leave us with some considerations of what I am calling a Black techno-conjuring and what it might offer us toward addressing, redressing, and\/or rerouting the fears, anxieties, desires, and anticipations of the political affect of the no longer\/what happened and the not yet\/whatÕs yet to happen.   Obviously, linear teleological time does not exist. Discrete categories of past, present, and future are inherited categories of modernism that were constituted by the interest in progress and the development of colonialism and capitalism. According to Alfred North Whitehead, there are only conceptual prehensions and persuasions of the future in the supposed immediate present. The past is immanent in the present. The Òwhat happenedÓ and the Òno longerÓ are enfolded in the present, encoding the fleshiness of bodily and techno-social systems.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Whether itÕs the neurobiological or neural network, the sociogenic code becomes reinforced through the spiraling feedback loops of recursion. As Mark Fisher described, the haunting of the past is instantiated in the disorienting experience of dŽjˆ vu or nostalgia where the past is immanent in the immediate occasion. I argue that this haunting event initiates the coding of the flesh.   The future is also immanent in the present. It is the virtual and what shapes affective anticipations and the constructed political necessity for algorithmic future prehension via prediction. The past is immanent in the future; it is futures past. The virtual becomes actual and the actual is shaped by the virtual. From the anticipation of the virtual, the not yet, the what is yet to happen haunts the event toward what Massumi has called preemptive logics of power.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Cybernetic ÒpredictionsÓ of the virtual are the preemptive logics of algorithmic governance that shape and become the actual. In other words, cybernetic ÒpredictiveÓ acts form the becomingactual that is haunted by futures past.   I am reminded of a passage from Claudia RankineÕs Citizen: You know feelings destabilize since everyone you ask is laughing that kind of  Recursion, Time, and Haunting Time is a fundamental part of the feedback loops from outputs to inputs in a recursive system. ItÕs  Time and Space  ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  Desire here is that which is the pursuit of knowability, recognition of affect, and even the potentiality of subversion. Yet, desire is also that which is already slipping the grasp of the present, becoming futures past.   The present is the heir of both the conceptual or perceived past and future. Replacing the category of history in MassumiÕs characterization of a Òhistory in the present,Ó I restate this as a Òbecoming-process in the present,Ó an affective becoming and material reconfiguring of encoded flesh. Yet, to be clear, the haunting presence is not colonial reason or whiteness, nor is it the creative indeterminacies of Blackness or the flesh.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Haunting, I argue, is the disjuncture or disjointedness that instantiates the recursive systemÕs inheritance and enfolding of colonial violence and racial subjugation. It is precisely the temporal skip or spatial discontinuity in the becoming-recursivity, as seen in the dis-adjustments of the toggled shifts in deepfake faces or the logo design of the Recursive Colonialism symposium website.5 And, with Parisi, it is that which is working in the interval between the finite system and the incomputable infinities. It is the tension thatÕs produced from the systemÕs recursive efforts to self-regulate and maintain the changing same of colonial reason (or whiteness) in the face of the incompressibility of the creative indeterminacies of Blackness or the flesh Ð what AimŽ CŽsaire called the colonialist encounter, yet in computational logics. political-symbolic matter? How is what Ramon Amaro has called the Black technical object configured or not configured in the computational production of these faces? 04\/11  known and this brings on the moment you recognize as desire. 4  As I mentioned earlier, history, time, and space (as in geography) were important in shaping categories of difference. As Denise Ferreira da Silva argues, it is through the temporalizing of categories, via HegelÕs and HerderÕs natural history of racial categories, that sociopolitical logics of raciality are produced.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  HerderÕs account of human history is situated in varying geographical contexts; he conceptualizes the development of the interiority of human groups by way of their achievements.   Da Silva states that Hegel replaces HerderÕs nature with Ò[Father] Spirit, a gesture that further apprehends the World as the Exhibition Hall of an entity that belongs in time, an interior thing. There he finds that Spirit had not É done its work on African minds and territories, for the Negro lacked the ideas that registered the SpiritÕs presence.Ó6 Through HerderÕs and HegelÕs move to make natural history and the Spirit the causal force of the development of a groupÕs interior capacities, they cemented colonial ideas of progress and development and, as such, the manifestation of sameness and difference via what Sylvia Wynter has called Man 1 and Man 2, or the cosmogonies of prototypical Man.   Consequently, time is not the only dimension in which haunting makes its appearance or apparition known but, as a significant premise in the conceptualization of the post-Enlightenment subject, time is also profoundly important for the spectrality of colonial violence and racial subjugation. In fact, time, history, and space (as demarcated by  05\/11 ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  longer and anticipations of the not yet that maintains or reinforces the changing same of the transparent subject. In techno-social and techno-political systems, haunting is the discontinuities and dis-adjustments of the recursive enfolding of the indeterminacies of Blackness that are a result of colonial violence and racial subjugation. Yet, I also posit haunting as a condition of possibility (or perhaps potentiality). That is to say, the fact of the apparitionÕs presence, its seething presence, demands address, redress, and\/or rerouting.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  I want to assert the utility of a technological reading and force that is in relation to haunting and the creative indeterminacies of Blackness, what I am calling a Black techno-conjuring, which has the potential to strengthen the influence of the diffractive.   In the Oxford English Dictionary, the third entry for ÒconjuringÓ is based on Caribbean and Southern US Black English. ItÕs an attributive noun in folk magic, religion, and medicine, such as the Òconjure manÓ or the Òconjure doctor.Ó ÒConjureÓ may refer to the trick or spell that has been placed on a body, while also being the work of ÒcuringÓ someone of a conjuring. While the algorithm may be possessed by colonial reason, and while Blackness is in part shaped by racial violence and subjugation, the haunting also conditions the possibility for the transformative force of the creative indeterminacies of Blackness. As Fred Moten reminds us, the forces of racial capitalism are necessary, yet not sufficient, for understanding Blackness, as racial capitalism conditions the very possibility for the infinite variability of Black performances. Thus, in relation to haunting, Black techno-conjuring brings forth two operations. The first is a reading of techno-social and techno-political systems that centers the metaphysics of Blackness as it seeks to trace the post-Enlightenment subject    The second operation of Black technoconjuring is a technological force that has the potential to reroute and alter the logic of the system. The discontinuities and dis-adjustments that emerge from the systemÕs limits to compress indeterminacies are part of the diffractive patterns that are residual in the GANproduced faces.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Borrowing from Karen BaradÕs articulation, diffraction is the way in which wave patterns overlap and how waves bend and spread when they encounter an interfering structure, producing differences that make a difference. The processed dividual data of human faces are diffracted through the generative adversarial network algorithm, the interfering structure, to produce the deepfake faces. The blurred spot and mismatched accessories of the algorithmic facial images are the diffractive wave patterns left in the wake of the GANÕs attempts to compress that which is incompressible, such as its inability to compress the creative indeterminacies of Blackness.   These indeterminate diffractive wave patterns in the wake of the GAN-produced deepfake faces also point toward the potentiality of computationally identifying, undoing, exorcizing, or conjuring the bodies of the racial Other in their diffractive wake. The computational identification of the diffractive wave patterns of temporal-spatial disjoint, I argue, opens up the possibility of a Black techno-conjuring reading of the haunting enfoldings of recursive logics. In other words, by identifying the discontinuities and disjointedness, it enables a reading of what happened, what happens, and what is yet to happen that occasions a potential address, undoing, or unmaking of the instituted violence that brought it into emergence. It is through such interventions that we might identify, exorcize, or conjure instances, moments, and openings  06\/11 Left: Henri Gouraud https:\/\/hist3d.fr\/le-futur-a-un-passe\/henri-gouraud\/. Right: Detail of anÊadvertisementÊfor Franz FanonÕsÊBlack Skin, White Masks.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  07\/11 ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  techniques in deep learning and artificial intelligence.   While sophisticated for its time, GouraudÕs 1960s wireframes methods are now part of a broader family of machine learning methods powered by artificial neural networks geared toward representation learning. These deep learning architectures produce results comparable to, and in some cases exceeding, human capabilities. As a result, it is increasingly difficult for the untrained eye to distinguish between an actual image seen through image capture (for instance, photography, film, or artistic representation) and those synthesized by means of deep learning (the so-called fake).   Although photorealism and human image synthesis technology push the boundaries of lifelike representation, DeepfakesÕs porn swaps seem to exceed a motivation to showcase the sophistication of the technology. ÒI just found a clever way to do face-swap,Ó Deepfakes commented in 2017, referring to their then newly created neural network training method.8 A deep tour through the history of human image synthesis reveals a rich playground for research and practice in human-centered technology. DeepfakesÕs choice to amuse themselves by making duplicitous scenes of women in sexualized situations is nonetheless notable. The face-swaps were not perfect, but close enough to reality to spark controversy and even a ban on the \/r\/deepfakes subreddit.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"    The limits of DeepfakesÕs desire are further disclosed at the site of sexual desire, stereotype, and gender representation. For instance, by intentionally face-swapping the idealized porn actress for the exalted Hollywood darling, Deepfakes effectively mutilated both by quite literally severing agency and everyday praxis for the purposes of technological experimentation. Despite this mutilation, we should all rest easy,  would. And it is the coderÕs stated responsibility to highlight the ethical concerns of machine learning by means of a violent example.   The moralist crusade against malignant techno-influence, although in the guise of the everyday programmer, is illustrative of the astounding haughtiness of synthesis. What I mean is that this superimposition of practices can help us understand how easily machine learning ethics can align itself with the same violences it seeks to mitigate; and how existing social constructs are open playgrounds where one can assume the role of ethicist based on the sole merit of an ability to code.   If deepfakes are, as Ezekiel Dixon-Rom‡n writes, Òthe disjointedness or discontinuities that mark the spectral immanence of the (actual),Ó then perhaps the synthesis of human faces is not novel at all, but the recursive composite of coder ethics and masculine desire. In addition, the fact that the staging for this synthesis is rehearsed in the image of whiteness adds an additional layer of necessary contemplation.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Perhaps in this way deepfake synthesis is more lifelike or like life than the ÒactualÓ images they are meant to represent. To use our example here, the actual reveals a techno-human state of being that restricts the inherent potential for a more fully realized machine learning. For instance, we are prompted to consider what it might mean when Deepfakes and others rely on existing figurations of masculine desire in the absence of a criticality that establishes links between itself, sex, the enduring violences against the feminine body, and issues of purity and deviancy.   Dixon-Rom‡n makes clear that our present anxieties about computation are haunted by a recurrent superimposition of whiteness onto the realms of possibility. This opening, as DixonRom‡n argues, provides a crucial opportunity for  08\/11 ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  Ramon Amaro The following reflections concern the mode of Black and technical existence; more so, they concern what I contend is the necessity to rearticulate the predominant notion of existence in relation to technology. By Òtechnology,Ó I refer to the application of technological tools or, following Simondon, objects that cannot be reduced to a mere utilitarian function. The technological object considered here resists temptations to reduce technology to the particular tools for use in specific domains or for particular purposes. Instead, I consider how the technological object is, according to Simondon, an ensemble of processes that, although they involve particular tools (for instance, the algorithm), emphasize the relations between algorithms and the humans who use them.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  I am interested in the way algorithms, as ensembles of relational processes between humans and data, might help further illuminate the complex relationship between human and racial processes. These are overridden by what Simondon describes as a ÒfacileÓ reality that constitutes itself in defense against the human stranger, or what I henceforth refer to as the Black object.   The concept of the Black object draws from Frantz FanonÕs writings on Black subjectivity and the existential reality of anti-Blackness. In Black Skin, White Masks, the Fanonian Black subject moves between the existential condition of dehumanization and the question of selfauthenticity. For Fanon, authenticity is not a process of legitimacy by virtue of being authorized or in accordance with whiteness or colonial law, but a state of being that seeks a genuine expression of self-image. Fanon has argued that in the absence of the latter, one is constituted under the duress of race not as a ÒrealÓ person with a real history, but as an object  differential virtues set forth by the enduring realities of otherness and non-belonging. This is no more apparent than in our predominant framing of the algorithm as either a tool engaged in the playful activities of the engineer or as an incubator of existing social strife. The most powerful cause of this resultant alienation resides in the conflation between a presumed command over the algorithmic as a mechanism for controlling and manipulating human social environments, and a seeming indifference to the key role humans play in our own social dysfunction.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"    This overly rehearsed play has already been set forth by enumerative logics of racial calculation, which is no more akin to preempting an equitable future today than it has been since the emergence of our obsession with social data. It is prescient, however, of an unmitigated techno-human desire to stage this confrontation of choice by maintaining mythical and imaginary ideals of holistic human behavior against the imposition of technological threat, effectively repeating the methods of exclusion that are already rehearsed, as Mbembe argues, on the peoples of the Global South.10 This ÒbecomingBlack of the world,Ó or what I might substitute with a becoming-Black of technology, is aligned more readily with the aspirations of a homogenous culture through the guise of objective representation than the aspirations of an authentic individual and collective Black being and becoming.   It is apparent that the significance of this violence lessens the actualization of the collective human species, which has yet to realize a sociality outside of the disintegration of the outsider, regardless of whether this foreign object is another human or machine. We are not unfamiliar with the idea of signification, whereby the outsider becomes the data type through  09\/11 ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  value might mean, let alone how it should be expressed.   Sylvia Wynter has already warned us that our contemporary conception of living value is preconditioned by humanist ideals of inter- and intraspecies hierarchy. According to Wynter, this grasping of hierarchal being is that which unifies perceptions of racial category and the staging of whiteness as the notional definition of the living ne plus ultra. Wynter turns to Fanon to show how this vague idea of interspecies superiority relies for its maintenance on the support of a theory of knowledge, resulting in a state of affairs that naturalizes the ill-derived fact of categorical difference. It is no surprise, then, as we sail through a new technological age, that a dominant minority in the guise of Big Tech would carry out this ongoing directive, whereby the scientific method, which was replaced by the machine gun, has now given way to the discriminating algorithm.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Let us not forget that one of the many values of WynterÕs thesis is in its illustration of the emergence of the category of the human as an irrecusable crisis of the white European Man, and the absolutism of his technological rationality. This is, of course, predicated on ManÕs assumed birthright over the epistemic model, wherein a new ordering of the world is installed as the recurrent byproduct of ManÕs resistance towards his own irrelevance. If a new social relation, or a new techno-human relation, is to be found, then Wynter is clear that the very conditions of human behavior through which human systems are realized must be understood as prescriptive of the Òseeking\/avoiding behavior[s]Ó through which one realizes oneself as this rhetorical human. One must, as Wynter posits, orient the parameters of the Òmotivation\/behaviorsÓ of epistemic order towards an interdiction of functions opposition to an inherited superiority.12  society as a whole other than to support a marketplace of identity, in contrast to a more nuanced set of ideas.   While we, the living, might continue to ignore this slide further into a reality whereby we summarily distinguish ourselves from that which we misuse or misunderstand according to use value, there still exists the inherent capability to live within what Fanon describes as a Òstructural harmony,Ó to pull us away from our fixation on the qualities of racial characteristics that we humans and algorithm hold so dear. Fanon defines Òstructural harmonyÓ as the sum of the individual and the conditions through which they emerge, including the constructed images of the self and environment. ÒWe shall see that this discovery is basic,Ó he writes. ÒEvery time the subject sees his image and recognizes it, it is always in some way Ôthe mental oneness which is inherent in himÕ that he acclaims.Ó13 Fanon believed that his cause for self-liberation from the constructed image of the idealized racial body image, and thereby the idealized social relation, is a self-evident one.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  After all, he did despise the blind faith that liberalism places in ultimate reconciliation and the harmony of interests through an appeal to reason.14   Today, how should we consider that this colonial appeal to reason has left a parting gift, namely the frantic double exposure of the racial image? On the one hand, the current human-tohuman relation is still largely saturated by images of a world constructed through epistemic whiteness. On the other hand, the technological object, in its ignorance, has been largely programmed to overwrite the complex dynamics of historical race relations, and has instead been designed to infer logical conclusions from a racist human history, as if this data is anything other than an ensemble of racial processes dragged through time on the instruction of the  Ezekiel Dixon-Rom‡nÕs Response In Boots RileyÕs debut film Sorry to Bother You, the character Cassius ÒCashÓ Green is struggling financially, lives with his girlfriend in his uncleÕs  10\/11 ember 2021 Ê Ezekiel Dixon-Rom‡n and Ramon Amaro Algorithmic Thought  technological and Black objects in an attempt to reach the best possible compatibility between these two worlds. While this modification of process might announce an awakening for both the human and technology from an intemperate historical coma, it also foreshadows the possibility of introducing new knowledge structures that can maintain distinctiveness both within and outside of category. But first, we must extinguish the grammars that lean towards the innateness of categorical strangeness and develop alternative ways to fulfil our aims toward a new techno-human temperament.   Through our colonial history, and the construction of the Black and technical object, an anxiety has effectively arisen that attempts to provoke a break within the recurrent speech arrangement of otherness. A more substantial awareness, or a more meaningful state of knowingness as the unifying principle of the techno-human relation, is a principal step towards the improvement of these conditions that can, alternatively, expand against the limitations of existing human-human and techno-human principles. It is here that the technical object finds its greatest potential in the dilution of practices that view racial processes, and even their mitigations, as matters of scientific discovery.\n"}
{"prompt":"Haunting, Blackness, and Algorithmic Thought ->","completion":"  Discovery, in this sense, is distinguished from perspectives of logical disclosure, in that discovery is tasked with reducing its reliance on making evident that which is already present in the racial imaginary, enabling a more fruitful engagement with the rhythms and arrangements of existence that exceed the caricatures of Black life. intervention aiming to rearticulate the predominant notion of existence.   Distinct from the discourses of Òrace as technology,Ó which are interested in the enframing and performative work of race, Amaro seeks to draw a parallel between Black existence and technical existence while also making Black existence a form of technical existence. He critically goes after discourses of representation and Black exclusion, or what Denise Ferreira da Silva has called a logic of exclusion, and he prioritizes what he sees as the self-affirmation of value in whatÕs always been there in the particles, spectacles, and specters that have been violently excluded in the homogenizing forces of modernity. This self-affirmation is not only a resistance to whiteness. It is also an affirmation of Blackness beyond the categorical constructs of identity and difference. While value has the potential to slip into moral and essentialist discourse, I read Amaro as going after an otherwise-valuing, alternative worlding that dismantles the inherited category of the Òhuman.Ó CassiusÕs character demonstrates the violent implications of homogenization, how these forces produce self-alienation rather than self-affirmation, and the ways in which selfidentifying enables a reified discourse of whitenessÕs lens of identity and difference. For capital in the film, Black existence is reduced to the thermodynamic energy of bodily production and is even enhanced via medical technology, transforming Cassius and his fellow workers into Òequisapiens.Ó This human-horse hybrid is seen as the ultimate replacement for human labor: the sentience of the human is embodied in the strength and energy of a workhorse; in other words, human sentience is converted to horsepower.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Cyberneticians reformulated ideas of reason to re-imagine both minds and machines as logical circuits. In doing so, early pioneers in neural nets and computing, such as Warren McCulloch, Walter Pitts, and John von Neumann, also created the epistemological conditions that underpin contemporary concerns with data visualization, big data, and ubiquitous computing. Keywords cybernetics, governmentality, neural nets, communication, memory, temporality “Real time,” “internet time,” “run time.” There is a seemingly endless vocabulary in our present for describing time in digital networks. What makes this surplus of language remarkable however is the stunning homogeneity of temporal modes being described. All this creative description refers, in one way or another, to notions of temporality as the emergent quality of network behavior. Time, in contemporary discourse, emerges from within systems. There are many temporalities, but none of them are outside of technical networks. The corollary to this obsession with temporality as a self-produced and modulated process is a concern about stasis or non-time.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Jamming, blocking, sabotaging, or otherwise “stopping” the network are all understood as usually negative (or at least destructive) acts. Such interruptions are often couched in a language of stupidity, psychosis, terror, opacity, and failure. Systems incapable of constantly assimilating change, variation, and difference are also systems that lack in contemporary parlance “resilience,” “smartness,” or “intelligence.”  fields ranging from neuro-science to finance to the social sciences.2 In this transformation, the “real” time of the 19th and early 20th century, the time of Henri Bergson, the time of a reality out there inaccessible to science, became today’s “real time,” a technical process, a time emanating from inside networks, a superficial design problem not a claim over an outside world awaiting discovery. This switch from real to “real” is also a transformation in epistemology from the search for truths in an external world, to the search for self-referential measures emanating from within our networks that underpins contemporary concerns about data visualization, ubiquitous computing, and “smart” networks. Our contemporary obsession with storage and “big” data emerges, I argue, from this history of memory and time in cybernetic notions of intelligence and networks. The Logical Calculus of the Nervous Net  Figure 2. Images of different states of nets. Source.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Adapted from McCulloch (1943\/1970, p. 36), public domain image. Figure 1. Mathematical theory of communication. Source. Adapted from Shanon (1963, p. 34), public domain image. shooting down planes in the terms of communication—between an airplane pilot and the anti-aircraft gun. These researchers postulated that under stress airplane pilots would act repetitively and, therefore, display algorithmic behaviors analogous to servo-mechanisms, and amenable to mathematical modeling and analysis. This understanding allowed for all entities to be “black boxed” so as to be studied behaviorally (Rosenblueth, Wiener, & Bigelow, 1943, pp.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  18-24). In 1943, inspired by this idea that machines and minds might be thought together through the language of logic and mathematics, the psychiatrist Warren McCulloch and the logician Walter Pitts at the University of Illinois at Urbana– Champaign, decided to take quite literally the machine-like nature of human beings. The pair would later go to MIT at 1952 at Norbert Wiener’s behest (Kay, 2001). Their article “A Logical Calculus of Ideas Immanent in Nervous Activity,” appearing in the Bulletin of Mathematical Biophysics, has now come to be one of the most commonly referenced pieces in cognitive science, philosophy, and computer science. There is a series of moves, both technical and conceptual, by which neurons could be made equivalent to logic gates, and therefore “thought” made materially realizable from the physiological actions of the brain. Not only did these moves reformulate psychology, but they also demonstrated a broader transformation in the constitution of evidence and truth in science. The model of the neural net put forth in this article has two characteristics of note that are critical in producing our  This discrete decision (true or false, activate or not) also made neurons equivalent to logical propositions and compatible with being though in the terms that define a Turing machine The second element of the model that is important here is the adoption of a strictly probabilistic and predictive temporality. Neuronal nets are determinate in terms of the future (they are predictive), but indeterminate in terms of the past.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  In other words, within this model, given a net in a particular time state (T), one can predict the future action of the net (T + 1), but not the past action (Figure 3). From within the net, one cannot determine which neuron fired to excite the current situation. McCulloch offered as an example the model (Figure 2) of a circular memory neuron activating itself with its own electrical impulses. In such a case, at every moment, what results as a conscious experience of memory is not the recollection of the activation of the neuron, but merely an awareness that it was activated in the past, at an indeterminant time. The firing of a signal, or the suppression of firing, can only be known as declarations of “true” or “false”—true there was an impulse, or false, there was no firing—not an interpretative statement of context or meaning that might motivate such firing. Within neural nets, at any moment, one cannot know which neuron sent the message, when the message was sent, or whether the message is the result of a new stimulus or merely a misfire. In this model (Figure 4), the net cannot determine with any certitude whether a stimulus comes from outside or from within the circuit; whether it is a fresh input or simply a recycled “memory.” Put another way,  of the actual operations of the neurons.4 “But one point must be made clear: neither of us conceives the formal equivalence to be a factual explanation. Per contra!” At no point should anyone assume that neural nets were an exact description of a “real” brain (McCulloch & Pitts, 1943\/1970, p. 22).\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  In fact, nets are not representations, they are methodological models, and processes. McCulloch and Pitts discussed this logical reasoning as an experiment, a machine perhaps like the ones described by Deleuze and Guattari in Thousand Plateaus (1987), that does not describe a reality, but rather helps scientists and engineers envision new types of brains and machines, and challenge what scientists thought they knew about how mental processes work. McCulloch went even further to propose that logic was not reasonable, but actually, psychotic. He proudly announced that the nature of computing is analogous to a psychotic mind: What we thought we were doing (and I think we succeeded fairly well) was treating the brain as a Turing machine; that is, as a device which could perform the kind of functions which a brain must perform if it is only to go wrong and have a psychosis . . . (von Neumann, 1948\/1986, p. 422)  Figure 3. Neural net structures expressing the indeterminacy of the past, as signals may come through a number of different routes. Source. Adapted from McCulloch (1943\/1970, p. 36).\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  These statements should not, however, be thought in terms of human subjectivity or psychology. Rather, McCulloch was responding to a famous paper delivered by the mathematician John von Neumann on logical automata, where Von Neumann laid out an argument for why computers and brains were not the same, but also the necessary conditions that would need to be created to make them commensurable (von Neumann, 1948\/1986). These circuits now labeled by McCulloch as “psychotic” because they challenged scientific perspective, and reformulated the boundaries of interiority and exteriority, between knowledge and practice. At stake in this statement was the set of methodologies and practices in the human sciences, statistics, and engineering, the epistemology, if we will, that might build new machines—whether organic or mechanical. It is perhaps no surprise that psychosis might offer the possibility of producing a logic “spoken” directly by  any clear referential relation to an external and meaningful “reality” (Kittler, 1990). But cybernetic invocations of psychoanalysis, and psychosis, complicate the seamless extension of the 1900 discourse network into the present. For Freud found psychotics threatening. The classical definitions of psychosis rest on the subject’s inability to organize time and space.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  To cite Roger Caillois (1935), there is a mimetic excess to these states; the subject is “consumed” by the environment, unable to delineate the boundaries between the Self and Others. Such proximities—between the doctor and the patient, mind and body, and desire and knowledge—Freud found troubling. For the psychoanalysis of the early 20th century, struggling for credibility under the terms of objectivity offered at the time, psychosis presented a danger to the practice of transference in psychoanalysis, and a threat to the clear-cut separation between the analyst and the analysand. Cyberneticians, however, displaced the relationship between the analyst and analysand entirely. The autonomous circuit can directly speak, thus providing the material (organic or electronic) substrate to language initially sought for in theories of telepathy, occultism, and psychosis. This emerging performativity and materiality of the net was what defined cybernetic methods as separating from earlier histories of psychoanalysis and psychology. However, this new epistemology was only made possible by deferring any encounter with historicity. Irrespective, therefore, of this models’ relationship to actual neurons, or human memory and intelligence, the pair had established that a capacity for logic and very sophisticated problem solving might emerge from small physiological units such as neurons linked up in circuits.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  In doing so, and by way of exploiting the amnesia of these circuits, McCulloch and Pitts were able to make neural nets analogous to communication channels, and shift the dominant terms for dealing with human psychology and consciousness to communication, cognition and capacities. Their conception of the neural net informs a change in attitudes to psychological processes that makes visible an epistemological transformation in what constituted truth, reason, and evidence in science. upon a repression of all questions of documentation, indexicality, archiving, learning, and historical temporality. And third, the temporality of the net is preemptive, it always operates in the future perfect tense, but without necessarily defined endpoints or contexts (Halpern, 2005). Nets are about T + 1, the past is indeterminate: McCulloch regularly argued against caring about the actual context, or specific stimulus that incited trauma in patients, or systems.5 Together, these points meant that rationality could be redefined as both embodied and affective, and good science was not the production of certitude but rather the account of chance and indeterminacy. Control and Computing Having inserted the logic of the machine into the brain, this model was then fed back into the design of machines. The model of the cycling memory neuron in fact directly refracts an earlier concept of control in the Turing machine (and would later become the model for memory in von Neumann’s architecture for EDVAC ((Electronic Discrete Variable Automatic Computer); von Neumann, 1945). Control in the Turing machine is the head that “reads” the program from memory and then begins the process of executing it according to the directions in the memory.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Control, therefore, directs the next operation of the machine. Control is directed by the program. The control unit, or the reading head in a Turing machine, is directed by the tape it is reading from memory, not reverse. Control is that function that will read and act upon these retrieved data, inserting the retrieved program or data into the run of the machine. Such machines do not operate top-down, but rather in feedback loops between storage, processing segments, and the interface for input and output. In his 1946 report on building a computing machine, the ACE Report, Turing reiterated that only the possession of memory give[s] the machine the possibility of constructing its own orders; i.e. there is always the possibility of taking a particular minor cycle out of storage and treating it as an order to be carried out. This can be very powerful.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  (A. M. Turing, 1986, p. 21)  could be proven? The problem could be inverted from seeking the limits of calculation to examining the possibilities for logical nets. What had been an absolute limit to mathematical logic became an extendable threshold for engineering. McCulloch implied we should turn instead to accepting our partial and incomplete perspectives, our inability to know ourselves and make this “psychosis” in his words an “experimental epistemology” (McCulloch, 1965, p. 359). Affective Logics  Figure 5. Diagrams of “c.”  Source. Adapted from Goldstine and Neumann (1948, p. 157), public domain image. Planning and Coding, von Neumann and Goldstine introduced flow charts and circuits for stored program computers.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  However, in describing their circuits, they wrote, “[w]e propose to indicate these portions of the flow diagram of C by a symbolism of lines oriented by arrows [see Figure 5] . . . Second, it is clear that this notation is incomplete and unsatisfactory . . .”(Goldstine & Neumann, 1948, p. 157). In other words, control is not definable; its operable imagining and its explicit definition are incommensurate. But rather than treat this failure in representation as a problem, this threshold became a technological opportunity; this emergent space between the definable and the infinite provided the contours of the engineering problem—an opportunity to turn from logic to technology. Significantly, for us, McCulloch and Pitts inverted the problem posed by the original negative proof of the entscheidungsproblem that is the Turing machine. If throughout the 19th and earlier 20th centuries an army of mathematicians and philosophers struggled to infinitely extend the limits of logical representation to which the Turing machine is a negative proof demonstrating the impossibility of fully representing all statements in first-order logic, then  What the cybernetic reformulation of logic as “psychotic” permitted was an abandonment of ontological concern with the past and the present in the interest of focusing on future interactions. These models measured not what is happening, but prepare us for what will happen as a result of finding patterns of past data, which ironically is devoid of historical temporalities. While such a-historicity had perhaps long been a problem for statisticians, in cybernetics, problems of causality were repressed by creating models that did not engage with historicity or linearity; this repression of historicity, however, as I hope to show, will come back to create new challenges for the sciences of communication and society now framed in terms of storage and information.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  The transformation in truth claims and epistemology opened a new frontier for study—subjective interactions in environments with incomplete information. These nervous networks and logical rationalities proliferated in the social and human sciences. Cybernetic and communicative concepts of mind were part of a broader shift at the time in concepts of reason, psychology, and consciousness; informing everything from finance and options trading equations, to environmental psychology and urban planning programs of individuals such as Kevin Lynch, and later MIT’s Architecture Machine Group and the Media Lab headed by Nicholas Negroponte, to the political science models of Karl Deutsch at Harvard, and the “bounded rationality” introduced by Herbert Simon and widely considered the foundation of contemporary finance. The post-war social sciences were repositories of these techniques that transformed what had once been a question of political  a logic guided by a reason separate from sense, then these discourses mark a clear contrast. The historian of science Lorraine Daston reminds us that we would do well to recall that those things today considered virtuous and intelligent, such as speed, logic, and definitiveness in action, were not always so. She is explicit: Rationality in its Cold War formulation, despite the insistence of technocrats, policy makers, and free-market advocating economists, is not reason as understood by Enlightenment thinkers, liberals, or even modern logicians (Daston, 2011; MacKenzie, 2006; Mirowski, 2002). If this is true, then our financial instruments, markets, governments, organizations, and machines are rational, affective, sensible, and preemptive, but not reasonable. To recognize the significance of this thinking in our present, it might help to contemplate Brian Massumi’s definition of “preemption.” Preemption, he argues, is not prevention; it is a different way of knowing the world.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Prevention, he claims, “assumes an ability to assess threats empirically and identify their causes.” Preemption, however, is affective; it lacks representation and is a constant nervous anticipation, at a literally neural if not molecular level, for a never fully articulated threat or future (Massumi, 2007, p. 4). Cyberneticians, within 10 years from the war, moved from working on anti-aircraft prediction to building systems without clear endpoints or goals, and embracing an epistemology without final objectives, or perhaps objectivity (even if many practitioners denied this). Nets, taken as systems, are probabilistic scenarios, with multiple states and indefinite run times even if each separate neuron can act definitively. In cognitive and early neuro-science, the forms of knowledge being espoused were always framed in terms of experiment, never definitive conclusions. “Experimental epistemologies,” as McCulloch put it, came to mean that there are never final facts, only ongoing experiments. These human and social scientists made operative the unknowable space between legibility and emergence, and turned it into a technological impulse to proliferate new tools of measurement, diagrams, and interfaces. At the limits of this analysis is the possibility that emergence itself has  How do agents act? Creating an ongoing opportunity to entangle calculation and life at the level of nervous networks, by correlating the nervous system with the financial and political system.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Memory as a Cyclical Machine Having supposedly exorcised the ghosts of historicity, cyberneticians, however, continued to struggle with memory and signification. In a 1952 letter to the cybernetician Norbert Wiener, Gregory Bateson spelled out the problem of memory, time, repetition, and rationality: What applications of the theory of games do, is to reinforce the players’ acceptance of the rules and competitive premises, and therefore make it more and more difficult for the players to conceive that there might be other ways of meeting and dealing with each other. . . . I question the wisdom of the static theory as a basis for action in a human world. The theory may be “static” within itself, but its use propagates changes, and I suspect that the long-term changes so propagated are in a paranoidal direction and odious. (Bateson, 1952, p. 2)  Discussing the premier private consulting group to the U.S. government and military on national security and public policy—the RAND Corporation—Bateson makes explicit a new dilemma: violence. In this formulation, players no longer create violence because of a misdirected desire resulting in a loathing for an imagined Other, but instead, they are led to produce violence through a self-referential performance within the game. Bateson correlates “static” games with paranoid schizophrenics, as a perceptual problem resulting in repetitive cycles culminating in potentially genocidal violence (nuclear war in this case)—in his language, a “paranoidal direction.” Authority emerging from the pure self-reference of the data field is psychotic and comes at the expense of futurity. Bateson fears that the performance of past data paraded as prophecy will produce only repetition without difference.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  In a stunning inversion of psychoanalytic concerns, Bateson recognizes that the ubiquity of computational logics makes distance impossible to achieve, and induces violence, not as a result of any misdirected object  this instance, the immediacy and temporality of the televisual came to replace the older conceptions of tapes, photographs, and films. McCulloch opened the conference with a beacon and a warning. He offered the example of a new type of tube, in development at Princeton, similar to a cathode ray tube, that beams onto a screen on which items are stored. The persistence of the “memory” of the beam is temporary and must be refreshed. This idea of a cycling, or scanning memory, McCulloch viewed as offering the possibility of miniaturizing and expanding machine memory (Pias, 2003). His second example was a warning from John von Neumann: Even the entire number of neurons in the brain, according to calculation, could not account for the complexity of human behavior and ability. McCulloch reported the finding that “the performance of the army ant . . . is far more complicated than can be computed by 300 yes or no devices” (Pias, 2003, p. 31).\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  But this was not to say that these capacities need be understood as illogical or analog. Rather, McCulloch turned to another model that might retain the logical nature of the neurons, but still account for the capacity to learn, and behave at scales beyond the comprehension of computation. The answer, coming through a range of discussions about protein structure and memory within cells, involved refreshing information in time. Wiener argued, “this variability in time here postulated will do in fact the sort of thing that von Neumann wants, that is, the variability need not be fixed as variability in space, but may actually be a variability in time.” (Pias, 2003, p. 35). The psychologist John Stroud offered the example of a “very large macroorganism called a destroyer.” This military ship has endless “metabolic” changes of small chores throughout the day, but still retains the function of a destroyer. This systemic stability, but internal differentiation and cycling, became the ideal of agency and action in memory McCulloch and Stroud went on to present understandings of memory in terms of an opposition between perfect retention of all information with retroactive selection or memory as a constant active site of processing of information for further action, based on internal “reflectors,” or “internal eyes.” “We may,” Stroud stated,  present of reception and circulating data, and memory in time, a cyclical “refreshing” as in a television screen system, where change, and differentiation—between the organism and the environment, between networks— becomes possible through the delay and reorganization of circuits from within the organism. The problems of computational representation, the initial problems that were faced in mathematically and logically representing intelligence, were reorganized away from a language of conscious and unconscious, discrete and infinite, reason and psychosis to the new terms of vacillating temporalities between immediacy and reflexivity. Bateson, also an attendant at the aforementioned conferences and one of the founders of family therapy and addiction treatment programs, offered one of the more compelling models and practices for rethinking mind in his use of a model of the “double bind” to explain psychic suffering, addiction and other maladjusted and compulsive behaviors.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  In a conference in 1969, at the National Institute of Health, he offered an example to demonstrate his ideas of both psychology and treatment. He discussed a research project conducted with porpoises trained at Navy research facilities to perform tricks and other trained acts in return for fish. One day, he recounted, one of the porpoises was introduced to a new regimen. Her trainers deprived her of food if she repeated the same trick. Starved if she repeated the same act, but also if she did not perform, the porpoise was caught in a double bind. This experiment was repeated with numerous porpoises, usually culminating in extreme aggression, and a descent into what from an anthropomorphic perspective might be labeled disaffection, confusion, and antisocial and violent behavior. Bateson with his usual lack of reservation was ready to label these dolphins as suffering a paranoid form of schizophrenia. The anthropologist was at pains, however, to remind his audience that these psychotic animals were acting rationally.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  In fact, they were doing exactly what their training as animals in a navy laboratory would lead them to do. Their problem was that they had two conflicting signals. The poor animals, having no perspective on their situation as laboratory experiments were natu-  endowed abilities, then, but were learned, the result of an experiment in time. This process in which the subject, whether a patient or a dolphin, uses the memories of other interactions and other situations to transform their actions within the immediate scenario was represented as the site of innovation. The dolphin’s ego (insofar as we decide she has one) was sufficiently weakened to develop new attachments to objects in its environment through the memories of its past and of other types of encounters. This rewired network of relations was what was held to lead to emergence through the re-contextualization of the situation within which the confused and conflicted animal found itself. Despite the suffering of this poor animal, Bateson ends on a positive note, having now successfully made the psyche inter-subjective and simultaneously amenable to technical appropriation via family therapy (Bateson, 2000, p. 278). The productivity of a schizoid situation rested for Bateson on the discovery made by both communication theory and physics that different times could not communicate directly to one another.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Only temporal differences resist circulation from within the definition of communication that was being put forward here. Bateson applied this understanding liberally to animals. In cybernetic models, the ability of an entity to differentiate itself from its environment and make autonomous choices is contingent on its ability to simultaneously engage in dangerous spatial proximities, for example, between the porpoise and her trainer, with other entities and the ability to achieve distance from them in time. At stake in the negotiation over the nature of networks and the time-scale of analysis was nothing less than how to encounter difference—whether between individuals, value in markets, or between vast states during the Cold War. A question that perhaps started in psychoanalytic concerns over psychosis found technical realization in cybernetics. For cyberneticians, the problem of analog or digital, otherwise understood as the limits between discrete logic and infinity, the separation between the calculable and the incalculable, the representable and the non-representable, and the differences between subjects and objects, was transformed into a reconfiguration of memory and storage—a transformation that continues to inform our multiplying fantasies of real-time  through better visualization and collective intelligence through the collaboration of many logical, but hardly reasonable, agents. Architecturally these dual desires incarnate themselves in a proliferation of interfaces and a fetish for visualization and interactivity, merged with an obsession to amass and store data in huge systems of data centers and server farms. What had first been articulated as a problem of memory and time has now become a compulsion for analytics.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  Theorizing the Nervous Network I opened this essay arguing that cybernetics and its affiliated communication and human sciences aspired to the elimination of difference in the name of rationality, a dream of self-organizing systems and autopoietic intelligences produced from the minute actions of small, stupid, logic gates, a dream of a world of networks without limit, focused eternally on an indefinite, and extendable, future state. Earlier in this essay, I also invoked Bateson’s concerns about self-referential violence. What Bateson articulated was the worry that in the real-time obsession to entangle life with calculative logics, learning, and by extension thought, would itself be automated in such a way as to lead to violent harm, and perhaps, the destruction of the world. This condition only becomes inevitable, however, if we ourselves descend into the logic of immediate and real-time analytics. We must avoid this conclusion, and this condition. Like Bateson’s porpoise, torn between reactionary return, and self-referentiality, we are forced to ask about the other possibilities that still lie inside our machines and our histories. The cycles of the porpoise reenact the telling of cybernetic history where ideas of control and rationality are often over-determined in their negative valence, and the inevitability of the past to determine the future is regularly assumed. Perhaps the hope is in the very machinery that was imagined into being through the cybernetic circuits—systems that can both recognize and disavow their history, for which memory and archiving remain at tense and productively incommensurable distances, incarnated in a drive to accelerate the speed of speculation while intensifying the infrastructure for data gathering and storage, all supported by a nervous rationality  Humanities Research Council, as part of the “Instruments” project.\n"}
{"prompt":"Circuits of Amnesia: Cybernetic Memory and Real-Time Analytics ->","completion":"  This research was also sponsored by the Graham Foundation.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  T h e C o g n i T i v e n o n C o n s C i o u s and The CosTs of ConsCiousness 1 Nonconscious Cognitions: Humans and Others 9 2 Interplays between Nonconscious Cognition and Consciousness 41 3 The Cognitive Nonconscious and the New Materialisms 65 4 The Costs of Consciousness: Tom McCarthy’s Remainder and Peter Watts’s Blindsight 86  Pa r T 2 . C o g n i T i v e a s s e m B L a g e s 5 Cognitive Assemblages: Technical Agency and Human Interactions 115 6 Temporality and Cognitive Assemblages: Finance Capital, Derivatives, and High-Frequency Trading 142 7 Intuition, Cognitive Assemblages, and Politico-Historico Affects: Colson Whitehead’s The Intuitionist 178 8 The Utopian Potential of Cognitive Assemblages 202 Notes 217 Works Cited 223  Acknowledgments  This book could not have come into being had it not been for the generous assistance, intellectual stimulation, and collaborations that helped to catalyze my thoughts (and unthoughts), refine my arguments, and extend my reach. Of primary importance were funding sources that gave me the time to think and write—a sabbatical year from Duke University, a fellowship from the Institute of Advanced Study at the University of Durham, UK, and an appointment as the Critical Inquiry Visiting Professor at the University of Chicago. I am pleased to acknowledge their assistance. During my months in Durham (UK), the windy winter days were warmed by the friends I made there, including Linda Crowe, Mikhail Epstein, Gerhard Lauer, Gerald Moore, Richard Reed, Nicholas Saul, and Veronica Strang. At the University of Chicago, the unparalleled Tom Mitchell was a constant friend, Bill Brown, an inspiring presence, Frances Ferguson, consistently friendly and generous with her time; and the Society of Fellows offered an opportunity for challenging and insightful exchanges. Hank Scotch provided material help and scrupulously accurate copyediting assistance. Also crucial were scholars who were willing to share their forthcoming work with me before it appeared in print, including Louise Amoore, Ulrik Ekman, Mark Hansen, William Hutchison, AnnChristina Lange, Luciana Parisi, and Patrick Whitmarsh.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Their trust that I would handle these resources appropriately warmed my heart. Providing support and stimulation were my outstanding colleagues at Duke University (Durham, NC), including Rey Chow, Elizabeth Grosz, Mark Hansen, Barbara Herrnstein-Smith, Deborah Jenson, Tim Le-  At Duke Kunshan University, where I taught in fall 2015, especially important for my months there was the support of Andrew Field, Haiyan Gao, and Deedra McClearn. Mark Kruse, my co-teacher in our course “Science Fiction\/Science Fact,” deserves special mention for his remarkable patience, clear expositions, and generosity in providing guidance to me and our students as we probed the complexities of quantum mechanics and relativity theory. Providing help and valuable resources was my research assistant Maryann Murtagh. Marjorie Luesebrink, a lifelong friend, lighted up innumerable conversations and dinners together as we hashed over many of the ideas that found their way into this book. One of the delights of getting older is to see one’s former students flourish in their own right, often with cutting-edge work that exceeds whatever I might have accomplished. I have been fortunate to work with an extraordinarily talented group of young scholars who are now setting the agendas for their fields, including Olivia Banner, Zach Blas, Nathan Brown, Todd Gannon, Amanda Gould, Patrick Jagoda, Melody Jue, Patrick Le Mieux, Kate Marshall, Jessica Pressman, David Rambo, Jenny Rhee, Allen Riddell, David Shepard, John Stadler, and Vidar Thorsteinsson. I am indebted to many scientists, cultural critics, media theorists, and humanists whose writing and research were crucially important for this project and for my work in general, including Karen Barad, Lauren Berlant, Rosi Braidotti, Jean-Pierre Changeux, Antonio Damasio, Stanislas Dehaene, Gerald Edelman, Danuta Fjellestad, Elizabeth Grosz, Mark Hansen, Donald MacKenzie, Franco Moretti, Luciana Parisi, Garrett Stewart, and Giulio Tononi.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Alan Thomas, my editor at the University of Chicago Press, has been a constant friend and colleague now for many years, and I owe him a tremendous debt of gratitude for his steadfast support. My greatest debt, as always, is to my partner and friend, Nicholas Gessler, who never fails to amaze with his encyclopedic knowledge of everything technical, his dedication to figuring things out for himself, his curiosity about the material world, and his love, warmth, and generosity. I am grateful to the following for giving me permission to reprint previously published material in this book: most of chapter 2 appeared as  in Critical Inquiry 4 (4): 783–808 (Summer 2016), and most of chapter 5 also appeared in Critical Inquiry, “Cognitive Assemblages: Technical Agency and Human Interactions” 5 (1) (Autumn 2016), © 2016 by The University of Chicago, all rights reserved; portions of chapter 6 appeared as “The Cognitive Nonconscious and Automated Trading Algorithms,” in Parole, écriture, code, edited by Emmanuele Quinz, translated by Stéphane Vanderhaeghe, Petite Collection ArtsH2H (Paris-Dijon: Les presses du réel, 2015); and portions of chapter 8 appeared as “Cognition Everywhere: The Rise of the Cognitive Nonconscious and the Costs of Consciousness,” in New Literary History 45.2 (Spring 2014): 199–220. ProLogue  Transforming How We See the World  When he looked at me with his clear, kind, candid eyes, he looked at me out of a tradition thirteen thousand years old: a way of thought so old, so well established, so integral and coherent as to give a human being the unself-consciousness of a wild animal, a great strange creature who looks straight at you out of his eternal present. The epigraph, from Ursula Le Guin’s science fiction novel The Left Hand of Darkness, describes the encounter of protagonist Genly Ai with Faxe, acolyte of the Zen-like cult of the Handdarata and their tradition of “unlearning” (57). “Given to negatives” (57), the Handdarata would immediately recognize “unthought” as indicating a kind of thinking without thinking. There is thought, but before it is unthought: a mode of interacting with the world enmeshed in the “eternal present” that forever eludes the belated grasp of consciousness. “Unthought” may also be taken to refer to recent discoveries in neuroscience confirming the existence of nonconscious cognitive processes inaccessible to conscious introspection but nevertheless essential for consciousness to function.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Understanding the full extent of their power requires a radical rethinking of cognition from the ground up. In addition, because the very existence of nonconscious cognitive processes is largely unknown in the humanities, “unthought” indicates the terra incognita that beckons beyond our received notions of how consciousness operates. Gesturing toward the rich possibilities that open when nonconscious cognition is taken into account, “unthought” also names the potent force of conceptualizing interactions between human and technical systems that enables us to understand  more clearly the political, cultural, and ethical stakes of living in contemporary developed societies. The first step toward actualizing this potential is terminological ground clearing about conscious, unconscious, and nonconscious mental processes. “Thinking,” as used in this book, refers to the thoughts and capabilities associated with higher consciousness such as rationality, the ability to formulate and manipulate abstract concepts, linguistic competencies, and so on. Higher consciousness is not, of course, the whole or indeed even the main part of this story: enhancing and supporting it are the ways in which the embodied subject is embedded and immersed in environments that function as distributed cognitive systems. From a cluttered desktop whose complicated topography acts as an external memory device for its messiness-inclined owner, to the computer on which I am typing this, to the increasingly dense networks of “smart” technologies that are reconfiguring human lives in developed societies, human subjects are no longer contained— or even defined—by the boundaries of their skins. Part of the book’s project is to analyze and explore the nonconscious cognitive assemblages through which these distributed cognitive systems work.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In choosing the definite article (the cognitive nonconscious), I intend not to reify these systems but rather to indicate their systemic effects. When my focus is on individual subjects, I will use the more processually marked term “nonconscious cognitive processes.” The power of these assemblages, however, is maximized when they function as systems, with well-defined interfaces and communication circuits between sensors, actuators, processors, storage media, and distribution networks, and which include human, biological, technical, and material components. In these instances, I will refer to the cognitive nonconscious, a term that crucially includes technical as well as human cognizers. As noted in chapter 5, I prefer “assemblage” over “network” because the configurations in which systems operate are always in transition, constantly adding and dropping components and rearranging connections. For example, when a person turns on her cell phone, she becomes part of a nonconscious cognitive assemblage that includes relay towers and network infrastructures, including switches, fiber optic cables, and\/or wireless routers, as well as other components. With the cell phone off, the infrastructure is still  in place, but the human subject is no longer a part of that particular cognitive assemblage. Although nonconscious cognition is not a new concept in cognitive science, neuroscience, and related fields, it has not yet received the attention that I think it deserves. For the humanities, its transformative potential has not yet begun to be grasped, much less explored and discussed.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Moreover, even in the sciences, the gap between biological nonconscious cognition and technical nonconscious cognition still yawns as wide as the Grand Canyon on a sunlit morning. One contribution of this study is to propose a definition for cognition that applies to technical systems as well as biological life-forms. At the same time, the definition also excludes material processes such as tsunamis, glaciers, sandstorms, etc. The distinguishing characteristics, as explained in chapter 1, center on interpretation and choice—cognitive activities that both biological life-forms and technical systems enact, but material processes do not. A tsunami, for example, cannot choose to crash against a cliff rather than a crowded beach. The framework I propose, although it recognizes that material processes have aweinspiring agency, comports neither with vitalism nor panpsychism. Although some respected scholars such as Jane Bennett and Steve Shaviro have given reasons why they find these positions attractive for their purposes, in my view they are not helpful in understanding the specificities of human-technical cognitive assemblages and their power to transform life on the planet. I see this ongoing transformation as one of the most urgent issues facing us today, with implications that extend into questions about the development of technical autonomous systems and the role that human decision making can and should play in their operation, the environmental devastation resulting from deeply held beliefs that humans are the dominant species on the earth because of their cognitive abilities, and the consequent need for reenvisioning the cognitive capabilities of other life-forms.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  A correlated development is the spread of computational media into virtually all complex technical systems, along with the pressing need to understand more clearly how their cognitive abilities interact with and interpenetrate human complex systems. As this framework suggests, another contribution of this study is to formulate the idea of a planetary cognitive ecology that includes both  human and technical actors and that can appropriately become the focus for ethical inquiry. While traditional ethical inquiries focus on the individual human considered as a subject possessing free will, such perspectives are inadequate to deal with technical devices that operate autonomously, as well as with complex human-technical assemblages in which cognition and decision-making powers are distributed throughout the system. I call the latter cognitive assemblages, and part 2 of this study illustrates how they operate and assesses their implications for our present and future circumstances. Here is a brief introduction to the book’s plan and structure. Part 1 focuses on the concept of nonconscious cognition, with chapter 1 developing a framework for understanding its relation both to consciousness\/unconsciousness and material processes. Chapter 2 summarizes the scientific research confirming the existence of nonconscious cognition and locates it in relation to contemporary debates about cognition. Chapter 3 discusses the “new materialisms” and analyzes how these projects can benefit from including nonconscious cognition in their frameworks.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As nonconscious cognition is increasingly recognized as a crucial component of human cognitive activity, consciousness has consequently been scrutinized as incurring costs as well as benefits. We can visualize this dynamic as a kind of conceptual seesaw: the higher nonconscious cognition rises in importance and visibility, the lower consciousness declines as the arbiter of human decision making and the dominant human cognitive capability. Chapter 4 illustrates the costs of consciousness through an analysis of two contemporary novels, Tom McCarthy’s Remainder (2007) and Peter Watts’s Blindsight (2006). Part 2 turns to the systemic effects of human-technical cognitive assemblages. Chapter 5 illustrates their dynamics through typical sites ranging from traffic control centers to piloted and autonomous drones. Chapter 6 focuses on autonomous trading algorithms, showing how they require and instantiate technical autonomy because the speeds at which they operate far transcend the temporal regimes of human decision making. This chapter also discusses the implications of these kinds of cognitive assemblages, particularly their systemic effects on destabilizing the global economy. Chapter 7 explores the ethical implications of cognitive assemblages through a close reading of Colson Whitehead’s novel The Intuitionist.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Chapter 8 expounds on the  to the digital humanities, proposing that they too may be considered as cognitive assemblages and showing how the proposed framework of nonconscious cognition affects how the digital humanities are understood and evaluated. In conclusion, I want to present a few takeaway ideas that I hope every reader of this book will grasp: most human cognition happens outside of consciousness\/unconsciousness; cognition extends through the entire biological spectrum, including animals and plants; technical devices cognize, and in doing so profoundly influence human complex systems; we live in an era when the planetary cognitive ecology is undergoing rapid transformation, urgently requiring us to rethink cognition and reenvision its consequences on a global scale. My hope is that these ideas, which some readers may regard as controversial in part or whole, will nevertheless help to initiate conversations about cognition and its importance for understanding our contemporary situations and moving us toward more sustainable, enduring, and flourishing environments for all living beings and nonhuman others. Pa r T 1  The CogniTive nonConsCious and The CosTs of ConsCiousness  ChaPTer 1  Nonconscious Cognitions: Humans and Others  Rooted in anthropocentric projection, the perception that consciousness and advanced thinking necessarily go together has centuries, if not millennia, of tradition behind it. Recently, however, a broadbased reassessment of the limitations of consciousness has led to a correspondingly broad revision of the functions performed by other cognitive capacities and the critical roles they play in human neurological processes. Consciousness occupies a central position in our thinking not because it is the whole of cognition but because it creates the (sometimes fictitious) narratives that make sense of our lives and support basic assumptions about worldly coherence. Cognition, by contrast, is a much broader capacity that extends far beyond consciousness into other neurological brain processes; it is also pervasive in other life forms and complex technical systems. Although the cognitive capacity that exists beyond consciousness goes by various names, I call it nonconscious cognition.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Perhaps no areas are more rife with terminological disparities than those dealing with consciousness; rather than sort through centuries of confusions, I will try to make clear how I am using the terms and attempt to do so consistently throughout. “Consciousness,” as I use the term, comprises core or primary consciousness (Damasio 2000; Dehaene 2014; Edelman and Tononi 2000), an awareness of self and others shared by humans, many mammals, and some aquatic species such as octopi. In addition, humans and (perhaps) a few primates manifest extended (Damasio 2000) or secondary (Edelman and Tononi 2000) consciousness, associated with symbolic reasoning, abstract thought, verbal language, mathematics, and so forth (Eagleman 2012;  ographical self (Damasio 2012, 203–07), reinforced through the verbal monologue that plays in our heads as we go about our daily business; that monologue, in turn, is associated with the emergence of a self aware of itself as a self (Nelson, in Fireman, McVay, and Flanagan 2003, 17–36). Recognizing that the cognitive nonconscious (in his terms, the protoself) can create a kind of sensory or nonverbal narrative, Damasio explains how the narratives become more specific when melded with verbal content in higher consciousness. “In brains endowed with abundant memory, language, and reasoning, narratives . . . are enriched and allowed to display even more knowledge, thus producing a well-defined protagonist, the autobiographical self” (Damasio 2012, 204). Whenever verbal narratives are evoked or represented, this is the mental faculty that makes sense of them.1 Core consciousness is not sharply distinguished from the so-called “new” unconscious (in my view, not an especially felicitous phrase), a broad environmental scanning that operates below conscious attention (Hassin, Uleman, and Bargh 2005). Suppose, for example, you are driving while thinking about a problem.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Suddenly the car in front brakes, and your attention snaps back to the road. The easy and continuous communication between consciousness and the “new” unconscious suggests that they can be grouped together as modes of awareness.2 In contrast, nonconscious cognition operates at a level of neuronal processing inaccessible to the modes of awareness but nevertheless performing functions essential to consciousness. The last couple of decades in neuroscientific research show that these include integrating somatic markers into coherent body representations (Damasio 2000), synthesizing sensory inputs so they appear consistent across time and space (Eagleman 2012), processing information much faster than can consciousness (Dehaene 2014), recognizing patterns too complex and subtle for consciousness to discern (Kouider and Dehaene 2007), and drawing inferences that influence behavior and help to determine priorities (Lewicki, Hill, and Czyzewska 1992). Perhaps its most important function is to keep consciousness, with its slow uptake and limited processing ability, from being overwhelmed with the floods of interior and exterior information streaming into the brain every millisecond. The point of emphasizing nonconscious cognition is not to ignore the achievements of conscious thought, often seen as the defining  accurate view of human cognitive ecology that opens it to comparisons with other biological cognizers on the one hand and on the other to the cognitive capabilities of technical systems. Once we overcome the (mis)perception that humans are the only important or relevant cognizers on the planet, a wealth of new questions, issues, and ethical considerations come into view. To address these, this chapter offers a theoretical framework that integrates consciousness, nonconscious cognition, and material processes into a perspective that enables us to think about the relationships that enmesh biological and technical cognition together. Although technical cognition is often compared with the operations of consciousness (a view I do not share, as discussed below), the processes performed by human nonconscious cognition form a much closer analogue.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Like human nonconscious cognition, technical cognition processes information faster than consciousness, discerns patterns and draws inferences and, for state-aware systems, processes inputs from subsystems that give information on the system’s condition and functioning. Moreover, technical cognitions are designed specifically to keep human consciousness from being overwhelmed by massive informational streams so large, complex, and multifaceted that they could never be processed by human brains. These parallels are not accidental. Their emergence represents the exteriorization of cognitive abilities, once resident only in biological organisms, into the world, where they are rapidly transforming the ways in which human cultures interact with broader planetary ecologies. Indeed, biological and technical cognitions are now so deeply entwined that it is more accurate to say they interpenetrate one another. The title of part 1, the cognitive nonconscious, is meant to gesture toward the systematicity of human-technical interactions. In part 2, I will refer to these as cognitive assemblages. Assemblage here should not be understood as merely an amorphous blob.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Although open to chance events in some respects, interactions within cognitive assemblages are precisely structured by the sensors, perceptors, actuators, and cognitive processes of the interactors. Because these processes can, on both individual and collective levels, have emergent effects, I will use nonconscious cognition(s) to refer to them when the emphasis is on their abilities for fluid mutations and transformations. The more reified formulation indicated by the definite article (the cognitive  important. I adopt this form for my overall project because the larger implications of cognitive assemblages occur at the systemic rather than individual levels. As a whole, my project aims to chart the transformative perspectives that emerge when nonconscious cognitions are taken fully into account as essential to human experience, biological life, and technical systems. Although my focus is on biological and technical cognitions that function without conscious awareness, it may be helpful to clarify my position relative to the cognitivist paradigm that sees consciousness operating through formal symbol manipulations, a framework equating the operations of human minds with computers. Clearly humans can abstract from specific situations into formal representations; virtually all of mathematics depends on these operations. I doubt, however, that formal symbol manipulations are generally characteristic of conscious thought.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Jean-Pierre Dupuy (2009), in his study arguing that cognitive science developed from cybernetics but crucially transformed its assumptions, characterizes the cognitivist paradigm not as the humanization of the machine (as Norbert Weiner at times wanted to position cybernetics) but as the mechanization of mind: “The computation of the cognitivists . . . is symbolic computation. The semantic objects with which it deals are therefore all at hand: they are the mental representations that are supposed to correspond to those beliefs, desires, and so forth, by means of which we interpret the acts of ourselves and others. Thinking amounts, then, to performing computations on these representations” (Dupuy 2009, 13). As Dupuy shows, this construction is open to multiple objections. Although cognitivism has been the dominant paradigm within cognitive science throughout the 1990s and into the twenty-first century, it is increasingly coming under pressure to marshal experimental evidence showing that brains actually do perform such computational processes in everyday thought. So far, the results remain scanty, whereas experimental confirmation continues to grow for what Lawrence Barsalou (2008) calls “grounded cognition,” cognition supported by and entwined with mental simulations of modal perceptions, including muscle movements, visual stimuli, and acoustic perceptions. In part this is because of the discovery of mirror neuron circuits in human and primate brains (Ramachandran 2012), which, as Miguel Nicolelis (2012) has shown in his work on Brain-Machine-Interfaces (BMI),  to extrapolate beyond bodily functions such as limb movements into prosthetic extensions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  One aspect of these controversies is whether neuronal processes can in themselves be understood as fundamentally computational. Dissenting from the computationalist view, Walter J. Freeman and Rafael Núñez argue that “action potentials are not binary digits, and neurons do not perform Boolean algebra” (1999, xvi). Eleanor Rosch, in “Reclaiming Concepts” (Núñez and Freeman 1999, 61–78) carefully contrasts the cognitivist paradigm with the embodied\/embedded view, arguing that empirical evidence is strongly in favor of the latter. Amodal symbolic manipulation, as Barsalou (2008) characterizes the cognitivist paradigm, depends solely on logical formulations unsupported by the body’s rich repertoire of physical actions in the world. As numerous researchers and theorists have shown (Lakoff and Johnson 2003; Dreyfus 1972, 1992; Clark 2008), embodied and embedded actions are crucial in the formation of verbal schema and intellectual comprehension that express themselves through metaphors and abstractions, extending out from the body to sophisticated thoughts about how the world works. My comparison between nonconscious cognition in biological lifeforms and computational media is not meant to suggest, then, that the processes they enact are identical or even largely similar, because those processes take place in very different material and physical contexts. Rather, they perform similar functions within complex human and technical systems. Although functionalism has sometimes been used to imply that the actual physical processes do not matter, as long as the results are the same (for example, in behaviorism and some versions of cybernetics), the framework advanced here makes context crucial to nonconscious cognition, including the biological and technical milieu within which cognitions take place.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Notwithstanding the profound differences in contexts, nonconscious cognitions in biological organisms and technical systems share certain structural and functional similarities, specifically in building up layers of interactions from low-level choices, and consequently very simple cognitions, to higher cognitions and interpretations. Exploring these structural parallels requires a good deal of ground clearing to dispense with lingering questions such as whether machines can think, what distinguishes cognition from consciousness  terial processes. Following from these fundamental questions are further issues regarding the nature of agencies that computational and biological media possess, especially compared with material processes, and the ethical implications when technical cognitive systems act as autonomous actors in cognitive assemblages. What criteria for ethical responsibility are appropriate, for example, when lethal force is executed by a drone or robot warrior acting autonomously? Should it focus on the technical device, the human(s) who set it in motion, or the manufacturer? What perspectives offer frameworks robust enough to accommodate the exponentially expanding systems of technical cognitions and yet nuanced enough to capture their complex interactions with human cultural and social systems? Asking such questions is like pulling a thread dangling from the bottom of a sweater; the more one pulls, the more the whole fabric of thinking about the significance of biological and computational media begins to unravel. Parts 1 and 2 pull as hard as they can on that thread and try to reweave it into different patterns that reassess the nature of human and technical agencies, realign human and technical cognitions, and investigate how these patterns present new opportunities and challenges for the humanities.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Thinking and CogniTion The first twist in knitting these new patterns is to distinguish between thinking and cognition. Thinking, as I use the term, refers to high-level mental operations such as reasoning abstractly, creating and using verbal languages, constructing mathematical theorems, composing music, and the like, operations associated with higher consciousness. Although Homo sapiens may not be unique in these abilities, humans possess them in greater degree and with more extensive development than other species. Cognition, by contrast, is a much broader faculty present to some degree in all biological life-forms and many technical systems. This vision overlaps with the position that Humberto Maturana and Francisco Varela articulated in their classic work on cognition and autopoiesis (1980). It also aligns with the emerging science of cognitive biology, which views all organisms as engaging in systematic acts of cognition as they interact with their environments. The field, named by Brian C. Goodwin (1977), has subsequently been developed  as “FP”; 2007), who has been instrumental in codifying its principles and exploring its implications. Cognition as formulated in cognitive biology employs some of the same terms as mainstream views but radically alters their import.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Traditionally, cognition is associated with human thought; William James, for example, noted that “cognition is a function of consciousness” ([1909] 1975, 13). Moreover, it is often defined as an “act of knowing” that includes “perception and judgment” (“Cognition,” in Encyclopedia Britannica, www.britannica.com\/topic\/cognition-thought -process). A very different perspective informs the principles of cognitive biology. Consider, for example, Kováč’s observation that even a unicellular organism “must have a certain minimal knowledge of the relevant features of the environment,” resulting in a correspondence, “however coarse-grained and abstract,” between these features and the molecules of which it is comprised. He concludes, “In general, at all levels of life, not just at the level of nucleic acid molecules, a complexity, which serves a specific function . . . corresponds to an embodied knowledge, translated into the constructions of a system. The environment is a rich set of potential niches: each niche is a problem to be solved, to survive in the niche means to solve the problem, and the solution is the embodied knowledge, an algorithm of how to act in order to survive” (“FP,” 59). In this view cognition is not limited to humans or organisms with consciousness; it extends to all life-forms, including those lacking central nervous systems, such as plants and microorganisms.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The advantages of this perspective include breaking out of an anthropocentric view of cognition and building bridges across different phyla to construct a comparative view of cognition. As formulated by Pamela Lyon and Jonathan Opie (2007), cognitive biology offers a framework consistent with empirical results: “Mounting evidence suggests that even bacteria grapple with problems long familiar to cognitive scientists, including: integrating information from multiple sensory channels to marshal an effective response to fluctuating conditions; making decisions under conditions of uncertainty; communicating with conspecifics and others (honestly and deceptively); and coordinating collective behavior to increase the chances of survival.”3 Kováč calls the engagement of a life-form with its environment its onticity, its ability to survive and endure in changing circumstances. He  ‘testing’ all the possibilities of how to advance ahead” (“FP,” 58). In a playful extension of this reasoning, he imagines a bacterial philosopher confronting the same issues concerning its onticity as a human, asking whether the world exists, and if so, why there is something rather than nothing. Like the human, the bacterium can find no absolute answers within its purview; it nevertheless pursues “its onticity in the world” and accordingly “is already a subject, facing the world as an object. At all levels, from the simplest to the most complex, the overall construction of the subject, the embodiment of the achieved knowledge, represents its epistemic complexity” (“FP,” 59). The sum total of the world’s epistemic complexity is continually increasing, according to Kováč, advanced by the testing of what he calls the beliefs of organisms: “only some of the constructions of organisms are embodied knowledge, the others are but embodied beliefs. . . . If we take a mutation in a bacterium as a new belief about the environment, we can say that the mutant would sacrifice its life to prove its fidelity to that belief” (“FP,” 63).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  If it continues to survive, that belief becomes converted into embodied knowledge and, as such, is passed along to the next generation. Comparing traditional and cognitive biology perspectives shows that the same words attain very different meanings. Knowledge, in the traditional view, remains almost entirely within the purview of awareness and certainly within the brain. In cognitive biology, on the contrary, it is acquired through interactions with the environment and embodied in the organism’s structures and repertoire of behaviors. Belief in the traditional view is a position held by a conscious being as a result of experience, ideology, social conditioning, and other factors. In the cognitive biology view, it is a predisposition toward the environment that has not yet been confirmed through ongoing interactions testing its robustness as an evolutionary response to fluctuating conditions. Finally, subject in the traditional view is taken to refer to humans or at least conscious beings, while in the cognitive biology view it encompasses all life forms, even humble unicellular organisms. P LanT signaLing and CLaims for PLanT inTeLLigenCe A convenient site to explore the complex interactions that arise when  gence is the world of plants.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In a recent New Yorker article, Michael Pollan summarizes research that explores homologies between “neurobiology and phytobiology,” specifically that plants are “capable of cognition, communication, information processing, computation, learning and memory” (Pollan 2013, 1). The claims are made explicit in a 2006 article in Trends in Plant Science (Brenner et al.). Positioned as a review article, the piece is also a polemical manifesto aiming to establish the field of plant neurobiology, arguing that many of the complexities of plant signaling strongly parallel animal neurobiology. As the authors recognize, plant “intelligence” had become a lightning rod for controversy since the 1973 pop science book The Secret Life of Plants by Peter Tompkins and Christopher Bird, which made extraordinary claims with little evidence. As a result, many plant scientists wanted to distance themselves as much as possible from claims about plant “intelligence,” including the assertion that plants are somehow attuned to human emotional states. Brenner et al. suggest that as a result, many plant biologists refused even to consider parallels between plant responses and animal neurology, practicing “a form of self-censorship in thought, discussion and research that inhibited asking relevant questions” (415). However justified this comment, the Brenner article itself manifests rhetorical and argumentative strategies that exhibit a deep ambivalence.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  On the one hand, the authors want to document research showing how complex and nuanced are the mechanisms that underlie individual and communal plant behaviors; on the other, they inadvertently reinstall the privilege of animal intelligence by implying that the more plant signaling resembles animal neurobiology, the stronger the case that it is really intelligence. The ambivalence is apparent in the sidebar tracing the etymology of the term “neuron” back to Plato and the Greeks, where “‘neuron’ means “anything of a fibrous nature” (414). By this definition, plants clearly do have neurons, but in the usual sense of the term (cells with nuclei and axons that communicate using neurotransmitters), they do not. A similar ambivalence is apparent in how they define intelligence; by insisting on the word, they create a rhetorical tension between what they seem to be claiming and what they are actually saying. Offering first a definition of plant intelligence (from Trewavas 2005) as “‘adaptively variable growth over the lifetime of a plant’” (414), they expand on it, adding an emphasis on process-  information from both abiotic and biotic stimuli that allows optimal decisions about future activities in a given environment” (414). In my view, this definition offers important clues for reenvisioning cognition (a trajectory I was already following before reading the Brenner article), as well as providing a case study in why it is better to avoid using “intelligence” for nonhuman (and technical) cognitions. As Pollan documents, “many plant scientists have pushed back hard” against what they (mis)understood to be the argument. He notes that thirty-six plant biologists issued a rebuttal to the Brenner piece, also published in Trends in Plant Science.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The refutation opens with this salvo: “We begin by stating simply that there is no evidence for structures such as neurons, synapses or a brain in plants” (qtd in Pollan, 3). Pollan points out that “no such claim had actually been made—the manifesto had spoken only of ‘homologous’ structures—but the use of the word ‘neurobiology’ in the absence of actual neurons was apparently more than the scientists could bear” (3). This rather snide comment (revealing Pollan’s own sympathies) does not, in my view, do justice to the complexities of the situation. The issue is not what plant scientists can bear, but how traditional views of intelligence interact with and complicate research that challenges (and perhaps also inadvertently reinstalls) the anthropocentric perspective of what intelligence is. Daniel Chamovitz, for example, while insisting on the remarkable abilities of plants to sense and respond to their environments, argues that “the question . . . should not be whether or not plants are intelligent—it will be ages between we all agree on what that term means; the question should be, ‘Are plants aware?’ and, in fact, they are” (2013, 170). Indeed, Pollan himself points out that “the controversy is less about the remarkable discoveries of recent plant science than about how to interpret and name them; whether behaviors observed in plants which look very much like learning, memory, decision-making and intelligence deserve to be called by those names or whether those words should be reserved exclusively for creatures with brains” (4). For an analogy, I think of Gillian Beer’s brilliant study in Darwin’s Plots: Evolutionary Narrative in Darwin, George Eliot, and NineteenthCentury Fiction (1983) tracing the struggle in Darwin’s The Origin of Species between his view of evolution as a process with no foreordained end and the teleological worldview embedded in the Christianoriented language he inherited and upon which he instinctively drew.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  sentence structures, and rhetorical strategies his desire to articulate a new vision through language saturated with the old. A similar struggle informs the Brenner article; although it is true that the scientists who objected to the article’s claims did misread it in a literal sense, they were reacting to the kind of ambivalence noted above between actual evidence and insinuations carried through such tactics as redefining “neuron.” In this sense, they accurately discerned the article’s double intent to draw upon the cachet of “intelligence” as an anthropocentric value while simultaneously revising the criteria for what constitutes intelligence. Since plants make up 99 per cent of the planet’s biomass, the issue is not trivial across a range of sites, including the question Christopher D. Stone ([1972] 2010) posed decades ago of whether trees should have legal standing. My own clear preference is to create a framework that is both robust and inclusive, and I see no way to exclude plants without sacrificing conceptual coherence (not to mention ignoring the wealth of evidence documenting their remarkable abilities to respond to changing environments).4 Nevertheless, assuming that one wanted to draw the line separating cognitive organisms from the noncognitive differently, most aspects crucial to my argument could still be included: the reevaluation of cognition as distinct from consciousness; the recognition that cognitive technologies are now a potent force in our planetary cognitive ecology; and the rapidly escalating complexities created by the interpenetration of cognitive technologies with human systems. These, in my view, are not debatable, while the arguments about plants occupy a less central (although still important) role in my own priorities. I recognize, then, that locating the boundary between the cognitive and noncognitive may be contested, and that different perspectives will lead to conclusions other than those that I endorse. The crucial point for me is less where the line is drawn than that the core issues mentioned above are recognized as critical to our contemporary situation. For me, another important point is the role that humanistic inquiry can play in this arena.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Because reenvisioning cognition occurs along a broad interdisciplinary front fraught with linguistic as well as conceptual complexities, the humanities, with their nuanced understanding of rhetoric, argument, and interpretation, are well positioned to contribute to the debate. plex plant cognition is, where “cognition” here refers to the ways plants sense information from their surroundings, communicate within themselves and to other biota, and respond flexibly and adaptively to their changing environments. Their “‘sessile life style’” (Pollan, 4–5—“sessile” refers to organisms attached directly to a substrate, for example, corals and almost all plants) includes more than a dozen senses, among them kin recognition, detection of chemical signals from other plants, and analogues to the five human senses. Pollan explains how kin recognition has been observed to work: “Roots can tell whether nearby roots are self or other, and if other, kin or stranger. Normally, plants compete for root space with strangers, but, when researchers put closely related Great Lakes sea-rocket plants (cakile edentual) in the same pot, the plants restrained their usual competitive behaviors and shared resources” (Pollan, 5). It has long been known that plants emit and sense a wide variety of chemical signals; they also manufacture chemicals that deter predators and release others that have psychotropic effects for pollinators, encouraging them to revisit that particular plant again. As researchers continue to investigate the interplays between electrical and chemical signaling, gene structures, and plant behaviors, it becomes increasingly clear that, whatever one’s position on the anthropocentrically laden word “intelligence,” plants interpret a wide range of information about their environments and respond to challenges in remarkably nuanced and complex ways. TeChniCaL CogniTio n Cognitive biology, along with related research in phytobiology discussed above, opens the concept of cognition to a broad compass, and to that extent, it is consistent with the path I want to pursue here.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  However, these research endeavors miss the opportunity to think beyond the biological to technical cognition, despite redefining terms in ways that partially enable that extension. To illustrate, I turn to the view of cognition proposed by Humberto R. Maturana and Francisco J. Varela in their seminal work Autopoiesis and Cognition: the Realization of the Living (1980). Maturana and Varela are distinct from the science of cognitive biology, associated instead with the Chilean School of Biology of Cognition; nevertheless, their views are close enough to cognitive biology to show the modifications necessary to extend cognition to  Although they agreed about the cognitive capabilities of living organisms, they disagreed about whether these capabilities could be extended to technical systems—Maturana dissenting, Varela embracing. The disagreement is understandable, for their vision of what constituted cognition made the extension to technical systems far from obvious. In their view, cognition is intimately bound up with the recursive processes whereby an organism’s organization determines its structures, and its structures determine its organization, in cycles of what Andy Clark (2008) subsequently called continuous reciprocal causality (note, however, that Maturana and Varela would not have used the term causality because an essential part of their vision was the closed or autopoietic nature of the living). Cognition, for them, is nothing other than this informational closure and the recursive dynamics it generates. Their postulated informational closure of organisms makes the extension to technical systems problematic, as technical systems are self-evidently not informationally closed but accept information inputs of various kinds and generate information outputs as well. Exploring more fully the cognitive capacities of technical systems, then, requires another definition of cognition than the one they adopted.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In The Embodied Mind: Cognitive Science and Human Experience (1991), Varela and coauthors Evan Thompson and Eleanor Rosch extend these ideas into comparisons between the cellular automata (a kind of computer simulation) and the emergence of cognition within biological cells (1991, 150–52). Their definition of enaction is consistent with the approach that I follow, insofar as it recognizes that cognition emerges from context-specific (i.e., embodied) interactions. “We propose as a name the term enactive to emphasize the growing conviction that cognition is not the representation of a pregiven world by a pregiven mind but is rather the enactment of a world and a mind on the basis of a history of the variety of actions that a being in the world performs. The enactive approach takes seriously, then, the philosophical critique of the idea that the mind is a mirror of nature but goes further by addressing this issue from within the heartland of science” (1991, 9). In his later work, Varela was also interested not only in computer simulations but in creating autonomous agents within simulations, an approach known as Artificial Life (Varela and Bourgine 1992). Several years ago pioneers in this field argued that life is a theoretical program that can be instantiated in many different kinds of platforms,  Rosen 1991). For example, in an effort to show that technical systems could be designed to carry out biological functions, John von Neumann introduced the idea of “self-reproducing automata” (1966). More recently, John Conway’s game of “life” (Gardner 1970) has often been interpreted as generating different kinds of species that can perpetuate themselves—as long as the computer does not malfunction or the electric current does not shut down.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  These caveats point to an insurmountable obstacle these researchers faced in arguing that life could exist in technical media, namely that such technical “life” can never be fully autonomous in its creation, maintenance, and reproduction. From the vantage of hindsight, I think this field of inquiry, although useful and productive in generating controversies and questions, was finally doomed to failure because technical systems can never be fully alive. But they can be fully cognitive. Their overlap with biological systems, in my view, should not be focused on “life itself” (as Rosen [1991] put it), but on cognition itself. Following a path that has occupied me for several years, I offer a definition that will allow me to expand outward to include technical as well as biological cognition. Cognition is a process that interprets information within contexts that connect it with meaning. For me, the genesis of this formulation lay in Claude Shannon’s theory of information (Shannon and Weaver 1948), in which he shifted the emphasis from a semantic basis for information to the selection of message elements from a set, for example, letters in an alphabet. This way of thinking about information has been enormously fruitful, as James Gleick has explained (2012), for it allowed the development of theorems and engineering practices that extended far beyond natural languages to information processes in general, including binary codes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  From a humanities perspective, however, it had a major disadvantage. As Warren Weaver emphasized in his introduction to Shannon’s classic work (Shannon and Weaver 1948), it appeared to sever information from meaning. Since the quest for meaning has always been central to the humanities, this meant that information theory would have limited usefulness for humanistic inquiries. In retrospect, I think Weaver overstated the case in subtle but significant ways. As Shannon knew quite well, the process of selection, which he expressed as a function of probabilities, is not entirely divorced from a message’s content and consequently from its mean-  will follow their predecessors are already partially determined by the distribution of letters and their relative frequencies within a given language. In English and Romance languages, for example, there is a nearly 100 percent chance that a “q” will be followed by a “u,” a higher than random chance that an “e” will be followed by a “d,” and so forth. Shannon (1993) linked this idea to the redundancy of English (and other languages), and the theorems that followed were crucial for information compression techniques still in use for telephonic and other kinds of communication transmissions. Nevertheless, to arrive at meaning, the constraints operating through selection processes are not enough.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Something else is needed: context. Obviously, the same sentence, uttered in different circumstances, can change its meaning completely. The missing link between Shannon’s view of information and context was supplied for me in a seminar given by the theoretical physicist Edward Fredkin, when he casually observed, “The meaning of information is given by the processes that interpret it” (Hayles 2012, 150). Although Fredkin gave no indication he thought this idea was particularly powerful, it hit me like a bolt of lightning. It blows the problem of meaning wide open, for processes occur within contexts, and context can be understood in radically diverse ways for different situations. It applies to utterances of natural language between humans, but it equally well describes the informational processes by which plants respond to information embedded in the chemicals they absorb, the behavior of octopi when they sense potential mates in their vicinity, and the communications between layers of code in computational media. In another context, the insight can also be related to how the brain processes sensory information, in which action potentials and patterns of neural activity may be experienced in different ways depending on which part of the brain engages them (see for example chapter 21, “Sensory Coding,” in Kandel and Schwartz 2012, 449–74).5 Consistent with Fredkin’s explosive insight is the processual and qualitative view of information (as distinct from the quantitative theory developed by Shannon) proposed by the French “mechanologist” Gilbert Simondon in the 1960s as part of his overarching philosophy focusing on processes rather than hylomorphic concepts (form and matter). For Simondon, reality itself is the tendency to engage in processes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  A central metaphor for him is the concept of potential energy  coming to a stable equilibrium, only transitional metastable states. He called this flow “information” and thought it is inherently connected with meaning (Simondon 1989; see also Scott 2014; Iliadis 2013; and Terranova 2006). Similar to Fredkin’s insight, information in this view is not a statistical distribution of message elements but the result of embodied processes emerging from an organism’s embeddedness within an environment. In this sense, the processes that nonconscious cognition uses to discern patterns are constantly in motion, reaching metastable states as patterns are discerned and further reinforced when temporal matching with the reverberations between neural circuits cause them to be fed forward to consciousness. These processes of discerning patterns are always subject to new inputs and continuing transformations as the nonconscious and conscious contexts in which they are interpreted shift from moment to moment. In Simondon’s terms, the transfer from one neural mode of organization to another can be conceived as a transfer from one kind of potential energy to another. The information coming to consciousness has already been laden with meaning (that is, interpreted in the relevant contexts) by the cognitive nonconscious; it achieves further meaning when it is rerepresented within consciousness. As we will see in chapter 5, interpretation within contexts also applies to the nonconscious cognitive processes of technical devices.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Medical diagnostic systems, automated satellite imagery identification, ship navigation systems, weather prediction programs, and a host of other nonconscious cognitive devices interpret ambiguous or conflicting information to arrive at conclusions that rarely if ever are completely certain. Something of this kind also happens with the cognitive nonconscious in humans. Integrating multiple somatic markers, it too must synthesize conflicting and\/or ambiguous information to arrive at interpretations that may feed forward into consciousness, emerging as emotions, feelings, and other kinds of awareness upon which further interpretive activities take place. In automated technical systems, nonconscious cognitions are increasingly embedded in complex systems in which low-level interpretative processes are connected to a wide variety of sensors, and these processes in turn are integrated with higher-level systems that use recursive loops to perform more sophisticated cognitive activities such as drawing inferences, developing proclivities, and making decisions  In an important sense, these multi-level systems represent externalizations of human cognitive processes. Although the material bases for their operations differ significantly from the analogue chemical\/electrical signaling in biological bodies, the kinds of processes have similar informational architectures. In addition, technical systems have the advantage of working nonstop 24\/7, something no biological body can do, and of processing vast amounts of information much faster than humans can. It should not be surprising that human and technical nonconscious cognitions share attributes in common, because brains (deploying nonconscious cognition in their own operations) designed them. Parsing CogniTion With this background, let us return to parse my definition more fully, since it is foundational for the arguments to follow.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Cognition is a process: this implies that cognition is not an attribute, such as intelligence is sometimes considered to be, but rather a dynamic unfolding within an environment in which its activity makes a difference. For example, a computer algorithm, written as instructions on paper, is not itself cognitive, for it becomes a process only when instantiated in a platform capable of understanding the instruction set and carrying it out. That interprets information: interpretation implies a choice. There must be more than one option for interpretation to operate. In computational media, the choice may be as simple as the answer to a binary question: one or zero, yes or no. Other examples include, in the C++ programming language, commands such as “if” and “else” statements (“if” indicates that a procedure should be implemented only if certain conditions are true; “else” indicates that if these conditions are not met, other procedures should be followed). Moreover, these commands may be nested inside each other to create quite complex decision trees. Choice here, of course, does not imply “free will” but rather programmatic decisions among alternative courses of action, much as a tree moving its leaves to maximize sunlight does not imply free will but rather the implementation of behaviors programmed into the genetic code.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In Cognitive Biology, Gennaro Auletta (2011) writes that “biological systems represent the integration of the three basic systems that are  cessor, the regulator, and the decider” (200). In unicellular organisms, the “decider” may be as simple as the lipid membrane that “decides” which chemicals to admit and which to resist. In more complex multicellular organisms such as mammals and in networked and programmable media, the interpretive possibilities grow progressively more multileveled and open-ended. In contexts that connect it with meaning: the implication is that meaning is not an absolute but evolves in relation to specific contexts in which interpretations performed by the cognitive processes lead to outcomes relevant to the situation at that moment. Note that context includes embodiment. Lest I be misunderstood, let me emphasize that technical systems have completely different instantiations than biological life-forms, which are not only embodied but also embedded within milieus quite different from those of technical systems.6 These differences notwithstanding, both technical and biological systems engage in meaning-making within their relevant instantiated\/embodied\/embedded contexts. For high-level cognitive processes such as human thought, the relevant contexts may be very broad and highly abstract, from deciding whether a mathematical proof is valid to questioning if life is worth living. For lower-level cognitive processes, the information may be the sun’s angle for trees and plants, the location of a predator as a school of minnows darts to evade it, or the modulation of a radio beam by a radio-frequency identification (RFID) chip that encodes it with information and bounces it back.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In this framework, all these activities, and millions more, count as cognitive. A meta-implication is that humans do not have a lock on which contexts and levels are able to generate meanings. Many technical systems, for example, operate through communication signals such as radio waves, microwaves, and other portions of the electromagnetic spectrum inaccessible to direct human perception. To unaided human senses, the signals bouncing around the atmosphere are both imperceptible and meaningless, but to technical devices that operate in contexts relevant to them, they are filled with meaning. Traditionally, the humanities have been concerned with meanings relevant to humans in human-dominated contexts. The framework developed here challenges that orientation, insisting cognitive processes happen within a broad spectrum of possibilities that include nonhuman animals and plants as well as technical systems. Moreover, the meanings gener-  own right, are also consequential for human outcomes as well, from the flourishing of trees in rain forests to the communication signals emanating from a control tower to aircraft within its purview. This framework emphasizes that these different kinds of meanings are entangled together in ways that transcend any single human viewpoint and that cannot be bounded by human interests alone.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As our view of what counts as cognition expands, so too do the realms in which interpretations and meanings emerge and evolve. All of these, this framework implies, count as meaning making and consequently should be of potential interest to the humanities, as well as to the social and natural sciences. T he TriParTiTe framework of (human) CogniTion Turning now specifically to human cognition, I develop this view with a tripartite framework that may be envisioned as a pyramid with three distinct layers (fig. 1, p. 40). At the top are consciousness and unconsciousness, grouped together as modes of awareness. As noted earlier, research on the “new” unconscious sees it as a kind of broad environmental scanning in which events are heeded and, when appropriate, fed forward to consciousness (Hassin, Uleman, and Bargh 2005). The new unconscious differs from the psychoanalytic unconscious of Freud and Lacan in that it is in continuous and easy communication with consciousness. In this view the psychoanalytic unconscious may be considered as a subset of the new unconscious, formed when some kind of trauma intervenes to disrupt communication and wall off that portion of the psyche from direct conscious access.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Nevertheless, the psychoanalytic unconscious still expresses itself to consciousness through symptoms and dreams susceptible to psychoanalytic interpretation. The modes of awareness, designating the neurological functions of consciousness and the communicating unconscious, form the top layer of the pyramid. The second part of the tripartite framework is nonconscious cognition, described in detail elsewhere (Hayles 2012). Unlike the unconscious, it is inherently inaccessible to consciousness, although its outputs may be forwarded to consciousness through reverberating circuits (Kouider and Dehaene 2007). Nonconscious cognition integrates somatic markers such as chemical and electrical signals into  integrates sensory inputs so that they are consistent with a coherent view of space and time (Eagleman 2012). In addition, it comes online much faster than consciousness and processes information too dense, subtle, and noisy for consciousness to comprehend. It discerns patterns that consciousness is unable to detect and draws inferences from them; it anticipates future events based on these inferences; and it influences behavior in ways consistent with its inferences (Lewicki, Hill, and Czyzewska 1992). No doubt nonconscious cognition in humans evolved first, and consciousness and the unconscious were subsequently built on top.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Removed from the confabulations of conscious narration, nonconscious cognition is closer to what is actually happening in the body and the outside world; in this sense, it is more in touch with reality than is consciousness. It comprises the broad middle layer of the tripartite framework. The even broader bottom layer comprises material processes. Although these processes are not in themselves cognitive, they are the dynamic actions through which all cognitive activities emerge. The crucial distinguishing characteristics of cognition that separate it from these underlying processes are choice and decision, and thus possibilities for interpretation and meaning. A glacier, for example, cannot choose whether to slide into a shady valley as opposed to a sunny plain. In contrast, as Auletta explains, “any biological system . . . produces variability as a response to environmental challenges and tries to integrate [these] aspects inside itself” (2011, 200).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In general, material processes may be understood through the sum total of forces acting upon them. A special case is formed by criticality phenomena, structured so that even minute changes in initial conditions may change how the system evolves. Even here, the systems remain deterministic, although they are no longer predictable. There are many examples of material processes that can self- organize, such as the Belousov-Zhabotinsky (BZ) inorganic reaction. However, there remain crucial distinctions between such far-from-equilibrium systems and living organisms, for whom choices, decisions, and interpretations are possible. As Auletta points out, “biological systems are more than simply dissipative self-organizing systems, for the reason that they can negotiate a changing or nonstationary environment in a way that allows them to endure (to change in an adaptive sense) over substantial periods of time” (2011, 200). Material processes may however be harnessed  are applied in such a way as to introduce choice and agency into the system (Lem 2014), for example, through the interactions of multiple independent agents in complex environments. Although the pyramidal shape of the tripartite framework may seem to privilege the modes of awareness over nonconscious cognitions and material processes, inasmuch as they occupy the top strata, a countervailing force is expressed through the pyramid volumes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The modes of awareness, precisely because they come at the top, reign over the smallest volume, a representation consistent with the roles they play in human psychic life. Nonconscious cognition occupies a much greater volume, consistent with the processes it performs as the neurological function mediating between the frontal cortex and the rest of the body. Material processes occupy a vast volume, consistent with their foundational role from which all cognition emerges. Although the tripartite framework divides human processes into three distinct layers for analytical clarity, in reality complex recursive loops operate throughout the system to connect the layers to each other and connect different parts of each layer within itself. Each layer operates dynamically to influence the others all the time, so the system is perhaps better described as a dynamic heterarchy rather than a linear hierarchy, a view that animates and interconnects the system as it evolves in real time. Consequently, the structure sketched above is a first approximation. It is not so much meant to settle questions as to catalyze boundary issues and stimulate debates about how the layers interact with each other. That said, it nevertheless serves as a starting point to discuss issues of agency and to distinguish between actors and agents.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Because cognition in this framework is understood as inseparable from choice, meaning, and interpretation, it bestows special functionalities not present in material processes as such. These include flexibility, adaptability, and evolvability. Flexibility implies the ability of an organism or technical system to act in ways responsive to changing conditions in its environment. Whereas a ball thrown toward a window has no choice to alter its trajectory, a self-driving car can respond with a large repertoire of possibilities to avoid damage. As indicated above, flexibility is present in all living organisms to some extent, even those lacking central nervous systems.7 Adaptability denotes developing capacities in response to environmental conditions. Examples  mans in response to environmental stresses or opportunities, such as the neurological changes human brains undergo through extensive interactions with digital media (Hayles 2012). Evolvability is the possibility to change the programming, genetic or technical, that determines the repertoire of responses. Genetic and evolutionary algorithms are examples of technical systems with these capabilities (Koza 1992), as are computers that can reconfigure their own firmware, rearranging logic gates to solve problems with maximum efficiency (Ling 2010).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Biological examples are of course everywhere, as biologists from Darwin and Wallace on have confirmed. The important point is that material processes do not possess these capabilities in themselves, although they may serve to enhance and enlarge cognitive capabilities when enrolled as supports in an extended cognitive system. aCTors and agenTs It is fashionable nowadays to talk about a human\/nonhuman binary, often in discourses that want to emphasize the agency and importance of nonhuman species and material forces (Bennett 2010; Grosz 2011; Braidotti 2013). To my mind, there is something weird about this binary. On one side are some seven billion individuals, members of the Homo sapiens species; on the other side sits everything else on the planet, including all the other species in the world, and all the objects ranging from rocks to clouds. This binary, despite the intentions of those who use it, inadvertently reinstalls human privilege in the vastly disproportionate weight it gives to humans. Some theorists in the ecological movement are developing a vocabulary that partially corrects this distortion by referring to the “more-than-human” (Smith 2011), but the implicit equivalence of the human world to everything else still lingers.8 Recognizing that binaries can facilitate analysis (their limitations notwithstanding), I propose another distinction to replace human\/ nonhuman: cognizers versus noncognizers. On one side are humans and all other biological life forms, as well as many technical systems; on the other, material processes and inanimate objects.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  At the very least, this distinction is more balanced in the relative weights it gives to the two sides than the very unbalanced human\/nonhuman formulation. This binary (like all binaries) is not innocent of embedded implica-  category. Skeptics may object that it too reinstalls human privilege, since humans have higher and more extensive cognitions than other species. However, this binary is part of a larger cognitive ecology emphasizing that all life forms have cognitive capabilities, including some that exceed human cognitions (smell in dogs, for example). Moreover, because only cognizers can exercise choice and make decisions, they have special roles to play in our current environmental crises and the sixth mass extinction already underway. The one motivation that all life-forms share is the struggle to survive. As environmental stresses increase differentially, cognizers at all levels, from worms to humans, will make choices that tend to maximize their chances for survival. Admittedly, species with higher cognitive capabilities can supervene this motivation as it interacts with other priorities—as many humans are doing at present.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Having an analytical category that emphasizes choice may help to foreground our common causes with other cognizers and draw our attention more vividly to the fact that we all make choices, and that these choices matter, individually and collectively. Moreover, the capabilities that cognition bestows—flexibility, adaptability, evolvability—imply that cognizers have special roles to play in our evolving planetary ecologies. Finally, this framework sets up the possibility that cognitive technologies may perform as ethical actors in the assemblages they form with biological life-forms, including humans. For their part, noncognizers may possess agential powers that dwarf anything humans can produce: think of the awesome powers of an avalanche, tsunami, tornado, blizzard, sandstorm, hurricane. Faced with these events, humans utterly lack the ability to control them; the best they can do is get out of the way. Moreover, since material processes are the underlying forces that nourish and give rise to life, they deserve recognition and respect in their own right, as foundational to everything else that exists (Strang 2014). What they cannot do, acting by themselves, is make choices and perform interpretations. A tornado cannot choose to plow through a field rather than devastate a town.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Material processes, of course, respond to contexts and, in responding, change them. But because they lack the capacity for choice, they perform as agents, not as actors embedded in cognitive assemblages with moral and ethical implications. I propose a further shift in terminology that clarifies the different  suggest reserving the term actors for cognizers, and agents for material forces and objects. This latter category includes objects that may act as cognitive supports; it also includes material forces that may be harnessed to perform cognitive tasks when suitable constraints are introduced, for example, when electrical voltages are transformed into a bit stream within a computational medium. Fueled by global capitalism, technical cognitive systems are being created with ever more autonomy, even as they become increasingly pervasive within developed societies. As David Berry (2015) among others points out, there is no technical agency without humans, who design and build the systems, supply them with power and maintain them, and dispose of them when they become obsolete. Nevertheless, the pockets within which technical systems operate autonomously are growing larger and more numerous. Examples include environmental monitoring systems, surveillance and communication satellites, digital search engines, and language learning systems, among many others.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Perhaps an appropriate way to think about the growing autonomy of these systems is as punctuated agency, analogous to “punctuated equilibrium” (Gould 2007). Like punctuated equilibrium, punctuated agency operates within regimes of uneven activity, longer periods when human agency is crucial, and shorter intervals when the systems are set in motion and proceed on their own without direct human intervention. Even within the autonomous regions, the effects of technical cognitions are not contained wholly within the technical systems. They interact with human complex systems to affect myriad aspects of human and biological life. In this respect, even the cognizer\/noncognizer binary falls short because it fails to capture the powerful and subtle ways in which human and technical cognizers interact with each other as well as with noncognizing objects and material forces. Water is a good example (Strang 2014): on its own it exercises agency through such phenomena as waterfalls, rain, snow, and ice; incorporated into biological bodies, it provides fluids essential for life; run through a turbine, it contributes to the cognitions and effectiveness of a computerized hydroelectric power system. To express more adequately the complexities and pervasiveness of these interactions, we should resist formulations that reify borders and create airtight categories. The better formulation, in my view, is not a binary at all but interpenetration,  beyond the humans, nonhumans, cognizers, noncognizers, and material processes that make up our world.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  why ComPuTaTionaL media are noT JusT anoTher TeChno Logy In What Technology Wants, Kevin Kelly (2010) argues that technologies develop along trajectories that he anthropocentrically identifies with “desire,” including ubiquity, diversity, and intensity. As the provocation of his title indicates, his discussion fails to give a robust account of how human agency enters this picture. Nevertheless, there is a kernel of insight here, which I rephrase as this: technologies develop within complex ecologies, and their trajectories follow paths that optimize their advantages within their ecological niches. The advent of photography in the mid-to-late nineteenth century, for example, preempted the category of landscape description, and consequently literary novels readjusted their techniques, moving away from the pages of landscape description notable in late-eighteenth- and early-nineteenthcentury novels and into stream of consciousness strategies, an area that photography could not exploit as effectively. As Cynthia Sundberg Wall has shown (2014, esp. chapters 1–3, 2–95), literary descriptive techniques are enmeshed within a cultural matrix of techniques of vision, including microscopes, telescopes, maps, and architectural diagrams. The dynamics of competition, cooperation, and simulation between media forms are powerful analytics for understanding technological change (Fuller 2007; Hansen 2015; Gitelman 2014). In these terms, computational media have a distinct advantage over every other technology ever invented.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  They are not necessarily the most important for human life; one could argue that water treatment plants and sanitation facilities are more important. They are not necessarily the most transformative; that honor might go instead to transportation technologies, from dirt roads to jet aircraft. Computational media are distinct, however, because they have a stronger evolutionary potential than any other technology, and they have this potential because of their cognitive capabilities, which among other functionalities, enable them to simulate any other system. We may draw an analogy with the human species. Humans are not the largest life-form; they are not the strongest or the fastest. The  within their ecological niche are their superior cognitive capabilities. Of course, we are long past the era when the Baconian imperative for humans to dominate the earth can be embraced as an unambiguous good. In an era of ecological crises, global warming, species extinction, and similar phenomena, the advent of the Anthropocene, in which human influences are changing geological and planetary records, is properly cause for deep concern and concerted political activism around climate change, preservation of habitats, and related issues.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The analogy with the cognitive capacities of computational media suggests that a similar trajectory of worldwide influence is now taking place within technical milieus. Fueled by the relentless innovations of global capital, computational media are spreading into every other technology because of the strong evolutionary advantages bestowed by their cognitive capabilities, including water treatment plants and transportation technologies but also home appliances, watches, eyeglasses, and everything else, investing them with “smart” capabilities that are rapidly transforming technological infrastructures throughout the world. Consequently, technologies that do not include computational components are becoming increasingly rare. Computational media, then, are not just another technology. They are the quintessentially cognitive technology, and for this reason have special relationships with the quintessentially cognitive species, Homo sapiens. Note that this position should not be conflated with technological determinism. As Raymond Williams has astutely observed, such evolutionary potentials operate within complex social milieus in which many factors operate and many outcomes are possible: “We have to think of determination not as a single force, or a single abstraction of forces, but as a process in which real determining factors—the distribution of power or of capital, social and physical inheritance, relations of scale and size between groups—set limits and exert pressures, but neither wholly control nor wholly predict the outcome of complex activity within or at these limits, and under or against these pressures” (Williams 2003, 13). In fact, one can argue that the larger the cognitive components of technological systems, the more unpredictable are their specific developments, precisely because of the qualities conferred by cognition, namely flexibility, adaptability, and evolvability.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As global capital continues to innovate ways in which computational media may be infused into other technologies, the e-waste created by  they end up, disproportionately, in poor, underprivileged, and underfunded countries. Given that the cognitive capabilities of technical media are achieved at considerable cultural, social, political, and environmental costs, we can no longer avoid the ethical and moral implications involved in their production and use. TeCh noLogiCaL CogniTion a nd eThiCs As we have seen, choice in my framework has a very different meaning than in ethical theories, where it is associated with free will. What ethical approaches are appropriate to the former, which I will call CHOICEII (interpretation of information), as distinct from CHOICEFW (free will)? Bruno Latour (1992) touches on this question when he suggests that the “missing masses” of ethical actors (by analogy with the missing mass\/energy that physicists need to explain the universe’s inflation) are technical artifacts: “here they are, the hidden and despised social masses who make up our morality” (1992, 227). Using simple examples of seat belts and hydraulic door closers, Latour shows that technical artifacts encourage moral behavior (annoying buzzers that remind drivers to fasten seat belts) and influence human habits (speed bumps influencing drivers not to speed in school zones) (2002). In these examples, the technical objects are either passive or minimally cognitive. Even at this modest level, however, artifacts act as “mediators” influencing human behaviors, notwithstanding that they often sink into the background and are perceived unconsciously (Latour 1999, 2002; Verbeek 2011).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When artifacts embody higher levels of cognition, they can intervene in more significant and visible ways. Peter-Paul Verbeek develops a philosophical basis for thinking about technical systems as moral actors and suggests how to design technologies for moral purposes (2011, 135). The Fitbit bracelet (my example, not his) encourages fitness by monitoring heart rate, keeping track of workouts, noting calories burned, and measuring distances covered and stairs climbed. None of these devices absolutely compel obedience, as Latour acknowledges, because there are always ways to defeat their behavioral intent. Nevertheless, they have cumulative (and expanding) effects that significantly affect human social behaviors and unconscious actions. Following Latour’s lead in thinking about technical systems as  technologies such as obstetric ultrasound not only open new areas for ethical consideration (for example, whether to abort a malformed or, even more distressing, a female fetus) but also reconfigure human entities in new ways (the fetus becoming a medical patient viewable by the physician). In the entangled web of human and technical actors, Verbeek argues, both humans and technics share moral agency and, implicitly, moral responsibility: “moral agency is distributed among humans and nonhumans; moral actions and decisions are the products of human-technology associations” (Verbeek 2011, 53).9 Like Verbeek, Latour emphasizes the unexpected effects of technological innovations, arguing that technological systems almost always modify and transform the ends envisioned in their original designs, opening up new possibilities and, in the process, entangling means and ends together so that they can no longer reasonably be regarded as separate categories.10 The thrust of this argument, of course, is to defuse the objection that technological artifacts are merely the means for ends established by humans. Examples of technologies invented for one purpose and reappropriated for another are legion, from the typewriter, initially invented for blind people, to the Internet, originally intended as a place where scientific researchers could exchange results.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  While Latour and Verbeek offer valuable guidance, to my mind their arguments do not go far enough. With technologies capable of significant decision making—for example, autonomous drones—it does not seem sufficient to call them “mediators,” for they perform as actors in situations with ethical and moral consequences. One might argue, as Verbeek does, that distributed agency implies distributed responsibility, but this raises the prospect of a technological artifact being called to account for performing the actions programmed into it, a misplaced ethical judgment reminiscent of medieval animal trials in which starlings were executed for chattering in church and a pig was hanged for eating a communion wafer. Ethical theories, for their part, are often intensely anthropocentric, focusing on individual humans as the responsible agents to whom ethical standards should apply, as in Emmanuel Levinas’s complex notion of the Other’s face (1998). Although some theories extend this to animals (for example, Tom Regan’s suggestion [2004] that mammals over a certain age should be considered subjects of a life and there-  as responsible technical actors. Latour is certainly right to point to human-technical assemblages as transformative entities that affect ends as well as means, but he offers little guidance on how to assess the ethical implications of such assemblages. If, to use Latour’s example, neither guns nor people are the agents responsible for gun violence but rather the gun-person collective they form (Latour 1999, 193), surely drone-with-pilot is a much more potent assemblage than either by itself\/himself. To assess such assemblages, we should move from thinking about the individual and CHOICEFW as the focus for ethical or moral judgment, and shift instead to thinking about CHOICEII and the consequences of the actions the assemblage as a whole performs.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Jeremy Bentham suggested a similar move when he wrote, “The general tendency of an act is more or less pernicious according to the sum total of its consequences, i. e., according to the difference between the sum of its good consequences and the sum of its bad ones” ([1780] PDF, 43). We need not subscribe to all the tenets of utilitarianism to accept this as an adequate framework in which to evaluate the effects of cognitive assemblages that include technical actors. Drone pilots cannot be considered simply as evil for killing other humans; even less so can the drone itself. Rather, they act within structured situations that include tactical commanders, lawyers, and presidential staff, forming assemblages in which technological actors perform constitutive and transformative roles along with humans. The results should therefore be evaluated systemically in ways that recognize not all of the important actors are human, an argument developed further in part 2. Moreover, drone assemblages are part of larger conflicts that includes suicide bombers, IEDs, military incursions, insurgent resistance, and other factors. The cognitive assemblages in such conflicts are differentially empowered by the kinds of technologies they employ as well as by how the humans enmeshed within them act. The consequences of the assemblages further interact with existing discourses and ethical theories in dynamic, constantly shifting constellations of opposing interests, sovereign investments, personal decisions, and technological affordances.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Attempting to evaluate moral and ethical effects from the actions of individual people alone by focusing on CHOICEFW is simply not adequate to assess the complexities involved. As part 2 argues more fully, we need frameworks  transform the very terms in which ethical and moral decisions are formulated. We can see the inadequacy of remaining within individual-focused frameworks by considering the justification for designing robot weapons offered by Ronald C. Arkin, Regents Professor of computer science at Georgia Tech, compared with the drone theory of Grégoire Chamayou. Arkin, who has Defense Advanced Research Projects Agency (DARPA) grants to develop autonomous robot warriors for the battlefield, argues that robots may be morally superior to human warriors because they would be forbidden by their programming to commit atrocities, immune to emotional stress and the bad decisions that can accompany it, and able to direct their lethal encounters more precisely, minimizing collateral damage (Arkin 2010, 332–41). His critics attack these claims on a number of fronts; perhaps the most compelling is the objection that once robot warriors are available, they would likely be used more widely and indiscriminately than human warriors, where the prospect of putting one’s troops “in harm’s way” acts as a significant restraint on military and political leaders. Evaluating the claims for robot morality requires a larger interpretive frame than the one Arkin uses. Leaving aside the question of whether robots would in fact be programmed to follow the rules of war established by international treaties (and whether these rules could ever make war “moral,” an issue explored in part 2), I note that he treats the robots in the same terms as human individuals (but equipped with better sensors and decision-making capabilities) rather than as technical systems embedded in complex human-technical assemblages. Grégoire Chamayou (2015) is subtler in interrogating how the specific rules of engagement for drone pilots cause conventional standards of appropriate behavior in warfare to be transformed and reinterpreted to accommodate the pilots’ actions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For example, he points out that traditional accounts of war distinguish sharply between soldiers and assassins. Whereas the former are considered honorable because, by entering a field of combat, they establish who is an enemy combatant and also put their own bodies at risk, assassins are cowardly because they may strike targets who are not combatants and do not necessarily put themselves at risk in doing so. Applied to drone pilots, these views could force them to be counted as assassins rather than soldiers. To mitigate the situation, the US military has emphasized that drone pi-  sense are putting themselves at risk as well. Although Chamayou has his own agenda and often is one-sided in his appraisals (as argued in part 2), his analyses nevertheless show that the consequences of human-technical assemblages include not only the immediate results of actions but also far-reaching transformations in discourses, justifications, and ethical standards that attempt to integrate those actions into existing evaluative frameworks. The more powerful the cognitive capabilities of technical systems, the more far-reaching are the results and transformations associated with them. Drones are especially controversial examples, but technical cognitive systems employing CHOICEII are all around us and operating largely under the radar of the general public, including expert medical systems, automated trading algorithms, sensing and actuating traffic networks, and surveillance technologies of all kinds, to mention only a few. To analyze and evaluate their effects, we need robust frameworks that recognize technical cognition as a fact, allowing us to break out of the centuries-old traditions that identify cognition solely with (human) consciousness.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  We also need a more accurate picture of how human cognitive ecology works, including its differences from and similarities to technical cognition. Finally, we need a clear understanding of how cognizers differ from material processes, which includes a definition of cognition that sets a low threshold for participation but includes ways to scale up to much more sophisticated cognitions in humans, nonhuman life forms, and technical systems. Added together, these innovations amount to nothing less than a paradigm shift in how we think about human cognition in relation to planetary cognitive ecologies, how we analyze the operations and ethical implications of human-technical assemblages, and how we imagine the role that the humanities can and should play in assessing these effects. In conclusion, let me address the role of humanistic critique. If thought in general is associated with consciousness, critique is even more so. Some may object that challenging the centrality of reason in cognitive processes undermines the nature of critique itself. Yet consciousness alone cannot explain why scholars choose certain objects for their critique and not others, nor can it fully address the embodied and embedded resources that humanities scholars bring to bear in their rhetorical, analytical, political, and cultural analyses of contem-  Figure 1. The tripartite framework of (human) cognition as a pyramid  have always drawn upon the full resources of human cognitive ecologies (fig.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  1), both within themselves and within their interlocutors. Recognizing the complexities of these interactions does not disable critique; on the contrary, it opens critique to a more inclusive and powerful set of resources with which to analyze the contemporary situations that confront us, including but not limited to the entanglements and interpenetrations of human and technical cognitive systems. That is the importance, and the challenge, of the cognitive nonconscious to the humanities today. ChaPTer 2  Interplays between Nonconscious Cognition and Consciousness  Whereas chapter 1 explored cognition across the full spectrum of biological life-forms, this chapter focuses on the relation of nonconscious cognition to consciousness, specifically in humans. It explores the ongoing reassessments of consciousness in cognitive science, human neurology, and related fields in view of the important functions that nonconscious cognitions perform. It discusses theories about how nonconscious cognitive processes relate to consciousness, the mechanisms that enable nonconscious processes to feed forward intuitions to conscious awareness, and the important role that temporality plays in these mechanisms. The chapter concludes with a consideration of how recognizing the importance of nonconscious cognition can inform contemporary debates about consciousness. It also discusses how nonconscious processes have been represented in non-Western traditions, specifically meditative techniques and mindfulness, and how philosophical movements such as speculative realism overlap with, and diverge from, the framework presented here.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  CosTs of ConsCiousness As noted in chapter 1, we can distinguish between core or primary consciousness, widely shared among mammals and other life-forms, and higher or secondary consciousness, unique to humans and some primates. According to Thomas Metzinger (2004, 107–305), a contemporary German philosopher, core consciousness creates a mental model of itself that he calls a “Phenomenal Self-Model” (PSM) (107); it also creates a model of its relations to others, the “Phenomenal Model  els could exist without consciousness, since they require the memory of past events and the anticipation of future ones. From these models, the experience of a self arises, the feeling of an “I” that persists through time and has a more or less continuous identity. The PMIR allows the self to operate contextually with others with whom it constructs an intentionality relation. The sense of self, Metzinger argues, is an illusion, facilitated by the fact that the construction of the PMS and the PMIR models are transparent to the self (that is, the self does not recognize them as models but takes them as actually existing entities). This leads Metzinger to conclude, “nobody ever was or had a self” (1). In effect, by positioning the self as epiphenomenal, he reduces the phenomenal experience of self back to the underlying material processes. In my view, we need not accept his claim that the self is an illusion to find the PMS and PMIR useful as explanations for how a sense of self evolves and operates.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Philosopher of consciousness Owen Flanagan, following William James, tracks a similar line of reasoning: “the self is a construct, a model, a product of conceiving of our organically connected mental life in a certain way” (Flanagan 1993, 177). Who thinks the thoughts that we associate with the self? According to Flanagan (and James), the thoughts think themselves, each carrying along with it the memories, feelings, and conclusions of its predecessor while bearing them toward its successor. Antonio Damasio (2000) holds a somewhat similar view, in the sense that he considers the self to be a construct created through experiences, emotions, and feelings a child has as she grows, rather than an essential attribute or possession. Damasio, however, also thinks that the self evolved because it has a functional purpose, namely to create a concern for preservation and well-being that propels the organism into action and thus guarantees “that proper attention is paid to the matters of individual life” (303). Owen Flanagan agrees: consciousness and the sense of self have functions, including serving as a clearing house of sorts where past experiences are recalled as memories and future anticipations are generated and compared with memories to arrive at projections and outcomes. In Daniel Dennett’s metaphor (1992, 139–70), consciousness and the working memory it enables constitute the “workspace” (about which we will hear more later) where past, present, and future are put together to form meaningful sequences  Meaning, then, can be understood at the level of core consciousness as an emergent result of the relation between the PMS and the PMIR—that is, between the self-model and models the self constructs of objects that it has an “intention toward.” Damasio puts it more strongly; there is no self without awareness of and engagement with others (2000, 194, emphasis added). The self thus requires core consciousness, which constructs the PMS and the PMIR; without consciousness, a self could not exist.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In humans (and some primates), the core self is overlaid with a higher-level consciousness capable of meta-level reasoning, including interrogations of meanings that call for interpretations. Through becoming aware of and reflecting on the self as a self, higher consciousness has the effect of reifying the sense of self even more. Higher consciousness, because it generates the verbal monologues that interpret the actions of the self, has a tendency also to become imperialistic, to appropriate to itself the entirety of consciousness and even of cognition, about which we will hear more in chapter 4. John Bickle neatly summarizes the situation when he discusses what he calls the Elaborate Practical Reasoning, author of the verbal narratives mentioned above. “What kind of self do [these narratives] create and express? Clearly, they create and express a causally efficacious self-image: one of a self not only in causal control of important cognitive, conscious, and behavior events but also aware of exerting this control” (Bickle 2003, 199). As he points out, however, this sense of control is largely illusory. “The inner narratives that create and sustain our selves are relatively impotent over information processes in other neural regions .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . [the] language systems summarize and then broadcast a highly edited snapshot of the outputs of the brain’s cognitive processing networks” (201). Nevertheless, this editing does have a strong adaptive purpose, for it creates and maintains a coherent picture of the world. As Gerald Edelman and Giulio Tononi put it, “Many neuropsychological disorders demonstrate that consciousness can bend or shrink, and at times even split but it does not tolerate breaks of coherence” (Edelman and Tononi 2000, 27). We can easily see how this quality would have advantages. Creating coherence enables the self to model causal interactions reliably, make reasonable anticipations, and smooth over the gaps and breaks that phenomenal experiences present. If a car is momentarily hidden by a truck and then reappears, consciousness recognizes this  Inextricably woven with these advantages are costs, for safeguarding coherence above all frequently causes consciousness to misrepresent anomalous or strange situations. A number of experiments in cognitive psychology confirm this fact (not to mention the entire history of stage magic). In one now-famous situation (see video at http:\/\/www .youtube.com\/watch?v=vJG698U2Mvo), subjects are shown a video of players passing a basketball and are asked to keep track of the passes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In the middle of the scene, someone dressed in a gorilla suit walks across the playing area, but a majority of subjects report that they saw nothing unusual (Simons and Chabis 2011, 8; Simons and Chabis 1999). In another staged situation, a man stops a passerby and asks for directions (Simons and Chabis 2011, 59). While the subject is speaking, two workmen carrying a vertical sheet of wood pass between them, momentarily blocking the view. After they have passed, the interlocutor has been replaced by another person (who has been walking unseen behind the wood panel), but the majority of subjects do not notice the discrepancy. Useful as is the tendency of consciousness to insist on coherence, these experiments show that one cost is the screening out of highly unusual events. Without our being aware of it, consciousness edits events to make them conform to customary expectations, a function that makes eyewitness testimony notoriously unreliable. Even in the most ordinary circumstances, consciousness confabulates more or less continuously, smoothing out the world to fit our expectations and screening from us the world’s capacity for infinite surprise. A second cost is the fact that consciousness is slow relative to perception.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Experiments by Benjamin Libet and colleagues (Libet and Kosslyn 2005, 50–55) show that before subjects indicate that they have decided to raise their arms, the muscle action has already started. Although Daniel Dennett is critical of Libet’s experimental design (Dennett 1992), he agrees that consciousness is belated, behind perception by several hundred milliseconds, the so-called “missing half-second.” This cost, although negligible in many contexts, assumes new importance when cognitive nonconscious technical devices can operate at temporal regimes inaccessible to humans and exploit the missing halfsecond to their advantage, as Mark B. N. Hansen points out in FeedForward: On the Future of Twenty-First- Century Media (2015). The full implications of temporality as it concerns the interplay between human and technical cognition are explored in chapter 6 on automated  Finally there are the costs, difficult to calculate, of possessing a self aware of itself and tending to make that self the primary actor in every scene. Damasio comments that “consciousness, as currently designed, constrains the world of imagination to be first and foremost about the individual, about an individual organism, about the self in the broad sense of the term” (Damasio 2000, 300). The anthropocentric bias for which humans are notorious would not be possible, at least in the same sense, without consciousness and, even more so, the impression of a reified self that higher consciousness creates. The same faculty that makes us aware of ourselves as selves also partially blinds us to the complexity of the biological, social, and technological systems in which we are embedded, tending to make us think we are the most important actors and that we can control the consequences of our actions and those of other agents. As we are discovering, from climate change to ocean acidification to greenhouse effects, this is far from the case. neur aL CorreLaTes To ConsCio usness an d The CogniTive nonCo nsCious Antonio Damasio and Gerald Edelman, two eminent neurobiologists, have complementary research projects, Damasio working from brain macrostructures on down, Edelman working from brain neurons on up.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Together, their research presents a compelling picture of how core consciousness connects with the cognitive nonconscious. Damasio’s work has been especially influential in deciphering how body states are represented in human and primate brains through “somatic markers,” indicators emerging from chemical concentrations in the blood and electrical signals in neuronal formations (Damasio 2000). In a sense, this is an easier problem to solve than how the brain interacts with the outside world, because body states normally fluctuate within a narrow range of parameters consistent with life; if these are exceeded, the organism risks illness or death. The markers, sending information to centers in the brain, help initiate events such as emotions— bodily states corresponding to what the markers indicate—and feelings, mental experiences that signal such sensations as feeling hungry, tired, thirsty, or frightened. From the parts of the brain registering these markers emerges what Damasio calls the proto-self, “an interconnected and temporarily co-  ganism, moment by moment, at multiple levels of the brain” (Damasio 2000, 174.) The proto-self, Damasio emphasizes, instantiates being but not consciousness or knowledge; it corresponds to what I have been calling the cognitive nonconscious. Its actions may properly be called cognitive in my sense because it has an “intention toward,” namely the representation of body states. Moreover, it is embedded in highly complex systems that are both adaptive and recursive.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When the organism encounters an object, which Damasio refers to as “something-to-beknown,” the object “is also mapped within the brain, in the sensory and motor structures activated by the interaction of the organism with the object” (2000, 169). This in turn causes modifications in the maps pertaining to the organism and generates core consciousness, a recursive cycle that can also map the maps in second-order interactions and thereby give rise to extended consciousness. Consciousness in any form arises only, he maintains, “when the object, the organism, and their relation, can be re-represented” (Damasio 2000, 160). Obviously, to be re-represented, they must first have been represented, and this mapping gives rise to and occurs within the proto-self. The proto-self, then, is the level at which somatic markers are assembled into body maps, thus mediating between consciousness and the underlying material processes of neuronal and chemical signals. This picture of how consciousness arises finds support in the work of Nobel Prize–winner neurologist Gerald M. Edelman and his colleague Giulio Tononi (Edelman and Tononi 2000). Their analysis suggests that a group of neurons can contribute to the contents of consciousness if and only if it forms a distributed functional cluster of neurons interconnected within themselves and with the thalamocortical system, achieving a high degree of interaction within hundreds of milliseconds. Moreover, the neurons within the cluster must be highly differentiated, leading to high values of complexity (Edelman and Tononi 2000, 146).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  To provide a context for these conclusions, we may briefly review Edelman’s Theory of Neuronal Group Selection (TNGS), which he calls “neural Darwinism” (Edelman 1987). The basic idea is that functional clusters of neurons flourish and grow if they deal effectively with relevant sensory inputs; those less efficient tend to dwindle and die out. In addition to the neural clusters, Edelman (like Damasio) proposes that the brain develops maps, for example, clusters of neurons that map in-  through recursive “reentrant connections” (Edelman 1987, 45–50, esp. 45), flows of information from one cluster to another and back through massively parallel connections. The maps are interconnected by similar flows, and maps and clusters are also connected to each other. To assess the degree of complexity that a functional neuronal cluster possesses, Edelman and Tononi have developed a tool they call the functional cluster index (CI) (2000, 122–123). This concept allows a precise measure of the relative strength of causal interactions within elements of the cluster compared to their interactions with other neurons active in the brain. A value of CI = 1 means that the neurons in the cluster are as active with other neurons outside the cluster as they are among themselves.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Functional clusters contributing to consciousness have values much greater than one, indicating that they are strongly interacting among themselves and only weakly interacting with other neurons active at that time. From the chaotic storm of firing neurons, the coherence of the clusters mobilize neurons from different parts of the brain to create coherent maps of body states, and these maps coalesce into what Edelman calls “scenes,” which in turn coalesce to create what he calls primary consciousness (in Damasio’s terms, core consciousness). Edelman’s account adds to Damasio’s the neuronal mechanisms and dynamics that constitute a proto-self from the underlying neurons and neuronal clusters, as well as the processes by which scenes are built from maps through recursive interactions between an organism’s representations of body states and representations of its relations with objects. It is worth emphasizing the central role that continuous reciprocal causation plays in both Damasio’s and Edelman’s accounts. More than thirty years ago, Humberto Maturana and Francisco Varela (1980) intuited that recursion was central to cognition, a hypothesis now tested and extended through much-improved imagining technologies, microelectrode studies, and other contemporary research practices. simuLaTions and re- rePresenTaTions in ConsCiousness Let us now turn to the processes by which re-representation occurs. Recalling Damasio’s strong claim that there is no consciousness without re-representation, representation is clearly a major function of the  feed forward information to core and higher consciousness. These representations constitute the ground upon which the re-representations are formed.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In his theory of “grounded cognition,” Lawrence W. Barsalou in an influential article gives a compelling account of how rerepresentation occurs in what he calls “simulation,” “the re-enactment of perceptual, motor and introspective states acquired during experience with the world, body, and mind” (Barsalou 2008, 618). In particular, sensory experiences are simulated when concepts relevant to those experiences are processed and understood by the modes of awareness, in particular the communicating unconscious. He marshals a host of experimental evidence indicating that such mental reenactments are integral parts of cognitive processing, including even thoughts pertaining to highly abstract concepts formulated by higher consciousness. The theory of grounded cognition “reflects the assumption that cognition is typically grounded in multiple ways, including simulations, situated action, and, on occasion, bodily states” (Barsalou 2008, 619). For example, perceiving a cup handle “triggers simulations of both grasping and functional actions,” as indicated by fMRI scans (functional magnetic resonance images). The simulation mechanism is also activated when the subject sees someone else perform an action; “accurately judging the weight of an object lifted by another agent requires simulating the lifting action in one’s own motor and somatosensory systems” (Barsalou 2008, 624). In order for a pianist to identify auditory recordings of his own playing, he must “simulate the motor actions underlying it” (2008, 624). The discovery of mirror neurons extends the idea of simulation to social interactions, including the ability to grasp the intentions of another.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Barsalou notes that “mirror neurons . . . respond strongest to the goal of the action, not to the action itself. Thus, mirror circuits help perceivers infer an actor’s intentions, not simply recognize the action performed” (623). V. S. Ramachandran in The Tell-Tale Brain: A Neuroscientist’s Quest for What Makes Us Human (2011) emphasizes the role of mirror neurons in empathy as well as in interpreting intentions: “It’s as if anytime you want to make a judgment about someone else’s movements, you have to run a virtual-reality simulation of the corresponding movement in your own brain” (123). Perhaps most surprisingly, such simulations are also necessary to grasp abstract concepts, indicating that the thinking associated with  actment of bodily states and actions. The importance of simulations in higher-level thinking shows that biological systems have evolved mechanisms to re-represent perceptual and bodily states, not only to make them accessible to the modes of awareness but also to support and ground thoughts related to them. In the “grounded cognition” view, the brain leverages body states to add emotional and affective “tags” to experiences, storing them in memory and then reactivating them as simulations when similar experiences arise. Thus the brain in this perspective conceptualizes not primarily through the manipulation of abstract symbols (the cognitivist paradigm) but through its embodied and embedded actions in the world, as noted in chapter 1 discussing Núñez and Freeman (1999) and Varela, Thompson, and Rosch (1992).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  One consequence of this view is the emphasis it places on the brain’s ontogenetic capacities, in which its interactions with the environment reconfigure synaptic networks (Hayles 2012; Clark 2008; Hutchins 1996). We can now appreciate the emphasis that Damasio places on re-representation, for simulations serve as essential parts of the communication processes between the proto-self and consciousness, investing even highly abstract thoughts with grounding in somatic states. The imP or TanCe of informaTio n ProCessing in The CogniTive nonConsCious The empirical work on human nonconscious cognition has largely concentrated on visual masking. This can be done either by flashing stimuli too brief to be consciously seen, or by exposing subjects to visual patterns in which target stimuli are “hidden” by a complex array of distractor symbols. In a critical review of these experiments, Sid Kouider and Stanislas Dehaene (2007) chart the changing responses in cognitive psychology to the idea that subliminal stimuli can nevertheless be processed nonconsciously and affect subsequent conscious perceptions in a variety of ways. Dating back to the nineteenth century, such experiments continued to generate interest into the twentieth century, with a flurry of activity that peaked in the 1960s and 1970s. Subsequent scrutiny revealed, however, that many of these midcentury experiments were methodologically flawed, primarily by not establishing with sufficient rigor that the stimuli in fact were not consciously  twenty-first century, the skepticism of the 1980s had shifted toward a consensus that nonconscious cognition does indeed occur and influences behavior on multiple levels, ranging from motor to lexical, orthographic, and even semantic responses. Nevertheless, there remains a spectrum of opinion about how important nonconscious cognition is and how it interacts with consciousness.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The positive end of the scale is articulated in a review essay by Pawel Lewicki, Thomas Hill, and Maria Czyzewska (1992) surveying results in cognitive psychology, cognitive science, and other disciplines regarding the functions and structures of nonconscious cognition. They cite empirical evidence showing that nonconscious cognition, in addition to pattern recognition, also performs sophisticated information processing including drawing inferences, creating meta-algorithms, and establishing aesthetic and social preferences. Recalling the fact that consciousness is much slower than nonconscious processes, they point out that “nonconscious information-acquisition processes are incomparably faster and structurally more sophisticated” (796). Indeed, they postulate that the ability of the nonconscious to acquire information “is a general metatheoretical assumption of almost all contemporary cognitive psychology” (796), because experimentalists generally assume that research subjects will not be able to tell them how they acquired the knowledge that their behavior demonstrates they have learned. The problem is not just articulating tacit knowledge, as one might suppose, but rather that subjects “not only do not know how they do all those things but [they] have never known it” (796). This ignorance indicates a “fundamental lack of access” by consciousness to nonconscious “algorithms and heuristics” (796), even though such nonconscious processes are “necessary for every perception, even simple ones.” Nonconscious cognition, in short, is absolutely essential for higher cognitions, contributing to “the very foundations of the human cognitive system” (796). The evidence supporting these claims comes from a wide variety of experiments showing that patterns are recognized nonconsciously. When research subjects are prompted to perform the same learning tasks consciously, they are either unable to do so or perform much more poorly than when operating with nonconscious cognition.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In one experiment, for example, subjects were asked to locate a target character (in one case, the digit 6) amid an array of distractor symbols. subtle background pattern and the target, subjects are able to perceive that correlation and learn from it, as indicated by increased performance and faster response times (796). Moreover, even though their improved performance depends on this learning, they are unable to detect the same pattern when consciously attempting to do so. In one experiment, college students were offered a $100 reward to find the “hidden” pattern; even though some participants “spent many hours trying to find the clue . . . none of them managed to come up with any ideas even remotely relevant to the real nature of the manipulation” (798). This result, among others, confirms the idea that the cognitive nonconscious is inaccessible to consciousness, and no amount of introspection will make it so. An amusing variation involved subjects assumed to be “intellectually capable enough to report any potential introspective experience,” namely faculty in a psychology department (797). First they nonconsciously learned a “set of encoding algorithms that allowed them to more efficiently” find the target, as measured by faster identification in a search task.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Then the covariation pattern (variables correlated with one another) was changed, and as expected, their performance deteriorated. The subjects had been informed that the test was for nonconscious cognition, but even though they tried hard to discern how the experiment worked, “none of them came even close to discovering the real nature of the manipulation” (797). Instead they speculated that their performance degraded because some kind of threatening subliminal stimuli had been flashed on the screen (798). In their conclusion, the authors ask whether nonconscious cognition may be considered intelligent. As might be anticipated, they respond by saying that depends on how one defines intelligence. If intelligence means “having its own goals . . . and being able to pursue them by triggering particular actions,” then the answer is no (800). However, if intelligence “is understood as ‘equipped to efficiently process complex information,’” then the answer is yes (801).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The conclusion’s significance points in multiple directions. In one sense, it highlights the differences between “intelligence” and “cognition.” While intelligence is generally considered an attribute that can be quantified, measured, and understood as something either present or not, cognition refers to processes that instantiate certain dynamics and structural regularities. This implies that cognition is inherently dynamic and subject to  makeup. This implication, as we will later see, ties in with how one thinks about information and information processing in general. In another sense, their conclusion highlights the distinction between goal-directed behavior and information processing. This distinction, however, is not entirely clear-cut, for if information processing provides the framework for subsequent interpretations, as has been shown to be the case in self-perpetuating nonconscious algorithms, then conscious behaviors and goals are always already influenced by inferences that nonconscious cognition has performed beyond the ken of consciousness. The full significance of this point will be explored later in this chapter, as well as in chapter 5, devoted to nonconscious cognitions performed by technical devices. In summary, the evidence from multiple research studies confirms the speed and complexity of the kind of information processing that nonconscious cognition performs.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  They reveal nonconscious cognition as a powerful means of finding patterns in complex information, drawing inferences based on these patterns, and extrapolating the learned correlations to new information, thus becoming a source for intuition, creativity, aesthetic preferences, and social interactions. Recalling that subjects were entirely unable to consciously identify patterns that they had already learned nonconsciously, we can appreciate the authors’ conclusion that nonconscious cognition is “incomparably more able to process formally complex knowledge structures, faster, and ‘smarter’ overall than our ability to think and identify meanings of stimuli in a consciously controlled manner” (10). The conclusion underscores one of the major points of my overarching argument: the growing awareness that consciousness is not the whole of cognition, and that nonconscious cognition is especially important in environments rich in complex information stimuli. inTe r aCTions BeTween nonConsCious CogniTion and ConsCio usness I turn now to consider how consciousness interacts with and is influenced by nonconscious cognition. If its workings are inaccessible to introspection, how does this influence take place? Moreover, does influence flow only from the cognitive nonconscious to consciousness, or does consciousness exert influence on nonconscious cognition as  and Nonconscious Processes: Distinct Forms of Evidence Accumulation?” (2009), which proposes a theoretical framework that coordinates nonconscious learning with consciousness. He identifies nonconscious cognition with “specialized information processors,” citing fMRI evidence (from his own experiments as well as those of others) showing that these specialized processors feed forward their results very quickly, within the first 270 milliseconds after nonconscious perception. These quick response processors have been shown to influence perceptions in a variety of ways, for example by priming subjects either to faster response times if the unseen (subliminal) prime is congruent with the consciously perceived target, or impeding recognition if the prime is incongruent.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Moreover, the specialized processors are capable of adding up evidence until a dynamic threshold is reached, after which a response takes place (97). Such a mechanism could account for the capability to learn nonconsciously, for learning would have the effect of lowering the dynamic threshold. Given this evidence, what are the mechanisms that enable nonconscious cognition to influence consciousness, and vice versa? Dehaene proposes a framework that postulates reverberating circuits of neurons that work through a combination of bottom-up and top-down signals. The temporal dimension here is crucial, for if the feedforward information is contextually appropriate to the (conscious) executive control that determines the focus of attention, then neurons with long-range excitatory axons, which are associated with consciousness, begin to “send supportive signals to the sensory areas that first excited them.” Let us suppose, for example, that a dog hears a sound in the woods. If his attention is attracted by it, he pricks up his ears, which happens as a result of top-down supportive signals responding to lower-level sensory excitations. This top-down support from higher levels may send “increasingly stronger top- down amplification signals” until a dynamic threshold is crossed. At this point, “activation becomes selfamplifying and increases nonlinearly,” as the areas of the brain associated with consciousness can then maintain activation indefinitely independent of the decay of the original signal.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This phenomenon, which Dehaene calls “ignition of the global workspace,” corresponds with the entry into consciousness of the feedforward signals from the specialized processors. Moreover, at this point “stimulus information represented within global workspace  enrolls diverse systems throughout the body in coordination with its neural activity. The dog, for example, may now identify the sound as coming from a nearby rabbit and rushes off to give chase. A critical point in Dehaene’s analysis of how subcortical processors work is the temporal dimension, for subcortical processors require this top-down support in order to endure past the half-second mark. Indeed, he defines a subliminal signal as one that “possesses sufficient energy to evoke a feedforward wave of activation in specialized processors,” but “has insufficient energy or duration to trigger a large-scale reverberating state in a global network of neurons with long–range axons.” From this analysis, a useful distinction emerges between nonconscious or subliminal processing and the kind of processing associated with what is called the “attentional blink,” popularized in Malcolm Gladwell’s Blink: The Power of Thinking Without Thinking (2005). In the attentional blink, information does not reach consciousness because the global workspace is occupied by information from another processor. A model for the attentional blink proposed by Dehaene, Claire Sergent, and Jean-Pierre Changeux (2003) has succeeded in predicting “a unique property of nonlinear transition from nonconscious processing to subjective perception. This all-or-none dynamics of conscious perception was verified behaviorally in human subjects” (2003, 8520).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In the case of the gorilla walking unnoticed across the basketball court, for example, the model would predict that the global workspace, occupied by the instruction to count the number of passes, will not accept the information being forwarded by nonconscious cognitive processes. Sid Kouider and Dehaene (2007) call this phenomenon of the attentional blink “preconscious processing,” defining it as occurring “when processing is limited by top-down access rather than bottom-up strength.” Nonconscious or subliminal processing, by contrast, may not receive the necessary top-down support to continue activation, and in these cases it does not have the energy or duration to activate the global workspace on its own, whereas preconscious processing can enter the global workspace once space becomes available. If we return to the example of the gorilla, this explains why some subjects did in fact consciously perceive the intrusion. For some reason, their attention (or executive control) was not so focused on the counting task that it preempted the global workspace entirely, so that preconscious processes containing information about the gorilla could enter the  Dehaene points out an important fact relevant to the distinction between preconscious processing and nonconscious cognition: although subliminal primes can modulate the response time, “they almost never induce a full-blown behavior in and of themselves” (emphasis added, Dehaene 2009, 101). Assigned a task by consciousness, nonconscious cognition can carry it out efficiently and effectively; it can also integrate multiple kinds of signals both from within the body and without, draw inferences from these signals, and arrive at decisions that adjudicate between conflicting or ambiguous information to create feedforward activation that influences a wide variety of behaviors. Nevertheless, consciousness remains necessary, as Dehaene puts it, for an “information representation [that] enters into a deliberation process” and “supports voluntary actions with a sense of ownership” (Dehaene 2009, 102). In this perspective, nonconscious cognition is like a faithful advisor supporting and influencing consciousness but not initiating whole-body action on its own—in other words, acting much more like Joe Biden than Dick Cheney. To round out this account of the relation between the cognitive nonconscious and consciousness, we may consider their respective evolutionary roles, a topic discussed by Birgitta Dresp-Langley (2012).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She argues that “statistical learning, or the implicit learning of statistical regularities in sensory input, is probably the first way through which humans and animals acquire knowledge of physical reality and the structure of continuous sensory environments” (1). She elaborates that “this form of non-conscious learning operates across domains, across time and space, and across species, and it is present at birth when newborns are exposed to and tested with speech stream inputs” (1). Consciousness, by contrast, “kicks in much later in life, involving complex knowledge representations that support conscious thinking and abstract reasoning” (1). On an evolutionary timescale, nonconscious cognition no doubt developed first and then consciousness was built on top of it, with massive cross-connections between them through what Edelman calls reentrant signaling and other mechanisms. Nevertheless, the limited ability of consciousness to process information, both because of its narrow focus and relatively slow dynamics, means that nonconscious cognition continues to play significant roles in discerning patterns in the environment, processing emotional cues in faces and body postures (Tamietto  among variables, and influencing behavioral and affective attitudes and goals. An important point to remember from this research is that the cognitive nonconscious not only has the function of forwarding information to consciousness but also of not forwarding information not relevant to the current situation. Otherwise, the capacity of consciousness to process information would soon be overwhelmed. As Dresp-Langley observes, “non- conscious representation is aimed at reducing the complexity at the level of conscious processing.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It enables the brain to select, from all that it has learnt about outer and inner events, only what is needed for producing a meaningful conscious experience” (7). Dresp-Langley summarizes, “A great deal of human decision making in everyday life occurs indeed without individuals being fully conscious of what is going on, or what they are actually doing and why. Also, human decisions and actions based on so-called intuition are quite often timely and pertinent and reflect the astonishing ability of the brain to exploit non-conscious representations for conscious action, effortlessly and effectively” (7). In short, consciousness requires nonconscious cognitive processing of information and could not function effectively without it. nonCon s Cious CogniTion a s a humanisTiC ConCe PT: The mCdoweLL- drey fus deBaTe How might the concept of nonconscious cognition be useful to the humanities? As an example, I take the debate between Hubert L. Dreyfus and John McDowell, two eminent philosophers, on the question of how pervasive rationality is in human experience. Their arguments take place within the disciplinary norms of philosophical discourse, and they illustrate the ways in which those norms can impede discussions about nonconscious cognition. The ostensible subject of the debate was the nature of conscious knowledge, and more broadly about the paradigm, dominant for decades in cognitive science, that sees the brain as a computer running programs and processing abstract symbols.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The debate’s genesis was Dreyfus’s 2005 presidential address at the meeting of the American Philosophical Association, when he took on McDowell’s claim in Mind and World (1996) that intelligibility is pervaded by rational faculties. McDowell answered, and their re-  Being-in-the-World: The McDowell-Dreyfus Debate (Dreyfus 2013), along with essays by a number of other philosophers commenting on the issues. At stake is whether ordinary human activities are pervaded by rationality, as McDowell seemed to claim, or whether nonrational processes also have important roles to play. Dreyfus, long a critic of the paradigm that equates the brain with a computer, argues that much of human life proceeds through what he calls “absorbed coping” (22– 23 passim) and that these actions are not fundamentally conceptual. As examples, Dreyfus cites a soccer player in the heat of a game, the distance two interlocutors stand from one another while engaged in conversation, the performance of gender roles, and (somewhat problematically, in my view), a chess master playing lightning chess. These practices, he argues, open “a space of meaning that governs all forms of cultural coping” (25). He wants to contest what he characterizes as McDowell’s position that “all human activity” can be accounted for either as “shaped natural reactions” or “the space of reasons” (26), and he maintains that “absorbed cultural coping” fits into neither of these categories. Moreover, he argues that absorbed coping is pervasive in human life.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  We can see in his argument parallels between “absorbed coping” and the nonconscious information processors discussed earlier, although such nuances as the distinction between preconscious processing and nonconscious cognition are blurred as they are mixed together in the “absorbed coping” catchall. Dreyfus uses as examples of absorbed coping a host of everyday activities, such as opening a door to enter a room or using chalk to mark on a blackboard; he also instances performances by chess masters and other highly skilled individuals, such as professional athletes. He argues that chess masters “learn primarily not from analyzing their successes and failure but from the results of hundreds of thousands of actions. And what they learn are not critically justifiable concepts but sensitivity to subtler and subtler similarities and differences of perceptual patterns. Thus, learning changes, not the master’s mind, but his world” (35). Although he does not mention nonconscious cognition, the reference to “subtler and subtler” patterns recalls the nonconscious learning in the experiments cited earlier. In his response, McDowell qualifies his claims to clarify what he means by rational experience. “The idea is not that our experiential  us to think about some question,” he explains (42).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “Normally when experience provides us with knowledge that such and such is the case, we simply find ourselves in possession of the knowledge; we do not get into that position by wondering whether such and such is the case and judging that it is. When I say that the knowledge experience yields to rational subjects is of a kind special to rational subjects, I mean that in such knowledge, capacities of the sort that can figure in that kind of intellectual activity are in play” (42). This is a considerably smaller claim than his original idea that rationality pervades everyday life; indeed it verges on a tautology, saying that organisms capable of reason exercise reason. Remarkably in this debate, neither philosopher makes a clear distinction between conscious and nonconscious thought, although Dreyfus’s “absorbed coping” edges toward the idea of a mode of cognition that is not fully conscious. Also remarkable is the confidence of both men that discourse and argument alone are sufficient to settle the dispute, a self-reinforcing circle of belief in McDowell’s case that uses rational argument to elevate the importance of reason. Although both mention a wide range of other philosophers, from Aristotle to Heidegger along with many others, neither cites any experimental research that would bear on the questions they debate. Even more dramatically, neither indicates that conscious processing, including rationality, is limited in its speed and range. When Dreyfus assigns habitual and learned cultural patterns to the category of “absorbed coping,” he recognizes the role of habit but fails to articulate clearly how nonconscious cognition supports, and is supported by, conscious actions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Although McDowell recognizes that we may not consciously know how we know (“we simply find ourselves in possession of that knowledge”), he seems entirely unaware of the sophisticated pattern recognition and inference capabilities of the cognitive nonconscious, leading to a systematic overestimation of how important rationality is to everyday life among humans (although he does not explicitly say so, he seems to assume that only humans have rational capabilities). Dreyfus clearly wants to challenge this conclusion for reasons similar to those articulated in his two books outlining “what computers can’t do” (essentially, he argues that embodied human actions in contexts create richer horizons of meaning than computers can ever  ment and not making use of empirical evidence such as experiments, statistics, and so forth, he is operating within disciplinary norms of philosophical discourse and hence is more or less bound to try to settle this matter through discursive argument alone. Moreover, even within the narrow circle of argument, he does not always choose the most felicitous means of making the case for absorbed coping. His example of a chess master playing lightning chess casts his argument in an untenable either\/or position (the chess master either uses absorbed coping or he uses rationality). McDowell takes advantage of this slip to point out, rightly, that intellectual analysis has to be part of that activity as well. Although this is only implicit in Dreyfus’s argument, the fact that the activity is lightning chess is important, for the implication is that the chess master will not have time to think, an indirect reference to the fact that conscious thinking is much slower than nonconscious cognition. In fact, it is likely that nonconscious cognition sifts through the information and forwards to consciousness only the decision points where reason has to be invoked. This might occur, say, only 5 percent of the time in which all the decisions must be made, but this 5 percent may be what separates the chess master from the accomplished player, and the grand master from the master.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Again, Dreyfus’s argument here does not fully make clear the kind of coordination between consciousness and nonconscious cognition explicated by empirical research. In short, Dreyfus’s argument is not as powerful as it might be if he had availed himself of a different kind of rhetoric and frame of reference that would show the majority of human information processing is not conscious at all, which, as we have seen, is a proposition now widely accepted in cognitive science. Then the debate could turn, not on the question of whether humans are capable of reason (which seems to be how McDowell wants to reposition his argument), but whether reason is central to everyday human action in the world. Such a clarification would make it possible to talk about the ways in which nonconscious processing, while distinct from consciousness, is in constant communication with it and supports consciousness precisely by limiting the amount of information with which consciousness must deal, so that consciousness, with its slower speed and more limited processing power, is not overwhelmed. The point is not that humans are not capable of reason (obviously an easy fallacy to refute),  nition in order to be free to work on the kinds of problems it is well designed to solve. McDowell’s claim that intellectual activity is central to human life could then be understood not as a quantitative claim (how much of human cognition can be counted as rational, on which grounds he is simply wrong about its pervasiveness in all cognitive activity), but rather as a value judgment about how much reason is able to accomplish, and how important these accomplishments are to human sociality and modern human life. That nonconscious cognition is absolutely crucial to normal human functioning in the world can then be understood not as a refutation of reason’s usefulness, but as the ground for how and why consciousness—and along with it, reason—could develop at all. In summary, this famous debate, considered sufficiently important to warrant the publication of an essay collection devoted to it and attracting contributions by several other philosophers, misfires because it takes no account of nonconscious cognition, either by McDowell, who would surely be antagonistic to the idea, or by Dreyfus, who moves in a direction that research on nonconscious cognition would support and to which it offers important clarifications.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The debate opens a window on how a field such as philosophy, with its emphasis on rational argument, could be both challenged and energized by including nonconscious cognition in its purview. The same could be said of many different disciplines in the humanities, especially in this era when the digital humanities are bringing nonconscious cognition in the form of computer algorithms into the heart of humanistic inquiry, a topic addressed in chapter 8. ParaLLeLs To nonConsCious Cog niTions in oTher TradiTions Whereas the previous section discussed how disciplines dedicated to rational discourse can benefit from recognizing nonconscious cognitive processes, this section discusses non-Western and alternative traditions that partially overlap with, and also diverge from, this expanded view of cognition. Mindfulness, my first example, emerged as a meditative practice and stress-reduction technique when it was introduced into Western clinical practice by Jon Kabat-Zinn, among others, in 1979 at the University of Massachusetts Medical School (n.d,  been used to treat a variety of disorders, including PTSD, depression, anxiety, and drug addiction, and has achieved wide acceptance within the psychological clinical community and beyond. The technique begins with adopting a correct posture (sitting cross-legged or with a straight back on a chair) and focusing on one’s breathing. The beginning meditator will notice almost immediately that her mind begins to wander (a phenomenon explored at length in Michael C. Corballis’s The Wandering Mind: What the Brain Does When You’re Not Looking [2015]); she is advised to note this phenomenon nonjudgmentally, with an alert curiosity and acceptance, returning her focus to her breathing “when it feels right.”1 With practice, the meditator can remain focused for longer periods beyond the initial suggested time of ten minutes, and with more acute awareness of bodily rhythms, the evanescence of conscious experience, and a reflective acceptance of her responses to incoming stimuli, without becoming caught up in the responses themselves. Although Kabat-Zinn argued that the practice is not identified solely with Buddhism and other Eastern religions, citing American transcendentalists Henry Thoreau and Ralph Waldo Emerson, these figures were of course themselves very influenced by non-Western meditative practices. In terms of the framework developed here, meditative practices have the effect of diminishing investment in the narratives of consciousness, partially or wholly clearing the global workspace, and therefore making room for feedforward information coming from nonconscious processes, particularly about body processes, emotional responses, and present awareness, thus centering the subject and putting her more closely in touch with what is actually happening from moment to moment within her body as it is embedded within the environment.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Meditation in this sense is compatible with the framework developed here, adding an experiential component to the intellectual arguments presented thus far. In the Buddhist tradition, however, clear divergences begin to appear in the epistemological and especially the ontological consequences of meditative practices. The seminal text exploring both the convergences and divergences between nonconscious cognition and meditation is The Embodied Mind: Cognitive Science and Embodied Experience, by Francisco J. Varela, Evan Thompson, and Eleanor Rosch (1992). Published more than two decades ago, this text remains an  together with meditative practices. Focusing specifically on such practices as immersing oneself in the rhythmic activity of breathing (rather than being immersed in the narratives of consciousness), they note that in such moments, one becomes aware that “at each moment of experience there was a different experience as well as a different object of experience” (69). The obvious conclusion is that there is no self as such, only the transient flow of experience. Because consciousness fears that the loss of selfhood would equal death, it tends to panic and to grasp after the illusion of a self. The purpose of meditation is to overcome this reaction, realize the absence of a self (emptiness or sunyata) as an opening out into the world instead of a loss, and begin to explore the experience of awareness within this opening out.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The divergences spring from the further realizations and consequences of this emptiness. In the Buddhist traditions of Madhyamika schools, which seek a “middle way” between objectivism and subjectivism (Varela, Thompson, and Rosch, 229ff. ), emptiness extends both to subject and object, self and world. Just as there is no ground for the self, there is no ground for the world either. Neither rests on a transcendental or permanently objective basis. Instead, they bring each other into existence through their interplay, which the authors designate as “codependent arising” (110). As the authors state, this marks a significant difference even with Western traditions that similarly endorse the view that the self is an illusion. “There is no methodological basis [in Western disciplines] for a middle way between objectivism and subjectivism (both forms of absolutism).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In cognitive science and in experimental psychology, the fragmentation of the self occurs because the field is trying to be scientifically objective. Precisely because the self is taken as an object, like any other external object in the world, as an object of scientific scrutiny, precisely for that reason—it disappears from view. That is, the very foundation for challenging the subjective leaves intact the objective as a foundation” (230). The upshot, for them, is that they endorse the Buddhist views philosophically but maintain that on a practical, everyday basis, it makes little difference—except, that is, in the case of theories of cognition, where it leads to a framework they call “enactive cognitive science,” based on the premise that self is embedded in world and world in self. Even so, this theory remains only a theory. “Enactive cognitive science and, in a certain sense, contemporary Western pragmatism re-  challenging theoretical foundations, wish to affirm the everyday lived world. Enactive cognitive science and pragmatism, however, are both theoretical; neither offers insight into how we are to live in a world without foundations” (234). Hence the importance for them of Buddhist traditions, where “the intimation of egolessness is a great blessing; it opens up the lived world as path, as the locus for realization” (234).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Although it is beyond the scope of the present study to delve more deeply into the ontological questions Varela, Thompson, and Rosch raise, I note that nonconscious cognitive processes do not require and, to a certain extent, actively counteract the need for transcendental certitudes. To this extent, then, the framework developed here is compatible with enactive cognition, although questions about the interplay between objectivism and subjectivism may indeed mark a rupture where divergences appear between my approach and that of Varela, Thompson and Rosch. The last parallel I want to explore is with speculative realism as articulated in the work of Graham Harman (2011) and Ian Bogost (2012). Similarities include a desire to decenter the human, an interest in inquiring into the modes through which nonhuman others encounter the world, a realization that we can never be bats (as Thomas Nagel pointed out in his famous essay), and the felt need to create an integrated framework through which these ideas might coalesce. As I have written elsewhere (Hayles 2014b), I have several points at which I diverge from their views, including what I see as the dearth of relationality in Harman’s model, as well as his assertion (and Bogost’s) that objects recede from us infinitely and so can never be known at all, which seems to me obviously contradicted by empirical knowledge in all its forms including science, engineering, medicine, anthropology, and digital humanities. Beyond these particulars, there is also the emphasis on cognition, conscious and nonconscious, that is central to my framework but more or less irrelevant to theirs. Nevertheless, Bogost’s exposition of the Foveon-equipped Sigma DP digital image sensor (Bogost 2012, 65–66) can serve as a fine demonstration of how technical cognition works, although this is not how he frames it (he positions it as a caricature or metaphor to make it align with his assertion that we can never know how objects actually experience the world). To conclude this chapter, I want to zoom out from its detailed expositions and sketch in broad terms my vision of how a member of the  is capable of using reason and abstraction but is not trapped wholly within them; embedded in her environment, she is aware that she processes information from many sources, including internal body systems and emotional and affectual nonconscious processes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She is open to and curious about the interpretive capacities of nonhuman others, including biological life-forms and technical systems; she respects and interacts with material forces, recognizing them as the foundations from which life springs; most of all, she wants to use her capabilities, conscious and nonconscious, to preserve, enhance, and evolve the planetary cognitive ecology as it continues to transform, grow, and flourish. That, for me, is the larger picture toward which the details documented in chapter 2 point. ChaPTer 3  The Cognitive Nonconscious and the New Materialisms  Among the promising developments for reassessing the traditional humanist subject are the new materialisms. Their diversity notwithstanding, the theoretical frameworks proceeding under this banner generally argue for a similar set of propositions. Chief among these is decentering the human subject, along with the characteristics that have long been identified with human exceptionalism, including language, rationality, and higher consciousness. Also prominent is the idea that matter, rather than being passive and inert, is “lively” and “vibrant” (Bennett). In some versions of the new materialisms, a strong emphasis on ontology emerges (Barad, Parisi, Braidotti), accompanied by a reframing of ontological premises, often along Deleuzian lines emphasizing metastabilities, dynamic processes, and assemblages (Grosz; Parikka; Bennett). In general, these approaches tend to locate the human on a continuum with nonhuman life and material processes rather than as a privileged special category (Braidotti; Grosz).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Finally, they emphasize transformative potentials, often linking these with the capacity for new kinds of political actions (Grosz; Braidotti). After the baroque intricacies of the linguistic turn, these approaches arrive like bursts of oxygen to a fatigued brain. Focusing on the grittiness of actual material processes, they introduce materiality, along with its complex interactions, into humanities discourses that for too long and too often have been oblivious to the fact that all higher consciousness and linguistic acts, no matter how sophisticated and abstract, must in the first instance emerge from underlying material processes.1 Despite their considerable promises, the new materialisms also have significant limitations. Conspicuously absent from their consid-  concern that if they were introduced, it would be all too easy to slip into received ideas and lose the radical edge that the focus on materiality provides. This leads to a performative contradiction: only beings with higher consciousness can read and understand these arguments, yet few if any new materialists acknowledge the functions that cognition enables for living and nonliving entities. Reading them, one looks in vain for recognition of cognitive processes, although they must necessarily have been involved for these discourses to exist at all. A new materialist might object that there are already plenty of discourses, historical and contemporary, that play up the roles of consciousness and cognition, and it is not her obligation to rehearse or amend these in order to foreground materiality. Separating materiality from cognition does not, however, strengthen the case for materiality.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  On the contrary, it weakens it, for it erases the critical role played by materiality in creating the structures and organizations from which consciousness and cognition emerge. While this is by no means all that the “liveliness” of materiality can do, it is a particularly fraught and consequential form of material agency, and to ignore it leads to a very partial and incomplete picture. Moreover, such erasures encourage overly general analyses, in which crucial distinctions between kinds of material agency are not acknowledged, presumably because to include them would compromise the decentering project. To reason so confuses decentering the human with its total erasure, an unrealistic and ultimately self-defeating enterprise, considering that the success of the decentering project depends precisely on persuading humans of its efficacy. The framework provided by an expanded idea of cognition can help to offset these limitations (Hayles 2014a). Traditionally, cognition has been identified with human consciousness and thought. As we have seen, this view is now under pressure from the emergence of cognitive biology, a scientific field that advances a much more capacious view of cognition, maintaining that all life-forms have some cognitive capacity, even plants and microorganisms. In the area of human cognition, nonconscious cognition has been shown to perform functions essential to consciousness; moreover, there is growing evidence, as documented in chapters 1 and 2, that most human behavior is not conscious but rather stems from both unconscious scanning and nonconscious processes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The emphasis on nonconscious cognition participates in the central thrust of decentering the human, both because it recognizes another agent in addition to consciousness\/unconsciousness in cognitive processes, and because it provides a bridge between human, animal, and technical cognitions, locating them on a continuum rather than understanding them as qualitatively different capacities. In addition, nonconscious cognition encourages us to recognize distinctions between different kinds of material processes and correspondingly different kinds of agencies. In particular, it distinguishes between material forces that can adequately be treated through deterministic methods, forces that are nonlinear and far from equilibrium and hence unpredictable in their evolution, the subset of these that are recursively structured in such a way that life can emerge, and the yet smaller set of processes that lead to and directly support cognition. Agencies exist all along this continuum, but the capacities and potentials of those agencies are not all the same and should not be treated as if they were interchangeable and equivalent. Finally, the nonconscious cognitive framework provides a countervailing narrative to the Deleuzian concepts and vocabularies pervasive in the new materialisms, recognizing that forces, intensities, assemblages, and the rest are balanced in living systems with forces of cohesion, survival, and evolution. Without such correctives, the enthusiasm for all concepts Deleuzian threatens to ensnare some of the more extreme instances of new materialism in a self-enclosed discourse that, although it makes sense in its own terms, fails to connect convincingly with other knowledge practices and veers toward the ideological, in which practices are endorsed for their agreement with the Deleuzian view rather than because they adequately represent acts, practices, and events in the real world. Making this case requires careful consideration of the differences between various camps among the new materialisms, along with a rigorous exploration of where and how a nonconscious cognitive framework adds constructively to new materialist projects, where it differs from new materialist claims and provides useful correctives, and where it breaks new ground not considered by the new materialists. To facilitate the analysis, the argument will proceed according to concepts central to new materialisms, including ontology, evolution, survival, force, and transformation.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  onToLogy An outlier among new materialists, Karen Barad derives her brand of materialism from the physics-philosophy of quantum mechanicist Niels Bohr. Faced with experimental evidence for the wave-particle duality in the 1920s, Bohr developed an interpretation distinctly different from that of Werner Heisenberg. As is well known, Heisenberg argued for the “interference” interpretation (the observer interferes with the experiment, which leads to the Uncertainty Principle: the uncertainty in the momentum times the position cannot be less than a minute quantity calculated from Planck’s constant). Bohr, by contrast, thought that the issue was more complex. He pointed out that to perform a measurement, the experimenter has to decide on an experimental apparatus. Using a simplified setup for clarity, Barad shows that the apparatus used to measure position is mutually exclusive from one measuring momentum, so the experimenter must choose between them. Consequently, as the apparatus measuring position achieves more precision, the measurement of momentum becomes correspondingly more uncertain, and vice versa. Bohr understood this situation as implying, not that the experimenter has “disturbed” the measurement, but rather that the position and momentum do not have determinate values until they are measured.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As Barad points out, later experiments confirmed his intuition. For Bohr, this phenomenon remained in the realm of epistemology. The point for him was that interactions, which include the experimental apparatus and the experimenter, form an inextricable unit determining how reality manifests itself and placing theoretical limits on what can be known. Making the leap into ontology, Barad’s strong contribution extends Bohr’s insight. She calls the measuring\/measurer unit a “phenomenon,” explaining that “phenomena are specific material performances of the world” (2007, 335) and coining the term “intraaction” to designate them, “intra” emphasizing that at least two agents must be involved, each bringing the other into existence simultaneously through their intraactions. Thus she answers one of philosophy’s first questions: why is there something rather than nothing? A universe without intraactions would in her view be a contradiction in terms, because without intraactions, the universe could not exist as such. In a course I co-taught with particle physicist Mark Kruse at Duke  chanics in science and fiction, we and the students worked through Barad’s book together.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Mark is part of the team that recently discovered the Higgs boson, and I was interested in his reaction to Barad’s claims; as a scientist, he must necessarily believe that the experiments he and his colleagues conduct at CERN indicate something about reality. Of all the scientific fields, particle physics (along with cosmology and cosmochemistry) comes closest to probing experimentally philosophy’s first question, although I doubt that anyone in the field would claim he has definitive answers. (When confronting this kind of issue, Mark was fond of saying, “That’s a philosophical question,” meaning that the question is not susceptible to experimental testing). Nevertheless, particle physics now offers a scenario of the universe’s first nanoseconds after the Big Bang (a temporal regime called “inflation”), and it has postulated the mechanisms and curtailments of that stupendous event. No doubt with that background in mind, Mark commented that he thought Barad’s vision was both reasonable and consistent with empirical results of his field. Barad, of course, does not terminate her analysis with quantum mechanics, extrapolating her notion of “agential realism” into discourses, cultural politics, and feminist theory to emphasize the crucial role of inter\/intraactions in those fields. Nevertheless, her careful explications of quantum mechanical theories and experiments provide the critical grounding for her project and lend it a certain cachet. She makes the point (not generally recognized) that quantum mechanics applies to macroscopic as well as microscopic objects and that it is our most encompassing, most successful scientific theory to date.2 Her impressive expertise with quantum mechanics notwithstanding, a skeptical reader may well ask what differences are entailed when her analyses move from elementary particles to organisms, humans, and cultures.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Even if the fundamental level of reality is intraactional, does that necessarily imply that cultures are? Here is where the framework of nonconscious cognition can contribute significantly, for the issue of levels is crucial to it. The specific dynamics operating at different levels provide a way to distinguish between material processes and nonconscious cognition as an emergent result, as well as elucidating the modes of organization characteristic of consciousness\/unconsciousness. The framework thus helps to bridge the gap between quantum effects and cultural dynamics, filling  exist but that she does not explicitly discuss. In this respect she is not unlike most new materialists, for the issue of level-specific dynamics gets short shrift in their discourses, as does the empirical fact that these levels are characterized by different modes of organization. By making clear how some of these distinctions work, the framework of nonconscious cognition offers a useful corrective to new materialist theories and claims. For example, as we saw in chapter 2, nonconscious cognitive processes cannot persist beyond about 500 ms without reinforcement from neurons with long axons involved in the production of consciousness (Kouider and Dehaene [2007]; Dehaene [2009]). Once this top- down reinforcement occurs, what follows is the “ignition of the global workspace,” as Stanislas Dehaene calls it, whereby reverberating circuits are activated and thoughts can persist indefinitely.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The combination of bottom-up signals with top-down reinforcement illustrates how important distinct levels are in neuronal processes in biological organisms. Similarly scale-dependent phenomena are also found in technical cognitions of computational media, where bottom-up and top-down communications take place more or less continuously. To understand why new materialisms tend to gloss over levels, we may refer to the philosophy of Gilles Deleuze, which has been enormously influential in the new materialisms. As Elizabeth Grosz observes in her explication of Deleuze, “Deleuze is primarily an ontologist, whose interest is in redynamizing our conception of the real” (Grosz 2011, 55). Writing against the subject, the organism, and the sign (Deleuze and Guattari 1987), Deleuze in the writings he coauthored with Guattari and in his single-author works aims to create a vision that does not depend on those entities and embraces a vitality driven by affects, intensities, assemblages, and lines of flight. He and Guattari acknowledge, of course, that subjects exist, but they highlight the forces that cut transversally across levels and thus do an end-run around most of the concepts populating traditional philosophy. “One side of a machinic assemblage faces the strata, which doubtless make it a kind of organism, or signifying totality, or determination attributable to a subject; it also has a side facing a body without organs, which is continually dismantling the organism, causing asignifying particles or pure intensities to circulate, and attributing to itself subjects that it leaves with nothing more than a name as the trace of an intensity”  In the more extreme interpretations of Deleuze, some new materialists focus almost entirely on the “side facing a body without organs,” eradicating from their narratives the necessary other side to the story, the forces of cohesion, encapsulation, and level-specific dynamics characteristic of living beings, for example in Jussi Parikka’s characterization of insects as “mechinological becomings” (2010, 129). As we will see in the following section, this leads either to contradictions, very partial accounts, or significant distortions of scientific practices, especially evolutionary biology.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This extreme approach also makes nonconscious cognition, along with the modes of awareness, almost impossible to imagine and certainly impossible to formulate as a formative force in contemporary culture. evoLuTion One of the bolder attempts to apply Deleuzian principles is Luciana Parisi’s Abstract Sex: Philosophy, Bio-Technology and the Mutations of Desire (2004). This project is noteworthy because, unlike most new materialisms, it creates a framework that recognizes and connects different levels of analyses, including evolutionary biology (the biophysical), sexual reproduction (the biocultural) and biotechnology (the biodigital). Intending to construct a counternarrative to what she calls “Darwinism and neo-Darwinism,” Parisi focuses on Lynn Margulis’s theory of endosymbiosis, the process by which cells absorbed other freely living organisms in mutations estimated to have occurred 1.5 billion years ago. In this theory, eukaryotic cells (cells with a nucleus and organelles enclosed by a membrane) originated from communities of interacting entities. The idea interests Parisi because she sees it as contesting a view in which natural selection works through heredity, thus privileging the repetition of the same. According to her, in the Darwinian paradigm heredity “crucially designates the economy of self-propagation of the genetic unit (the cause of all differences). Heredity confirms the autonomy of genes from the environment .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . The environment within which the organism is born cannot re-programme the hereditary function of genetic material” (49). This passage makes clear why she would see “Darwinism and neo-Darwinism” as the enemy, for inheritance in this view is a fundamentally conservative force, all the more so since natural selection is understood as a competitive  To a large extent, the specter she battles is a paper tiger. This view of evolution may have held true for evolutionary biology in the 1940s, but recent work in epigenetics has shown that DNA is not the whole story of how genes are expressed. Crucially important is gene regulation, carried out by hormones and other chemical signals that regulate when and what genes are activated. These regulatory mechanisms, in turn, have been shown to be affected by environmental conditions (López-Maury, Marguerat, and Bähler 2008). Consequently, gene expression does not, as Parisi would have it, exclude “the feedback relations between environment and genes” (49). Moreover, her argument ignores the Baldwin effect, which traces a feedback loop between mutations in species and the ways in which a species modifies its environment to favor the mutation, another means by which the environment is connected to evolutionary developments.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In addition, the Darwinian paradigm assumes that every species is attuned to the possibilities and challenges offered by its ecological niche, defined by its relation to other species and the dynamics of the surrounding habitat. It is simply incorrect, then, to assert as she does that “the environment [in neo-Darwinism] is destined to die as an irrelevant, inert and passive context of development” (49). Why focus on endosymbiosis? The theory appeals partly because of its displacement of “the zoocentrism of the theories of evolution (the priority of Homo sapiens)” (62); in addition, it emphasizes assimilation and networking (Margulis and Sagan 1986) rather than a competitive struggle to survive. To position this theory as opposed to “Darwinism and neo-Darwinism,” however, misses the point that assimilation and networking are themselves evolutionary survival strategies, particularly if one accepts (as Parisi does) that anaerobic bacteria merged with respiring bacteria as a survival strategy when the earth’s atmosphere began to change and the oxygen level rose (63). These flaws notwithstanding, Parisi’s vision works well at the level of endosymbiosis and leads to novel views of “abstract sex,” by which she means an analysis that “starts from the molecular dynamics of the organization of matter to investigate the connection between genetic engineering and artificial nature, bacterial sex and feminine desire that define the notion of a virtual body-sex” (10). If this seems difficult to understand, she offers this clarification, in a passage that makes clear her Deleuzian orientation. “Primarily sex is an event: the  mation that unleashes an indeterminate capacity to affect all levels of organization of a body—biological, cultural, economical and technological .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . Far from determining identity, sex is an envelope that folds and unfolds the most indifferent elements, substances, forms and functions of connection and transmission” (11). The vision of sex as a force that cannot be confined to a subject (whether human or animal) and that permeates life (and nonlife) at all levels, down to and including the molecular, is a compelling insight when applied at the level of bacteria and the functions of assimilation, division, nutrition, and reproduction they carry out. The vision works less well as Parisi moves to her other two levels, the biocultural and biodigital. The problem here is not so much that her analysis is incorrect as that it operates almost entirely within a Deleuzian perspective, making it difficult to connect her comments with other well-developed discourses in biotechnology, digital media, information, and cultural studies. For example, in the section “Organic Capital,” she writes, “With industrial capitalism, reproducibility becomes abstracted from the socio-organic strata through a new organization of biophysical forms of content and expression aiming to subject and regulate masses of decoded bodies (substances of content and expression). Industrial capitalism involves a reterritorialization of decodified socio-organic modes of reproduction (nucleic and cytoplasmic) bringing their sparse codes to the rhythms of mechanical reproduction” (103). The objects of her critique here, including genetic engineering, assisted reproductive techniques such as in vitro fertilization, human and nonhuman cloning, and so forth, are all brought within the purview of “industrial capitalism,” without much specificity about what techniques are involved, what the problems are, and exactly how her analysis works to solve them, other than by discursively opening preconceived\/preexisting entities to the forces of Deleuzian deterritorialization. It is not surprising that her analysis works best at the level of bacteria and cells, for here there is no consciousness to complicate the struggle for survival.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Surrounded by a permeable membrane defining an inner and outer environment, a unicellular organism interacts with its milieu in ways qualitatively different than more complex organisms, including very short timelines for reproduction and relatively rapid rates of mutation. Its potential for transformation is correspond-  as sensitivities to “intensities” and of the cell as a mutating “assemblage” indeed capture some of its significant aspects. As organisms become more complex, cellular dynamics are integrated with many other levels and modes of organization, and the countervailing forces to Deleuzian deterritorialization become correspondingly stronger. Consequently, Parisi must fall back almost exclusively on Deleuzian vocabulary and concepts at the biocultural and biodigital levels, creating a kind of self-enclosed discursive bubble unable to create meaningful links with actual practices in the world. A midlevel example of biolife forms more complex than single cells but still much simpler than mammals are insects, which may therefore pose an interesting case for how far the Deleuzean dynamics of flow, metamorphosis, and deterritorialization can apply in convincing and persuasive ways. Insects are like unicellular organisms in being devoid of consciousness; like cells, they also have relatively short timelines to reproduce and greater frequencies of mutations (the reason, of course, that fruit flies have been favorites of experimenters for decades). Jussi Parikka has applied Deleuzian ideas to insects, including to the interesting case of insect swarms, where nonconscious cognition emerges as the potential for collective action increases through chemical signaling and other nonsemantic modes of communication. Referring to von Frisch’s pioneering work on bee communication, Parikka argues they are not representational entities but machinological becomings, to be contextualized in terms of their capabilities of perceiving and grasping the environmental fluctuations as part of their organizational structures .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . where the intelligence of the interaction is not located in any one bee, or even a collective of bees as a stable unit, but in the ‘in-between’ space of becoming: bees relating to the mattering milieu, which becomes articulated as a continuum to the social behavior of the insect community. This community is not based on representational content, then, but on distributed organization of the society of nonhuman actors” (129). The denial of representation is striking, especially in light of the socalled “waggle” bee dance, where the orientation of the bee, the energy it puts forth, and the direction of the dance all communicate precise  sentation, in Parikka’s view? It seems that the primary reason is to maintain faithfulness to the Deleuzian paradigm, even when the facts indicate otherwise. Evoked instead is the continuum between the bees and their milieu, intensities as forces that precede and displace the individual, and contingent assemblages. While this vocabulary and set of concepts work well to characterize certain aspects of the behaviors of social insects, they underplay the possibilities for nonconscious cognition and representational actions, an erasure that the framework of nonconscious cognition would help to correct. This raises the important question whether a middle ground may be forged between Deleuzian becomings and cognition, subjectivity, and higher consciousness. On the one hand, a purist may object that such a middle ground is impossible, because the privilege of origin must be located either with forces and intensities, from which everything else derives (the Deleuzian view), or with the individual subject as a pre-existing entity upon which forces operate.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In this view, both cannot have priority simultaneously, and the choice of one or the other entails complex chains of consequences that amount to different worldviews. Suppose, however, that we position them not as contraries forcing an either\/or choice but as two different perspectives on an integrated whole (as Deleuze and Guattari seem to suggest in identifying two sides to an assemblage), each with its own truths and insights. In this case, an analogy may be drawn between this situation and the particle\/wave duality that Barad discusses. In this analogy, the particle, located as a point mass in space, corresponds to an entity, while wave action, propagating in a nonlocalized manner for a temporal duration, resembles an event. If we ask whether entities or events are primary, from Barad’s perspective we are asking the wrong question. Rather we should inquire where are the points of intraaction, the dynamic and continuing interplays between material processes and the structured, organized patterns characteristic of consciousness. Mediating between material processes and modes of awareness, nonconscious cognition provides a crucial site where intraactions connect sensory input from the internal and external environments (“events”) with the emergence of the subject (“entities”). In this view, the nonconscious cognitive framework is positioned not as anti- or pro-Deleuzian but as the mediating bridge between the two perspectives.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Among the theorists who have attempted to adopt a similar me-  are Elizabeth Grosz and Rosi Braidotti. While both strike some kind of balance between forces\/intensities and subjects\/organisms, each has her specific way of doing so, along with a distinctive rhetoric and mode of reasoning. We may compare their approaches through the crucial issue of survival, and in this context further explicate the role that nonconscious cognition plays. survivaL In her elegant discussion of Darwin, Elizabeth Grosz seeks to align him both with Bergson and Deleuze. Specifically, what she sees in Darwin that contributes to her project of decentering the human is his insistence on the continuum of humans with animals and all of life through evolutionary processes, making the differences between humans and nonhuman animals a matter of degree, not an absolute separation. If the human characteristic of language, for example, is already present in other animals to a lesser degree, then a small step leads to Deleuze’s view of life as “the ongoing tendency to actualize the virtual, to make tendencies and potentialities real, to explore organs and activities so as to facilitate and maximize the actions they make possible” (Grosz 2011, 20). Of course, something has to be erased from Darwin to bring about this rapprochement, specifically his assumption that natural selection works on and through the organism (as well as groups of individuals), whereas for Deleuze the organism is what emerges sometimes in metastabilities subject to constant dynamic rearrangements. In part Grosz sidesteps the organism as the focal point for natural selection through her emphasis on sexual selection.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Claiming that sexual selection cannot be reduced to natural selection (as some evolutionary biologists seek to do), she aligns sexual selection with the “force of bodily intensification, its capacity to arouse pleasure or ‘desire,’ its capacity to generate sensation” (118). This is tied in with an emphasis she sees in Darwin of “the nonadaptive, nonreductive, nonstrategic investment of (most) forms of life in sexual difference and thus sexual selection” (119). Of course, a skeptic can point out that sexual selection is tied to natural selection through competition for mates and thus ultimately for reproductive success, a point Grosz acknowledges but insists cannot be the whole story (120). Indeed, if we  to see what fitness this might signal. Rather, the reasons that peahens prefer one peacock instead of another seem to have very little to do with reproductive fitness and a great deal to do with pleasure, desire, and sensation, just as Grosz argues. What can the framework of nonconscious cognition add? The implicit conflict between the Darwinian organism and the Deleuzian flow becomes most apparent in Grosz’s essay “A Politics of Imperceptibility” (2002). Arguing against identity politics as a feminist strategy, she points out that even an identity acknowledged to be heterogeneous and fractured still assumes that identity will be replicated over time, thus leading to a repetition of the same.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For real change to be possible, Grosz argues, one needs a different theoretical orientation, one that emphasizes transformations and openness to constant changes and deterritorializations—namely, the Deleuzian paradigm. Still, it is difficult to see how political agency can be mobilized without some references to subjects, organisms, and signs, the entities that Deleuze writes against.3 Nonconscious cognition provides a means by which agency can be located in material processes and in nonconscious cognition as their emergent result, without implying the allegedly stultifying effects of a consciousness unable to transform in relation to its environment.4 “It is a useful fiction to imagine that we as subjects are masters or agents of these very forces that constitute us as subjects, but misleading,” Grosz writes (2002, 471). Nonconscious cognition is the link connecting material forces to us as subjects, thus serving to deconstruct the illusion of subjects as “masters . . . of the very forces that constitute us,” without requiring that subjects be altogether erased or ignored as agents capable of political actions. Notwithstanding the sometimes strained quality of Grosz’s argument here, imperceptibility has been given a new purchase on the political by the recent revelations of spying by the NSA and the associated tracking and data collecting of social media, search engines, and the like. Many are now taking down their Facebook pages and trying to erase their presences on the web, so imperceptibility has come to seem a desirable position to occupy. In 2006 Rosi Braidotti anticipated this trend in extending Grosz’s argument (while also modifying it) in her focus on “The Ethics of Becoming Imperceptible.” Unlike many new materialists, Braidotti acknowledges subjects, with an emphasis on the  in the corporeal materiality of the self, but the enfleshed intensive or nomadic subject is an in-between: a folding-in of external influences and a simultaneous unfolding- out of affects” (135). Obviously influenced by Deleuze and Guattari, Braidotti in The Posthuman nevertheless declares, “I am very independent in relation to them” (2013, 66).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Her independence can be seen in how she conceives the sustainable subject: “Sustainability is about how much of it a subject can take and ethics is accordingly redefined as the geometry of how much bodies are capable of” (136). By “how much of it a subject can take,” she means how much a subject can open itself to the “forces, or flows, intensities and passions that solidify—in space—and consolidate—in time—within the singular configuration commonly known as an ‘individual’ (or rather: di-vidual) self” (136). Her balancing act, then, is to conceive of the subject as an entity open to events, up to a threshold that marks where the subject would disintegrate altogether: “our bodies will thus tell us if and when we have reached a threshold or a limit” (137). Balancing on this threshold, the subject in her discourse sometimes sounds like a stable entity, and at other times, like a momentary assemblage about to disintegrate (note the hesitation above between the “individual” and the Deleuzian “dividual”). The same balancing act is evident in this passage: the subject is an “intensive and dynamic entity . . . [that is] a portion of forces that is stable enough—spatiotemporally speaking—to sustain and to undergo constant fluxes of transformation” (136). Ethics, then, “consists in re-working the pain into threshold of sustainability” (139), a determination to take the coherent self as far into the flux as possible while still maintain its integrity as a self: “cracking, but holding it, still” (139). By calling this the “sustainable” subject, Braidotti of course implies that survival is a paramount concern.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Yet we know that all “individuals” (and even “dividuals”) must die. The apparent conflict between death and sustainability is negotiated in her discourse by arguing that death applies only to the individual. Acknowledging that “self-preservation is a commonly shared concern” (146) and that “self-preservation of the self is such a strong drive that destruction can only come from the outside” (146), she nevertheless urges that we see death as “the extreme form of my power to become other or something else” (146), for example, the molecules that survive the body’s decay, or if not molecules (many proteins do not survive the death of the individual), then the  Surely the only creatures that can reason so, however, are humans; virtually all other life-forms will struggle to live as long as they can, a sign that they are never reconciled to death. Even as the gazelle feels the lioness’s claws in her back, she still desperately kicks to get away. In this sense, Braidotti reinstalls human privilege in the face of death. Although she argues that her framework “implies approaching the world through affectivity and not cognition” (139), surely only cognition—specifically, the higher consciousness that humans possess—can achieve the rapprochement with death that she recommends. One wonders, then, why she introduces the idea at all. I conjecture she requires it to achieve a resolution to the conflict between her insistence that the subject is sustainable and her commitment to the Deleuzian paradigm.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It is, so to speak, the price of sustaining the balance: the individual disappears but reappears in the Deleuzian flows and intensities with which we are nevertheless urged to identify as somehow another form of “us.” For the positions Grosz and Braidotti articulate, nonconscious cognition offers another interpretive option, a site in which subjects can emerge without implying they are immune to flows and intensities (Grosz’s concern), and without requiring that the living human subject should balance at the threshold of disintegration without exceeding it (Braidotti’s emphasis). Moreover, as shown in chapter 1, there is considerable empirical evidence that the kind of neurological structure giving rise to nonconscious cognition exists throughout the animal kingdom, including but by no means confined to humans. The issue of whether a discursive or ideological position has empirical support is, of course, complex, since the chains of reasoning involved in arriving at such conclusions are necessarily permeated with numerous assumptions about what constitutes evidence, what standards of confirmation are entailed, etc. Nevertheless, in my view a position that can claim empirical support is preferable to one that cannot; otherwise, as Bruno Latour has pointed out, it is impossible to distinguish between what is actually the case and what is ideologically driven fantasy. Not surprisingly, the Deleuzian paradigm does not place much (if any) emphasis on empirical verification, preferring to talk about “royal sciences.” These, according to Deleuze and Guattari, are concerned with the discovery of abstract laws and general principles, in contrast to the “minor sciences,” concerned with heteroge-  ena difficult to mathematicize (Deleuze and Guattari 1987, 398–413, esp. 413). Nonconscious cognition subverts this distinction, because it is inherently difficult to measure and yet has strong empirical confirmation from a range of experiments (see Lewicki, Hill, and Czyzewska). Bridging the gap between the mainstream “royal” and marginalized “minor,” it challenges the belief that most human behavior is directed by consciousness, without requiring that we accept the ideologically laden assumption that the “minor” or marginal is inherently superior to the “royal” or major.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  forCe “Force” is often invoked in the Deleuzian paradigm, but seldom is this designation made more specific or precise. In this worldview, force is an essential concept, for if subjects are absent, agency must be located somewhere, and “force” becomes a kind of agentless agent, the driving desire that brings about and also participates in “agencement” (usually translated as “assemblage,” a noun perpetually at risk of losing the Deleuzian emphasis on the eventful). Grosz, for example, writes of the “play of the multiplicity of active and reactive forces that have no agency, or are all that agency and identity consist in. Which is to say, force needs to be understood in its full sub-human and super-human resonances: as the inhuman . . . which both makes the human possible and which at the same time positions the human within a world where force works in spite of and around the human, within and as the human” (2002, 467). The eloquence of this passage notwithstanding, it remains extremely imprecise about the nature of “force” and fails to distinguish between different kinds of forces, although these kinds of distinction have been extensively investigated in various scientific fields. On the atomic and molecular levels that Parisi invokes, for example, four fundamental forces are recognized: strong, weak, electromagnetic, and gravity. In chemistry, other kinds of forces come into play in solutions and suspensions, leading to the possibility for self-organizing dynamics to come into play for far-from-equilibrium systems.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Parisi often invokes this language, but also fails to notice the importance of systems at equilibrium, whose dynamics can be described by linear differential equations. A great deal is known about when a system’s  a rocket to the moon, for example, or braking a car under specified weather conditions). The privilege that Parisi and others accord to nonlinear dynamics is often associated with unpredictability, and hence implicitly with the alleged inability of science to deal adequately with such systems. This ignores the important new field of simulation science, where chaotic and complex systems are modeled and yield reliable knowledge about how such systems will behave (Parikka is atypical in his interest in computer simulations on insect swarms and other swarming and schooling behaviors). Moreover, the vagueness of “force” elides an issue that ought to be crucial to the new materialisms: the differences between material forces whose actions are deterministic and hence can be calculated precisely as the sum of the relevant forces, and those that involve self-organizing, chaotic, and complex dynamics and whose actions can lead to the emergence of increasingly complex outcomes, including life and cognition. Among this group, there is also a crucial distinction between systems that are adaptive and those that are not. Both the BZ (Belousov-Zhabotinsky) reaction in chemistry and bacteria’s endosymbiosis history are examples of self-organizing systems, but the bacteria are adaptive and can change when conditions change, whereas the BZ reaction, although unpredictable in the various visual displays it creates, cannot adapt in the same way. In attributing agency to nonhuman forces, these kinds of distinctions are critical.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  A rock thrown against a window, for example, can be said to act as an agent when it breaks the glass; in this case, its trajectory and force are entirely deterministic and can be calculated precisely if the relevant factors are known. A different kind of agency is exhibited by an avalanche, capable of killing humans and other lifeforms and releasing energies on an awesome scale. Unlike the thrown rock, it involves criticality thresholds, which means that it may be difficult or impossible to predict exactly when it will take place. Nevertheless, the agency here is not intentional or mysterious; if all of the relevant factors are known, it can be modeled so as to arrive at a reasonable estimate of how it will behave (the same can be said of earthquakes, where models can predict likely sites for earthquakes and a rough estimate of the span during which they are likely to happen, although the models are not good enough to predict exactly when). dynamics; here truly surprising results may emerge, the preeminent example of which is the emergence of life millions of years ago in the planet’s history. All of these may be said to demonstrate the agency of material processes and the importance of nonhuman forces, but such generalizations are vapid without more precision about the kinds of dynamics and structures involved. Why keep “force” so vague, then, when so much is known about different kinds of forces and the different agencies they embody? As soon as agency is discussed in the terms indicated above, the mysterious effects of “force” driving the Deleuzian paradigm evaporate into a collection of known agencies.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Even when different kinds of agencies are acknowledged, there is a tendency to privilege those that lead to complexity and self-organization (evident in Parisi, for example), valuing the nonlinear over the linear, and the far-fromequilibrium over systems at equilibrium, presumably because these are the forces that lead to novel and unexpected results. Yet these same nonlinear systems are the ones from which life emerged. One might logically suspect, then, that embedded in these preferences is an implicit trajectory that would privilege the living over the nonliving, the complex and adaptive over the simple and deterministic. This result is forbidden, however, by the overall aim of decentering the human and celebrating the nonliving as fully capable of agency. Without further specification about the different kinds of agencies and forces, this contradiction indicates that the preference for one kind of force over another is an ideological choice, not an empirical conclusion. The framework of nonconscious cognition differs from the majority of new materialisms by being explicit about structures, dynamics, and organizations (i.e., “forces”) at multiple levels across the human, animal, and technological spectrum. Implicit in the framework is an emphasis on cognition in general, and thus a belief that cognition is important and worthy of study. Indeed, in arguing for nonconscious cognition, the framework aims to increase the kinds of acts that are seen as cognitive, especially those in which consciousness is not involved.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In this sense, then, it can be said to enlarge the realm of the cognitive as a special kind of capability that emerges from, and yet is distinct from, the material processes that underlie it. To explore further what this kind of approach has to offer, I turn now to transfor-  TransformaTion Transformation is typically highly valued in new materialist discourses, for a variety of reasons: the hope for constructive changes within the political scene (Grosz, Braidotti); a kinder, more eco-friendly world not centered around humans (Parisi, Shukin, Bennett); and the possibility of opening up productive changes within humans themselves (Braidotti, Parikka). These are important and significant goals, and the idea of locating agency within material processes is an intriguing possibility, especially given the desirability of locating agency other than in human actors. Nevertheless, the largest transformative forces on the planet today are undoubtedly human agency and human interventions, the effects of which are being registered in climate change, the worldwide loss of habitat for nonhuman animals, the idea of the Anthropocene, and in the reality that human actions are unleashing forces far beyond our ability to control them. It would seem, then, that a discussion of transformation must necessarily involve recognition of human agencies and the recent exponential growth of nonconscious cognition in technical objects. Jane Bennett, arguably less indebted to Deleuze than some other new materialists (although she mentions him and uses some Deleuzian vocabulary), recognizes the interpenetration of technics and humans in her references to Bernard Stiegler. As I have argued elsewhere (Hayles 2012), this interpenetration applies not only to the dawn of the human species in the Pleistocene era but also in the present, especially in the deep technological infrastructure affecting everything from human directional navigation to the neurological structures activated by reading on the web. Bennett (2010) makes an important point with regard to this interpenetration: namely the implication that human agency is always distributed, not only within the body between consciousness and nonconscious faculties, but also between the body and the environment.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Her examples include edible matter (affecting the body through nutrition), minerals (through bone formation, for example), and worms (whose “small agencies” [96] can be seen in the transformation of forest into savannah as recent research has shown, an example not mentioned specifically by Bennett). Allowing herself the speculation that the “typical American diet” may have played a role in “engender-  invasion of Iraq” (107), she clearly wants to make connections across multiple levels of analysis, but her focus on material processes makes such an idea almost impossible to document or even to explore. Adding nonconscious cognition into the picture, especially in relation to drones, unmanned autonomous vehicles (UAVs), and other technical devices, would help to bridge the chasm that currently yawns between her examples and her speculations. In conclusion, a robust account of material processes should not be the end point of analysis but rather an essential component of a multilevel approach that ranges from the inorganic to the organic, the nonhuman to the human, the nonconscious with consciousness, and the technical with the biological. While many new materialists might argue that far too much consideration has been given to the “entity” side of these intraactions, resulting in a devaluation of material processes, dwelling entirely on the “event” side fails to capture essential characteristics of the living, especially the ability of living organisms to endure through time, construct as well as interact\/intraact with their environments, and deploy agencies that are not merely emergent but also intentional, even when nonconscious. While it is likely that no one approach can do all this, nonconscious cognition can supply essential components presently absent from most new materialist analyses. Politically, nonconscious cognition grants to a technological object the privilege of what amounts to a worldview, thus linking its behaviors to the nature of the sensors and actuators that together constitute and define its capabilities.5 While living organisms (with a few exceptions) must be understood retroactively (for example, by reverse engineering the evolutionary processes), technical objects have been made. Leaving aside emergent results (a special case that requires careful orchestration to succeed), each technical object has a set of design specifications determining how it will behave.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When objects join in networks and interact\/intraact with human partners, the potential for surprises and unexpected results increases exponentially. The Deleuzian paradigm contributes an enhanced appreciation for nonliving technical objects to generate surprises, new potentialities, and mutating assemblages. The nonconscious cognitive framework supplies a nonreductive empirical approach that enlists the cognitive powers of humans, along with a precise analysis of the structures and  nitive powers of their own. This is not exactly new materialism, vibrant materiality, imperceptibility, or nomadic subjectivity, but rather a paradigm that, cognizant of scientific and technical knowledges, nevertheless strives to bring about a transformation of traditional views of the place of the human in the world. ChaPTer 4  The Costs of Consciousness: Tom McCarthy’s Remainder and Peter Watts’s Blindsight  Like the dark harmony running underneath a bright melody praising the virtues of consciousness, the suspicion that consciousness may not be all it is cracked up to be (by consciousness itself) runs through the history of Western thought. In the late nineteenth and early twentieth centuries, movements such as surrealism and practices like automatic writing sought to crack open the conscious surface and let something else—less rational, less dedicated to coherence—emerge. In the late twentieth century, this tendency began to assume sharper edges, honed by neuroscientific research on brain traumas and other neurological anomalies and benefiting from improved diagnostics, particularly PET and fMRI scans. Popular accounts of neurological deficits, such as Oliver Sacks’s The Man Who Mistook His Wife for a Hat (1998) and Antonio Damasio’s Descartes’ Error: Emotion, Reason, and the Human Brain (1995), called attention to the crucial role of nonconscious processes in supporting normal human behavior and the inability of consciousness, stripped of these resources, to carry on as if nothing had happened.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As these ideas spread through the culture, writers began to pick up the beat, exploring cracks in consciousness through such works as Richard Powers’s The Echo Maker (2007), Jonathan Lethem’s Motherless Brooklyn (2000), Mark Haddon’s The Curious Incident of the Dog in the Night-Time (2004), R. Scott Baker’s Neuropath (2009), and Ian McEwan’s Enduring Love (1998). Criticism followed suit, proposing the category “neurofiction,” typified by the special issue of Modern Fiction Studies, edited by Stephen J. Burn, “Neuroscience and Modern Fiction” (61.2, Summer 2015). Amid this profusion, two works stand out for the incisiveness with  tural, economic, evolutionary, and ethical implications: Tom McCarthy’s Remainder and Peter Watts’s Blindsight. Whereas Remainder focuses on an unnamed narrator who, as the result of a never-specified accident, has lost the functionalities that nonconscious cognition performs, Blindsight widens the canvas, representing anomalous forms of consciousness and exploring the stakes entailed by the evolutionary road that Homo sapiens traveled when the species (and other terrestrial life-forms) attained consciousness. In significant ways, both novels are influenced by current neuroscientific research, and yet they do not merely follow where science leads. Rather, they interrogate the consequences of consciousness far beyond what the science reveals, probing especially its phenomenological and cultural dimensions. Together, they highlight the crucial importance of nonconscious cognition, in Remainder through its loss, and in Blindsight through an alien species that has developed a technology vastly superior to earth’s even though they are entirely lacking in conscious thought.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Together, the novels show how extensively assumptions taken for granted in traditional Western cultures are undermined and even negated when the primacy of higher consciousness becomes questionable, including its association with authenticity, its ability to give (human) life meaning, its identification with rational actor economic theory, its entwinement with the development of sophisticated technologies, and the perceived superiority it bestows on humans as the most cognitively advanced species on the planet (and beyond). RemaindeR: ConsCiousness versus The TenaCious P ower of maTTer Against a background vagueness surrounding the accident in Remainder, two details stand out with sharp clarity: the narrator has been damaged neurologically, and in compensation has received a settlement of eight-and-one-half-million pounds. Although the exact nature of his injury is not specified, we learn that he has lost motor control over the right side of his body (hence damage in the left hemisphere), and that he undergoes therapy, “re-routing” (19) his synaptic networks so he can move his limbs again. Although some functionality is restored, it is not the fluidity most of us take for granted. Oliver Sacks recounts the case of the “Disembodied Lady” (1998,  quence, could move only by focusing consciously on the motion she wanted, as if she were a puppeteer controlling her puppet-body. She describes herself as “pithed,” and something similar seems to be the narrator’s case. He learns to run a simulation of the desired motion in his consciousness over and over, presumably training his synaptic networks to pick up the slack created by his injury, but when he moves from simulation to reality, the carrot he has lifted many times in his imagination proves to be obdurate—lumpy, hairy, full (as he perceives it) of spiteful agency. “My undoing: matter,” he comments (17), an observation that in a narrow sense describes the object hitting him out of the blue in his accident, and in a broader metaphoric sense, the struggle that will overtake and dominate his life.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The form that struggle takes strongly suggests that another casualty of his accident is nonconscious cognition. With it knocked out of the loop, consciousness must try to perform the tasks normally handled by nonconscious cognition, including the detection and extrapolation of patterns, the integration of somatic markers into coherent body representations, and the fusion of diverse temporal and spatial events so they attain simultaneity. Of course, the primary function of nonconscious cognition is to keep consciousness, with its slow uptake and limited information-processing ability, from being overwhelmed, so its absence means that consciousness is always teetering on the brink of information overload. With connection to body and world rendered tenuous, the narrator’s consciousness compensates by seeking more and more control, to the point of obsession. This, combined with the settlement, impels him to embark on his “re-enactments.” The reenactments stage a struggle between an unpredictable and constantly transforming world of matter, and the narrator’s attempt to wrest it into familiar patterns he can “capture” by reproducing them under conditions he controls. He begins with his own body, practicing mundane gestures such as opening the refrigerator door again and again until his shirt brushes in a certain way against the counter edge, the door opens smoothly but not too easily, and so forth. When he succeeds in getting it “right,” he is rewarded with tingling along his spine and other somatic signals that make him feel, for that instant, as if he is an authentic living being. His obsessive repetitions appear to be attempts to create artificially the modal brain simulations that, as Lawrence Barsalou (2008) has argued, are essential  tal processes because of his injury, he attempts to externalize them, although as he soon discovers, they are poor substitutes for doing it naturally.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The feeling they momentarily bestow on him never lasts, and as it fades, he is driven to try to recapture it through laborious repetitions and reenactments that become progressively more bizarre. Along with kinesthetic fluidity, the narrator seems also to have lost the neurological capacity for empathy, perhaps by damage to mirror neurons.2 This, coupled with his sudden fortune, allows him to acquire “staff,” which he treats as if they were his personal slaves to dispose as he wishes—reenactors, set designers, and most essential of all, Nazrul Ram Vyas from Time Control UK: “Naz facilitated everything for me. Made it happen” (67). The narrator, unable to feel connected to the world through embodied action, attempts to re-create the connections through conscious introspection, as when he first meets Naz and, at his request, Naz makes a cell phone call: “I traced a triangle in my mind from our restaurant table to the satellite in space that would receive the signal, then back down to Time Control’s office” (87). When the narrator happens upon workmen laying wires below street level and considers the connections they enable, he pronounces them “more than Brahmins: gods, laying down the wiring of the world, then covering it up—its routes, its joins” (120). Whereas the narrator shows the consequences of consciousness operating without nonconscious cognition, Naz embodies the cognitivist paradigm of consciousness that calculates by manipulating formal symbols, as if entirely independent from the inputs supplied by embodied actions and modal sensations. When the narrator explains to Naz what he wants, Naz’s “eyes went vacant while the thing behind them whirred, processing. I waited until the eyes told me to carry on” (89).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Together, Naz and the narrator represent a vision of human cognition that increasingly takes on nightmare proportions: rationality acting without empathy, decisions made without support from nonconscious cognition, actions undertaken without the connections created by embeddedness in the world. (re)enaCTing The dysfunCTio naLiTies of ConsCiousness The catalyst for the narrator’s first reenactment, a crack on a bathroom  actitude that characterizes his projects, as if he were channeling John Cage’s “chance operations” while gulping amphetamines. His imagination, growing outward from the crack, conjures an entire building, a mishmash of memories, second-hand anecdotes, and fantasized encounters. We know, for example, that the arrangement he dictates for the courtyard comes not from his own experience but from his friend Catherine’s account of the place in her childhood where she felt most authentic, “swings, on concrete . . . And there was a podium, a wooden deck, a few feet from the swings’ right” (76). The narrator appropriates her account to re-create this exact scene (122). Auditioning enactors, he chooses each according to the image he has of them, specifying precisely how they should act. When he doesn’t have a clear image, for example of the building’s concierge, he demands she wear a blank mask, a white hockey protector that hides her face.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Instructing the enactor playing the “liver lady” (so-called because he orders her to fry liver all day), he can’t decide what she should say as he passes her while she puts a garbage bag in the hall, so “rather than forcing it—or, worse, just making any old phrase up—I’d decided to let her come up with a phrase” (143), as if the actions and words he dictates are somehow other than arbitrary. His sense of operating within tight constraints makes it seem as if some prior reality is laying down the law he follows, but narrative cracks like this (metaphorically recalling the bathroom wall crack) reveal that the determining force is nothing other than the vignettes and narratives springing forth from his consciousness, shot through with fictions though they may be. Clues to this fictionality are everywhere, for example, in the passage describing his first meeting with Naz: “He looked just like I’d imagined him to look but slightly different, which I’d thought he would in any case” (85). Much later, when Naz interrupts to convey what he considers important information while the narrator is preoccupied by trivia, the narrator shouts, “No!” “You listen, Naz: I say what’s important.” He continues, “I could see him running what I’d just said past his data-checkers, and deciding I was right: I did say what was important. Without me, no plans, no Need to Know charts, nothing” (272). Consciousness here seemingly achieves its dream not only of narrating the world but acting as the dictator determining what goes into that narrative in the first place. In this sense, Remainder presents an exaggerated vision of what we may call the imperialism  tendency to insist that it alone is in control and is the sole originator of human agency. Antonio Damasio, in a passage cited in chapter 2, points out that consciousness tends to focus on the individual, making it the center of action: “I would say that consciousness .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . constrains the world of the imagination to be first and foremost about the individual . . . about the self in the broad sense of the term” (Damasio 2000, 300). To the extent that focus on the self is associated with the individualism inherent in liberal ideology, capitalism, and environmental predation, consciousness, especially higher consciousness, participates in and helps to solidify the excesses of consumerist culture. In Remainder, this process is exaggerated into maniacal obsession. Sailing through the world without the ballast provided by nonconscious cognition, the narrator’s consciousness attempts to seize total control of the environment, with the result that his sense of self swells to grotesque proportions. As his obsession grows, the self’s desires are treated as if they were absolute law, regardless of the costs to anyone else. The economics of the process are clear: the narrator simply buys the personnel necessary to his schemes, paying handsome salaries plus bonuses to his “staff” and forking over bribes to everyone else. In this sense, he is the ultimate economic rational actor, bending others to his will so that his (psychological) payoff in the Nash equilibrium matrix trumps everyone else’s.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In return for the money he distributes (which he regards as mere trash and has only a hazy idea of the amounts involved), he demands unquestioning obedience. For example, when the reenactor charged with tinkering with a motorbike in the courtyard inadvertently spills some oil, the narrator tells him to leave the oil mark because “I might want to capture it later” (144). “Capture?” the reenactor asks, whereupon the narrator thinks irately, “It wasn’t his business to make me explain what I meant by ‘capture.’ It meant whatever I wanted it to mean: I was paying him to do what I said. Prick” (144). In another instance, the narrator is shocked to see the pianist creeping down the stairs even as he hears music coming from the pianist’s apartment. Stunned, he demands an explanation, whereupon the pianist sheepishly admits he had made a recording to play when he was away on other business. Although the sensory stimulus the narrator receives is the same whether the music is live or recorded, he goes “white with both rage and dizziness” (157) and tells Naz to “give  mean,” ambiguously adding, “I suppose” (159). Still later he remarks, “I wasn’t bound by the rules [that he arbitrarily lays down]—everyone else was, but not me” (225).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  If capitalism alienates the worker from his labor, as Marx argued, the narrator uses money in a fashion even more alienating than an Industrial Age robber baron, demanding mind-numbing labor from his reenactors for hours on end without a break and without even the satisfaction of producing a tangible product, other than the temporary easing of his insatiable desire for repetitive patterns. “I generally put the building into on mode for between six and eight hours each day,” he remarks. “Sometimes there’d be a five-hour stretch” (161). Preoccupied with his own repetitive gestures, as when he spends an entire day practicing brushing past his sink, he sometimes forgets to reset the building to off, leaving his reenactors to cope as best they can. TemP orizing TemP o raLiTy The satisfaction the narrator receives is fleeting, so he must constantly introduce new tweaks, new realms over which he can gain control. At first this extension is achieved through a model of his building that he commissions, enabling him to position within it toy figures, which he then duplicates in the actual building. For example, the figurine he uses to stand in for the motorbike enthusiast is kneeling, so he requires the motorbike enactor to kneel first on the pavement and then on the swing, making life correspond to the simulation—a significant dynamic that expands to ominous proportions. When he has squeezed all the juice from the model, he goes further afield, drawn by chance to a shop where he gets a car tire fixed.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  He finds three boys there and asks the oldest where the “real people” are, and the boy responds, “I’m real” (168). Afterward the narrator orders an exact reproduction of the shop built inside an airplane hangar. As he has the tire-fixing scene reenacted, he reports, “I experienced a sensation that was halfway between the gliding one I’d felt when my liver lady had spoken to me on the staircase during the first reenactment in my building and the tingling that had crept up my right side on several occasions. This mixed sensation grew as we reached the part where the boy intoned the words: “I—am—real” (177). It is not a coincidence that his feeling peaks at this line. Much later, the narrator explains that his only goal  merge with actions and with objects until there was nothing separating us—and nothing separating me from the experience that I was having; no understanding, no learning first and emulating second-hand, no self-reflections, nothing: no detour. I’d gone to these extraordinary lengths in order to be real” (247). Having lost the fast information-processing capability of nonconscious cognition, the narrator cannot make his consciousness speed up faster than its belatedness allows, so he compensates by ordering the world to slow down.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  He explains to the pianist that he wants him to “Start out at normal—no, at half speed—and when you slow down, when you’re in the most slowed down bit of all, just hold the chord for as long as you can” (224). To the concierge, whom he had ordered to remain static, he says “now I want you to do nothing even slower . . . ‘What I mean,’ I told her, ‘is that you should think more slowly. Not just think more slowly, but relate to everything around you slower. So if you move your eyes inside your mask, then move them slowly and think to yourself: Now I’m seeing this bit of wall, and still this bit, and now, so slowly, inch by inch, the section next to it, and now an edge of door, but I don’t know it’s door because I haven’t had time to work it out yet—and think all this really slowly too’” (224). The monomaniacal nature of his obsessions expands so far that when he times the sun’s passage across the hall floor and finds it doesn’t match his previous observation, he complains to chief staff members Annie and Frank, “The sunlight’s not doing it right” (224). At first bewildered, Annie finally grasps his meaning and explains that the time difference is because weeks have passed, and the “sun’s at a different angle to us than it was” (229). Although the narrator quickly tries to cover over the gaffe, it reveals the extent to which he believes he can control his environment.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It also implicitly reveals that the time-slowing command only works with his “staff,” people whom he has hired to do his bidding. In the world at large he needs another strategy, one he discovers by hearing a coach shout to his players, “Take your time. Slow each second down” (238). “This was good advice,” he muses, and begins to practice slowing down his own perceptions, letting the instants stretch out until he can move within them at leisure. As we have seen, one of the functions that nonconscious cognition performs is integrating discrete temporal events (occurring at different points within a window of about 100 milliseconds) into perceived simultaneity. Operating in the absence  to carry out its own version of time manipulation, slowing down the action at decisive moments as if reality was being screened inside his head as a slow-motion film. With this strategy in place, the narrator moves in two directions at once—further into reenactments, hiring actors to reenact the actions of his own enactors in endless regression, and into the real world, where simulation and reality start to melt into one another. As the logistics become more complex, his consciousness, already overloaded with information it must try to process without the help of nonconscious cognition, begins to short out altogether as he repeatedly drifts off into “trances,” blackouts lasting for hours or days.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Naz, scrambling to keep up with the narrator’s increasingly ambitious plans, draws more and more on his computational abilities. The narrator comments, “I could almost hear the whirring: the whirring of his computations and of all his ancestry, of rows and rows of clerks and scribes and actuaries, their typewriters and ledgers and adding machines, all converging inside his skull into giant systems hungry to execute ever larger commands” (234–35). Faced with the narrator’s ultimate scheme—pretending to stage a bank robbery reenactment while actually robbing a bank—Naz becomes, as the narrator observes, “drunk: infected, driving onwards, on towards a kind of ecstasy just by the possibilities of information management my projects were opening up for him, each more complex, more extreme. My executor” (235). “Thank you,” Naz replies to the narrator; “I’ve never managed so much information before” (235). addiCTing Trauma As the narrator’s consciousness grows increasingly precarious, some portion of his psyche splits off and reappears in ventriloquized form as a short man, a borough councillor whom Naz identifies as such (239) but who assumes an alter hallucinated existence as an objective reporter on the narrator’s thoughts and condition. The tip-off that the character’s lines are hallucinated comes when he says he smells cordite (238), an odor the narrator notices on several occasions but no one else can detect. Within the diegesis, the hallucination suggests that narrating consciousness recognizes its own dysfunctionality and creates this figment to give accurate accounts of the narrator’s phenome-  lusional goals.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  From a perspective outside the diegesis, the character allows the author, as the narrator plunges deeper into dysfunctionality, to offer explanations to the reader. As the distance widens between the narrator’s perceptions and the (presumed) reader’s commonsense experiences of the world, the author risks the reader’s incredulity; the “short councillor” forestalls this possibility by mediating between the two perspectives, suturing one to the other. In a similar vein are Doctor Trevellian’s comments. Summoned by Naz when the narrator first falls into a trance, Trevellian explains that the brain, faced with trauma, manufactures its own endogenous opioids, in effect making the traumatized person into a home-grown addict, so that he returns again and again to the traumatic source to get another fix (220). reaL simuLaTions What these explanations cannot completely mask is the growing insanity of the narrator’s actions. Reading about a bank robbery, he first orders a reenactment of it but then makes “a leap of genius”: “a leap to another level, one that contained and swallowed all the levels I’d been operating on up to now . . . lifting the re-enactment out of its demarcated zone and slotting it back into the world, into an actual bank whose staff didn’t know it as a re-enactment: that would return my motions and my gestures to ground zero and hour zero, to the point at which the re-enactment merged with the event. It would let me penetrate and live inside the core, be seamless, perfect, real” (265).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The plan generates oxymorons that Baudrillard (1995) would have loved: a real reenactment, or a reenacted real. Naz immediately spots the logistical problem (although stunningly blind to the ethical one): preventing the enacting bank robbers from realizing that the narrator intends to transition into a real robbery. To solve the spiraling consequences of this realization, he proposes that following the robbery, they put all the “staff” and enactors on a plane and arrange for it to be blown up, while he and the narrator charter a private plane for their getaway. Of course, the perfection of which the narrator dreams remains forever out of reach, because there will inevitably be a “residual” (a word the short councillor uses and the narrator has Naz look up in a dictionary): a remainder. Significantly, the residual that causes the enacted-real bank robbery to go terribly wrong is not a presence but an  in the carpet that the narrator, with characteristic precision, wanted reproduced exactly, even causing a wood splinter to be inserted under the carpet to make sure the kink would be there. In the enacted-real robbery, however, there was no kink; “the carpet was flat” (290). The narrator describes what happens: “I saw his foot feel for the kink, and feel more, staying behind while the rest of him moved on. The rest of him moved so far on that eventually it yanked the foot up in the air behind it” (290).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This “ghost kink” then sets in motion a chain of horrific events, starting with one of the robber enactors accidentally shooting another, then to the narrator reproducing the event in the deserted airplane hangar to which they flee after their getaway from the bank. He characterizes his action as “half instinctive, a reflex,” but then admits, “I’d be lying if I said it was only that that made me pull the trigger and shoot [the surviving robber enactor]. I did it because I wanted to” (299). The “ghost kink” can be understood as the presence of an absence. In larger terms, it functions as more than the initiating wrinkle for the final sequence of events. Throughout the narrative looms another kind of present absence, nonconscious cognition. This is the absence that initiates the narrator’s feeling of inauthenticity, the absent functionalities for which consciousness tries to compensate, the missing processes that compel the narrator to more and more extreme measures to feel real. In this sense, the eponymous “remainder” may signify not only the resistance of intractable matter but also the intractable matter of resistance, that is to say, consciousness itself.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Bereft of its support system, consciousness refuses to recognize its status as a remainder of a cognitive whole fractured beyond repair, desperately trying to make up for the absence that is never mentioned but whose ghost presence nevertheless dominates this text: the cognitive nonconscious. B lindsight and neuro sCienCe Whereas in Remainder the neuroscience references are for the most part implicit, in Blindsight they are very much on display. Indeed, Watts on occasion resorts to “infodumps,” thinly motivated explanations aimed to enlighten readers; he even includes a bibliography of neuroscientific works he consulted. It is no surprise, then, to find that he includes a character reminiscent of Remainder’s narrator, the  age results from an accident, with Siri it derives from a radical hemispherectomy, the surgical removal of a hemisphere, an extreme cure for his out-of-control epilepsy. As a result, he is unable to feel empathy and operates largely through rational calculation, as the opening scene reveals when, as a grade school (postoperative) kid, he decides to come to the aid of a friend, Robert (Rob) Paglino, being beaten up by playground bullies. Taking the bullies by surprise, he pulverizes them, unconcerned with the damage he is causing and utterly without empathy for their pain. Even though Rob is the beneficiary of Siri’s intervention, he is shocked by its savagery and thereafter calls him “Pod-man” (58). Like Remainder’s narrator, Siri responds to his behavioral deficit by crafting compensatory strategies, although of a very different kind.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  He becomes expert in reading “information topologies,” microfacial movements and gestural subtleties communicating intentions, feelings, and motivations that exist independently from semantic content, operating much like the sociometer described in chapter 5 (except that he does it through training his perceptions rather than through an external instrument). Remarking that most people find this disconcerting, he muses, “people simply can’t accept that patterns carry their own intelligence, quite apart from the semantic content that clings to their surfaces; if you manipulate the topology correctly, that content just comes along for the ride” (115). His expertise is the more remarkable because he cannot himself feel empathy. He likens his ability to the philosopher John Searle’s Chinese Room, which Searle posed as a thought experiment to challenge strong artificial intelligence. Searle imagined a man sitting on a chair in a room with a slot in the door. Someone outside passes a string of Chinese letters through the slot. The man, who does not read or speak any Chinese languages, pulls Chinese characters from a basket at his feet, using a rule book to match the incoming string with another, which he passes through the slot. So convincing are his replies that his interlocutor is convinced the room’s occupant understands the strings he composes as answers.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  But Searle’s point is that the man is like a computer; it can match symbols according to given rules, but it has no comprehension of the strings’ meaning. There have been many responses to the Chinese Room challenge; Siri adopts one of the most compelling, that it is not the man by himself that understands Chinese but the entire room, including the rule book, basket of characters, and  By analogy, Siri does not understand empathy through mirror neurons or other neurological capacities, but his training and experience (his protocols) enable him to observe with minute care, draw inferences, and extrapolate from these data to conclusions about how someone feels. He comments to his friend Rob, “Empathy’s not so much about imagining how the other guy feels. It’s more about imagining how you’d feel in the same place” (234). By contrast, his method is to read how someone feels and then try to imagine his or her motivations. “I just observe, that’s all,” he tells Rob. “I watch what people do, and then I imagine what would make them do that” (233). In this conversation, Rob brings up cases similar to the “Disembodied Woman” from Oliver Sacks (without mentioning Sacks [1998], 43– 54), commenting that “Some of them said they felt pithed.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  They’d send a motor signal to the hand and just have to take it on faith it arrived. So they’d use vision to compensate; they wouldn’t feel where the hand was so they’d look at it while it moved, use sight as a substitute for the normal force-feedback you and I take for granted” (233). He continues, “You use your Chinese room the way they used vision. You’ve invented empathy, almost from scratch, and in some ways—not all obviously, or I wouldn’t have to tell you this—yours is better than the original. It’s why you’re so good at Synthesis” (233). As Rob’s comments imply, there remain crucial differences between feeling empathy and re-creating the knowledge that empathy bestows. Occasionally Siri dreams of his former self, and when he does, he is struck by the vividness of that former life. “I—I dream about him sometimes .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . About . . . being him . . . It was—colorful. Everything was more saturated, you know? Sounds, smells. Richer than life” (234). This difference, the feeling of being immersed in a rich sensory environment versus re-creating it from the outside, is the Derridean différance between authenticity and reconstruction that wreaked so much havoc in the life of Remainder’s narrator.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For Siri, the deficit is less immediately disastrous, although at crucial moments it surfaces as a decisive force sending him down one path rather than another. modifying human (and nonhuman) ConsCiousness Watts, who earned a PhD in marine biology, obviously already had a good basic understanding of evolutionary biology, especially with non-  uses this background knowledge as well as his research to imagine a cast of characters very far from “normal” psychic functioning. Before setting them in action, he provides the motive for their interactions. An alien species has visited earth vicariously on February 13, 2082, visually capturing earth in a network of optical surveillance devices that simultaneously image every square meter of surface before burning out, as if a global network of flash bulbs had taken earth’s picture; people call them the Fireflies. In response, the governments of earth determine to mount an expedition to find the aliens. They discover their location almost accidentally, by intercepting radio signals originating from a comet beyond Pluto in the Kuiper belt. They then put together the team that will man the spaceship Theseus in an exploratory journey to make contact with the aliens. Each crew member represents a specific attempt to push human neurology beyond traditional boundaries.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Amanda Bates, augmented with carboplatinum musculature, is the military person trained to command robot warriors, manufactured as needed by the ship’s fabricators. Susan James is the linguist who not only has nonsentient brain implants but also had her brain partitioned into four separate areas, each inhabited by a distinct personality. Isaac Szpindel is the biologist who has had his appendages so modified by prostheses that he “heard X-rays and saw in shades of ultrasound” (105), experiencing his lab equipment synesthetically. Siri, the Synthesist, has been sent along as an “objective” observer charged with sending reports back to earth. Finally, the commander is Jukka Sarasti—a vampire. Watts includes a section on vampire physiology and evolutionary history in the final “Notes and References” section (367–84), noting their superior analytical skills and heightened pattern detection (omnisavantism), superior vision and hearing, and their general cognitive superiority to humans. He also imagines that “vampires lost the ability to code for Υ-Protocadherin Y, whose genes are found exclusively on the hominid Y chromosome” (368), thus making human prey an essential component of their diet. To avoid depleting their food source, they developed the dormancy (“undead”) state, which allows them to have extended periods of inactivity.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Their evolutionary Achilles’ heel is the “Crucifix glitch,” a “cross-wiring of normally distinct receptor arrays in the visual cortex” (369) that sends them into grand mal seizures whenever they encounter an array of right angles (which almost never  try). For this reason (and only this reason), vampires went extinct until they were genetically reconstituted (a la Jurassic Park) by humans late in the twenty-first century. Including a vampire among the crew allows Watts to render the idea of an ecological niche vividly real, for humans and vampires compete for the same terrestrial niche of high cognitive functioning. Having eradicated, domesticated, or confined to reservations virtually all the other mammal contenders for their niche, humans reign supreme at the top of the food chain. Now that vampires have been resurrected, however, humans who come in contact with them are put in the rare position of being eyed as prey by a superior predator. Even if the constraints of civilization prevent the resurrected vampires from actually eating humans, this is a veneer covering over, but never entirely suppressing, the deep evolutionary history during which humans were helpless to avoid vampire predation. Even with all the modifications, adaptations, and prostheses through which the humans aboard have extended their abilities, the vampire could kill them all in seconds—a fact of which they are uneasily aware as they accept him as their commander. Behind the vampire lurks another presence, the “Quantical AI” computer that runs the ship.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “Sarasti was the official intermediary,” Siri recounts. “When the ship did speak, it spoke to him—and Sarasti called it Captain,” adding, “So did we all” (26). in TerPreTing The Ro Rsc hach With his cast of characters in place, Watts sets the plot in motion by having them encounter the alien ship, self-named the Rorschach, cloaked in the shadow of Big Ben, a planet with a gravitational mass of ten Jupiters. Almost thirty kilometers wide, the ship is “not just a torus but a tangle, a city-size chaos of spun glass, loops and bridges and attenuate spires” (108). It has an interior environment violently hostile to humans, with a magnetic field “thousands of times stronger than the sun’s” (109) and electromagnetic radiation strong enough to be lethal to humans within minutes. Moreover, it is surrounded by aircraft shoveling debris from Ben’s accretion belt toward the ship: “particles that collided with the artifact simply stuck; Rorschach engulfed prey like some vast metastatic amoeba . . . The procession never stopped.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Rorschach was insatiable” (109). The implication, of course, is  even more formidable, designed for purposes that the humans fear will include annihilation of earth. Sarasti reasons that there is no time to waste and orders his crew to carry out forays inside the Rorschach and, if possible, capture specimens. Amanda Bates, tactical commander of the Rorschach incursions, orders the others into a shielding tent while remaining outside herself. When her fellow crew members try to communicate with her, however, she utters enigmatic responses, saying, “I’m dead already” (162), “I’m not out here,” “[I’m] nowhere,” “I’m nothing” (171). Siri, looking at her faceplate, remarks, “I could tell that something was missing. All her surfaces had just disappeared” (162). Later, Szpindel tells Siri that Bates did not just “believe” she did not exist but “knew it.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For a fact” (180). Siri, intrigued, consults ConSensus, the ship’s equivalent of an interactive encyclopedia, to look up all the ways in which traumatized brains cause radical misperceptions of the body and outside world (here one of those infodumps appears, 193). Much later, he summarizes his conclusions: “The brain stem does its best. It sees the danger, hijacks the body, reacts a hundred times faster than that fat old man sitting in the CEO’s office upstairs; but every generation it gets harder to work around this—this creaking neurological bureaucracy” (302). The reference to knowledge that the brainstem has but cannot communicate to the “creaking neurological bureaucracy” “upstairs” is Watts’s version of the neurological phenomenon known as blindsight, inspiration for the book’s title. Lawrence Weiskrantz of Oxford University, a prominent researcher into blindsight, tracked for ten years a patient who had a small tumor removed from the visual center V1 on one side of the brain, leaving him blind to anything that happened on his other side (because of the crossover of neural connections) (see, for example, Weiskrantz et al. 1974). The patient reported that when events happened rapidly, he somehow knew something was occurring even though he could not see it.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Max Velmans explains the phenomenon: Blindsight [is] a condition in which subjects are rendered blind in one half of their visual field as a result of unilateral striate cortex damage. If stimuli are projected to their blind hemifield subjects cannot see them in spite of the fact that their full attention is devoted to the task. As they cannot see the stimulus they maintain that they have no  mance may be very accurate. For example, one subject investigated by Weiskrantz et al. (1974) was able to discriminate horizontal from vertical stripes on 30 out of 30 occasions although he could not see them. In short, the subject has the necessary knowledge but does not know that he knows. In information processing terms, it is as if one (modular) part of his system has information which is not generally available throughout the system (Velmans 1995). The alien life-form encountered by the Theseus crew, the so-called scramblers, are like people with blindsight in that they know but do not know that they know, because they lack consciousness.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Watts has his characters speculate that compared to the scramblers, consciousness as it evolved in humans carries with it costs that impose heavy evolutionary penalties. “It wastes energy and processing power, selfobsesses to the point of psychoses. Scramblers have no need of it, scramblers are more parsimonious. With simpler biochemistries, with smaller brains—deprived of tools, of their ship, even of parts of their own metabolism—they think rings around you . . . they turn your own cognition against itself. They travel between the stars. This is what intelligence can do, unhampered by self-awareness” (302). Bates, although she went into Rorschach as a human with a self, experiences a radical loss of self in its violently alien environment, temporarily becoming much closer to the scramblers.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She literally becomes “no one,”3 reduced to nonconscious cognitive and material processes that precede the self’s construction by consciousness. Her pronouncement “I’m dead” signals not the end of organismic life but the cessation of the narrating self, the “I” whose topological surfaces are wiped clean when consciousness ceases to function. When Siri understands, this is how he parses her situation: “for Amanda Bates to say ‘I do not exist’ would be nonsense, but when the [nonconscious] processes beneath say the same thing, they are merely reporting that the parasites [conscious processes] have died. They are only saying that they are free” (304). Although Bates recovers her sense of self when she returns to Theseus, her consciousness’s erasure more than hints that the aliens native to Rorschach’s environment function without consciousness as well. When the humans bring back a dead specimen, they submit it to extensive testing. The alien scramblers have neuronal structures ut-  space hibernation when Szpindel is killed in an incursion) announces that the scramblers have “no cephalization, not even clustered sense organs. The body’s covered with something like eyespots, or chromatophores, or both .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . Every one of those structures is under independent control . . . The entire body acts as a single diffuse retina. In theory that gives it enormous visual acuity” (224). He pronounces the alien “an absolute miracle of evolutionary engineering,” but because there is no central nervous system, he also judges it to be “dumb as a stick” (226). When the humans capture live specimens on their final incursion, testing reveals how wrong this judgment is.4 At first unresponsive, the scramblers are detected communicating covertly, and the humans decide to hurt\/torture them to force cooperation. Thereupon they show remarkable geometric skills, and when prodded with number sequences, “were predicting ten- digit prime numbers on demand” (265). When Cunningham dismisses these as “splinter skills,” Susan James draws the obvious conclusion: “They’re intelligent, Robert.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  They’re smarter than us. Maybe they’re smarter than Jukka [the vampire]. And we’re—Why can’t you just admit it?” (265). Later she says to Siri, “They’re intelligent; we know they are. But it’s almost as though they don’t know they know, unless you hurt them. As if they’ve got blindsight spread over every sense” (274).5  Blindsight and The CosTs of Co nsCiousness The eponymous blindsight appears sporadically in the text, for example when Szpindel explains to Siri how he almost caught the battery tossed to him although his conscious visual perception was blocked by Rorschach’s electromagnetic field. “Nothing wrong with the receptors . . .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Brain processes the image but it can’t access it. Brain stem takes over” (170). Later he elaborates: “You just—you get a feeling, is all. A sense of where to reach. One part of the brain playing charades with another, eh?” (180). Blindsight functions as a synecdoche for all the trauma-induced and brain- damaged syndromes mentioned in infodumps and explained in the “Notes and References” section: in different ways, all reveal the limitations of conscious thought and the inadequacy of equating cognition with consciousness alone. Watts postulates that for aliens who have never developed consciousness, the parts of human languages that describe conscious  ine you are a scrambler,” Siri says. “Imagine you have intellect but no insight, agenda but no awareness.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Your circuitry hums with strategies for survival and persistence, flexible, intelligent, even technological— but no other circuitry monitors it. You can think of anything, yet are conscious of nothing” (323). Then, he continues, imagine how human language would sound to you. “The only explanation is that something has coded nonsense in the way that poses as a useful message; only after wasting time and effort does the deception become apparent. The signal functions to consume the resources of a recipient for zero payoff and reduced fitness. The signal is a virus. Viruses do not arise from kin, symbionts, or other allies. The signal is an attack” (324).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  He concludes there can be no rapprochement between humans and this alien species; “How do you say We come in peace when the very words are an act of war?” (325). The very fact that human language springs from consciousness ensures that the aliens see humans as evolutionary enemies. As the costs of consciousness become more widely discussed in contemporary culture (for example, Hansen 2015), other writers also imagine language not as the singular achievement of the human species, as commentators such as Steven Pinker would have it, but as a virus, a disease, an evolutionary hiccup about to be replaced by other modes of communication, a trajectory pioneered by William Burroughs in Naked Lunch (1959) and other works. In The Flame Alphabet (2012), for example, Ben Marcus writes of children’s language toxic to their parents, sickening them the more they listen to it, and eventually becoming lethal. In The Silent History, Eli Horowitz, Matthew Derby, and Kevin Moffett (2014) imagine a generation of children who do not understand verbal language and are unable to learn it, no matter how desperately their parents strive to inculcate it. Instead they communicate with one another through microfacial gestures, developing an entire vocabulary that the children learn quickly and easily and use to communicate among themselves. One of the narrators, witnessing this communication, asks, “What unknown abilities had filled this void [the absence of verbal language]? Was the world somehow brighter, more tangible, without the nagging interference of language?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Was the absence of words actually a form of freedom?” (8). We may extend these questions to consciousness itself. Without words, would the nar-  be a liability rather than a crowning achievement illustrates how the costs of consciousness may be invoked to question the basis for human exceptionalism and the privileges it has traditionally bestowed, including the Baconian imperative for humans to achieve dominion over all other creatures on the earth, and over the earth itself. advanCed TeChnoLogy wiThouT Co nsCiousness One of the challenges Watts faces is how to account for the aliens’ vastly superior technology, achieved without conscious awareness. He locates the cause in emergent complexity. Michael Dyer, a computer scientist specializing in artificial intelligence and my former colleague at UCLA, remarked that the more intelligent the environment, the less intelligence one needs to put in the heads of the agents in an artificial life simulation, because the environment’s structured specificities make it possible for the agents to evolve emergent complexities through their interactions with it. Cunningham, Theseus’s biologist, proposes a similar dynamic for the alien ship Rorschach and the scramblers. To explain, he instances the well-known example of a honeycomb.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  No bee has an overall plan for the honeycomb in its head; all it has is an instinct to turn in a circle and spit wax while adjacent bees do the same. The wax lines press against each other to form a hexagon, the polygon with the closest packing ratio, and the honeycomb is the emergent result. In the case of Rorschach, Cunningham observes, it is the scramblers who are the honeycomb, the emergent result of the dynamics of the ship’s environment (267). “I don’t think Rorschach’s magnetic fields are counterintrusion mechanisms at all. I think they’re part of the life support system. I think they mediate and regulate a good chunk of scrambler metabolism” (267). The aliens represent, then, not only distributed cognition but distributed organismic life. Unlike on earth, where freely living independent organisms developed first and then created technology, here the technology and biological life evolved together, each stimulating the other to deeper interactions and greater emergent complexity.6 Cunningham discovers that the scramblers have no genes and no independent reproductive mechanism; the ship grows them in a stack, each scrambler with a navel in front and behind, and the top one buds off and becomes mobile when it is mature.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Devoid of consciousness yet still intelligent, the  the drive to survive is invested in ship-plus-scramblers, for without the ship environment, the scramblers would die within days because their metabolism slowly decays without the ship’s environment to regulate and replenish it. When they are captured and taken into Theseus, Cunningham remarks they are metaphorically “holding their breath. And they can’t hold it forever” (267). In contradistinction to the scramblers, the mainstream view of humans imagines us first as independent (and social) organisms, and our technologies as late-addition cultural achievements—nice to have, certainly, but hardly intrinsic to our survival. However, if all technical cognitive systems were to bite the dust tomorrow, the result would be systemic chaos and a massive die-off of the human species. Imagine all transportation systems inoperative (even cars and trucks have computerized ignition systems, and railroads and airplanes are completely interpenetrated by computational devices), all water and sanitation facilities off-line, all electric grids down, all national and international supply lines cut, banking systems crashed, agricultural and livestock production at a standstill, all medical equipment except the most robust hand instruments unavailable, etc. No doubt some people in rural and remote areas would survive, but the death tolls would likely mount to millions or billions. Why do we continue to think of ourselves as beings independent from our technologies and capable of living without them?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Here we may recall Damasio’s insight: “consciousness . . . constrains the world of the imagination to be first and foremost about the individual, about an individual organism, about the self in the broad sense of the term” (2000, 300). Consciousness, that is, insists that the human self is the primary actor, and technologies mere prostheses added on later (compare with Stiegler [1998]). Watts gestures toward the deep interconnection between technical and human cognition in his climax, when Sarasti prepares to make Theseus itself into a weapon and dive it into the Rorschach, condemning the crew to instant death—except for Siri, who is instructed to escape in a probe and return to earth to warn people about the alien threat. Susan James rebels, however, and tampers with Sarasti’s anti-Euclidean drugs. As a result he goes into a grand mal seizure— whereupon one of the robot warriors crushes his skull and inserts some electronics, and the undead body begins moving again, now under the control of the Captain, the “Quantical AI” at the ship’s heart. “Did he ever speak for himself? Did he decide anything on his own?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Were we ever following his orders, or was it just you all along?” (353). Tapping on a keyboard the undead body has seized, the Captain gives him his answer: “u disLke ordrs frm mChnes. haPPier This way” (353). It is ironic, of course, that the humans are imagined as happier taking orders from a vampire, their evolutionary archenemy, than from a computer. From the perspective of their dependence on the ship’s AI, the difference between them and the scramblers is not quite so great as it seemed—or more accurately, not as enormous as consciousness imagined it to be. As Siri begins the long fourteen-year journey home, he meditates on the role of humans in the universe. Susan James, resisting Sarasti’s implication that consciousness is a disability, asks why, in that case, had humans survived: “If [consciousness] were really so pernicious, natural selection would have weeded it out” (306). Sarasti delivers the riposte: “You have such a naïve understanding of evolutionary processes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  There’s no such thing as survival of the fittest. Survival of the most adequate, maybe. It doesn’t matter whether a solution’s optimal. All that matters is whether it beats the alternatives” (306). Interpreting this observation in topological terms, we may imagine a fitness landscape in which a local maximum has arisen. Elsewhere, however, an even larger global maximum towers. The problem from an evolutionary viewpoint is that an organism perched on the local maximum can never reach the global one, because to get there, it would have to go downhill, becoming less fit, to traverse the intervening distance. Consequently, it is more fit relative to its immediate competitors, but not from a global perspective.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Earth in this analogy is the local environment, and on it, humans have achieved a local maximum within their ecological niche (leaving aside the mythical vampires). Elsewhere in the universe, however, a larger global maximum rules. Siri had earlier grasped Sarasti’s implication: “scramblers were the norm. Evolution across the universe was nothing but the endless proliferation of automatic, organized complexity, a vast arid Turing machine full of self-replicating machinery forever unaware of its own existence. And we—we were the flukes and the fossils” (325). As he monitors communications streaming from earth, he begins to hear less music, and less human speech. He also receives a “general delivery” communication from his father that he interprets as a coded  words to the clicks and hisses characteristic of vampires, he begins to suspect that, like the dinosaurs in Jurassic Park, they have snapped their chains and broken out of their enclosures, now running rampant through the world. Moreover, he suspects that they have begun to evolve away from consciousness into non-conscious modes of being.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “We humans were never meant to inherit the Earth,” he muses. “Vampires were. They must have been sentient to some degree, but that semi-aware dreamstate [in which they live] would have been a rudimentary thing next to our own self-obsession. They were weeding it out. It was just a phase” (362). Contemplating how he has changed, he says, “Thanks to a vampire and a boatload of freaks and an invading alien horde, I’m Human again. Maybe the last Human. By the time I get home, I could be the only sentient being in the universe” (362).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Consciousness, in this view, was a clumsy evolutionary work-around that was better than its immediate competitors, but in the long run, cost more than it was worth, and was weeded out when the context for competition widened beyond earth to the universe. What are we readers, conscious beings all, to make of this conclusion? “normaL” ConsCiousness and TeCh niCaL CogniTion One way to evaluate these texts is to analyze the strategies they use to construct normality (the place where presumably we readers are). Viewed from this angle, strategies radically different from each other come into sight. In Remainder, the narrator starts from a place with which we can easily identify. He has suffered a serious accident through no fault of his own, an innocent bystander; as a result, he has had to struggle to regain functionality. From here, of course, he begins his disastrous slide into obsession and then psychosis, as his need to control spirals outward into the world. In Blindsight, by contrast, the protagonists begin very far from the human baseline, sporting technical modifications and augmentations in nearly every way imaginable— and then there’s the vampire, creature of myth and Gothic fiction.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As the narrative progresses, however, they come to seem normal by comparison with the aliens, their differences from unmodified humans swamped by the overwhelming tsunami of difference that the aliens represent. Then at the end, this normality is flipped again into the  Technical cognition also plays very different roles in the two texts. In Remainder, it is conspicuously absent. Absurdly by today’s standards, the narrator, when he encounters a word or concept he doesn’t know, has Naz call a colleague in the office, who looks it up, calls Naz back, and Naz then relates it to the narrator. Published in 2005, Remainder was already well into the era of the Palm Pilot and Blackberry, introduced in 2001. Granted that the now-ubiquitous iPhone was not marketed until 2007, there were plenty of smartphones and digital handheld devices already around, so this procedure cannot simply be business as usual. Rather, it seems designed to call attention to the fact that technical cognition plays virtually no role in the text. When the narrator wants to enlist reenactors, he chooses humans to do his bidding.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  He operates not within a distributed cognitive network but a self-designed, singularly idiosyncratic network to extend his own (dysfunctional) cognitions into the world. Moreover, as we have seen, he uses this network to impose his will on reality. A small indication of this occurs when the (hallucinated) short councillor uses the word “residual” (259). The narrator has Naz do the cell phone routine to look up the word, spelling it out for him. “A noun,” Naz pronounces, and then asks, “What short councillor?” Repeating the councillor’s words as he heard them, the narrator continues, “This strange, pointless residual. And he pronounced the s as an s, not a z. Re-c-idual. Have it looked up with that spelling.” Since this pronunciation is an artifact of his hallucination, it naturally does not exist in common usage: “Word not found,” Naz reports. At this, the narrator becomes enraged, commanding Naz to “tell them to go and find a bigger dictionary, then!” “I was feeling really bad now,” he says, continuing, “And if you see that short councillor here .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . ,” whereupon Naz again asks, “What short councillor?” (271). Played out at length, the scene illustrates the narrator’s belief that he can determine what counts as reality, including what words appear in a dictionary. Were technical cognition to play a larger role in the text, the narrator would be confronted with this kind of situation all the time, as technical systems are immune to bribes and payoffs. By restricting his network to humans, the narrator is able to persist in his delusions. In Blindsight, by contrast, the interpenetration of human cognition with technical cognitive systems constitutes the “new normal” in this fictional future (2082 and beyond). Like Remainder’s narrator, Siri has  an aspiration with which readers can identify. That he never entirely succeeds is illustrated in the scene where his sometime lover, Chelsea, contacts him because she has contracted a deadly virus and wants to see him again, reaching out before she dies. The “normal” reaction would of course be to call her back immediately.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Instead, Siri spends days searching for the right “algorithm that fit” (294), the rules that will tell him how to act, what to say. The effect is not to see him as a monster, however, as is the case with Remainder’s narrator, but rather sadness that in this difficult situation, he is unable to act at all. As we come to know the protagonists aboard Theseus, the estrangement effect diminishes, and their reactions, notwithstanding their technical enhancements and modified cognitions, seem very familiar. When the scramblers are introduced, the crew’s differences from the presumed normality of readers recedes into insignificance. But when Siri on the voyage home thinks he may be the last sentient creature in the universe, that normality is suddenly converted into abnormality. He has warned us readers repeatedly that he is not representing what literally happened aboard the Theseus, or what the characters actually said, but rather what they meant. His final words drive the message home: “So I really can’t tell you one way or the other. You’ll just have to imagine you’re Siri Keeton” (362), inviting us to identify with him as one dodo identifies with another.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Technical cognition, no matter how advanced, cannot remedy this situation, because consciousness is always part of the mix, calling the shots, designing the hardware, determining how and in what ways the interfaces work. Unless, of course, we consider Sarasti and the Captain, in which case consciousness again becomes the outlier in a universe dominated by the nonconscious. What these texts demonstrate, then, is how the very idea of “normal” mutates when the costs of consciousness are taken into account. They suggest that “normality” cannot be sufficiently anchored by consciousness alone, or indeed by human cognition. In a universe where technical cognition is already on the scene and NASA announces the discovery of earth-like planets in other solar systems,7 human cognition can no longer be regarded as the “normal” standard against which all other cognition can be measured, technical and nonhuman, terrestrial and alien. If decentering the human is a major thrust of contemporary cultural theory, including animal studies, posthumanities, new  shifts to a planetary scale, in which human actors are but one component of complex interactions that include many other cognizers. Whether consciousness is a crown or a burden, or both together, must be reevaluated in this larger context of planetary cognitive ecology— and perhaps beyond planetary as well. Pa r T 2  CogniTive assemblages  ChaPTer 5  Cognitive Assemblages: Technical Agency and Human Interactions  In a passage from Reassembling the Social: An Introduction to ActorNetwork-Theory (2007), Bruno Latour criticizes what he calls the “sociology of the social” for making an artificial distinction between humans and objects with this example.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “Any human course of action might weave together in a manner of minutes, for instance, a shouted order to lay a brick, the chemical connection of cement with water, the force of a pulley unto a rope with a movement of the hand, the strike of a match to light a cigarette offered by a co-worker” (74). While I very much admire Latour’s work and happily acknowledge the significant contributions of actor-network-theory (ANT) to science studies, this passage illustrates why a framework focusing on cognition adds an important dimension to existing approaches to complex human systems. Notice that the action begins with a “shouted order,” and that material forces are then enlisted as a result of this decision. The cement could not by itself build a structure; for that matter, cement relies on human intervention to come into existence as a construction material. In short, cognitive processes play crucial roles in Latour’s example, notwithstanding that he intends it to show the symmetry between human actions and material forces. The point, as I have emphasized, is not to glorify human choice but rather to expand the spectrum of decision makers to include all biological life-forms and many technical systems. Decision makers certainly can and do enlist material forces as their allies, but they are the ones who try to steer the ship in a particular direction. The term I use to describe these complex interactions between human and nonhuman cognizers and their abilities to enlist mate-  Guattari (1987) also invoke “assemblage,” a cognitive assemblage has distinctive properties not present in how they use the term.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In particular, a cognitive assemblage emphasizes the flow of information through a system and the choices and decisions that create, modify, and interpret the flow. While a cognitive assemblage may include material agents and forces (and almost always does so), it is the cognizers within the assemblage that enlist these affordances and direct their powers to act in complex situations. Having invoked the idea of power (most tellingly in the book’s title, and in passing throughout), I will now indicate how power— and its handmaiden, politics— appear in this framework. Here Latour offers valuable guidance, for he points out that power is an effect produced by mediators (human and nonhuman) that transform temporary and shifting configurations into durable, robust, and reproducible structures capable of creating, solidifying, and wielding power. Responding to critiques of ANT as a theory that ignores politics and social inequalities, Latour argues that its focus on mediators is precisely what enables politics to come into view as provisional practices that can always be otherwise than they are. “Sociologists of the social,” as Latour characterizes his colleagues who invoke “the social” as an explanatory force, ignore the mediators that make power possible, thereby mystifying power so that constructive change becomes more difficult to imagine or initiate. “By putting aside the practical means, that is the mediators, through which inertia, durability, asymmetry, extension, domination are produced and by conflating all those different means with the powerless power of social inertia, sociologists, when they are not careful in their use of social explanations, are the ones who hide the real causes of social inequalities” (85). Although Latour would not agree with the distinction I make between cognizers and material processes, his focus on mediators fits well with my vision of cognizers as transformative actors.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  By reenvisioning cognition and crafting a framework in which nonconscious cognition plays a prominent role, my approach enables analyses of cognitive assemblages, and the mediators operating within them, as the means by which power is created, extended, modified, and exercised in technologically developed societies. The charge that Latour levels at sociology can apply equally (or even more so) to the humanities. “To the studied and modifiable skein of  has too often substituted an invisible, immoveable, and homogeneous world of power for itself . . . Thus, the accusation of forgetting ‘power relations’ and ‘social inequalities’ should be placed squarely at the door of the sociologists of the social” (86). His emphasis here on the studied and modifiable implies that modification of power relations requires detailed and precise analyses of the ways in which assemblages (in my terms, cognitive assemblages) come together, create connections between human and technical actors, initiate, modify, and transform information flows, thereby bringing contexts into existence that always already determine the kinds and scope of decisions possible within milieus and the meanings that emerge within them. On the offensive, Latour drives home his critique of critical sociology in strong terms that, unfortunately, are resonant with the critical humanities as well. “If, as the saying goes, absolute power corrupts absolutely, then gratuitous use of the concept of power by so many critical theorists has corrupted them absolutely—or at least rendered their discipline redundant and their politics impotent” (85).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This last phrase stings with special force because it is so obviously true of the critique of power as it was displayed in the humanities during the 1970s, 1980s, and beyond. If we judge a political agenda by its efficacy in persuading a populace, then the deconstructive theory that swept the humanities during this period had, in a generous interpretation, mixed results: while it succeeded in radicalizing many academics within the humanities, it estranged the humanities from the general public with discourses seen as obscure, not to mention nonsensical, and made the humanities seem increasingly peripheral to the main business of society. This suggests that at the very least, it might be time to try another approach that analyzes power relations by focusing on how power is created, transformed, distributed, and exercised in an era when complex human systems are interpenetrated by technical cognition—that is to say, by focusing on cognitive assemblages. I turn now to parsing this key term in more detail. In Deleuze and Guattari’s usage, “assemblage” [agencement] carries the connotations of connection, event, transformation, and becoming. They privilege desire, affect, and transversal energies over cognition, but the broader definition of “cognition” that I employ brings my argument somewhat closer to theirs, although significant differences remain. I want to convey the sense of a provisional collection of parts in constant flux as  that transformations are inhibited and not so loosely connected that information cannot flow between parts. An important connotation is the implication that arrangements can scale up, progressing from very low-level choices into higher levels of cognition and consequently decisions affecting larger areas of concern.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In focusing on cognition, which the reader will recall I defined as “a process of interpreting information in contexts that connect it with meaning,” I highlighted the activities of interpretation, choice, and decision and discussed the special properties that cognition bestows, namely flexibility, adaptability, and evolvability. A cognitive assemblage approach considers these properties from a systemic perspective as an arrangement of systems, subsystems, and individual actors through which information flows, effecting transformations through the interpretive activities of cognizers operating upon the flows. A cognitive assemblage operates at multiple levels and sites, transforming and mutating as conditions and contexts change. Why choose assemblages rather than networks, the obvious alternative? The question is especially pertinent, since “network” is usually favored by Latour (witness ANT), although he tends at times to use “assemblage” as a synonym (Latour 2007). Networks are typically considered to consist of edges and nodes analyzed through graph theory, conveying a sense of sparse, clean materiality (Galloway and Thacker 2007). Assemblages, by contrast, allow for contiguity in a fleshly sense, touching, incorporating, repelling, mutating. When analyzed as dynamic systems, networks are like assemblages in that they function as sites of exchange, transformation, and dissemination, but they lack the sense of those interactions occurring across complex threedimensional topologies, whereas assemblages include information transactions across convoluted and involuted surfaces, with multiple volumetric entities interacting with many conspecifics simultaneously.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Because humans and technical systems in a cognitive assemblage are interconnected, the cognitive decisions of each affect the others, with interactions occurring across the full range of human cognition, including consciousness\/unconscious, the cognitive nonconscious, and the sensory\/perceptual systems that send signals to the central nervous system. Moreover, human decisions and interpretations interact with the technical systems, sometimes decisively affecting the contexts in which they operate. As a whole, a cognitive assemblage  responding to new situations, incorporating this knowledge into adaptive strategies, and evolving through experience to create new strategies and kinds of responses. Because the boundaries are fuzzy, where one draws the line often depends on the analytical perspective one uses and the purposes of the analysis. Nevertheless, for a given situation, it is possible to specify the kinds of cognitions involved and consequently to trace their effects through an evolutionary trajectory. The most transformative technologies of the later twentieth century have been cognitive assemblages: the Internet is a prime example. While many modern technologies also had immense effects—the steam engine, railroads, antibiotics, nuclear weapons and energy— cognitive assemblages are distinct because their transformative potentials are enabled, extended, and supported by flows of information, and consequently cognitions between human and technical participants. Hybrid by nature, they raise questions about how agency is distributed among cognizers, how and in what ways actors contribute to systemic dynamics, and consequently how responsibilities—technical, social, legal, ethical—should be apportioned.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  They invite ethical inquiries that recognize the importance of technical mediations, adopting systemic and relational perspectives rather than an emphasis (I would say overemphasis) on individual responsibility. Developing the concept of a cognitive assemblage in this chapter, I begin with the basic level of a city’s infrastructure. Nigel Thrift (2004) has called infrastructures governing our everyday assumptions about how the world works the “technological unconscious,” consisting of predispositions that regulate our actions in unconscious and nonconscious ways through routine anticipations, habitual responses, pattern recognition, and other activities characteristic of the cognitive nonconscious. From there my analysis moves inward toward the body to discuss digital assistants that interact directly on a personal level. As these devices become smarter, more wired, and more capable of accessing informational portals throughout the web, they bring about neurological changes in the mindbodies of users, forming flexible assemblages that mutate as information is gathered, processed, communicated, stored, and used for additional learning that affects later interactions. As the user’s responses and interactions reveal more and more about her predispositions of which she may not even be aware, the possibility for surveillance grows progressively stronger,  (“Sandy”) Pentland (2008) and epitomized by Frans van der Helm’s extreme proof-of-concept in the MeMachine (AR Lab 2013). I turn next to analyze the implications of increasing technical autonomy evident in many research programs now underway, for example self-driving cars, face-recognition systems, and autonomous weapons. My focus is on the transition from pilot-operated drones to autonomous drone swarms.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Amplifying technical autonomy requires that the cognitive capabilities of technical devices be increased, so distributed agency is preceded by and dependent on a prior redistribution of cognition. The tendency of technical devices to unsettle discursive formations and shake up cultural practices is exacerbated in the case of military drones, where nothing less than life and death may be at stake. Illustrative sites for such seismic disturbances are international treaties delineating the so-called laws of war, which assume that agency, and consequently decisional power, lie entirely with humans, without considering the effects of technical mediations. The significant changes brought about when technical devices do have agency illustrate what happens to complex human social systems when they are interpenetrated by technical cognition. As I will show, the resulting cognitive assemblages transform the contexts and conditions under which human cognition operates, ultimately affecting what it means to be human in developed societies. infra s TruCTure and TeChniCaL CogniTion Imagining the future of technical cognition, Alex (“Sandy”) Pentland of MIT Media Lab writes, “It seems that the human race suddenly has the beginnings of a working nervous system. Like some worldspanning living organism, public health systems, automobile traffic, and emergency and security networks are all becoming intelligent, reactive systems with . . . sensors serving as their eyes and ears” (2008, 98).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The analogy has not been lost on neuroscientists, who adopt traffic metaphors to characterize information flowing through the body’s nervous system (Neefjes and van der Kant 2014). As Laura Otis argues about the connections nineteenth-century scientists made between nerves and networks of telegraph lines, such analogies have real conceptual force: “metaphors do not ‘express’ scientists’ ideas; they are the ideas” (2001, 48). tem” and that of humans is ATSAC, the Automated Traffic Surveillance and Control system in Los Angeles that controls traffic on 7,000 miles of surface streets (ATSAC n.d.). I made a site visit there in November 2014 and spoke with Edward Yu, ATSAC’s director. The computer system at ATSAC’s heart, fed by information flowing from sensors and actuators throughout the city, is flexible, adaptive, and evolutionary, capable of modifying its own operations. Combined with human operators who work with it, ATSAC illustrates the ways in which technical nonconscious cognition works with human capabilities to affect the lives of millions of urban inhabitants. Located four levels below the street, the center is housed in an underground bunker originally designed to protect city officials from bomb attack (that it has now been turned over to ATSAC is perhaps an unintentional acknowledgment of how crucial traffic control is to Los Angeles). Information flowing into the center includes reports from 18,000 loop detectors, working by magnetic induction, that register traffic volume and speed every second in over 4,000 intersections, while more than 400 surveillance cameras monitor the most troublesome or important intersections.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Analyzing these data streams, computer algorithms automatically adjust the signal lights to compensate for congested lanes. This requires changing the relevant signals in coordinated fashion, so that side streets coming into a main thoroughfare, for example, are timed to work together with the main street’s lights. The system also monitors traffic in the dedicated bus lanes; if a bus is behind schedule, the algorithms adjust the signals to allow it to make up time. All the monitoring information is processed in real time. The entire system is hardwired to prevent latency, with copper wire from the loop detectors running into hubs, where the information is carried by fiber optic into the center. ATSAC thus represents a considerable civic investment in infrastructure. Begun for the 1984 Olympics in Los Angeles, it was finally completed in 2012. In addition to everyday traffic, engineers adapt the system for special events such as a presidential visit or a blockbuster premiere.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Even the automatic cycles have special provisions. In neighborhoods with large Orthodox Jewish communities, for example, the push buttons operating “walk” signals are programmed to work automatically during the daylight hours of the Jewish Sabbath, during which times Orthodox Jews are prohibited from working machinery and thus can-  sons, the system has programmed into it the times for sunrise and sunset for the entire year. Without the help of the system’s sensors, actuators, and algorithms, it would be impossible for humans to conduct such widespread traffic coordination, and prohibitively expensive even to attempt it. According to studies, the system has resulted in 20 to 30 percent fewer stops at intersections, reduced travel time by 13 percent, cut fuel consumption by 12.5 percent, and air emissions by 10 percent (Rowe 2002). These statistics have real consequences for the lives of Angelenos. Having lived in Los Angeles for two decades, I can testify how important traffic patterns become, often dictating life choices such as work schedules, entertainment possibilities, and friendship networks. When Yu attends community meetings, he likes to ask audiences how many have been affected by a major crime. Typically, two or three people out of a hundred raise their hands.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Then he asks how many have had their lives affected by traffic; hands shoot up from virtually everyone. Specifically, how do the technical cognitions instantiated in ATSAC interact with human cognitions? The algorithms are coordinated with a database in which the traffic information is stored for a week; this allows the system to extract patterns, and it uses these patterns to update the algorithms accordingly. Drivers also detect patterns, no doubt at first consciously and then nonconsciously as they travel the same routes over and over. When anomalies occur, they are quick to notice and often call the center to alert operators to problems at particular intersections. The operators also must internalize the patterns so they can make informed decisions. Yu reported that it typically takes about a year and a half to train new personnel before they have enough experience to distinguish the ordinary from the extraordinary. For example, Santa Monica Boulevard feeds into the Santa Monica freeway; if the freeway entrance is backed up, there is no point in arranging the signals to permit traffic to move faster on the street, since that would only exacerbate the problem.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When an intersection becomes congested, the screen graph displaying that information begins to flash red, and the operator can pull up the camera feed to identify the problem. The afternoon I visited, an intersection on Alameda Street in the downtown area became congested, and the camera image revealed that police had blocked off a  portion of the street to prepare for a demonstration. Unfortunately they had not informed the center, and with rush hour approaching, active intervention was necessary to prevent traffic from snarling throughout the downtown area. With a single command, an operator can change a whole network of signals, as was necessary in this instance. ATSAC exemplifies productive collaboration between human conscious decisions, human nonconscious recognition of patterns by both operators and drivers, and the technical cognitive nonconscious of the computer algorithms, processors, and database. As Ulrik Ekman notes in discussing the topology of intelligent cities, “Design here must meet an ongoing and exceedingly complex interactivity among environmental, technical, social and personal multiplicities of urban nodes on the move” (2015, 177). Functioning within these complexities, ATSAC demonstrates how a cognitive assemblage works. At any point, components are in flux as some drivers leave the system and others enter.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Although the underlying infrastructure is stable, the computer’s screenic interfaces constantly change as older trouble spots are cleared up and new ones emerge. Similarly, the basic cognitive structures of the algorithms are set, but they are also modified through the extraction of patterns, which are used to modify continuing operations as contexts change and new meanings are produced. The political assumption instantiated in the system’s cognitive functioning is that it is desirable for traffic to flow smoothly. In this sense, it contributes positively to the experiences of Angelenos. The downside, of course, is that by decreasing traffic congestion, it allows the (in)famous L.A. dependence on cars to continue and even increase. Yet the system has also been engineered to encourage increased use of public transport through the dedicated bus lanes it manages.1 Consequently, it can be argued that the net results are positive overall. The system is the beneficiary of investments by the city over several decades and different political regimes, which nevertheless managed to summon the political will to keep the system running and enlarge it until the entire city was included. ATSAC thus shows the possibilities for constructive outcomes from the deep penetration of the technical cognitive nonconscious into complex human systems.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It is worth noting that the system has no direct connection to market considerations of profit and loss. digiTaL a s sisTanTs and informaTion P orTaLs From the mediations of an urban traffic infrastructure, we move up close and personal to consider the more intimate and arguably more neurologically consequential interactions with a digital assistant. VIV, a device being developed by VIV Labs in San Jose, CA, evolves its capacities through web reading, geolocation, mobile interactions, and real-life queries (Levy 2014). The program, soon to be marketed as the “next generation Siri,” combines GPS orientation with an open system that programs on the fly, parses sentences, and links to third-party sources. Developers Dan Kittlaus, Adam Chever, and Chris Brigham say that VIV can parse relatively complex queries such as this, shown in Wired alongside a flowchart indicating VIV’s search techniques: “On the way to my brother’s house, I need to pick up some cheap wine that goes well with lasagna.” The program first parses “brother” as a family relationship and looks for the appropriate entry in the user’s Google contacts. It then plots the route and, noticing a missing variable, asks the user how far she is willing to deviate to get the wine. With this information, the program searches the web for lasagna recipes, identifying it as a food item containing tomato, cheese, and pasta. Searching for wine-food matches yields appropriate varietals, and further inquiries yield price ranges from which a “cheap” spectrum is identified.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The next step queries catalogues of the wine stores en route, with the final result being a list of wines at the appropriate stores. VIV is designed to learn continuously, keeping track of its inferences in a growing database. Unlike language learning programs such as NELL, the Never Ending Language Learning program developed by computer scientist Tom Mitchell and his group at Carnegie Mellon University, VIV has the advantage of interacting with the real world, including locations, the user’s range of interests, and indicators of tastes and preferences. With a wider range of movement and knowledge, VIV can perform calculations correlating trade-offs such as time versus money, quality versus price, and proximity versus distance. It interacts with the user’s cognitions in directing movements, interpreting sensory signals such as location indicators, and responding to queries. Moreover, it has the advantages of massive storage space in the cloud, fast processing speed, and computational intensity of data manipulation. VIV and the user, considered as parts of a cognitive assemblage,  of other functionalities associated with web queries and curating algorithms that correlate VIV’s data with other information about the user stored in myriad relational databases. If the rollout of VIV is successful, we can anticipate that it will have considerable commercial value, because it will integrate geolocation with specific product requests.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Moreover, it will enable data collection on a scale that surpasses even that available with present smartphones and desktop searches. It will be able to correlate user movements in real time, location data about present trajectories as well as past trips, and the queries and purchases associated with these trips. Some of this functionality is already available in GPS devices, for example the store locations displayed under search categories—information that corporations pay to have listed. When several routes are available, the GPS typically chooses the one that passes by the greatest number of listed stores, for example malls or shopping plazas. All this, and more, will be potentially available with VIV. Having such a smart digital assistant will also affect how users integrate this technical cognition into their daily lives. We can expect that certain evolved cognitive abilities present in human brains—for example, the ability to navigate and judge where one is in the world—will receive less stimulation with this device, for now it navigates for the user, and the human synaptic networks involved with navigation will tend to shrink. We know from experiments evaluating web scanning versus print reading that human neurology can undergo changes after even minimal exposure to digital media, with long-lasting effects (Hayles 2012).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The predictable result is that the more one uses a digital assistant such as VIV, the more one needs to use it, as one’s natural abilities to navigate in the world decline, perhaps to the point of atrophy. Moreover, the device will likely result in a certain homogenization of behavior; exploratory wandering will decrease and routinization of movement will increase. The same will be true of shopping practices; less wandering around the store and more direct selection of desired items, where “desire” is itself manipulated by marketing. Overall, the interpolation of the user into corporate designs will be intensified and expanded. To the extent that Augmented Reality may also be part of VIV’s functionality, this intensification will occur on nonconscious as well as conscious cognitive levels. As with other digital affordances, VIV will follow what Bernard Stiegler (2010a, 2010b) has characterized  ful advantages of convenience, satisfaction of desires, and enhanced navigation while increasing surveillance, directed marketing, and capitalist exploitation. Are devices such as VIV the predecessors of fully conscious technical systems, as Spike Jonze’s film Her (2012) suggests? If the twentieth and twenty-first centuries have taught us anything, it is that only fools would rush in to proclaim “Impossible!” The real temptation here, however, is to imagine that we are awaiting the arrival of technical cognition, when it is already realized in myriad complex systems and computational devices.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Humans living in societies with deep technological infrastructures are enmeshed in cognitive assemblages shaped and interpenetrated by technical cognition, including language learning systems. If “the language instinct” separates humans from other biological organisms in a rupture so extreme it marks human uniqueness, as Steven Pinker has controversially argued (2007), the language gap is narrowing between humans and their digital interlocutors. soCia L s ignaLing and somaTiC surveiLLanCe At MIT Media Lab, Pentland, working with his graduate students, has developed a device he calls the sociometer, designed to detect, measure, and display physiological indicators of social signaling among groups (Pentland 2008). The device, worn like a shoulder badge, detects who is talking to whom (via IR transceivers), for how long, and with what intensity (Choudbury and Pentland 2004; Pentland 2008, 99–111). It also analyzes nonlinguistic speech features such as consistency of emphasis, tracks body movements and infers from them the activities involved, measures the proximity to other people, and from these data identifies the social context. Pentland calls the behaviors measured by the sociometer “honest signals” because they take place below the level of conscious awareness; he further argues that attempting to fake them would require so much effort that it is virtually impossible (Pentland 2008, 2–3). The sociometer performs in a technical mode operations similar to the human cognitive nonconscious by sensing and processing somatic information to create integrated representations of body states. As we have seen, the human cognitive nonconscious recognizes and interprets patterns of behavior, including social signals emanating from  externalized in the sociometer, for the social signals it detects enable Pentland and his group to predict outcomes for various kinds of interactions, from salary negotiations to dating preferences.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Even with thin slices of behavior as short as thirty seconds, sociometer data indicate accurately what decisions a group will reach. It is worth emphasizing that these predictions are derived solely from the sociometer’s analysis of social signals, with no attention to verbal content or rational argument. There are several implications to be drawn from these experiments. First, they indicate the usefulness of the sociometer as a feedback device to help a group improve its functioning. Pentland reports that his lab has developed “a computer algorithm that builds on the sociometer’s ability to read the group’s honest signaling. Using this technology we are beginning to build real-time meeting management tools that help keep groups on track, by providing them with feedback to help avoid problems like groupthink and polarization” (49). More fundamentally, sociometer data indicate how essential social signals are to human sociality, and conversely, how more limited rational discussion and conscious deliberation may be than traditionally supposed. In this respect, humans may have something in common with social insects such as bees and ants (as E. O. Wilson argues in another context; Wilson 2014, 19–21).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “Honest signals are used to communicate, control the discovery and integration of information, and make decisions” (83), Pentland writes. Extrapolating from this insight, he argues that “important parts of our intelligence exist as network properties, not individual properties, and important parts of our personal cognitive processes are guided by the network via unconscious and automatic processes such as signaling and imitation” (88). With classic understatement, he predicts that “we will come to realize that we bear little resemblance to the idealized, rational beings imagined by Enlightenment philosophers” (88). In addition to this major conclusion, there are important corollaries. Because social signals take time to generate, transmit, receive, and recognize, they operate on a slower timeline than either the cognitive nonconscious (in the 200-ms range) or consciousness (in the 500-ms range). Pentland estimates they work in the 30-second range, a temporality analogous to the time it takes to interpret complex verbal information such as narratives (107–111). This implies that the processing of  opening the possibility of a feedback loop between them, such as happens when two people engaged in conversation begin to mimic one another’s gestures as they become more engaged with each other verbally, each form of communication reinforcing the other. Pentland references research showing that when this kind of mimicry occurs, interactors report that they like the other more, trust each other more, and reach more accommodating outcomes (10–11).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Another corollary is that social signaling affects both participants, unlike verbal language, which can be directed at another without necessarily affecting the speaker. Pentland summarizes this effect: “When you engage in social signaling, you are often affected just as much as the other person. Signals are two-way, not one-way, so that pulling on one corner of the social fabric stretches all members of the network” (40). Evolutionarily, it is likely that social signaling developed before language; many mammals use such signals to negotiate over territory, communicate intentions, and coordinate group activity. Pentland references brain research indicating that “we all have networking hardware that gives us the ability to read and respond to other people” (37), specifically, the mirror neurons mentioned in chapter 2 (Barsalou 2008; Ramachandran 2012). “This signal-response channel seems to have evolved much earlier than the linguistic channel,” he continues, “with language building on top of the capabilities of this channel” (42), a trajectory analogous to nonconscious cognition developing first, with consciousness emerging later and being built on top. The sociometer, then, may be regarded as an exteriorization of the cognitive nonconscious, collecting, interpreting, analyzing, and displaying information in ways that make it available for conscious consideration. Insofar as social signals are essential to effective group functioning, we may draw a somewhat different conclusion from those that concern Pentland.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The sociometer’s exteriorization reveals that the work of the cognitive nonconscious is crucial to social networking, group decision making, and indeed human sociality. Functioning as part of a cognitive assemblage, the sociometer is enmeshed in a human-technical system with porous borders, depending on who is using the device for what purpose—whether to monitor one’s own responses, to surveil those of someone else, or to analyze group behavior from the outside, so to speak, analyzing its dynamics with or without the group’s permission . category of analysis that I call somatic surveillance. While traditional surveillance technologies focus on exterior appearances, movements, clothing, and such, somatic surveillance registers the body’s interior markers and displays them in real time. The concept is not entirely new. Lie detector tests, for example, measure physiological responses such as heart rate and galvanic skin response and display them through a moving graph; hospital medical devices display heart rate on monitors. Although these technologies operate in real time, they lack two crucial features illustrated by the sociometer—mobility and miniaturization, properties necessary to make the technology wearable (for an analysis from a medical viewpoint of the importance of mobility, see Epstein 2014). The idea of using wearables for somatic surveillance is still relatively new, and its implications remain largely unexamined.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This state of affairs catalyzed a Dutch researcher, Frans van der Helm, to create what he calls the MeMachine. Internationally renowned for his cutting-edge research in robotics and prosthetics, van der Helm and his lab have developed hardware devices and software programs to aid them in their research, including an animated display of an anatomical figure mirroring in real time the movements of a subject wearing multiple tracking sensors on his body. Because their work requires detailed knowledge of how muscles, tendons, and joints move, the figure is imaged sans skin to reveal more clearly the complex interactions that constitute human mobility. This figure, appearing somewhat like one of the flayed bodies in Gunther von Hagens’s Körperwelten (Body Worlds), is all the more dramatic because it moves in perfect synchrony with its real-life counterpart. The capability to create this image had already been developed for research purposes, so it required only a few tweaks to make it into the occasion for a spectacular demonstration of somatic surveillance: the MeMachine. In 2012, van der Helm demonstrated the MeMachine in a videotaped presentation before a large audience. The video shows the preparations: an anonymous hairy chest being shaved so sensors can be attached; sensors being carefully placed on each finger; a headband with eye-tracking devices slipped into place; a backpack with the computer equipment communicating wirelessly with the sensors hefted onto shoulders. Preparations complete, a nattily suited van der Helm strides on stage wearing this gear, his face partially obscured by  on his body.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  On screen, however, everything is revealed: as the flayed figure mirrors his posture, gestures, and body language, data scrolls underneath showing ECG readings of his heartbeat, EMG (electromyography) tracking of electrical impulses generated by his muscles, galvanic response indicating skin conductance, EEG readouts showing his brainwaves, and an inset using the eye-tracking data to show where he is looking. Each data cluster is estimated in real time, so that the audience knows his focus of attention, arousal level, emotional state, brain activity, and muscle tension. The kinds of information that the cognitive nonconscious processes are here opened out to an unprecedented degree. Moreover, in Stelarc-like fashion, he suggests in his videotaped lecture that in future instantiations of the MeMachine the audience may be invited to intervene in his somatic states, for example, by setting limits for physiological parameters which, if exceeded, “punish” him by removing some of his functionality. In this case, the boundaries of the MeMachine’s cognitive assemblage would include any number of spectators as well as van der Helm and the technical devices monitoring his activities. The prospect suggests that the MeMachine’s exteriorization could create surveillance scenarios in which virtually nothing of the surveilled person’s thoughts, affects, and autonomic responses would remain private or capable of resisting exterior scrutiny. When I spoke to van der Helm after his presentation at Delft Technical University (van der Helm 2014), he framed the project as a provocation designed to catalyze discussions about the ethical, social, and cultural implications of somatic surveillance. He reported that ethicists, philosophers, and others who had seen the MeMachine demonstration were shocked by its surveillance potential, proposing that issues of privacy, public policy, and ethical guidelines should be explored before the technology was developed further.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  To this view, van der Helm was vehemently unsympathetic, asking why these people had not come to his lab to engage in dialogue and what gave them the right to impose constraints after the fact.2 I found his response illuminating; it shows the problems with approaches in which humanists stand aloof from technological projects and deliver judgments on them from an exterior perspective. Suppose, instead, that a humanist had found her way to his lab, attended the weekly lab meetings, asked questions, engaged in discussions, and  then have been very different. Rather than demonstrating the MeMachine as a technologically neutral project (which is how it was presented at Delft), van der Helm might have set it up as a cautionary tale, an occasion for a panel discussion, or as an indication of the technology’s dangerous potential, along with a discussion of how safeguards and limitations could be built into the technology. In this sense, we might regard the MeMachine as a missed opportunity for productive collaboration between the sciences and humanities. In another sense, the MeMachine demonstrates the extent to which the workings of the cognitive nonconscious can be externalized through technical mediation, creating situations in which the human cognitive nonconscious, technical cognition, and human consciousness interact in real time through multiple feedback loops and recursive circular causalities to create a cognitive assemblage of unprecedented surveillance potential. disTriBuTe d agenCy and TeChniCaL auTonomy Cognitive technologies show a clear trajectory toward greater agency and autonomy. In some instances, this is because they are performing actions outside the realm of human possibility, as when highfrequency trading algorithms conduct trades in five milliseconds or less, something no human could do. In other cases, the intent is to lessen the load on the most limited resource, human attention, for example with self-driving cars.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Perhaps the most controversial examples of technical autonomy are autonomous drones and robots with lethal capacity, now in development. In part because these technologies unsettle many traditional assumptions, they have been sites for intense debate, both within the military community and in general discussions. They can therefore serve as test cases for the implications of distributed agency and, more broadly, for the ways in which cognitive assemblages interact with complex human systems to create new kinds of possibilities, challenges, and dangers. To limit my inquiry, I will focus on autonomous drones, but many of the same problems attend the creation of robot warfighters, as well as nonmilitary technologies such as self-driving cars, and quasi-military technologies such as face-recognition systems. The present moment is especially auspicious for analyzing techni-  possible, but the technical infrastructures are not so deeply embedded in everyday life that other paths are “locked out” and made much more difficult to pursue. In short, now is the time of decision. Debates entered into and choices made now will have extensive implications for the kinds of cognitive assemblages we develop or resist, and consequently for the kinds of future we fashion for ourselves and other cognitive entities with whom we share the planet. My focus will not be on drone assassinations carried out by the United States in other countries without respect for national boundaries, including some American citizens killed without trial or jury, in clear violation of the Constitution and civil rights.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This aspect is well covered by Medea Benjamin’s Drone Warfare: Killing by Remote Control (2013), in which she passionately opposes the drone program both for its unconstitutionality and more specifically for the horrific toll in civilian deaths (“collateral damage”), estimated to be as high as 30 percent.4 I also will not consider the myriad uses emerging for civilian UAVs, including rangeland monitoring, search and rescue missions, emergency responders in the case of fire and other life-threatening events, and UAVs used as mobile gateways, or “data mules,” collecting data from remote environmental sensors scattered over large territories (Heimfarth 2014). Rather, I will focus on piloted and autonomous UAVs,5 as well as multivehicle systems proceeding autonomously, with the swarm itself deciding which individual will play what role in an orchestrated attack. This range of examples, showing different levels of sensing abilities, cognitions, and decisional powers, illustrates why greater technical cognition might be enticing and the kinds of social, political, and ethical problems it poses. With the massive shift after 9\/11 from state-on-state violence to what Norman Friedman, a military analyst, calls expeditionary warfare, targets are not associated with a geographically defined entity but with highly mobile and flexible insurgents and “terrorists.” Friedman points out that if surveillance can be carried out without the enemy’s ability to perceive it, then the enemy is forced to devote resources to hiding and concealing its positions, which not only drains their ability to carry out offensives but also makes it more difficult for them to organize and extend their reach. These factors, he argues, combine to make UAVs superior to manned aircraft for expeditionary warfare. A fighter jet can typically stay aloft only for two hours before it needs to  trast, the UAV Global Hawk can stay aloft literally for days, refueling in the air; with no pilot aboard, pilot fatigue is not a problem (PBS 2013). These factors have led to a significant redistribution of resources in the US Air force, with more UAV pilots currently being trained than pilots for all types of manned aircraft combined. Spending about $6 billion annually on drone development and purchase (Human Rights Watch 2012, 6), they currently deploy about 7,000 drones, compared to 10,000 manned aerial vehicles (Vasko 2013, 84).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The factors that have made UAVs the contemporary weapons of choice for the US Air Force required the coming together of many technological advances, including global satellite positioning, superior navigation tools, better aerodynamics for increased stability and fuel economy, increased computational power, and better sensors for visual reconnaissance, obstacle avoidance, and ground coordination. The weak link in this chain is the necessity to maintain communications between the UAV and the remote pilot. As long as the UAV’s performance requires this link, it is subject to disruption either internally, as when the remote pilot banks too suddenly and the link is lost, or because the link has been hijacked and control wrested away by another party, as happened when a Lockheed Martin RQ170 Sentinel drone landed in Iranian territory in December 2007, likely because the UAV was fed false GPS coordinates by the Iranians. This implies that the next wave of development will be UAAVs, unmanned vehicles that fly autonomously, and UAAVS, multivehicle autonomous systems. Still at a nascent stage, UAAVs and UAAVS are nevertheless developing rapidly. The Navy, for example, is developing the experimental X-47B Stealth UAAV, which can perform missions autonomously and land on an aircraft carrier without a remote pilot steering it. Moreover, the technical components necessary to make UAAVs and UAAVS reliable and robust are coming together very quickly in transnational research projects, particularly in the United States and China. A recent article written in English by Chinese researchers illustrates the growing awareness of UAAVS of their internal states as well as the environment (Han, Wang, and Yi 2013, 2014).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The study discusses the development of software that allows a swarm to coordinate its individuals in cases where one or more vehicles are assigned to attack. The model uses an “auction” strategy, whereby each unit responds to a request for a bid by assessing what the authors call its “beliefs,” “desires,” and  a quantitative number for the bid. The software enables the swarm to balance competing priorities in rapidly changing conditions, taking into account their position, velocity, and proximity to one another (“beliefs”), their assigned mission priorities (“intentions”), and the intensity with which they will execute the mission (“desires”), with the latter parameters tailored for specific mission objectives. The anthropomorphic language is not merely an idiosyncratic choice, for it indicates that as the sensory knowledge of external and internal states, autonomous agency, and cognitive capabilities of the swarm increase, so too does their ability to make decisions traditionally reserved for humans. With autonomous drones and other autonomous weapons on the horizon, there has been increased attention to the ethical implications of their use. Most of these discussions refer to the Geneva Conventions and similar protocols, which require that weapons must “distinguish between the civilian population and combatants” (Article 48 of Additional Protocol 1 to the Geneva Conventions, cited in Human Rights Watch 2013, 24). In addition, international humanitarian law prohibits disproportionate attacks, defined as ones that “may be expected to cause incidental loss of civilian life, injury to civilians, damage to civilian objects, or a combination thereof, which would be excessive in relation to the concrete and direct military advantage anticipated” (from the Customary International Humanitarian Law Database, cited in Human Rights Watch, 24). Finally, additional requirements are the rather vague concept of “military necessity,” defined by British scholar Armin Krishnan as dictating that “military force should only be used against the enemy to the extent necessary for winning the war” (2009, 91), and the even vaguer “Martens Clause,” intended to cover instances not explicit in the Geneva Conventions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It requires that weapons be consistent with the “principles of humanity” and the “dictates of public conscience” (Human Rights Watch, 25). In assessing autonomous weapons in these terms, Human Rights Watch and the International Human Rights Clinic (IHRC) at the Harvard Law School argue that autonomous weapons, including autonomous drones, cannot possibly make the required distinctions between combatants and civilians, particularly in the context of insurgent tactics that deliberately seek cover within civilian populations. Peter Singer, for example, instances the case of a gunman who shot at a US Ranger with “an AK-47 that was propped between the legs of two kneel-  303). They also argue that “proportionality” and “military necessity” are violated by drones, although “necessity” clearly is itself a moving target, given that what constitutes it is obviously context dependent and heavily influenced by the kinds of weaponry available. The Geneva Conventions were, of course, forged in the aftermath of World War II, characterized by massive state-on-state violence, firebombings of cities, gratuitous destruction of cultural monuments, and the nuclear holocausts wreaked by the United States upon Nagasaki and Hiroshima. With the move to expeditionary warfare, rise of insurgent attacks, and continuing increases in US drone attacks, these protocols seem badly outdated, even inappropriate. Why keep coming back to them? On an even deeper level, why should we care about ethics in wars where the intent is precisely to kill and maim?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Why, as Peter Singer puts it, try to determine what is right when so much is wrong, a question that drives straight to the oxymoron implicit in the phrase “Laws of War” (309). His defense is that the Geneva Conventions, obsolete as they may be, are the only international accords on the conduct of warfare we have and that we are likely to have, short of another world war with even more devastating violence. He believes there is an important distinction between those who practice restraint in warfare and “barbarians” (309) who are willing to go to any extreme, however savage and brutal. To argue thus is to plunge into a definitional abyss, since what counts as “restraint” and “barbarism” are as contextually and culturally dependent as the distinctions they propose to clarify. A better approach, I argue, is to evaluate the ethical questions surrounding piloted and autonomous drones from the relational and processual perspectives implicit in the idea of a cognitive assemblage. Mark Coeckelbergh, one of the few philosophers urging a relational perspective on robotics, observes that most ethical theories carry over to robotics the assumption characteristic of liberal individualism, taking “the main object of ethical concern [as] the individual robot” (2011, 245). In contrast, he argues that “both humans and robots must be understood as related to their larger techno-social environment” (245). Regarding ethical issues through the perspective of a cognitive assemblage foregrounds the interpretations, choices, and decisions that technical and human components make as information flows from the UAV’s sensors, through choices performed by the UAV software, to interpretations that the sensor and vehicle pilots give to the  sile, which involves the pilots, their tactical commander, and associated lawyers, on up to presidential advisors and staff.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Autonomous drones and drone swarms would operate with different distributions of choices, interpretations, and decisions, but they too participate in a complex assemblage involving human and technical cognizers. The choice, then, is not between human decision versus technical implementation, which is sometimes how the situation is parsed by commentators who prefer a simplistic picture to the more realistic complexities inherent in the situation. As Bruno Latour (2002) argues, changing the means of technical affordances always already affects the terms in which the means are envisioned, so ends and means mutually coconstitute each other in cycles of continuous circular causality. That said, the human designer has a special role to play not easily assigned to technical systems, for she, much more than the technical cognitive systems in which she is enmeshed, is able to envision and evaluate ethical and moral consequences in the context of human sociality and world horizons that are the distinctive contributions of human conscious and nonconscious cognitions. Consequently, we need a framework in which human cognition is recognized for its uniquely valuable potential, without insisting that human cognition is the whole of cognition or that it is unaffected by the technical cognizers that interpenetrate it. Understanding the situation as a cognitive assemblage highlights this reality and foregrounds both the interplay between human and technical cognitions and the asymmetric distribution of ethical responsibility in whatever actions are finally taken. Although the cognitive assemblage approach can provide useful perspectives on ethical issues, it does not by itself answer the urgent question of whether autonomous drones and drone swarms should be developed by the US military, and if developed, under what circumstances they should be deployed. Arguing in the affirmative, Ronald Arkin, a roboticist at Georgia Tech, envisions an “ethical governor” (2009, 69) that would be built into the weapon’s software requiring the weapon first to determine whether the presumed target is a combatant, and then to assess whether the proportionality criteria are met.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This proposal strikes me as naïve in the extreme, not only because of the ambiguities involved in these determinations, but more fundamentally, because of the presumption that the weapon’s designers would agree to these criteria. Even if the US military decided to do  entities fail to incorporate these restraints, would not “military necessity” dictate that the United States do likewise? The issue, then, cannot be resolved through technical fixes but requires considered debate and reflection, an insight that highlights the importance of human cognizers as they act within cognitive assemblages. Ultimately the humans are the ones that decide how much autonomy should be given to the technical actors, always recognizing that these choices, like everything else within a cognitive assemblage, are interpenetrated by technical cognition. A chorus of voices argues that fully autonomous weapons should not be developed and certainly not deployed. Human Rights Watch and the IHRC, in their thoughtful white paper considering the issue, conclude, “The development of autonomous technology should be halted before it reaches the point where humans fall completely out of the loop” (36). The summary emerging from the Stockdale Center’s year-long program on “Ethics and Emerging Military Technologies,” which culminated in the Tenth Annual McCain Conference on Military Ethics and Leadership, reaches a similar conclusion: “extreme caution should govern the actual deployment of autonomous strike systems” (Stockdale Center 2010, 429). Even before deployment, however, they write, “We strongly advise against incorporating ‘strong artificial intelligence’ in such systems, which would render them capable of learning and even choosing ends, inasmuch as strong artificial intelligence is highly likely to introduce unpredictability and\/or mitigate human responsibility” (429– 30).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Noel Sharkey of the University of Sheffield is more blunt; he is quoted by the website Defense One as saying, “Don’t make them fully autonomous. That will proliferate just as quickly and then you are going to be sunk” (Tucker 2014). The risk of proliferation is real; already fifty-five countries have the capacity to manufacture or build arsenals of UAVs. Friedman’s appendix listing UAVs larger than fifty kilograms in use around the world runs to a massive 220 pages (Friedman 2010). Matthew Bolton of Pace University in New York City puts the issue of lethal force deployed autonomously through UAAVS eloquently. “Growing autonomy in weapons poses a grave threat to humanitarian and human rights law, as well as international peace and security. . . . Death by algorithm represents a violation of a person’s inherent right to life, dignity, and due process” (Tucker 2014). As these analyses recognize, the possibility of developing autono-  The masses of humans that required nations for mobilization, as in World Wars I and II, can potentially be replaced by masses of combat aerial vehicles, all operating autonomously and capable of delivering lethal force. UAVs can now be built for as little as $500–$1,000, making it possible to field a 2,000-vehicle swarm for as little as a million dollars, a sum that emphatically does not require the deep pockets of a national treasury.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This enables an entirely different kind of warfare than that carried out by single UAVs, and it brings into view the possibility that UAAVS could be used to launch massive attacks almost anywhere by almost anyone. This nightmare scenario is worked out in fictional form in Daniel Suarez’s Kill Decision (2013). With a fair bid to become Tom Clancy’s successor, Suarez is like Clancy in including detailed descriptions of military equipment and operations, but he is considerably more critical of US policies and more sympathetic to utopian impulses. Kill Decision’s plot revolves around Linda McKinney, an entomologist studying the warlike weaver ants in Africa, targeted for assassination by unknown persons and saved at the last moment by a covert black ops force led by the enigmatic Odin. It seems that the shadowy antagonists have marked for assassination anyone with in-depth knowledge of the technologies they are using to create UAAV swarms, including McKinney, because the swarms recognize colony mates and coordinate attacks using the same kind of pheromone signals she found in the ant colonies. As Odin and his crew (including two ravens) track the UAAVS, it becomes apparent that the drones represent a new kind of warfare. The clarion call comes first in targeted drone assassinations within the United States (an eventuality almost certain to arrive someday in real life). At first their nature is concealed by the government calling them bombs set off by terrorists, and the victims seem randomly chosen with no connecting thread.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  But a larger plot is afoot, although the perpetrators remain in the shadows. All we know for sure is that the timing is coordinated with a US appropriation bill to create a large fleet of autonomous drones. The question the text poses, then, is whether autonomous drone warfare on a massive scale is inevitable, given the advantages of UAAVS over manned aircraft and piloted UAVs. Unlike these, autonomous drones have no limit on how far they can be scaled up and thus are  are a colony of ship-attacking drones inhabiting a huge commercial freighter, each autonomous but responsive to the colony’s chemical signals. The freighter is on course to intercept the US fleet as it carries out military exercises in the South China Sea. The predictable result would be the annihilation of US ships and an international incident blaming the Chinese for the attack. It begins to look as if the drone legislation might be approved, plunging the United States and subsequently the world into a new era of automated drone warfare. Odin observes that “with autonomous drones, you don’t need the consent of citizens to use force—you just need money.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  And there might be no knowing who’s behind that money either” (261). As the fiction suggests, Suarez believes that autonomous weapons must be constrained by international treaty before we are plunged into a Terminator-like scenario in which we are no longer able to control the proliferation of these weapons. He also implies that the only political circumstance in which this is likely to happen is if the United States, having exploited its technological advantage in being the first to develop and use drone technology, reaches the stage where drone proliferation by other state and nonstate entities becomes inevitable. In a report issued by the Council on Foreign Relations, Micah Zenko writes, “The current trajectory of U.S. drone strike policies is unsustainable. Without reform from within drones risk becoming an unregulated unaccountable vehicle for states to deploy lethal force with impunity” (2013, 4). Ironically, the threat of unlimited drone warfare may be the strongest motivation for the United States to reform its own drone policies first, in order to argue for international accords prohibiting further proliferation. The situation is analogous to the United States being the first to develop—and use—nuclear weapons, but then when other states acquired nuclear capability, being a leader in arguing for international controls. However cynically conceived, this strategy did rescue the world from all-out nuclear war.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Nuclear weapons, of course, require massive resources to develop and build, which largely limits them to state enterprises. Autonomous drones are much cheaper. Whether the same strategy would work with them remains to be seen. human e m oTion and TeChniCaL CogniTion So far my argument has emphasized the ways in which human and  less have distinctive differences. On the technical side are speed, computational intensity, and rapid data processing; on the human side are emotion, an encompassing world horizon, and empathic abilities to understand other minds. Roboticist Arkin tends to present human emotion as a liability in a warfighter, clouding judgment and leading to poor decisions (2010). However, emotion and empathy also have positive sides; considered as part of a cognitive assemblage, they can make important contributions. The French theorist Grégoire Chamayou refers to suicide bombers as “those who have nothing but their bodies” (2015, 86).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Applied to groups such as Al- Qaeda and the Islamic State, this is obviously incorrect; they also have AK-47s, rocket grenades, suicide bombs, IEDs, and a host of other weaponry. There have, however, been instances of resistance by those who indeed have nothing but their bodies: the lone student confronting a tank in Tiananmen Square, the hundreds of satyagrahis (resistors) who followed Gandhi to the Dharasana Salt Works in India and were beaten by British soldiers. Intentionally making oneself vulnerable to harm for principled reasons has the capacity to evoke powerful emotions in those who witness it, as world outrage over the episode at the Dharasana Salt Works demonstrated. Vulnerability, whether intentional or not, can also evoke strong emotions in those who perpetrate violence, in some instances leading them to reject violence as a viable solution. Such is the case of Brandon Bryant, who performed as a drone sensor pilot for the US Air Force for almost six years until he refused to go on, turning down a $109,000 bonus to reenlist. When he finally sought therapy, he was diagnosed with post-traumatic stress disorder. The diagnosis represents, as journalist Matthew Power notes, “a shift from a focusing on the violence that has been done to a person in wartime toward his feelings about what he has done to others— or what he’s failed to do for them” (2013, 7). Chamayou sees this shift as a cynical tactic by the US military to claim that drone pilots suffer too, but this interpretation fails to do justice to Bryant’s feeling that he has been through a “soul-crushing experience” (Power, 7).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Granted that drone pilots suffer far less harm than those they kill or maim, the fact that some of them experience real “moral injury” (Power, 7) can be understood as one of the contributions human emotions make to cognitive assemblages—something unique to biological life-forms that has no  Along with emotion, language, human sociality, and somatic responses, technological adaptations are crucial to the formations of modern humans. Whether warfare should be added to the list may be controversial, but the twentieth and twenty-first centuries suggest that it will persist, albeit in modified forms. As the informational networks and feedback loops connecting us and our devices proliferate and deepen, we can no longer afford the illusion that consciousness alone steers our ships. How should we reimagine contemporary cognitive ecologies so that they become life-enhancing rather than aimed toward dysfunctionality and death for humans and nonhumans alike? Recognizing the role played by nonconscious cognitions in human\/ technical hybrids and conceptualizing them as cognitive assemblages is of course not a complete answer, but it is a necessary component. For the cultural critic, knowing precisely how the informational exchanges operate within a cognitive assemblage is a crucial starting point from which to launch analyses and arguments for modifications and transformations, deployments or abstentions, forward-moving trajectories or, as a contrary example, international accords banning autonomous weapon systems. Providing the conceptual scaffolding for such analyses is therefore a profoundly political act, self-evidently so in military contexts but also in many other everyday contexts in which technical nonconscious cognitions interpenetrate human systems, such as those instanced in this chapter. We need to recognize that when we design, implement, and extend technical cognitive systems, we are partially designing ourselves as well as affecting the planetary cognitive ecology: we must take care accordingly.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  More accurate and encompassing views of how our cognitions enmesh with technical systems and those of other life-forms will enable better designs, humbler perceptions of human roles in cognitive assemblages, and more life-affirming practices as we move toward a future in which we collectively decide to what extent technical autonomy should and will become increasingly intrinsic to human complex systems. ChaPTer 6  Temporality and Cognitive Assemblages: Finance Capital, Derivatives, and High-Frequency Trading Whereas chapter 5 illustrated how cognitive assemblages work by surveying sites ranging from urban infrastructure to personal assistants, this chapter focuses on a more delimited set of practices enmeshing human and technical cognition in finance capital, specifically financial derivatives. At issue are not only flows of information, choices, and interpretations, but also the tendency of these cognitive assemblages to create temporal loops that quickly spiral out of control, ungrounded by referential stability. Another issue is the vast difference between the speeds at which technical cognizers operate in high-frequency trading (HFT), versus the cognitive timelines of humans in the assemblage. Combined with faster processor speeds, vast increases in computer memory, and fiber optic cables through which information travels at near-light speeds, HFT has introduced a temporal gap between human and technical cognition that creates a realm of autonomy for technical agency. Within the space of this “punctuated agency,” algorithms draw inferences, analyze contexts, and make decisions in milliseconds. HFT appeared on the scene when derivatives had already begun to dominate financial trading. The complex temporalities inherent in derivatives interact with the changed temporality of HFT to increase further the fragility of financial markets and their vulnerability to feedback loops and selfamplifying dynamics.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Analyzing these effects opens a window on how the interpenetration of technical and human cognition functions to redefine the landscape in which human actors move. The predominance of dueling algorithms has created a machinemachine ecology that has largely displaced the previous mixed ecology  can and do lead to catastrophic failures. In this sense, then, this chapter continues the discussion at the end of chapter 5 about the importance of human cognition in the design process and the essential role it plays in designing the dynamics of cognitive assemblages, especially in specifying the kinds of autonomy technical cognizers will have and the regions within which technical autonomy will operate. In the case of HFT, among the consequences of technical autonomy as it now operates are increased frequency of “black swan” events that threaten the stability of financial markets, a radically changed distribution between human and technical agency, and the emergence of complex ecologies between algorithms that undermine, if not render obsolete, the efficient market hypothesis that underlies many economic models. Because HFT significantly increases risk and exacerbates inequalities, it is an important site to explore how systemic approaches can intervene effectively to create more sustainable, just, and equitable results. The key to achieving this, as we will see, is altering temporal ecologies so that humans can exercise greater decision powers and machines have more limited scope for autonomous actions. As in the previous discussion about autonomous weapon systems, the point here is that recognizing how cognitive assemblages operate provides crucial resources for constructive intervention and systemic transformation. ComPLe x TemP oraLiTies and derivaTives Following Michel Serres, Bruno Latour developed the idea of temporal folding in technical artifacts.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Here is his description, taking as its occasion an ordinary hammer. The hammer, he writes, encapsulates a heterogeneous temporality, including “the mineral from which it has been moulded, the oak which provided the handle . . . the 10 years since it came out of the German factory which produced it for the market” (2002, 249). Not only is the past folded within it, the future is as well, in the sense that the hammer anticipates and helps to call into being the future, for example, the nails it will be used to drive. (Perhaps a clearer example would be a hammer gun, which not only catalyzed the development of nail cartridges but also new construction materials suited to rapid nailing patterns.) All technical artifacts encapsulate such heterogeneous temporalities, but the temporality of derivatives is especially complex because  verb form called in English the future perfect, and more elegantly in French, the futur antérieur, or future anterior. A curious mixture of future and past, the future anterior is represented by the compound verb “will have been,” as in “I will have been done by next week.” It looks to the future (will), then pivots and looks back on this point as if it had already happened (have been), in this way stapling the future to the past through an articulation in the present. This doubling-back movement has significant consequences for questions of value.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Yesterday’s newspaper, had we been able to read it day before yesterday, would be invaluable; today it is worthless. The cliché forms the basis of the film Paycheck (2003), where Michael Jennings (Ben Affleck) completes a job for a multinational, the details of which have been wiped from his memory, only to find that his past self has traded a multimillion dollar paycheck for an envelope of seemingly worthless trinkets, which, however, subsequently prove vital to his survival, as his past\/ future self had already (fore)seen. As derivative trader and cultural theorist Elie Ayache points out in The Blank Swan: The End of Probability (2010), also involved in folding time is a potential or actual change in context, created through the operation of writing. As written contracts, derivatives look to the future through their expiry date, and then as it were turn back to see this future date as having already happened to correlate it with a strike price (the derivative’s value at expiration). This complex temporality, already in effect when the first derivative was written, has in the contemporary period grown exponentially more powerful and pervasive through the use of HFT algorithms, which create their own version of the future anterior through the microtemporalities in which they operate. These temporal regions are inherently inaccessible to human cognition, which can follow their electronic traces only in a temporal window that has, from the viewpoint of the algorithm, already faded into the past, but which for the inquiring human resides in the future of conscious recognition. Derivatives may be considered a form of writing, as Ayache suggests, and this writing happens within contexts that are inherently complex because of the fold in time that derivatives enact. Context and writing\/reading are bound together in dynamic interplays; each helps to stabilize the other while also operating as flowing mutabilities that transform through time.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The situation is delightfully illustrated  which Menard, a twentieth-century French critic, is attempting to recreate the Don Quixote—not to copy or reconstruct it from memory but to write it afresh out of his own imagination while nevertheless adhering, word for word, to Cervantes’s original. As Borges observes, thoughts springing easily to pen for Cervantes have become almost unthinkable for the twentieth-century writer. “Truth, whose mother is history” (1994, 53) is Borges’s chosen example; what could this mean for someone whose history includes the holocaust, Orwell’s 1984, and political spinmasters, not to mention deconstruction? Ayache uses Borges’s fiction to point out that writing, as durable inscription, has the potential not only to smooth and linearize context by subjecting its unruly chaotic streaming into a uniform flow of language, but also to create a rupture or break that changes context incrementally by interacting with it. Arjun Appadurai also emphasizes the written nature of derivatives in his recent book Banking on Words: The Failure of Language in the Age of Derivative Finance (2016), in which he argues that the market crash of 2008 was essentially a failure of language. The complex temporality inherent in the future anterior is squared for derivatives, for they transform the contexts into which they are inscribed as any writing does, but beyond that, derivatives change contexts further through their operations as derivatives. To illustrate, we can briefly review how derivatives are written and exchanged. In its simplest (vanilla) form, a derivative is a kind of insurance or hedge for an underlying asset.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Say that you purchase 100 shares of stock A for $100 each, believing it will go up in price. But you also know that it may go down, so you buy a derivative that lets you sell the stock for $100 at a specified future date. If the stock goes up, well and good, you have made a profit. If it goes down, your loss is limited to the derivative price, say $10. The hedge works in the opposite direction if you think the stock will go down; in this case, you purchase a derivative that lets you sell the stock at a future date at a certain strike price, even if the market price by then is lower. Alternatively, you may sell the option without ever buying the shares, in a move that greatly increases your leverage (ratio of assets controlled to investment) over buying the stock itself. This illustrates the process by which derivatives trade in their own right, independent of whether the underlying asset is purchased. Since the value of a derivative changes over time, its price must be modeled using probabilities.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In the famous differential equation  ditions by Robert Merton (called BSM, after its three creators), the derivative price is calculated as a function of the underlying stock price, the riskless interest rate (for example, the interest rate of a certificate of deposit), and the “implied volatility,” or the rate of change of the underlying asset’s price. Since all the parameters are known except the derivative price and implied volatility, one may assume a value for the implied volatility and solve for price, or conversely run the BSM “backwards” and use the prevailing market price to calculate the implied volatility. The higher the volatility (that is, the more the underlying stock price varies as a function of time), the higher the price of the derivative, for more change implies more risk in hedging the underlying asset. The great accomplishment of BSM, and the reason its development correlated with an explosive increase in the derivative market, is that it shows how to price derivatives so as to hedge the underlying asset to make risk disappear (at least in theory!). This is accomplished through a strategy known as “dynamic replication,” in which the amount of underlying stock held is constantly changed as the stock price (and consequently the derivative price) changes over time. The BSM makes several assumptions at variance with reality (e. g., there are no transaction costs and one can buy or sell at any time without affecting the prevailing price), but undoubtedly the most important is that price variations will follow an equilibrium model. When price variations are graphed, this model assumes that they will follow a normal curve distribution, resulting in the famous bell curve. (Usually the logarithm of the square of the variations is used; this is called the log-normal distribution).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  At this point Ayache, building on Nassim Taleb’s “Black Swan” argument that highly unlikely events may nevertheless have large-scale effects, intervenes to point out that decisive ruptures can and do occur, in effect rendering the equilibrium assumption untenable. “The Black Swan,” he writes, is “a non-probability-bearing event of change of context or, in other words, a truly contingent event” (2010, 11). What then determines the prices of derivatives? According to Ayache, the market itself. Recall that one may solve BSM for the implied volatility if the price is known. Since the market establishes the price, it also determines the volatility, which implies that it operates in a kind of recursive loop grounded on nothing other than the market’s own performance. Hence for Ayache, the market is “a matter of ontology,  asserts is that the market is inherently unpredictable, and the most one can say is that the market is simply whatever happens next. Although the market may seem to follow an equilibrium model for some periods of time, it is always open to contingent and unforeseeable developments.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Writing derivatives, which Ayache characterizes as “contingent claims,” injects into the present an untamable and unforeseeable future, through the fold in time intrinsic to their operations. It is this aspect that Warren Buffet highlighted when he famously characterized derivatives as financial weapons of mass destruction (Buffet 2002). The fragility derivatives introduce has been exacerbated by the huge expansion of over-the-counter (OTC) derivatives, which remain entirely unregulated. When Brooksley Born, head of the Commodity Futures Trading Commission from 1996–99, sought to expand the agency’s regulatory power to OTCs, she met with huge resistance and, eventually, legislative action prohibiting the CFTC from regulating them, detailed in PBS’s documentary “The Warning” (2010). As the documentary’s title suggests, her concerns in retrospect seem entirely justified. Shortly after her attempt to regulate OTCs, Long-Term Capital Management (LTCM) in effect went bankrupt, a failure in which derivatives played a major role, as detailed below. The future anterior temporal loop, brought into existence by writing derivatives, makes derivative writing a form of extrapolation cut free from its underlying grounding base, free to float where the winds of chance blow it. As Brian Rotman (1987) puts it in his analysis of derivatives based on currency exchange, “Any particular future state of money when it arrives will not be something ‘objective,’ a reference waiting out there, determined by ‘real’ trade forces, but will have been brought into being by the very money-making activity determined to predict its value.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The strategies provided by options and futures for speculation and insurance against money loss caused by volatility of exchange interest rates become an inexplicable part of what determines those rates” (1987, 96, emphasis added). In using the future anterior verb form, Rotman retraces in his analysis the folding in time that derivatives perform. Time folded, twice. Traum a, rePression, and Th e markeT But surely this cannot be correct, you may object. Is not Ayache’s as-  behavior that markets typically follow? Indeed, Ayache’s vision of the market’s ontological power is a neoliberal fantasy run wild, fueled by Quentin Meillassoux’s (2010) philosophical argument for the absolute nature of contingency and applied by Ayache to finance capital. The flip side of this coin is what Scott Patterson (2010), in his breezy, tabloid-inflected (infected?) account of the tremendous fortunes and enormous egos of hedge fund traders, calls The Truth, the belief that the market is rational, obeys consistent laws, and follows a predictable trajectory.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In view of the pervasive search for The Truth through over a century of trading, it is worthwhile to look more closely into the assumptions behind an equilibrium model. Bill Mauer (2002), in his article on the “theological repressed,” starts his account of the history of equilibrium models with Abraham de Moivre, who in 1773 discovered that measurement errors consistently followed what we now call the bell curve, the distribution that consistently appears when random events are charted. For de Moivre, the bell curve was evidence of divine design, God’s thumbprint that reassured man there was a hidden order even in seemingly chance events. As the world became more secular, Mauer argues, the explicit acknowledgment of divine design in normal distributions dropped away, or more precisely, became deeply embedded as an unacknowledged presupposition, which he calls the “theological unconscious.” He points to the fact, for example, that when college students are asked to do a series of measurements and their results vary from the bell curve distribution, they often fudge them and thus reenact, albeit unknowingly, the theological unconscious. In the same way that Freud argued the unconscious is founded on an original trauma that is subsequently repressed, only to have it return as a symptom, so the theological unconscious, Mauer argues, is formed by repressing the theological association that de Moivre thought he discerned, only to have it return as a symptom, in this case behaviors that blur the line between reality and the model of reality, the stock market as it actually behaves and the equilibrium models that purport to describe it. This is precisely Donald MacKenzie’s point (2008) when he calls a financial model “an engine, not a camera,” arguing that models drive the market rather than merely reflect its preexisting reality. With BSM, arguably the market’s most influential model, equilibrium assumptions enter through Merton’s idea that stock prices follow  cules, resulting in the normal curve described above. This assumption is closely tied with the efficient-market hypothesis (EMH), or the idea that markets are “informationally efficient,” so that all participants have the same information about past and current developments, and that this information is already taken into account in the prices.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In other words, EMH assumes that prices accurately reflect the state of the world as it exists at any given moment. As a corollary, the model implies that in the long run, one cannot make excess profits over what the index averages achieve (a result confirmed by empirical data). BSM, in modeling what the “optimal” prices for derivatives should be, paradoxically also enables traders to identify derivatives that are mispriced, either selling above or below what the BSM model indicates, offering an opportunity for arbitrage (the simultaneous purchase and sale of an asset to benefit from a price difference). The model’s predictions here are taken as the ideal standard from which the market prices may deviate, another case of a self-referential loop that becomes insulated against its mismatch with reality by operations that tend to bring reality in line with the model. MacKenzie (2008), in his careful analysis of how well the BSM has matched historical derivative prices, divides the history into “three distinct phases” (202). The first period is from before April 1973 when the Chicago Board Options Exchange opened and the first year of its operation, when there were “substantial differences between patterns of market prices and Black-Scholes values” (202). The second period goes from 1976 to summer 1987, when the prices matched Black-Scholes well. Then the third phase goes from 1987 to 2005–06 (the time MacKenzie was writing), when the fit has been poor, “especially for index options” (that is, options tied to the major exchange indexes such as Standard and Poor).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  MacKenzie’s explanation for this is fascinating. He conjectures that once traders began using BSM, their activities brought about a better fit between actual prices and the model’s predictions in the manner noted above, because they were using the model to decide when derivatives were under- or overpriced and acting accordingly. The tsunami that occurred in the market crash of October 1987, MacKenzie suggests, was so traumatic for traders who lived through it that it left a permanent mark on their psyches, causing them to price options higher than the model indicates, as a kind of unconscious compensation for their  as a symptom not of the theological unconscious but of its opposite: the affective (and not merely conscious) response to finding out that God’s thumbprint does not after all mark every trade; sometimes wild gyrations result in crashes that seem more devilish than divine. The lingering trauma of the 1987 crash, MacKenzie suggests, results in the volatility smile, volatility smirk, or volatility skew, so-called because the volatility plotted against strike price, instead of being flat as BSM predicts, is curved upward or sideways. “The skew seems more extreme than can be accounted for simply by the extent to which empirical price distributions depart from the log- normal assumption of the Black-Scholes-Merton model,” MacKenzie writes (2008, 204); he continues, “prices may have incorporated the fear that the 1987 crash would be repeated” (205, emphasis in original). Lest this explanation seem far-fetched, we should remember the generation that lived through the Great Depression of 1929–39 and the ways in which it marked them for life. I remember my grandmother, whose husband died abruptly in spring 1929, leaving her with four young children to support (until then she had never worked outside the home). Later in life she saved scraps of string and used them to crochet shelf-edging, a decorative touch her frugality forbade her unless it could be done with material she would otherwise have thrown away.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Of course, that generation has now disappeared into dust. The 1987 crash was 28 years ago, and fresh-cheeked traders who were not born when it happened are today writing derivatives. If the fear lingers, what mechanisms are generating it, and what kind of dynamics create ruptures so fierce as to render equilibrium models worthless? feedBaCk LooPs: The aChiLLes heeL of ProBaBiLiTy To answer these questions, I will find it useful to refer to the detailed case studies MacKenzie performs to determine the causes of spectacular market crashes. One such study is the failure of Long-Term Capital Management (LTCM), a company trading in derivatives; like the crash of 1987 he similarly investigates, feedback loops played a prominent role. LTCM was started in 1994 by John E. Meriwether, and boasted of having Myron Scholes and Robert Merton on its board of directors, the creators of BSM, who would win the Nobel Prize for their work in 1997 (Fisher Black was deceased by then, ruling him out as a  around arbitrage, in the sense that they would look for anomalies or mispricings and create options to take advantage of them. An example MacKenzie cites is the price of 30-year treasury bonds versus the “odd year” twenty-nine-year bonds (2008, 216–17). The 30-year bonds typically sold for more than the 29-year ones, but as the maturity date came closer, the prices tended to converge, so LTCM would create an option that shorted the 30-year bonds and went long on the 29-year bonds.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  If held to maturity, the option would necessarily make the firm money, but the problem was losses in the meantime that could lead to calls for more collateral, a serious issue because LTCM sometimes had leverages as high as 40:1 (although the average was 27:1, not unusual for a hedge fund). When Russia announced on August 17, 1998, that it was defaulting on bonds denominated in rubles, the event initiated a “flight to quality,” with investors fleeing illiquid or risky ventures for more liquid or safer ones. According to MacKenzie, LTCM had anticipated that some event might lead to a flight to quality, and for this reason required their investors to leave their capital in the firm for three years (2008, 230). Nevertheless, the relative prices (in the example above, between 30-year bonds and 29-year bonds) began to widen, and as the spreads widened, arbitrageurs reduced their positions, in effect making the price pressures even more intense. As the losses mounted, LTCM was taking huge hits, losing as much as 44 percent of its capital in August 1998. The death blow was the monthly newsletter Meriwether sent out to his investors. Although he took the position that this was an extraordinary buying opportunity, investors when they saw the numbers withdrew their capital in droves, forcing LTCM into crisis, teetering on the brink of failure. Indeed, Meriwether was correct; if LTCM could have held out long enough, it would eventually have been able to profit handsomely from the precipitous drop in prices.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The situation recalls John Maynard Keynes’s well-known aphorism, “The market can remain irrational longer than you can remain solvent” (qtd. in Lowenstein 2001, 123). Time had run out. On September 20, officials from the New York Fed and Assistant Secretary of the Treasury Gary Gensler met with the board of LTCM, and quickly brokered a deal in which fourteen of LTCM’s largest creditors agreed to infuse $3.6 billion into the fund, in return for which they received 90 percent ownership. zie argues that there was another force at work. LTCM’s success and extraordinary profits (as high as 40 percent in some years) catalyzed a host of imitators, who tried to infer from LTCM’s moves what economic models it was following and adjusted their models accordingly, creating what MacKenzie calls a “superportfolio” (MacKenzie 2005). In effect, LTCM’s success invited imitation, and the more imitators, the less diverse the investment landscape became, and consequently more fragile and vulnerable to disruption (a well-known result in ecology). Although the specifics were different than for the 1987 crash (portfolio insurance and mechanical selling in the former case, arbitrage in the later instance), one similar aspect stands out: both crashes involved feedback loops that broke out of the parameters of equilibrium models and created self-reinforcing spirals downward.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Because LTCM had Scholes and Merton on its board, many commentators drew the conclusion that when the firm crashed and burned, it showed the BSM model simply did not work. Others attributed the firm’s demise to greed, excessive risk, and\/or over-leveraging, but MacKenzie is at pains to emphasize the safeguards that the firm put in place and the (relatively) conservative nature of its estimates and cash reserves. The lesson I draw from his analysis is this: even careful planning, stress testing, and Nobel Prize–winning minds are not sufficient to guard against the consequences of the temporal folding that derivatives enact, with consequent instabilities in value and ruptures of context. When conditions are right for feedback loops to emerge, they will erupt, frequently with devastating consequences. Moreover, history demonstrates that sooner or later, conditions will be right, as they were again in the crash of 2007–8 and the resulting Great Recession, from which we are still recovering. gLoBaLizaTion, “exorBiTanT PriviLege,” an d The 2007– 8 finanCiaL Crisis Were feedback loops also a major factor in the crisis of 2007–8? Certainly they played a part, but a full panoply of financial sins was operating as well: overleveraging, excessive risk, duplicity, exploitation, double-dealing, and old-fashioned human greed. Derivatives were involved primarily in two guises: through the use of credit default swaps, and as options written on subprime mortgages.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Credit default swaps  fering credit default swaps in the run-up to 2007–8 was AIG, American International Group. AIG offered insurance on derivatives written on bundled assets in which subprime mortgages were “tranched,” that is, sliced into pieces, divided into different risk classes, and sold as Collateralized Debt Obligations, or CDOs. The idea was that repayments from mortgages would go first to the highest tranche, and only when those obligations were satisfied would the returns flow down to the next tranche, and so forth. The highest-grade tranche was rated by rating agencies (themselves paid by the very institutions they were supposed to be evaluating) as AAA investments, even though the basis for all the tranches were risky investments with higher-than-normal rates of default. Moreover, credit default swaps, like derivatives in general, could be traded in their own right without owning the underlying asset of subprime mortgages, a fact that increased the speculative bubble as more investors poured in. When large numbers of these subprime mortgages began defaulting as economic conditions tightened, AIG was unable to meet all of its obligations and, facing a liquidity crisis and possible bankruptcy, received a bailout of $85 billion from the United States Federal Reserve Bank, on the grounds that it was “too big to fail”—the largest bailout in history at that point. Eventually this ballooned into $183.2 billion as Treasury provided additional funds, and AIG was subsequently forced to sell off numerous assets to repay its government loans. As credit tightened because of the large number of loans in default, almost every sector of the economy was affected.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The feedback loops here were global in scope, plunging the US stock market into free fall and spiraling out to stock markets in China, Europe, and elsewhere. The story, then, is not only about the US economy but the world financial system. MacKenzie reports a retrospective reflection by Myron Scholes about the failure of LTCM; “maybe the error of LongTerm was . . . that of not recognizing that the world is becoming more and more global over time” (MacKenzie 2008, 242). As our scope widens to encompass the world economy, I turn to Yanis Yaroufakis’s analysis of the “exorbitant privilege” (2013, 93) that the United States enjoys by having the dollar as the world’s reserve currency.1 When the Bretton Woods agreement was nullified by President Nixon in 1971, taking the US dollar off the gold standard and allowing currencies to float relative to one another, the United States’ hegemonic  into the United States, both in terms of Treasury bonds and corporate debt vehicles. As Yaroufakis points out, the exponential growth of derivatives from the 1970s onward in effect served as a huge increase in the amount of private money. Since derivatives are contracts written in the present against some future event, they leverage underlying assets such as stocks, related to the “real economy” through ownership in corporations, by creating financial instruments that have their own market and exchange values. The more those markets increase, the more the financial economy expands, even though the “real economy,” as Robert Brenner (2006) has forcefully argued, may have been stagnating and even declining since the 1970s.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Coupled with this inflationary money supply are the twin deficits that the United States has been running since the 1970s, the national debt and the trade deficit. Yaroufakis asks rhetorically, “And who would pay for the red ink? Simple: the rest of the world! How? By means of a permanent tsunami of capital that rushes ceaselessly across the two great oceans to finance America’s twin deficits” (2013, 22), flowing from such surplus countries as China and Germany. Writing with soul- cleansing anger and white-hot rhetoric,2 Yaroufakis traces the transition from the post–World War II Global Plan, when America used its surplus to invest in Europe and Japan, to the Global Minotaur, the image he uses to describe the flows of money from surplus countries to the United States, where consumers purchase the products produced by those same countries, which increases debt, which is further financed by capital abroad and further increases the twin deficits, in a continuous cycle. Yaroufakis argues that the crisis of 2007–8 rendered this cycle untenable. However that may be, it is selfevidently not a sustainable model, since the twin deficits cannot keep increasing forever without consequences.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  According to Yaroufakis, the demise of the Global Minotaur has left the global economy without a viable mechanism for the flow of international trade and capital, and the Great Recession cannot permanently be put behind us until this problem is solved. Dick Bryan, associate professor of political economy at the University of Sydney, and coauthor Michael Rafferty, associated with the Faculty of Commerce at the University of Wollongong, Australia, offer another explanation (2006) for the exponential growth of deriva-  provides a way to achieve commensuration over time and space, thus serving to anchor the transnational flows of money and capital after the gold standard was abandoned. The point can be illustrated with the CDOs composed of subprime mortgage slices (my example, not theirs). Any one mortgage is tied to a particular house serving as collateral and a particular debtor responsible for making the mortgage payments. If the debtor defaults, the creditor is out of luck, and so banks lending money for mortgages have traditionally been careful to make sure the debtor is creditworthy and can afford the loan. However, if that same property is tossed in with hundreds of others and sold as a CDO, the situation changes significantly. First, the firm selling the CDOs does not suffer if they become toxic, for they have made their commission in the sale. Second, the creditors buying the CDOs insure them through AIG, so if they go bad, AIG is responsible for making them whole.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When AIG itself teeters on bankruptcy, the government intervenes with a bailout that makes AIG whole, dollar for dollar. Thus the risk is transferred again and again until it ultimately winds up with the taxpayer, who foots the bill. Add in the commensuration effect, and the risk is now spread worldwide. There are two consequences to this system. The first is that derivatives, functioning as a form of private money as Yaroufakis argues, keep inflating the money supply and pumping more and more money into these cycles. The second is that the financial economy now comprises an ever-growing percentage of total economic activity, while the real economy languishes. The result is to make it more crucial than ever to analyze the effects of financial derivatives, including how HFT algorithms and technical cognition are transforming the landscape of finance capital. This leads us back to cognitive assemblages and another dimension of the complex temporalities derivatives enact, this time in the incommensurable timelines of human and technical cognizers.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  hfT aLgoriThms and The fLa sh Cra sh of may 2010 An example will illustrate how trading algorithms engage in continuous reciprocal causality through recursive feedback loops, sometimes with results that defy human reason. A third-party book on Amazon, entitled The Making of a Fly, shot up in ten days from an initial price  ported on CNN April 25, 2011; see http:\/\/www.michaeleisen.org\/blog\/?p =358 for an account). How did this absurd price emerge? One seller’s algorithm priced the book at 1.27 times the price of another seller’s algorithm, which would in turn revise its price to 0.998 times the price of the first algorithm. For example, if the book was listed at $100 by the second seller, the first seller’s algorithm would price it at $127. Reacting to this revised price, the second algorithm would price it at $126.75. The first algorithm then prices the book at $160.96, and so on, up to millions of dollars. Of course a human, with a deeper knowledge of the world and wider world horizon, would have known the figure was ridiculous.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When and why did the market revolution happen that moved the action from human traders to automated trading algorithms and HFT trading in particular?3 Wall Street Journal writer Scott Patterson traces the history of automated trading (2012). He recounts its origins in the programs Joshua Levine designed for Datek, a firm that traded on Instinet, a private exchange created for firms to buy and sell stocks directly to one another, avoiding the fees charged by the NYSE. When Datek asked for lower fees from Instinet and was turned down, the company went out on its own and Levine created Island, a new kind of electronic pool in which algorithms, retrospectively discovered and given names like Dagger, Sniper, Raider, and Stealth, fought each other, using cutting-edge artificial intelligences to sell and buy with reaction times measured in milliseconds. Levine sent out an e-mail to users of his Watcher program, writing in January 1996, “We want Island to be good and fair and cheap and fast. We care. We are nice. SelectNet is run by Nasdaq. They don’t care.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Instinet is run by Reuters. They aren’t nice . . . Won’t you join us at Island” (qtd. in Patterson 2012, 121). When Levine wrote that Instinet was not “nice,” he was referring to the ways in which HFT traders ripped off other traders and indeed their own clients, helped by exchanges such as Instinet that cloaked their bids from public view. A trader could, for example, offer to buy a large block of stock for a client, which would drive the price higher, while offering to sell the same stock over Instinet at the new higher price. The client would not know about this side deal, because he could not see the Instinet side of the offer. In other practices, traders would front run a stock.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For example, if a trader submitted an order to  would detect the bid, purchase the stock and relist at a higher price, a practice called “sniffing,” about which we will hear more shortly. The complexities of trying to regulate a large-scale technical system driven by the capitalist imperative to maximize profits is difficult even in the best of times. A case in point is the SEC’s attempt to make the market fairer by introducing Order-Handling Rules that created new entities called Electronic Communication Networks, or ECNs, and imposing certain restrictions that forced markets such as Instinet to list their quotes on Nasdaq. Patterson summarizes the effects of ECNs: “With the Order-Handling Rules, the entire Nasdaq marketplace would shift toward an electronic platform wide open to computer-driven trading . . . the phone-based system of human dealers would quickly become a screen-based cyberpunk network of computer jockeys born and bred in electronic pools such as Island” (2012, 128). With the floodgates open to computerized trading, speed became the name of the game. Stock trading companies are willing to pay high fees to have their computers located on rack space within the server farms run by the major exchanges (a practice called colocation), because the proximity shaves milliseconds off the time it takes to transfer information from the exchange to the trader, time that can be turned into money by taking advantage of the small price differences that occurred in that time interval. Currently an ultrafast transatlantic cable is being constructed, at the cost of several billion dollars, to connect high-frequency traders in the United States with those in Britain.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The estimated time acceleration is five milliseconds, which works out to about a billion dollars per millisecond advantage (Johnson et al. 2012, 4). As a result of HFT, the average time a stock is held has plummeted across all the exchanges. After World War II, it clocked in at four years; by the turn of the millennium, it had dropped to eight months; by 2011, it had, according to some estimates, dived to an astonishing twentytwo seconds (Patterson 2012, 46). The amount of information being exchanged on stock trades correspondingly grew to gargantuan figures. Nanex, a firm that tracks speed trading, estimates that on all US stocks, options, futures, and indexes on a single day, one trillion bytes of data are exchanged (Patterson 2012, 63). As speed trading increased, the duopoly of NYSE and Nasdaq shattered into a number of private markets such as Instinet as well as “dark  tempting to cope with this fragmentation, the SEC introduced in 2007 a new set of regulations called the National Market System, or Reg NMS. The idea was to bind together all the electronic marketplaces into a single network so they would operate as a true national market.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  At the heart of the Reg NMS was the mandate that any order to buy or sell a stock must be routed to the market that had the best price. If there was a disparity, for example, between the price a stock sold on Nasdaq and a higher price listed on the NYSE, the order would automatically be routed to the Nasdaq. To facilitate this mandate, an electronic ticker tape was instituted called the Security Information Processor, or SIP feed. One consequence of Reg NMS was that now the trading houses had to monitor the prices in all venues, all the time, which virtually forced them to use cutting-edge algorithms. Moreover, there were also unintended consequences. Orders are executed according to their place in the “queue,” the electronic monitoring system that assigns them a priority according to the time they were placed. But, as Patterson explains, “an order in one exchange queue could be suddenly rejected, routed to another exchange, or kicked to the back of the queue if an order that beat its price” appeared (2012, 49). This provided a host of new ways to game the system.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  High-frequency traders had by this time become the largest customers of the exchanges; by 2009, it is estimated that they accounted for 75 percent of all trades. In addition, the NYSE had transformed from a nonprofit entity to a for-profit corporation when in April 2005 it merged with a private exchange, Archipelago (modeled on Levine’s Island), and then a couple of years later with Euronext, the European combined stock market. For its part, Nasdaq had changed in 2006 from a quotation service to a licensed national exchange, and by 2011, more than two-thirds of its revenue came from HFT (Lewis 2014, 163). Operating as for-profit corporations with their own stockholders to please, the exchanges instituted new order types that went far beyond the old-fashioned limit orders (orders to buy or sell within specified price limits) that were the bread and butter of exchanges in previous decades. Moreover, competition had become so fierce that high-frequency traders were making less on each deal, and as a consequence they became more dependent on “maker and taker” fees, a structure the exchanges had put into place to maximize liquidity. rebate, while a trader who takes it has to pay a small fee (called the “maker\/taker” policy). Patterson summarizes the effects when the new order types were combined with the rebate\/fee structure. The new type of orders “allowed high-frequency traders to post orders that remained hidden at a specific price point at the front of the queue when the market was moving, while at the same time pushing other traders back.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Even as the market ticked up and down, the order wouldn’t move . . . By standing at the front of the queue and hidden as the market shifted, the firm could place orders that, time and again, were paid the [rebate or ‘make’] fee. Other traders had no way of knowing that the orders were there. Over and over again, their orders stepped on the hidden trades, which acted effectively as an invisible trap that made other firms pay the ‘take’ fee” (Patterson 2012, 50). This situation makes clear the emergence of a new type of hypercapitalism that I call vampiric capitalism. As Mark Neocleous observes (2003), Marx in Capital uses the vampire as a metaphor for capital sucking the lifeblood from the working class; by contrast, vampiric capitalism preys on other capitalistic enterprises. These practices illustrate how far the stock market had drifted from its initial purposes. As Sal Arnuk and Joseph Saluzzi (2012) explain, the stock market was originally set up to enable new companies to attract capital by issuing IPOs, thus spurring innovation and creating diversity in the marketplace.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It also provided a way for ordinary people with disposable income to invest in the stock market through mutual funds, options, and other investment instruments. High-frequency traders perform none of these useful services. They justify their existence by claiming they provide liquidity for the marketplace (Perez 2011, 163), and because they trade so often, they have also driven down the spread between buy and sell orders, which they argue benefits everyone. But as we shall see, there is another side to this story. Although their commissions are smaller, because they trade so often, the pennies quickly mount into dollars and, eventually, into billions a year—money that ultimately comes out of the pockets of investors. The deleterious effects on innovation may be seen in the alarming decrease in publicly traded companies: in 1997, there were 8,200 public companies; by 2010, only 4,000 remained (Patterson 2012, 59). The most disastrous effects, however, are the instabilities that HFT introduces. Nanex, a company that analyzes the algorithms high-  The Disruptor is designed to flood the market with so many orders that, effectively, it disrupts the market itself (Patterson 2012, 63).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  These instabilities became shockingly evident on May 6, 2010, when in the space of two minutes the Dow fell 700 points, and then just as quickly rebounded. How did this happen? In an already down market nervous about possible defaults by Greece and Spain, Waddell & Reed Financial from Kansas City was monitoring a massive order to sell seventy-five thousand S&P 500 E-mini futures contracts, worth about $4 billion dollars. The algorithm they were using was designed to sell at a pace that would keep it at about 9 percent of the market’s overall volume, with thirty-second pauses to throw off the shark algorithms hunting for “whales” (large orders) so they could front run them. These sell orders were bought by high-frequency funds that, within milliseconds, sold them again to other high-frequency traders, sometimes at a slightly lower price; these algorithms in turn sold them again. As the volume shot up and the market plunged down, the trading algorithm from Waddell & Reed increased its selling because its 9 percent limit kept increasing, which prompted an even fiercer feedback cycle. Patterson reports that “within a fourteen second period high-frequency traders bought and sold an astonishing twenty-seven thousand E-mini contracts” (Patterson 2012, 264). As the market plunged, other stocks were affected as well.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Accenture, a global consulting company that normally sold for about $50 a share, dropped to an absurd price of a penny a share, a so-called “stub quote” that trading firms place simply to fulfill their obligations as market makers but that they never expected to have filled. Procter & Gamble plunged from its normal price of $60 a share to around $30. On the other end of the scale, some stocks, notably Apple, demonstrated an amazing upward spike, reaching $99,999 per share (no doubt another stub quote). As the insanity proceeded, many high-frequency traders, alarmed by the volatility and concerned that transactions would be retroactively cancelled by the SEC, simply pulled the plugs on their computers. This meant that even fewer buyers were in the market, accelerating the market’s downward plunge. Only when NYSE shut down trading for five seconds was the feedback cycle broken, and at that point, because prices on many stocks were ridiculously low, the algorithms started buying and, within a couple of minutes, the market was back to where it was before. But not before inflicting real harm on  before its price bottomed out lost $17,000, and a hedge fund in Dallas lost several million dollars when the price of options it was buying spiked from 90 cents to $30 per contract. Subsequently, the SEC revoked or “broke” trades that exceeded a 60 percent variation from their prices before the flash crash.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Then the SEC, in coordination with the Commodity Futures Trading Commission (CFTC), set about to investigate the flash crash, issuing a report in September 2010 (while the flash crash took only five minutes to plunge and recover, they took a full four months to figure out what happened). The report focused on liquidity, concluding that Waddell & Reed’s sell order was the culprit, initiating a chain of events that “sucked liquidity out of the market and allowed prices to go into freefall” (Buchanan 2011). Mark Buchanan, a theoretical physicist who blogs on financial matters, references the research done by Eric Scott Hunsader, founder of Nanex and a software engineer. Hunsader followed 6,483 trades that Waddell & Reed made that fateful day; Buchanan notes that “the company’s execution broker fed the market throughout the day—a tactic specifically designed to minimize the price impact of a large sale” (Buchanan 2011, 2). Instead of locating the problem in this sale, Hunsader’s analysis “suggests this plunge was caused by high-frequency traders. They typically act as liquidity providers, standing ready to buy and sell at certain price levels. But the day’s volatility prompted them to dump their holdings to avoid losses . . .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It was this selling, not Waddell & Reed’s passive orders, that caused the liquidity to disappear” (Buchanan 2011, 2). The comments to Buchanan’s article are revealing. “Guest” called the SEC report a “fairy tale,” and “Fritz Juhnke” commented that “it is about time someone pointed out that ‘making trades’ is not the equivalent to providing liquidity. The exchanges have hoodwinked the regulators into believing that it is acceptable to pay brokers for making trades. The farce is that the exchanges call it ‘providing liquidity.’ Regulators need to wake up to the fact that sales which trigger due to a price decrease are removing liquidity (i.e., exaggerating price moves) rather than providing it” (Buchanan 2011, 3). “SofaCall” commented, “This is why I have been out of the market for the past six years. It’s no longer possible to handicap value. All you can do is try to catch the trend—which is not much different from casino gambling.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Only the gaming commissions do a better job of assuring that casinos are hon-  Calling the SEC report “a trend in finance industry public relations strategy,” “Matthew” noted that most people “won’t understand they are being ripped off if the con is cloaked in a modest level of complexity” (Buchanan 2011, 5). “H_H_Holmes” succinctly summed up the consensus: “The façade that the industry has anything to do with ‘people’ investing in ‘businesses’ is gone. All algorithms, all the time. Joe Six-Pak, meet Skynet” (Buchanan 2011, 4). The significance of the flash crash was underscored by Nanex’s research into other miniflash crashes that occurred from 2006–10 but went largely unnoticed because they involved single stocks and unfolded too quickly to attract attention. Flash crashes tend to disappear in statistics using day-by-day figures; a finer-grained temporal metric, such as the one used by Nanex, is necessary to spot them. Nanex’s analysis found 254 minicrashes in 2006, before Reg NMS was initiated, and in 2007, when Reg NMS was being rolled out over the course of a few months, 2,576. In 2008, when Reg NMS was fully in effect, that number increased to 4,065.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Clearly, the unintended effect of Reg NMS was dramatically to increase the likelihood of flash crashes (www .nanex.net\/FlashCrashEquities\/FlashCrashAnalysis_Equities.htmlco). Neil Johnson, a physicist at the University of Miami, published with his colleagues “Financial Black Swans Driven by Ultrafast Machine Ecology” (Johnson et al. 2012), which confirmed Nanex’s research. Their abstract notes, “We provide empirical evidence for, and an accompanying theory of, an abrupt system-wide transition from a mixed human-machine phase to a new all-machine phase characterized by frequent black swan events with ultrafast durations.” Analyzing 18,530 black swan events between 2006–11, they construct a model that indicates black swan events are more likely as the time duration of trades decreases and as the diversity of strategies diminishes. They assume that the algorithms, having to act so fast, must have only a few strategies from which to choose, and moreover that many algorithms will have very similar strategies, exacerbating the possibilities for feedback loops. The upshot is that black swan events are not anomalous; rather, they reflect the dynamics of a machine-driven trading in which humans play no part in the actual transactions. Reflecting back on the SEC report about the May 6, 2010, flash crash, we can now see that its conclusion that the Waddell & Reed transaction was the culprit is incorrect. It may have been the initiating event (i.e., the last straw), but  ComPLex eCoLogies o f hum an- aLgoriThm inTeraCTions In a study based on sixty-seven interviews with traders in a firm that engaged in high-frequency trading (HFT), Ann- Christina Lange (2015) creates a vivid picture of how humans interact with the algorithms operating on their behalf.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She observes, “I was quite surprised to learn that [the traders] talked about their algorithms not as purely rational actors making markets more efficient but rather as interacting agents operating in the market” (1). She records one trader pointing to the screen and saying “‘I can see how this guy is moving. I learn from him . . . There is no way I can really know who is behind the algorithms, but I recognize this pattern’” (1). Another trader observes, ‘“You read other algorithms. They are all based on rules. You come out with a generalized robust set of rules to deal with others”’ (5).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  An analogy is a video game player who infers the rules governing the algorithm generating the screen display by observing the game’s behavior when he tries various tactics; with practice, he is able to predict how the game will react in specific circumstances and refines his tactics accordingly, a phenomenon that James Ash calls an “envelope”: “Envelopes emerge from the relationship between the user’s body and . . . an ‘interface environment’” (2016, 9). As Johnson noted above, HFT algorithms typically sacrifice multiplicity of inputs for speed; they usually have only a few strategies and thus are able to be “read” by traders watching their moves. Moreover, as Lange points out, the algorithms are constantly interacting with other algorithms, generating a complex ecology that, Lange suggests, can be understood as swarm behavior. In human terms, their interactions resemble the kinds of moves and countermoves typical of propaganda (psyops) warfare: feints, dodges, misinformation, and camouflage. MacKenzie (2011), for example, notes that order execution algorithms typically do not place large orders all at once but slice the orders into smaller pieces and feed them into the market gradually, just as the Waddell & Reed algorithm did when trying to execute a large sell order. One kind of algorithm does this through volume-weighted average price, or VWAP (veewap), parceling out the order in proportion to volumes of shares traded in equivalent time slots on previous days. Other algorithms hunt for these VWAP  running their orders to take advantage of this knowledge.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In other practices of questionable legality, “spoofing” algorithms place orders to entice other algorithms to respond, and when they do, instantly cancel the orders and use the knowledge to make profits. One trader that Lange interviewed explains, “We want to have as many quotes as possible but also to make sure we don’t need to get fills . . . we hope not to have to execute them as they usually don’t end up making us money or even lose us money. But the information they provide is very important, where we can know very quickly if something is going to happen. And we don’t have to wait for the data feeds update to come in, which is too slow” (Lange 2015). Another of her interlocutors sums up the situation: “it’s algorithms fighting other algorithms. You can game the kill switches. Push this algorithm into this position and you know it will pull back and you can profit from that” (Lange 2015).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As Arnuk and Saluzzi have pointed out, the profits generated by HFT are purely speculative and contribute nothing to the real economy other than making money for the trading firms that employ them. As the percentage of trades executed by HFT algorithms continues to increase, the result is that the market ecology moves more and more into speculation and less into synergistic interactions with the real economy. Not everyone agrees with Johnson’s and Nanex’s claim that HFT is rendering the market more fragile and unstable. MacKenzie (2011), for example, asserts that the data is not clear one way or the other, although he sounds a note of caution about the instability of complex technological systems such as finance trading has become. Nanex’s discovery that Ultrafast Extreme Events (UEEs) are not anomalies but frequent occurrences can be read in two ways: either they do not much matter because they are so small and disappear so fast, or they are like tiny fractures in a space capsule, harbingers of a major catastrophe. In my view, MacKenzie is too cautious in his assessment; the small cracks to my mind are signals that the cognitive assemblages formed by HFT and human actors are systemically risky and are weighted too much toward technical rather than human cognition. Whatever one makes of UEEs, some effects are indisputable. One, indicated above, is the huge growth of speculative activity through HFT over investing in the real economy.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Another is the shredding of the efficient market hypothesis, which readers will recall is the idea  tion at the same time, along with the corollary that prices reflect the real state of the world at any moment. In HFT, the algorithms are designed precisely to disrupt equal access to market information and to create informational inequalities by ferreting out information from rival algorithms while concealing their own actions. A third effect, and perhaps the most important, is the complete transformation of the temporal regimes within which trading occurs, and a consequent “arms speed race” toward faster and faster algorithms, faster and faster connection cables, and faster and faster exchange infrastructures. MacKenzie (2011) writes that Turquoise, the trading platform of the London Stock Exchange, can now execute trades in 129 microseconds (that is, a little more than a tenth of a millisecond). The transformation from the world of the pits, where traders stood next to one another in all their sweating, noisy, pushy macrophysicality, has given way to the world of screens and algorithms, endlessly searching for the small perturbations and algorithmic interactions that can make money in the world of derivatives and HFT. Andy Clark (1989, 62), in discussing why consciousness emerged through evolutionary processes, has called it a weapon in the cognitive arms race (61). HFT may similarly be regarded as an evolutionary milieu in which speed, rather than consciousness, has become a weapon in the nonconscious cognitive arms race—a weapon that threatens to proceed along an autonomous trajectory in a temporal regime inaccessible to direct conscious intervention. Any solution, then, must address the cognitive dynamics of the entire cognitive assemblage.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  sysTe m iC reengineering: invesTors exChange (iex) and BaTCh auCTions In Flash Boys: A Wall Street Revolt (2014), Michael Lewis documents the experiences of Brad Katsuyama, initially a trader for Royal Bank of Canada (RBC) Capital Markets. He notes Katsuyama’s mystification when he put in a bid (for example, to buy a stock) and watched the price move away from him as soon as the price was entered. With hindsight, we can surmise what was happening; an algorithm had detected his bid and moved the price higher a fraction of a second later. Katsuyama then embarked on a journey to discover what was happening, querying colleagues throughout the industry to find out how the algorithms  other traders actually knew; here the story does not quite ring true, for it is more likely that at least some of them knew but were unwilling to divulge the information. In any event, when Katsuyama finally discovered what was happening, he felt strongly that it was a perversion of the legitimate purposes that the stock market is supposed to serve (a conclusion Arnuk and Saluzzi [2012] also endorse, as we have seen, and Lewis cites them for their contestations of HFT practices). Unlike almost everyone else who was going along with the game, Katsuyama began a quest to rectify the situation. He determined to attack the root of the problem: the systemic dynamics that had resulted in a cognitive arms race. Older ideas about how the market operates, including the efficient market hypothesis and regulatory interventions, were rapidly becoming obsolete.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Lewis quotes Katsuyama’s reaction when he analyzed the SEC report about the flash crash of May 2010: what leaped out to him was its “oldfashioned sense of time.” Katsuyama concluded, “‘Once you get a sense of the speed . . . you realize that explanations like this . . . are not right’” (Lewis 2014, 81). Realizing that HFT had effectively rigged the markets so they no longer functioned as unbiased intermediaries, he and his colleagues determined to create a new exchange, which they called simply Investors Exchange (IEX), designed to reinstate the legitimate purposes of stock and derivative trading. The idea was not to speed trades up but on the contrary to slow them down, so that everyone’s bid arrived simultaneously, no matter how fast their algorithms were. In addition to this general idea, Katsuyama and his colleagues spent long hours anticipating how the system might be gamed, making it as resistant as possible to predatory strategies. IEX’s battle for credibility and official sanction as an exchange has been a long and arduous uphill fight. Lewis documents that even when IEX was functioning—a small miracle in itself—and investors were instructing their brokers that they wanted their trades routed through it, some brokers were deliberately sidestepping these instructions and sending them to other exchanges instead.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  After several delays, IEX has won the fight to become an official exchange and not just a trading site. In the meantime, the IEX website emphasizes what may be de-  marketplace via simplified market structure design and cutting-edge technology,” the website reads: http:\/\/www.iextrading.com\/about\/. A short video at the site begins with the question, “What is the purpose of the stock market?” and then proceeds to give a lesson on HFT and predatory trading. It ends with aligning IEX’s principles with the Securities Exchange Act of 1934: “uphold just and equitable principles of trade,” “remove impediments to a fair and open market,” “protect the investors and public interest,” and “facilitate an opportunity for investor orders to meet directly.” This approach merits serious attention, for it suggests that ethical responsibility is not only possible within a capitalistic system, but that large investors such as institutions handling retirement and pension funds would prefer a fair and equitable exchange in which predatory algorithms are not given free rein, for the simple reason that the profits created by HFT in the end come out of their pockets. A different solution is proposed by Budish, Cramton, and Shim in their article on frequent batch auctions (2015). They document some of the costs of the speed arms race, including Spread Networks’s cable from New York to Chicago that cost $300 million and shaved off three milliseconds from the communication time. They also test the claim of high-frequency traders that HFT increases liquidity and measure it against the cost of “sniping,” that is, “stale” bids that lag behind market data and are picked off by high- frequency traders before the offering firm has a chance to withdraw them. These costs are figured into the bid-ask spread and therefore increase the cost of trading for everyone.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Moreover, in the present system of continuous limit order book (CLOB) trading, in which trades are executed throughout the day, there is a high probability that bids will be sniped because orders are executed serially. Whereas only one firm is trying to retract its stale bid, many high-frequency traders are trying to benefit from it, and the probability is that one of them will succeed in having its order filled before the firm’s order can be executed in the queue. There are other problems with CLOB, as the authors note. They investigated two securities that normally closely track each other, the SPDR S&P 500 exchange-traded fund (SPY) and the S&P 500 E-mini futures contract (ES). Because both are based on the S&P index, one would expect that they would move in tandem with a high correlation, and this is what the data show when the metric is a day, an hour,  250 milliseconds, large gaps appear between the movements of the two securities, and the correlation breaks down almost completely. “This correlation breakdown in turn leads to obvious mechanical arbitrage opportunities,” they write, “available to whomever is fastest” (2015, 2). Moreover, the breakdown does not lead to an increase in market efficiency, only to an increased arms race in which the window of profitability drops dramatically, “from a median of 97 ms in 2005 to a median of 7 ms in 2012” (2015, 2). The amount of money siphoned off by the arms race is significant.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  With this pair of securities alone, the authors estimate that annual cost is $75 million. Although they decline to speculate on what the cost would be for all traded securities, saying only that “the sums are substantial,” it does not take a rocket scientist to see that the cost would soar to many billions and perhaps even trillions—money that does nothing for the real economy and only serves to enrich HFT firms committed to the arms race. When the authors modified their initial model, which assumed that all traders had simultaneous access to the same information about prices, to take into account differentials between firms that invested heavily in the arms race and consequently had faster algorithms that those that did not, what emerged was a classic prisoner’s dilemma. “All firms would be better off if they could collectively commit not to invest in speed, but it is in each firm’s private interest to invest” (2015, 5). The solution to these interrelated problems, the authors suggest, is to move from CLOB, which treats time as a continuum, to a system of batch auctions executed frequently, say every tenth of a second (100ms). In the batch auction, all bids present at that time would compete against one another, in effect moving the competition from time to price. Moreover, the lack of correlation between securities that in longer temporal metrics move together would be mitigated, again moving the competition from time to price. Because the length of time algorithms had to act would be increased, there would be less incentive to make algorithms simple so they could be fast, encouraging the development of “smarter” algorithms with more diverse trading strategies, thus increasing the depth and diversity of strategies in the algorithmic ecology, with a consequent increase in robustness and a decrease in fragility.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Finally, the competition based on price would move the market toward efficiency rather than toward the increasing  ing faster connections through expensive infrastructure, and the resources devoted to building ever- faster algorithms. These two different solutions—IEX making trading slower, and the batch auction idea—share in common the belief that the answer does not lie in regulation but rather than in systemic (re)engineering. They assume that the profit motive will remain intact, but by changing the ways in which profits can be realized, they move the entire system toward efficiency, fairness, and the productive use of capital maximized for larger social goals and not merely for personal gain by individual trading firms investing in the arms race. Note, however, that in the process, fundamental ideas about how the world is structured become transformed: for the batch auction proposal, time is changed from a continuum to a set of discrete intervals, and for IEX, time is slowed down so that trading occurs closer to the range of human perception and away from computational speed. These are not inconsequential differences. Transformative within the realm of finance capital, they can also potentially spread beyond financial exchanges into other areas of social and cultural life. They illustrate how the interpenetrations of complex human systems with cognitive technical systems form larger techno-epistemo-ontological structures that determine our sense of how the world works. They also show that human agency, deployed with a strong sense of ethical values such as fairness and social good, can create new systemic structures more conducive to human flourishing than can the profit motive unrestrained by other considerations.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  fina nCe CaPiTaL and The h umaniTies For better and worse, finance capital is so deeply enmeshed with the self-organizing ecology of ultrafast machine algorithms that it has become impossible to think of our global economy without them. As we have seen, the machine ecology is extraordinarily sensitive to small changes in its environment (i.e., the regulatory framework within which it operates). Every new regulation introduces new ways to game the system, a fact confirmed by historical research (Lewis 2014, 101). Consequently, Katsuyama and his collaborators concluded, “There was zero chance that the problem would be solved by financial regulation” (Lewis 2014, 101). Their solution of attacking the problem through sys-  auction proposal, offers important clues to the role that the humanities can play in intervening in the world of HFT and finance capital more generally. Catalyzed by an idealistic desire to make the markets fairer, Katsuyama and his colleagues put everything on the line to make their vision a reality. Their commitment illustrates that in a large sense, the situation is not strictly a technological problem but one of value and meaning (recall Heidegger’s famous argument that the essence of technology is nothing technological). One of the few humanists to tackle the issue is Bernard Stiegler.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Through a series of important texts—Technics and Time, 1 and Time and Technics, 2 (1998, 2008), Taking Care of Youth and the Generations (2010), and especially For a New Critique of Political Economy (2010)—he undertakes the ambitious project of proposing a general framework through which to understand the coevolution of humans and technics. Because of its scope, the project has both impressive virtues and limitations that may not be immediately apparent. The test case proposed here, HFT algorithms, can help to refine Stiegler’s framework and also reveal new insights as to where the coevolution between humans and technics is heading in the contemporary period, especially in the evolution of cognitive assemblages, the complex temporalities they instantiate, and the resulting incommensurable timelines of human and technical cognition. In Technics 1 and 2, Stiegler develops the concept of tertiary retention—memories stored in artifacts that allow access to events a person never experienced first-hand. Moreover, he argues that tertiary retention precedes individual cognition. In Taking Care, this formulation is linked with the development of “long circuits” that allow transindividuation to occur, resulting in an individual becoming intellectually mature and taking responsibility. Subverting the development of “long circuits” are what Stiegler calls the programming industries such as television, video games, and the Web, which seek to capture the attention of young people and convert the tradition of what I have called deep attention into hyper attention (Hayles 2012). The case of HFT programs allows us to see in Stiegler’s concept of tertiary retention an unrecognized print- centric bias.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  While tertiary retention works well for books as external storage devices, it covers over the rupture that occurred when technics ceased to be only about storage and instead became about machine agency and systemic ma-  reads it and the act of reading causes the human’s cognitive system to work in a different way—a dynamic central to the humanities, with their deep tradition of ideas conveyed through writing or what Stiegler calls a “grammatological” process. Note, however, that this agency is converted from a passive possibility into an actuality only because a human is involved in writing and reading. In contrast, the point of HFT programs is precisely that, once created and set in motion, they do not require any human agency to act. Indeed, humans are deliberately cut out of the circuit to allow the machines access to the microtemporalities essential for HFT. Stiegler is correct in noting that the creation of a “grammatological” process such as alphabetization breaks a continuous flow of words into discrete units such as letters, phonemes, etc. However, using this same term for digitization glosses over the difference between alphabetization and executable program code: while letters are passive, code executed by a machine can actually make things happen without human intervention. “Long circuits,” as Stiegler uses them, apply to human cognition. But machines have “long circuits” too, and the effects here are quite different from those Stiegler attributes to humans.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When automated trading programs execute trades, they often do so in circuitous routes in order to optimize certain parameters, for example keeping the fees that brokers pay as low as possible. Their effects, in other words, protect and advance vampiric capitalism, as pointed out by Arnuk and Saluzzi as they diagram the convoluted “wandering path from ordergeneration to execution” (2012, 146). The “long circuits” in intelligent machines also relate to anticipation. This too becomes a machine function as the algorithms search for patterns that will enable them to predict the next micromovement of stock prices, as well as orders that competing algorithms may be about to execute. In a sense, these algorithms have both too much memory—hypermnesia—as they race through real-time data streams analyzing what all the other algorithms are doing, and too little memory—hypomnesia—as they jettison the information about what happened yesterday (never mind years or centuries ago) to cope with the huge amounts of information streaming into their processing units. Unlike humans, who must sleep to process their memories, these machines have no unused computer cycles. Even when the markets are closed, they are still gathering data, analyzing it, and placing  Clearly, then, focusing on memory functions alone is insufficient to understand the complex dynamics of the machine ecologies of automated trading. Also crucial is the agency that the machines possess and their abilities to analyze and predict at lightning speeds, and also to evolve and learn as they compete with other algorithms.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Automated trading systems embody evolutionary dynamics that can lead to unpredictable consequences and emergent behaviors. Humans may set up these systems, but they are not in complete control of how they operate, evolve, and mutate. The issue is not memory alone, but a transformation of global economic systems that increasingly drive us toward vampiric capitalism and away from social responsibility. Another aspect of HFT that has engaged humanists is the transformation of the temporal regimes into microtemporalities inaccessible to humans. A theorist at the forefront of this discussion is Mark B. N. Hansen in Feed-Forward: On the Future of Twenty-First Century Media (2015). Working through the processual philosophy of Whitehead, Hansen focuses on what he calls “atmospheric media” designed to fly under the radar of consciousness and influence actions, behaviors, affects, and attitudes before consciousness, with its relatively slow uptake and limited information processing ability, has an opportunity to evaluate the media input. I am not sure if HFT qualify as “atmospheric media” in Hansen’s sense, because they are aimed not at affective states but at executing trades within machine-machine ecologies. Nevertheless, HFT certainly use similar microtemporal strategies; they also suggest how the kind of analysis that Hansen enacts might be expanded beyond the affective realm that concerns him.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This point may be developed by comparing Hansen’s approach with that of Luciana Parisi and Steve Goodman (2011) in their essay on mnemonic control. Also working from Whitehead, although with a different interpretation, Parisi and Goodman write about the potential of digital media to address the affective body through what Whitehead called prehensions; their essay focuses particularly on branding. When the phenomenon of a prehension goes through further neuronal processes and arrives in consciousness, it will already seem familiar even though it has not been consciously experienced before, leading them to speak of the “past not lived, a future not sensed” (2011, 164) that nevertheless makes one susceptible to branding influences. We can see that their idea of mnemonic control works on a timeline that op-  erates before Stiegler’s primary retention (conscious experience), and much earlier than his secondary or tertiary retention. It does not depend upon inscription and recovery at a later time through “grammatological” decoding; rather, control comes in the form of sensations that precede consciousness and directly address the body’s affective responses, leading to the cultural and media phenomena now called affective capitalism. Mnemonic control thus exploits the half-second of neuronal processing that occurs before consciousness comes online to create susceptibilities and vulnerabilities used to sell products. Hansen, by contrast, wants to place the intervention that twentyfirst century media make into what he, following Whitehead, calls the “vibratory continuum” or the “worldly sensibility”; importantly, these influences occur prior to sensation and perception. Twenty-first century media, as Hansen uses it, does not mean merely media operating in the twenty-first century but rather is an analytical category for a specific kind of media synonymous with “atmospheric” or environmental effects.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  These media operate so quickly and pervasively that they intervene in the ground from which prehensions arise. They thus precede the cognitive timeline while also decisively influencing the kinds of sensations and perceptions that are possible and relevant within a given milieu. In terms of this project, Hansen’s work is a crucial intervention for at least three reasons. First, it foregrounds the issue of temporality in relation to technical and human cognition, recognizing the incommensurability of their cognitive timelines. Second, it proposes that the effective point of intervention must occur on timelines appropriate to technical cognition, placing it prior to the 100-millisecond range where perception and sensation register for humans. Third, it recognizes that such interventions will be effective only if they are systemic, which he aims to do by both invoking and modifying Whitehead’s radically processual view of reality. A limitation of his analysis from this point of view is that he gives almost no examples of media that operate in this way. The media he mentions—the sociometer, sound art, etc.—work through sensation and perception, not prior to them.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For an explication of interventions occurring prior to sensation, we may turn to Nigel Thrift’s “technological unconscious,” discussed in chapter 5 in relation to urban infrastructure (Thrift 2004, 2007, 91). As noted previously, Thrift sees  technical infrastructures as generating a host of presuppositions about the way the world is and how it works, for example, the weightbearing capacities and kinesthetic qualities of concrete, asphalt, and steel compared to dirt, grass, and swampland. “All human activity,” Thrift writes, “depends upon an imputed background whose content is rarely questioned: it is there because it is there. It is the surface on which life floats” (2007, 91). Someone raised in a city would have one set of presuppositions, for example, while another person raised in a tribal area of Africa would have quite another. Multiply these presuppositions by a hundred- or thousandfold operating in every area of life, and you arrive at something like the technological unconscious. Its content “is the bending of bodies-with-environments to a specific set of addresses without the benefit of any cognitive inputs” (Thrift 2004, 177). The technological unconscious is “a prepersonal substrate of guaranteed correlations, assured encounters, and therefore unconsidered anticipations” (177).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  These presuppositions form, as it were, an interface of high dimensionality mediating between the world and the body, the technical milieu and the humans who learn to navigate and manipulate it. While Hansen’s analysis cogently captures the essential ways in which temporality enters this picture, it is not clear in his analysis why media should have pride of place in the technological unconscious compared to skyscrapers, light rail transit, and a host of other technological infrastructures. However, if we note that nearly all these infrastructural architectures have computational components (as argued in chapters 1 and 5), then the focus returns not to media in general, but to computational media specifically. As David Berry (2011) puts it, “the ontology of the computational is increasingly hegemonic in forming the background presupposition for our understanding the world” (Kindle locations 2531–32). As we have seen, the qualities that make computational media exceptional are their cognitive capacities and their abilities to interact with humans as actors within cognitive assemblages. They thus address human cognitive capabilities across the full range of precognitive and cognitive timelines: as presuppositions preceding sensation, as stimuli producing sensations and perceptions, as input through somatic markers into the cognitive nonconscious, and as experiences within the modes of awareness, consciousness, and the unconscious. Returning now to HFT, we can see how these ideas serve as resources to grasp more fully the implications of the transition to a machine-machine ecology of automated trading. It is not entirely accurate to say that human intentionality and agency have been sidelined in HFT, but certainly they now operate much more visibly and selfevidently though an elaborate chain of technical mediations than ever before was the case.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Personification, always lurking when technical systems exhibit agential powers, becomes almost inevitable, as indicated in the quotations above where traders give personal pronouns and genders to the algorithms they design and observe. In terms of the technological unconscious, perhaps the major predisposition to emerge from these complex human-nonhuman technical systems is the awareness that cognitions happen throughout the system in ways that enmesh them together. Human complex systems and cognitive technical systems now interpenetrate one another in cognitive assemblages, unleashing a host of implications and consequences that we are still struggling to grasp and understand. Nevertheless, the examples of IEX and batch auctions show that human intervention is certainly possible when aimed at systemic dynamics, and that such interventions can and do change the cognitive ecologies to make them more sustainable, more affirmative of human flourishing, and more equitable in their operations. mean ing , inTerPreTaTion, and vaLues Let us return now to the urgent question of how the humanities might intervene in the increasingly precarious position into which HFT seems to be leading us. Here Stiegler makes a crucial contribution, for he insists that the fundamental questions concerning technics have to do with meaning, interpretation, and values. Hansen’s intervention is also a major contribution, for his intention in Feed-Forward, as in most of his work, is to provide theoretical frameworks that enable and catalyze constructive political action. As we have seen, humanists are unlikely to contribute to debates about regulatory reform of the stock markets, a task that requires intimate knowledge about the systemic dynamics to ensure that the reforms will not have deleterious unintended consequences, which in any event may be unavoidable.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Humanists can contribute, however, to discussions about the larger social  purposes that finance capital is intended to serve. As recent events have vividly demonstrated, the profit motive stripped of all other considerations leads to a disastrous spike upward in systemic risk and, consequently, in global economic instability. Humanists can help to put finance capital in historical perspective and connect it with values such as social responsibility, fairness, and economic justice. Questions of meaning that occupy the humanities, then, are if anything even more important with the rise of the cognitive nonconscious and the growing importance of cognitive assemblages in finance capital. Because this framework enlarges the realms in which meaning and interpretations can be seen to operate (as detailed in chapter 1), it implicitly creates a bridge between the traditional humanities and the kinds of nonconscious cognitions performed in HFT, as well as between the technical cognitions of the algorithms and those of humans who design and implement them. What other kinds of initiatives will further this goal? There is already a growing body of research that undertakes this task, including historical research on finance capital (Poovey 2008; Baucom 2005; Lynch 1998), ethnographies of Wall Street (Ho 2009; MacKenzie 2008; Lange 2015), STS-inflected studies of finance (Callon 1998; MacKenzie 2008), and analyses of automated cognition (Parisi and Goodman 2011; Thrift 2007). This emerging field, which lacks a universally acknowledged name, might be called “Critical Studies in Finance Capital,” a term that links economic practices with the recognition that the world has a stake in these practices, which consequently cannot and should not be considered only in terms of how much profit they generate.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  To be taken seriously in this endeavor, humanists will need to learn the vocabulary, mechanisms, and histories of finance capital. While Stiegler’s work has much to offer in this regard, it is couched in terminology that an economist would find completely opaque; Hansen’s work, although more lucid, is also dense with argumentation and references that the finance community would likely find difficult to negotiate. The work of building bridges between finance capital and the rich critical and philosophical traditions of the humanities requires that humanists learn to write and speak in ways legible to the finance community, for only so can there be a successful transmission of ideas across these fields. The price to gain admission to discussions with  influential actors is steep, but the potential contributions humanists can make more than justify the investment. If there is no way out of the global financial system, then the way forward may require going more deeply into it. “Critical Studies in Finance Capital” should be a project in which humanists claim their stakes and make their arguments, transforming it even as we are also transformed by it. ChaPTer 7  Intuition, Cognitive Assemblages, and Politico-Historico Affects: Colson Whitehead’s The Intuitionist  As previous chapters have suggested, cognitive assemblages are inherently political. Comprised of human-technical interfaces, multiple levels of interpretation with associated choices, and diverse kinds of information flows, they are infused with social-technological-culturaleconomic practices that instantiate and negotiate between different kinds of powers, stakeholders, and modes of cognition.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Chapters 5 and 6 explored how these negotiations take place in urban infrastructures and finance capital, respectively. In chapter 6, the focus was on the technical cognitions of algorithms, and the possibilities for systemic transformations by changing the kinds of temporalities involved. In contrast, this chapter focuses on affective forces within assemblages, which as we will see go beyond human responses to the postulated responses of technical artifacts. The chapter takes as its tutor text a novel by African American writer Colson Whitehead, The Intuitionist (1999), interrogating how the novel creates richly textured affective, embodied, and interpretive contexts. Through these, the novel shows how the systems making up a cognitive assemblage form connections, create linkages between disparate phenomena, facilitate or block information flows between sites, make choices at multiple levels of human and technical cognitions, and morph as the assemblage gains or loses parts and undergoes systemic transformations in its dynamics. The Intuitionist nominally takes the electromechanical elevator as its focus but soon invokes a larger cognitive assemblage, progressively widening the boundaries to include the first “colored” female inspector, Lila Mae Watson, city politicians, the Department of Elevator Inspectors and associated Guild, competing elevator corporations  scarcely least, “the most famous city in the world” (33), notorious for its verticality and hence its infrastructural dependence on elevators. The story is set in an era when integration in Northern cities has a tentative foothold in city job placements but blatant racism is still everywhere apparent, from housing patterns and casual bar conversations to such racist entertainments as blackface minstrel shows. Weaving these diverse strands together, The Intuitionist foregrounds two distinctively different modes of cognition, represented by the two factors struggling for power in the Guild, Empiricism and Intuitionism.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Whereas Empiricism investigates the soundness of elevators using measurable variables and arrives at results that can be verified empirically, Intuitionism relies on intuition, internal visualization, and feelings to arrive at judgments expressed not through measurements but subjective feelings. The Inspectors who use Intuitionism are called by detractors “swamis, voodoo men, juju heads, witch doctors, Harry Houdinis,” all terms, the narrator notes, “belonging to the nomenclature of dark exotica, the sinister foreign” (57–58). By contrast, Empiricism, derided by its opponents as “flat-earthers, ol’ nuts and bolts, stress freaks” (58), is identified with a rationality infused with white values, practices, and histories. The issue is political in a literal sense, for the election for the Guild chair looms, in which Orville Lever, champion of the Intuitionists, is pitted against Chancre, an Empiricist and the incumbent chair; by tradition, the winner becomes the head of the Department of Elevator Inspectors. Historically, of course, the empiricism of such English scientists as James Clerk Maxwell (1871) and William Thompson (Lord Kelvin) played central roles in the expansion of the British Empire by inventing more efficient steam engines, resulting in superior naval power and the subsequent subjection of native peoples in India, the Pacific Islands, and elsewhere, a story repeated with tragic regularity over the globe as tribal peoples came in contact with Western technologies. As Chancre proclaims, “Why hold truck with the uppity and newfangled when Empiricism has always been the steering light of reason? Just like it was in our fathers’ days, and our fathers’ fathers” (27). Empiricism rules the day—except in Whitehead’s fiction, where “No one can quite explain why the Intuitionists have a 10% higher accuracy rate than the Empiricists” (58).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Lila Mae Watson, the first female and the second African American  vert to Intuitionism during her student days at the Institute for Vertical Transport, when she encountered James Fulton’s two books, Theoretical Elevators One and Two, works that entranced her and launched Intuitionism. Whitehead gives us a sample of intuitionism methodology when Lila Mae inspects the elevators at 125 Walker. She’s trying to concentrate on the vibrations massaging her back. She can almost see them now. This elevator’s vibrations are resolving themselves in her mind as an aqua-blue cone . . . The ascension is a red spike circulating around the blue cone, which doubles in size and wobbles as the elevator starts climbing. You don’t pick the shapes and their behavior.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Everyone has their own set of genies. Depends on how your brain works. Lila Mae has always had a thing for geometric forms. As the elevator reaches the fifth floor landing, an orange octagon cartwheels into her mind’s frame. It hops up and down, incongruous with the annular aggression of the red spike . . . The octagon ricochets into the foreground, famished for attention. She knows what it is” (6).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Thereupon she cites the elevator for a faulty overspeed governor, the orange octagon’s technical correlate. In free indirect discourse, the narrator announces repeatedly that when it comes to elevators, “She is never wrong,” following it up in the text’s final words, “It’s her intuition” (253). It would be difficult to imagine a more direct assertion of nonconscious cognition and its crucial importance for the modes of awareness. Lila Mae’s conscious mind is not in control of the shapes presenting themselves for her inspection: “You don’t pick the shapes and their behavior.” Recognizing that it “depends on how your brain works,” the narrative accepts matter-of-factly that the shapes represent meaningful interpretations of incoming data. Tracing the processes involved, we note that the elevator’s performance is sensed and analyzed nonconsciously from incoming somatic data (the vibrations on her back) and then forwarded to core consciousness, which renders the data as visual forms (much like the modal simulations discussed by Barsalou [2008]), whereupon higher consciousness correlates the shapes with technical knowledge available as verbal formulations (a faulty governor). Lila Mae’s elevator inspections, then, operate as cog-  tor as technical object reporting on its state, Lila Mae’s nonconscious cognition interpreting this input, and her conscious mind delivering a technical diagnosis. That the elevator, an electromechanical machine lacking electronics and sophisticated computational capabilities, can nevertheless function as a cognitive agent requires a radical shift of viewpoint, as Mr. Reed, mastermind of Lever’s campaign and himself a convert to Intuitionism, explains to Lila Mae in discussing Fulton’s two volumes. “[Fulton’s] diary shows that he was working on an elevator [when he died], and that he was constructing it on Intuitionist principles,” he tells her.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She responds, “At its core, Intuitionism is about communicating with an elevator on a nonmaterial basis. ‘Separate the elevator from elevatorness,’ right? Seems hard to build something of air out of steel.” He ripostes that “they are not as incompatible as you might think.” “That’s what Volume One hinted and Volume Two tried to express in its ellipses—a renegotiation of our relationship to objects.” He clarifies: “If we have decided that elevator studies—nuts and bolts Empiricism—imagined elevators from a human, and therefore inherently alien point of view, wouldn’t the next step, after we’ve adopted the Intuitionist perspective, be to build the right way. . . .” Grasping his point, Lila Mae finishes the thought: “Construct an elevator from the elevator’s point of view” (62). why nonConsCious CogniTion is noT enough Tempting as it may be to see this as a conceptual breakthrough of the kind new materialists advocate, we can take a clue that this is not the whole story from the fact that Mr. Reed is soon revealed to be as manipulative as Chancre’s gang. He and his accomplices at the Intuitionist House are intent on using Lila Mae for their own designs, which include recruiting an African American corporate agent\/spy to their plot. The agent introduces himself to Lila Mae as “Natchez,” playing on her sense of racial solidarity to elicit her help to find Fulton’s visionary design, called simply the “black box” (61), and subtly romancing her, succeeding in tempting her to drop her customary guard enough to become his ally. The plot then, if nothing else, indicates that realigning human with technical cognition will not be enough to catalyze a reconfiguration of cognitive assemblages profound enough to unsettle  Throughout the text, elevator technology serves as a metaphor for “racial uplift,” an elevation that propelled the city toward verticality and simultaneously opened a wedge for the first tentative moves of integration.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Violence still simmers, however; the text alludes to the recent riots, and other historical indicators suggest it is set in the period following the Harlem riots of 1964.1 Lila Mae’s father makes clear to her, before she leaves her Southern home, that “they can turn rabid at any second; this is the true result of gathering integration; the replacement of sure violence with deferred sure violence” (23). Before she leaves her tiny city apartment in the morning, Lila Mae girds herself with her inspector’s uniform, her badge, and her guarded face. “She needs the cut of the suit to see herself,” the narrator remarks. “The bold angularity of it, the keen lapels—its buttons are the screws keeping her shut” (56). She survives, she fits herself into the marginal spaces available to her, like the converted janitor’s closet she lived in while at the Institute. After graduation she does her job, but her reach is limited, and the further she moves from the city’s “zero-point” (4), the more entrenched the opposition, the more suspicious and closed down the faces become. Two related events catapult her out of survival mode, her customary guarded position in which she reacts to events but does not initiate them. Elevator No.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  11 in the Fanny Briggs Memorial Building crashes; it does not just fail but fails catastrophically, going into free fall in defiance of the safety features that supposedly make such an accident impossible. Since Lila Mae had inspected that elevator the day before and given it a clean bill of health, suspicion immediately falls on her, and it is her determination to clear her name that moves her out of her narrow domain, first to the Intuitionist House, then to a detective’s peripatetic wanderings as she searches for evidence that the elevator was sabotaged. The second event comes on the heels of the first, when “Natchez” reveals to Lila Mae that James Fulton, founder of Intuitionism and her hero, was an African American passing for white. Although Natchez lies in claiming that he is Fulton’s nephew and that he is searching for Fulton’s plans for the black box to take back for black people what white people have stolen from them, Lila Mae tests the tale of Fulton’s passing against her intuition and decides that part of the story is true. Armed with this knowledge, she returns to Fulton’s two volumes. Mae also teaches herself to read. She focuses on this passage in volume two: “The race sleeps in this hectic and disordered century. Grim lids that will not open.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Anxious retinas flit to and fro beneath them. They are stirred by dreaming. In this dream of uplift, they understand that they are dreaming the contract of the hallowed verticality, and hope to remember the terms on waking. The race never does, and that is our curse.” “The human race, she thought formerly . . . But now—who’s ‘we’?” (186). Her movement from reaction to action can be traced through her visits to Marie Claire Rogers, the black housekeeper (and perhaps lover) that Fulton insisted on hiring and ensured her future by trading the promise of his papers to the Institute for her right to continue living in his faculty house at the Institute after his death. On her first visit, Lila Mae goes at the behest of the Intuitionist faction, which hopes she will be able to persuade Mrs. Rogers to turn over the missing journals, and perhaps Fulton’s plans for the black box that will revolutionize vertical transport technology.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She is unsuccessful, and although Mrs. Rogers confides more to her than to any of the others who came seeking the information, Lila Mae leaves without the papers. On her second visit, however, she goes of her own accord, having decided, based on her new ability to read Fulton’s texts for what they hint but do not say, that the transcendental claims he wrote in volume one were intended as a prolonged practical joke against the elevator industry, a satiric response to their insistence on the replication of mundane reality. “Well look at you,” Mrs. Rogers replies. “Not the same girl who was knocking on my door last week, are you? . . . You’ve seen some things between now and then, huh?” (236). Mrs. Rogers relates that she learned Fulton’s secret when his much darker-skinned sister came to visit. Shortly thereafter he began work on volume two, having become a believer in the utopian vision that began as a joke. Her house has been trashed, presumably by the same crew that came after Lila Mae when she discovered that “Natchez,” actually Raymond Coombs, was employed by the Arbo corporation as an enforcer.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Unexpectedly, Mrs. Rogers gives her the remaining journals, appropriately hidden in the kitchen dumbwaiter, a vertical transport device. Lila Mae discerns a relation between the daily anxiety Fulton must have felt and the catastrophic accident of elevator No. 11. “What pass-  skin, the one you encounter at that unexpected time on that quite ordinary street. What Intuitionism does not account for: the catastrophic accident the elevator encounters on that unexpected moment on that quite ordinary ascent, the one who will reveal the device for what it truly is. The colored man passing for white and the innocent elevator must rely on luck” (231), on the hope that the sister will not appear, the ascent will not be betrayed to gravity. Lila Mae discovers the elevator’s secret when she returns late at night to the Fanny Briggs building. Although No.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  11 is now smashed to bits, she re-creates her experience of it with No. 14, using the elevator’s ascent to remember, as vividly and in as much detail as possible, her intuitive grasp of No. 11’s performance. As she rises, “The genies appear on cue, dragging themselves from the wings. All of them energetic and fastidious, describing seamless verticality to Lila Mae in her mind’s own tongue. . . . The genies bow and do not linger for her lonely applause. She opens her eyes. The doors open to the dead air of the forty-second floor.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She hits the Lobby button. Nothing” (227). What Lila Mae confirms in that “Nothing” is that No. 11’s demise was not sabotage—not by United or Arbo, Chancre or his underlings. Forensics, she intuits, will find nothing to account for the accident. She likens the catastrophic accident to comets that, having undergone “countless unavailing ellipses,” suddenly diverge and hit a planet, “emissaries from the unknowable.” She realizes what “her discipline [of Intuitionism] and Empiricism have in common: they cannot account for the catastrophic accident” (228). “The elevator pretended to be what it was not . . . Did it know?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  After all of Fulton’s anthropomorphism: did the machine know itself. Possessed the usual spectrum of elevator emotion, yes, but did it have articulate self-awareness . . . Did it decide to pass? To lie and betray itself? Even Fulton stayed away from the catastrophic accident: even in explicating the unbelievable he never dared broach the unknowable, Lila Mae thinks out of fear” (229). The obscure meaning here is heightened by the free indirect discourse of her conclusion: “This was a catastrophic accident, and a message to her. It was her accident” (229). CaTa sTroPhiC faiLure: The meaning of The message What message is she discerning?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Despite the intelligent criticism this  John Johnston, and Ramón Saldívar, among others, to my knowledge no one has published a convincing explanation for this extraordinary passage, or indeed any explanation at all, notwithstanding that it arguably constitutes the narrative’s climax. In view of this lacuna, I propose a somewhat controversial interpretation that relies on making a connection between the novel and a classic problem in computational theory. Since the text never mentions computation, this move might ordinarily be considered as overreaching, but I think a strong case can be made for its ability to illuminate a crucial absence in the text. It also makes a provocative connection between a technical device often seen as epitomizing technical cognition—the computer—and another device that is rarely considered in cognitive terms—the electromechanical elevator. The interpretation advanced here thus shows how the notion of a cognitive assemblage may be extended to include not only other technical devices but also overtly political concerns such as racism, gender discrimination, urban infrastructural design, and institutional politics. John Johnston (2008) gives a valuable hint opening the possibility of this interpretation when he notes in passing, without elaborating, that the elevator is a finite-state machine. A finite-state machine is a device, like an elevator or a turnstile, which has a very limited number of determinate states in which it can operate, with clear transitions between states. A turnstile, for example, is normally in the “locked” position, in which case people are prevented from passing through; after insertion of a coin or token, which initiates a transition phase, it moves to the “unlocked” position, enabling people to pass.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Like the turnstile, an elevator has a finite number of states represented by the floors at which it stops; pushing a button initiates a transition phase as it moves from state to state, floor to floor. The significance of the elevator as a finite-state machine lies in its similarity to another finite-state device, the theoretical computer that Alan Turing proposed as a conceptual device to understand the potentials and limitations of computation. Like the elevator moving from floor to floor but going horizontally rather than vertically, Turing’s device has a head that moves along a tape divided into a series of discrete blocks or cells.2 The head writes a one or zero in a cell or erases what is already there, moving back and forth along the tape the specified number of cells and marking the designated symbol according to  length, the number of cells it employs is always finite, so it qualifies as a special kind of finite- state machine, albeit with enhanced powers because of its computational potential. By convention, this simple device is called the Turing machine. Turing, along with many others since his seminal 1936–37 article, used it to prove important theorems about computation, and it is widely regarded as foundational to modern computational theory. In his original publication proposing this device (Turing 1936–37), Turing used it to explore the Entscheidungsproblem or the so-called halting problem.3 The halting problem is important because it falls in the category of mathematical problems that have been proven to be undecidable. The question Turing examined is this: is there a procedure that, for all possible Turing machine algorithms, can determine in advance whether or not a given algorithm will halt (that is, whether the computation will conclude)? Turing proved that no such generalpurpose procedure exists by showing that if it did exist, it would engender a contradiction.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The proof is technical, but in broad strokes his strategy was as follows. It is known that most real numbers are not computable, that is, no program exists that can generate them, digit by digit. Turing demonstrated that any program predicting whether a computation would halt would also be able to compute real numbers.4 Hence, since most real numbers are incomputable, the assumption that such a program would exist must be false. As a result, he established a conceptual limit to what computation can accomplish. His proof for the halting problem has since been shown to be interconvertible with Kurt Gödel’s incompleteness theorem. Just as Turing proved that the question of whether all possible algorithms will halt is undecidable, Gödel proved that any formal system powerful enough to do arithmetic must have at least one statement that cannot be proven to be either true or false and so is undecidable. Gödel showed that it is always possible to fold statements about number theory (that is, metastatements) into a statement within number theory, and the reflexivity resulting from this infolding creates an ambiguity and hence an undecidability. A simple example of a similar ambiguity is the statement “This sentence is false.” If the sentence is true, then it must be false; but if it is false, then it must be true: in other words, the statement’s truth or falsity is undecidable.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  We can now return to the enigmatic passages in which Lila Mae  cludes the catastrophic accident is what cannot be predicted, either by Empiricist or Intuitionist methodology; it is what escapes both the rationality of measurement and the nonconscious cognition of intuition. I propose that the catastrophic failure is the translation into “elevatorese” of the halting problem, rendering the notion of “halting” as a literal cessation of movement (rather than the conclusion of a calculation). By analogy, the question confronting Lila Mae when she revisits the Fanny Briggs building is this: is there a procedure that can decide, in advance, whether a given elevator will halt when it is supposed to? The answer, she realizes, is no: no such procedure exists for all elevators, just as no procedure exists that will determine in advance whether all Turing machine algorithms will halt. The fact that the probability of such an event is minuscule does not diminish its theoretical importance. Despite the elevator’s catastrophic failure being “a million-in-a-million occurrence” (230), its existence is confirmed by the implicit analogy with the halting problem, indicating that it cannot be eliminated completely without engendering a contradiction. Such events, Lila Mae thinks, are “not so much what happens very seldom but what happens when you subtract what happens all the time” (230). “They are, historically, good or bad omens .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . urging in reform . . . or instructing the dull and plodding citizens of modernity that there is a power beyond rationality” (230). While traditionally the catastrophic failure is the ultimate nightmare for those whose job it is to ensure the safety of vertical transport, so potent a specter that even the visionary James Fulton avoided it, what Lila Mae learns from the catastrophic failure of No. 11 is that another realm beckons beyond the binary choice of Empiricism and Intuitionism: the undecidable. The LiBeraTory P oTenTiaL o f error To amplify further the theoretical significance of Turing’s work on the halting problem and its relevance to Whitehead’s narrative, we can turn to the work of Gregory J. Chaitin (Chaitin 1999; 2001; 2006). Chaitin, fascinated by Turing’s proof, asked a related but different question: what is the probability of picking out, at random, a program that will halt from all possible programs the Turing machine can run? Note that Turing’s proof did not concern itself with the relative frequency  asked if it was possible to devise a procedure that could determine, in advance, whether all possible programs would halt. The answer to Chaitin’s question was a number that he designated as Omega, and the class of numbers that qualify as Omegas turn out to have unusual properties.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Among them is the fact that the sequence of numbers making up an Omega is random; that is, the prevalence of a given number in the sequence is no different than for that of a fair coin toss. Consequently, since Omegas cannot be computed in totality (that is, the sequence of an Omega cannot be predicted and is infinite), they constitute not just the undecidable but the unknowable. The implications of Omegas for the foundations of mathematics are highly significant, for when tested in terms of number theory, they reveal that even in mathematics, long considered the most exact of the sciences and the foundation for such disciplines as theoretical physics, “randomness is everywhere” (Calude and Chaitin 1999, 319). As these authors conclude, “randomness is as fundamental and as pervasive in pure mathematics as it is in theoretical physics” (320). They continue: “Even after Gödel and Turing showed that Hilbert’s dream [that all of mathematics could be shown to be both provable and consistent] didn’t work, in practice most mathematicians carried on as before, in Hilbert’s spirit. But now, finally, the computer is changing the way we do things. It is easy to run a mathematical experiment on a computer, but you can’t always find a proof to explain the results. So in order to cope, mathematicians are sometimes forced to proceed in a more pragmatic manner, like physicists.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The Omega results provide a theoretical underpinning for this revolution” (Calude and Chaitin 1999, 401). Returning to The Intuitionist, we find in this revolutionary spirit an explanation adequate to account for Lila Mae’s belief that the catastrophic accident and the lesson it teaches her will, along with Fulton’s notebooks, open an entirely new terrain that will enable her to make the next great leap forward, the “second elevation” (61). At the beginning of her quest, Mr. Reed had asked her, “What does the perfect elevator look like, the one that will deliver us from the cities we suffer now, these stunted shacks? We don’t know because we can’t see inside it, it’s something we cannot imagine, like the shape of angels’ teeth. It’s a black box” (61). Reed’s imagery suggests that when the black box is opened, the truth will be revealed. The answer Lila Mae intuits, how  lie in concealing a knowable answer, but rather in its symbolization of the limits of knowledge, both Empirical and Intuitionist. The black box cannot be opened because, as an integral and mysterious unity, it gestures toward the unknowable itself.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In volume two of Theoretical Elevators (when he began to take seriously the utopianism that began as a joke in volume one), Fulton wrote, “An elevator is a train. The perfect train terminates at Heaven. The perfect elevator waits while its human freight tries to grab through the muck and find the words . . . In the black box, this messy business of human communication is reduced to excreted chemicals, understood by the soul’s receptors and translated into true speech” (87). This passage has often been interpreted as an allusion to the kind of intuitive knowledge that Lila Mae had when she did her inspections, but “learning to read” the black box as the unknowable yields a different possibility. After her enlightenment, Lila Mae remembers the lectures that Fulton gave to “his flock,” which they heard but were “not aware of what he [was] truly speaking. The elevator world will look like Heaven but not the Heaven you have reckoned” (241).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Similarly, what the black box reveals is a truth upon which mathematicians had not reckoned— not the consistent and knowable systems postulated by Hilbert. If for Hilbert Heaven was a completely axiomatized mathematics, this is in contrast a mathematics shot through with randomness, derived as much from intuition as logical deduction and induction, with certain knowledge riddled by unavoidable bursts of the undecidable and unknowable. Meditating on the limits of Fulton’s explorations, Lila Mae thinks he “never dared broach the unknowable” because he was afraid (229). When he finally confronted it in the form of the black box, he realized its liberatory potential, but “of course when he started to believe, it was too late” (252); he dies before completing it, leaving to Lila Mae the task of birthing it into the world. CogniTive a ssemBLages and Th e unknowaBLe The Intuitionist is not, of course, a treatise on mathematics but rather a complexly wrought novel in which racism, capitalism, institutions, politics, technical infrastructure, finite-state machines, and the messy human psychologies are entwined, coproducing cognitive assem  rialities circulate and coalesce into temporary and shifting configurations and potentialities. To explicate the implicit connections between Turing and Chaitin’s work and these assemblages, I turn to an essay by Luciana Parisi, an Italian theorist located at Goldsmiths, University of London, who has brilliantly expounded on the significance of Chaitin’s Omegas (Parisi 2015). Following on Calude and Chaitin’s observation that mathematics must now proceed more like the experimental sciences rather than by the supposedly more “rigorous” methodologies of deduction and induction, Parisi turns to the semiotics of C. S. Peirce to explicate the significance of this turn toward what she, following Deleuze and Guattari, calls an “experimental axiomatics” (Parisi 2015, 8). It is typified in her view by Peircean abduction, the process of using data to formulate a best-guess hypothesis.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “Chaitin claims that computational processing leads to postulates that cannot be predicted in advance by the program and are therefore to be explained in the terms of ‘experimental axiomatics,’ a postulate or truth emerging from the inferential synthesis of data carried out by algorithms” (8). This leads in turn to “the emergence of a form of intelligibility able to use data environments— which are the concretizing info-structures of incorporated or automated social practices—to add new axioms, codes, and instructions and new meaning to what was initially programmed. Programming here corresponds to the formation of intelligible procedures in which algorithmic instructions extrapolate new patterns from the data environment they retrieve, thus transforming the pre-established function of programming itself” (8). In the turn toward algorithms that, instead of excluding contingency and error, learn from them, she sees a major shift in the form of neoliberal capital as it operates through computational media and databases. Rules, rather than governing how the algorithms work, instead emerge abductively from data environments, which themselves may be understood as the “collective use-meaning of data” (3). “This is a mode of reasoning based not on pre-established axioms that need to be proven true,” Parisi notes, “but on an hypothetical function, which includes the importance of fallibility or error for the discovering of new concepts, involving the revision of both the scientific and manifest image of cognition” (10–11). In Parisi’s explanation, we find an interpretation that will allow us  not only of reconceiving elevators but of shaking the foundations of entrenched racism and launching the “world’s most famous city” on a new trajectory capable of achieving the “second elevation” (Whitehead 1999, 61) of a more just, equitable, and free society. The discovery of the “new concepts” that error and fallibility make possible releases algorithmic reasoning, and by extension the elevator as a finite-state machine, from simply executing the program determining its operation.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  There is always the possibility of the catastrophic failure, the “thinking through doing” (Parisi 2015, 11) that the elevator enacts through its unexplained, and unexplainable, failure. This explanation also allows us to understand why nonconscious cognition, symbolized by the sensations received from the elevator and interpreted by core consciousness as visualizations that Lila Mae experiences when inspecting elevators, cannot by itself bring about this transformation. With the advent of affective capitalism and computational media that exploit the missing half-second to hijack human affective responses before consciousness has a chance to evaluate them and respond (Parisi and Goodman, 2011), nonconscious cognition can be held hostage by the designs of neoliberal capital—or in terms of Whitehead’s novel, by the institutional racisms and hierarchies that the elevator corporations foster to their advantage. For Parisi, the escape clause that allows a measure of interpretive choice even in the face of affective capitalism goes by the name of general artificial intelligence. “Against the anti-logical machine of neoliberal capitalism ready to deny the autonomy of general intelligence through the affective capture of thinking, a pragmaticist view of reasoning may help us to explain the extent to which fixed capital is not only a new source of surplus value, but also contains an alien logic, extrapolates a new order of meaning that is not readily subsumed under capital’s visceral apparatus of capture” (Parisi 2015, 11). This “alien logic” is very different from that formulated by Mr. Reed in his conversation with Lila Mae, when he implied that the key to transformation may be formulating a theory from the elevator’s point of view rather than from the “alien” logic of humans. The elevator he has in mind is the well-performing finite-state machine, not the misbehaving elevator that crashes unexpectedly for no knowable reason. Regardless whether an elevator is seen from an “alien” human view or its own perspective, if it is forever trapped in the discrete finite states  radical transformation for which Lila Mae—and we may assume the author—yearns.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The significance of the “experimental axiomatics” that Parisi invokes, following Chaitin, is that they generate new rules and concepts precisely from data environments, which as Parisi notes are the “concretizing info-structures of incorporated or automated social practices” (Parisi 2015, 8). In my terms, data environments are the milieus out of which cognitive assemblages are formed and through which they are able to create new concepts via experimental axiomatics, which in turn change the rules governing how data are processed, which feed back into the cognitive assemblages to transform how they operate. This is the kind of reflexive dynamic that enables cognitive assemblages to evolve in new and unexpected directions—and it is, I suggest, the key to understanding how an elevator’s catastrophic failure can expand in widening circles of cognition capable of transforming how the “world’s most famous city,” and all cities, are constituted and constructed. In a weird coincidence, Parisi invokes a philosopher—and a philosophy—that has been hovering on the edge of this discussion when she writes that computation may need to be “conceived in terms of its speculative intelligible functions through which unknowns are algorithmically prehended” (Parisi 2015, 8). Prehension is of course the term that Alfred North Whitehead uses to formulate a processual worldview in which “actual entities” (Whitehead 1978, 7, 13 passim) arise and coalesce, a view central to Mark Hansen’s reading of twentyfirst-century media that operate in temporal regimes inaccessible to humans. The argument advanced here brings together the two Whiteheads, one a novelist who creates a fiction in which an elevator is postulated as an agent capable of prehensions and interpretive choice, and the other the thinker for whom the “extensive continuum” (Whitehead 1978, 61 passim) give rise to prehensions, from which in turn emerge “actual entities.” When everything is connected, with everything being influenced by and influencing everything else, transforming elevator technology can potentially transform culture and society. In this context, errors in an elevator’s operations are not mere deficiencies; rather, taken to the extreme of violent and catastrophic failure, they tear open a rip in the temporal fabric of the historical present, through which a better and more utopian future may be glimpsed. concepts”—in this case concepts about verticality that transform urban architecture, which in turn open new possibilities for rethinking infrastructures, including human, capitalist, technological, and finite-state components as they come together to form new kinds of cognitive assemblages capable of resisting capture by affective and fixed capitalism and transforming the entrenched hierarchies of privilege and the institutionalized racisms associated with them.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  aesTheTiC s TraTegies and sPeCuLaTive reaLism Even if we disregard (or remain skeptical toward) the novel’s allusion to the halting problem for which I have argued, we must nevertheless admit there is something odd about The Intuitionist. Located in an unnamed but very recognizable city, set in an unspecified era rendered with considerable historical specificity, The Intuitionist is slightly displaced from the history we know—not far enough away to qualify as an alternative history, not close enough to be immediately classifiable as a historical novel. Ramón Saldívar has argued that The Intuitionist is part of a literary trend that he characterizes as “postracial” (Saldívar 2013, 1), pointing to Colson Whitehead’s op-ed piece in the New York Times (Whitehead 2009) in which the writer used the term to characterize American society after Obama’s election. Saldívar makes clear from the outset that “race and racism are nowhere near extinct in contemporary America,” noting that he follows Whitehead’s lead in invoking it “under erasure and with full ironic force” (2). Nevertheless, he identifies four general characteristics that “postracial” novels exhibit, along with a host of writers and texts representative of the trend. While engaging with postmodern aesthetics, they mix generic forms, focus thematically on race, and qualify as “speculative realism,” “a hybrid crossing of the fictional modes of speculative genres, naturalism, social realism, surrealism, magical realism, ‘dirty’ realism, and metaphysical realism” (5). From my perspective, the most intriguing part of his analysis focuses on why speculative realism should emerge as the aesthetic mode associated with postracial texts. “How can one write the history of the future?” he asks.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  “What are the conditions of a style appropriate to representing futures that do not and may never exist?” (7). Referring specifically to The Intuitionist, he sees it as “the racialized depiction of Utopian desire raised to a sec-  open to the vagaries not of history but of fantasy . . . the point is what this mixing of genres allows for the justification of Utopia, in the face of all evidence to the contrary” (11). The sense in which he appropriates speculative realism as a literary term shares with the philosophical movement known by that name a desire to break the bounds of finitude—that is break from the closed circle of Kantian thought, in which we are always and inherently distanced from things in themselves, into what Quentin Meillassoux calls the “great outdoors” of other possibilities (Meillassoux 2010, 29). That mathematics, specifically Zermelo-Fraenkel set theory, should be the path into these possibilities had already been explored by Meillassoux, following his teacher Alain Badiou (Meillassoux 2010, 112–28). In this context, it is perhaps not so strange that Whitehead’s novel may be linked to the computational theory, specifically the halting problem, as a path into the “great outdoors” of the “second elevation.” Saldívar’s argument captures precisely the utopian yearning evident at the novel’s conclusion. “They are not ready now but they will be,” Lila Mae thinks. “Sometimes in her new room she wonders who will decode the new elevator first.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It could be Arbo. It could be United. It doesn’t matter. Like the election, their petty squabbling feeds the new thing that is coming. In its own way, it prepares them” (Whitehead 1999, 253). With breathtaking casualness, she dismisses the capitalist enterprise as all but irrelevant, in sharp contrast to the picture that Ben Ulrich, Lift investigative journalist and sometime torture victim, had painted for her earlier. “Did you think this was all about philosophy? Who’s the better man—Intuitionism or Empiricism?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  No one really gives a crap about that. Arbo and United are the guys who make the things. That’s what really matters” (208). Ulrich’s view fits well with the position argued by Mark Fisher in Capitalist Realism, when he reads the film Children of Men, with its vision of near-universal sterility, as a metaphor for a society facing the “end of history” (Fisher 2009, 80) that finds impossible the task of imagining an alternative to capitalism. “How long can a culture persist without the new?” Fisher imagines the film asking. “What happens if the young are no longer capable of producing surprise?” (3). He suggests that capitalism, with its remarkable capacity to morph and absorb everything into its dynamics, even putative oppositions and resistances, is akin to The Thing, the amorphous, all-devouring entity in  here is analogous to the deflationary perspective of a depressive who believes that any positive state, any hope, is a dangerous illusion” (5). Against this backdrop, the peculiarities of The Intuitionist can be understood not simply as idiosyncrasies but as politico-aesthetic strategies.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Its almost, but not quite our history serves to defamiliarize the history of capitalism just enough to allow a glimmer of hope to enter, while remaining close enough to our historical present to enable us to recognize the structures of inequality and institutionalized racism it depicts. Hopeful but not naïve, not yet fully formed but not vague either, the new era that Lila Mae believes she can midwife into existence trembles at the edge of an unbelievable, yet crucially necessary, affirmation. “It will come. She is never wrong. It’s her intuition” (Whitehead 1999, 255). T he hisToriCaL PresenT and CogniTive a ssemBLages Assuming that a path into a better future has been opened, how does it affect the present in which Lila Mae lives, or the present of readers for whom the novel’s not quite our present is already not quite our past? What roles do nonconscious cognitions and cognitive assemblages play in the future\/past\/present transformation? Lauren Berlant provides a helpful framework for addressing these questions in her essay on history, affect, and their interactions (Berlant 2008).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  She asks, “How is it possible for the affects to sense that people have lived a moment collectively and translocally in a way that is not just a record of ideology?” (846). She posits that affect is the result of “the body’s active presence in the intensities of the present,” that it “embeds the subject in a historical field,” and moreover that “its scholarly pursuit can communicate the conditions of an historical moment’s production as a visceral moment” (846). In short, she searches for a way to incorporate affects as historical phenomena responsive to, and partially responsible for, the historical specificities that in retrospect can be recognized as what Raymond Williams called the “structures of feeling” characteristic of a particular era (Williams 1977). As she rightly argues, the Marxist view for which Williams stands as representative has acknowledged that affects must be involved in the production of historical moments, but it primarily emphasizes systematicity and ideology, with the theoretical treatment of affects remaining vague and  To create a theory capable of incorporating affect into historical events in more than a superficial way, Berlant employs a term that has already appeared in this chapter, namely the “historical present.” She explains, “My interest is in constructing a mode of analysis of the historical present that moves us away from a dialectic of structure (explanation of what is systemic in the reproduction of the world) and agency (what people do in everyday life), and toward attending to their embeddedness in scenes that make demands on the sensorium for adjudication, adaptation, improvisation, and new visceral imaginaries for what the present could be” (846–47). The historical present, then, is “not a matter for retroactive substantialization,” but rather “a thing being made, lived through, and apprehended” (848). Moreover, she theorizes that a chronic crisis, and associated literary genres, “produce the present as a constant pressure on consciousness that forces consciousness to apprehend its moment as emergently historic.” “Crisis reveals and creates habits and genres of inhabiting the ordinary while reconstituting worlds that are never futures but presents thickly inhabited, opened up, and moved around in” (848). The historical present, then, is at once ordinary and multiple, affectively experienced and yet open to other modes of being that may also be inhabited. Berlant’s essay is a wonderful analysis, so good it makes your teeth ache to read it.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When she turns to The Intuitionist, one of her two tutor texts (the other being William Gibson’s Pattern Recognition), she astutely recognizes the important role that affect plays in the text, quoting at length Lila Mae’s intuitive evaluation of the elevator at 125 Walker. The weak point comes, however, when Berlant arrives at the catastrophic failure of elevator No. 11. She reads Lila Mae’s late-night visit to the Fanny Briggs building as “the elevator calling out to her to clear her name and find a higher truth” (853). Although she recognizes that this somehow involves a retraining of Lila Mae’s intuition, she sees this as an “intuitional shift to living a fearless racialized imaginary in the present, with no fidelity toward protecting the built white world as such, and theorizing the beyond as an act of vitalism” (854), with no explanation for how a catastrophic accident is able to launch Lila Mae on this path or what kind of “higher truth” might be involved. Crucially for her argument, she has no way to connect the personal message that the elevator’s failure reveals to Lila Mae with the larger social transformation of the impending change that Lila Mae’s efforts  rienced by a single person to larger social experiences of affect that construct and define the specificities of the historical present. My previous argument about the halting problem provides precisely the kind of connections and links that Berlant’s essay is missing. It relates the personal message Lila Mae receives to broader social concerns and indeed to the nature of epistemology itself, especially the productive roles of error and failure in an era on the verge of developing the powerful computational media that would profoundly alter the dynamics of human-technical cognitions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  I want to underscore the importance of affects in cognitive assemblages, a matter on which Berlant’s essay is admirably eloquent. She shows with forceful clarity how affect can thicken and extend into prehension of historical events, without however becoming an “eventilization” (849), sliding into the past, and thereby losing its potency. As she argues, they continue to operate in the “historical present,” rendering it at once as immediate lived experience and as prehensions that interact with other contingencies to form a historical nexus. Recall that nonconscious cognition is intimately related to affect, serving as a site of mediation between bodily and visceral actions and the higher modes of consciousness\/unconsciousness. In this context, the theoretical importance of cognitive assemblages stems from their ability to show how affects come together with other forms of technical and human cognitions to create dynamic systems flexible enough to change their configurations continuously, and stable enough to function within the complex architectures of human-technical interactions. Within such systems, errors and contingencies may, at decisive cusp points, tip the system one way or another so that the assemblage begins to operate in new and unanticipated modes. CogniTive a s semBLages and noveLisTiC forms Berlant’s essay strives to incorporate affects into history and therefore into our understanding of historical (or, in the case of The Intuitionist, almost historical) novels. Behind her quest looms another question relevant to my project here: what does literature, especially the novel, contribute to our understanding of cognitive assemblages and the roles played by human and technical nonconscious cognitions?\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  What specific dynamics do novels enact that are not already present  statistics, mathematics, physics, and biology, for example? For convenience I use examples from The Intuitionist, but most novels would offer similar instances. A tentative answer would include the following points: 1. Novels show how affects work in individual and collective human lives. The precariousness of Lila Mae’s position in the “world’s most famous city” is shown not only through the suspicious reactions and petty meanness she experiences but through how it affects her body, dress, emotions, gestures, postures, facial expressions. She lies in bed at night moving the muscles of her face to arrive at exactly the right expression to show to a hostile and indifferent world, a fragile defense against slurs, insinuations, unwanted advances, disrespect. On the collective side, the scene of the elevator inspectors gathered at O’Connor’s bar (Whitehead 1999, 24) to watch the news about the catastrophic failure of No. 11 shows how the excitement of the crowd is contagious, spurring the watchers on through a sense of group solidarity and its necessary other, the exclusion of those who, like Lila Mae, do not belong.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When Lila Mae corrals Chuck, her one and only friend in the department, into the ladies room to enlist his help (34–37), his discomfort at the setting is exacerbated by the drunk woman passed out on the room’s only toilet in a posture that reminds him of his mother. These affects go a long way to explaining why Chuck agrees to help Lila Mae, despite the risk he runs. 2. Novels provide specific contexts—historical, racial, gendered, economic, psychological—of lived experiences. The basement of Johnny Shush’s unsafe (rather than safe) house doubles as a torture chamber, and the mattress and wall stains that Ben Ulrich sees there speak volumes about the room’s purpose and former occupants (94–95). When Lila Mae is also taken to the basement, the implicit menace increases the tension of her conversation with Chancre. It also makes believable his assertion that he did not sabotage elevator No. 11, for clearly he has the upper hand and therefore no reason to lie to Lila Mae.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Ben Ulrich later tells Lila Mae that he knew his abductors were not Johnny Shush’s boys, although that is what they pretended, but rather were corporate stooges, from the quality of the shirts they wore (210). Details of architecture, clothing, furniture, and myriad other small specificities flesh out and give meaning to  3. Novels depict ranges of interpretations and choices that drive the dynamics of systems. When Lila Mae visits Fulton’s housekeeper, Marie Claire Rogers, a second time, her house (and it is hers, she had reminded Lila Mae on her first visit) has been desecrated by corporate goons, who not only broke all her ceramic horses decorating the mantle but also urinated on the floor. When Lila Mae picks up a broom to help and lies about the room not smelling of urine, these small courtesies may be what tip the balance and make Mrs. Rogers decide to give her Fulton’s remaining papers. Lila Mae’s choice to help rather than stand by creates a small perturbation in the system that nevertheless initiates a large change in its dynamics. 4. Novels provide form and shape experience.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Berlant’s essay defines genre as a “loose affectual contract that predicts the form that an aesthetic transaction will take” (Berlant 2008, 847). The hybridity of Whitehead’s novel stems, as Saldívar points out, from its mixing of realist modes of narration, setting, character, and action with the fantastical elements of intuiting an elevator’s health by making contact between a human back and the elevator’s vibrations, of attributing to the elevator emotion, the capacity to lie, and the ability to engage in deliberate misdirection as a form of elevator “passing.” The kinds of aesthetic transactions the novel’s form predicts, guides, and enacts, then, take place in a borderland between the hard realities of racial and gendered structural inequalities and the speculative possibilities of utopian transformation. Contingency, error, and necessity mingle indiscriminately, with each playing a role in determining how the dynamics of cognitive assemblages emerge and evolve. Fulton sees Lila Mae on campus and asks her name; then, distracted by the cost of resoling his shoes and other matters, he scribbles in the margin of his paper, “Lila Mae is the one” (251), a message hovering indeterminately between prophecy and coincidence, error and anointment. 5. Novels enact connections and links between disparate phenomena. The entwining of racial uplift and vertical transport, notable in Fulton’s papers but present elsewhere as well, provides the ground for a whole series of other analogies—a black man passing for white and a faulty elevator passing for healthy; a second elevation in architecture and race relations; a technological revolution that will rearrange cities and souls. The enactment of unlikely connections  Institute late at night, has a clear line of sight to James Fulton as, already slipping into dementia, he moves about the library located at the Institute’s top floor late at night.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  He sees her light, she sees his in a contingent arrangement that, in retrospect, is an uncanny coincidence or the beginning of a mystical bond between them. 6. Novels use literary resources to mean more than they say. On a thematic level, the allusions to the halting problem and the black box as the unknowable show how the range of reference can expand in almost unlimited fashion. In literary terms, rhetorical tropes such as irony, metaphor, metonymy, and synecdoche (Kenneth Burke’s four master tropes) show how literary language can function affectively as well as conceptually. Garrett Stewart (1990) has argued that literary language differs from ordinary prose precisely in its ability to address a wide range of embodied responses. If we ask not what but where we read, Stewart comments, the answers would include: in the throat through subvocalization, the viscera through embodied responses, the circulatory system through increases or decreases in blood pressure, the central nervous system through pupil contraction and dilation in response to suspenseful or peaceful passages, and a host of other embodied and affective reactions. 7.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Novels explore ethical issues in specific and concrete, rather than abstract, terms. Lila Mae’s decision to give Fulton’s notebook to Raymond Coombs is fraught with irony, from her opening confrontation in his Arbo office to her parting shot, “I just wanted to help” (251). What he does not yet know is that she also gave it to Chancre and thus to Arbo’s archcompetitor United, and to Ben Ulrich, the investigative reporter who has positioned himself as the enemy of both corporations. Her equal-opportunity disclosures indicate how irrelevant the recipients’ differences have become in her mind as she contemplates the coming future. “The elevator she delivered . . . should hold them for a while. Then one day they will realize it is not perfect. If it is the right time she will give them the perfect elevator.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  If it is not time she will send out more of Fulton’s words to let them know it is coming” (255). Her choices, at once ethical, political, and technological, indicate the shift of mindset that has positioned her as the leader and designer of the future, rather than as someone who can at best only react to actions that others take. Her allegiance—we might say, her only allegiance—is to the future  The above points refer, of course, to representations within novels, but novels also function as cognitive devices in larger assemblages that include publishers, readers, reviewers, media, networked and conventional dissemination channels, and a host of other human and technical systems loosely aggregating to form flexible and shifting cognitive assemblages through which choices, interpretations, and contexts operate as information flows through and between systems. The broader significance of intuition comes not only from its contrast with empirical rationality (as the mutually entailed limitations of Intuitionism and Empiricism in Whitehead’s novel suggest), but from the assemblages in which cognizers at many levels cooperate and compete to create the emergent dynamics of human-technical interactions. Nonconscious cognition is an important key to understanding how these assemblages form and transform, especially in the connections it builds between human and technical cognizers, but it is in and through cognitive assemblages themselves, in the folds in time (Serres and Latour 1995; Latour 1992, 230) they create in which the past jostles with the future, that the historical present comes thickly into existence. ChaPTer 8  The Utopian Potential of Cognitive Assemblages  At midcentury, Norbert Wiener was struggling with what he saw as the peril and promise of the cybernetic paradigm. One result of that struggle was The Human Use of Human Beings (1950), which is less a coherent argument than a somewhat chaotic mix of hope and dread. Half a century later, we can see with the benefit of hindsight in what ways the cybernetic paradigm was both prophetic and misguided.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  It was correct in anticipating that modes of communication between humans, nonhuman life-forms, and machines would come to be increasingly critical to the future of the planet; it was wrong in thinking that feedback mechanisms were the key to controlling this future. In fact the whole idea of control, with its historical baggage of human domination and exceptionalism, has come to seem increasingly obsolete, if not outright dangerous. Now well into the new millennium, we can appreciate the enormous differences that networked and programmable media have made in human complex systems, and we are beginning to glimpse how these conditions have opened new possibilities for utopian thoughts and actions. If control in the sense of anticipating all relevant consequences and using this foreknowledge to determine the future has been consigned to the dustbin of history, its demise reveals that the very attempts to render formal (mathematical and computational) systems tractable by rigorous procedures defining boundaries and establishing protocols have confirmed the existence of what lies beyond those boundaries: the incomputable, the undecidable, and the unknowable. Luciana Parisi, in her work on general artificial intelligence (2015), points to the importance of Gregory Chaitin’s work in this regard, as discussed in  veloped societies, where correlations between databases and increasingly sophisticated surveillance techniques seem to make the interacting imperatives of state control and capitalist exploitation ever more intrusive and oppressive. Beatrice Fazi (2015), who completed her dissertation under Parisi’s direction, approaches the issue from another direction, showing how Turing’s work on incomputable numbers opens an area of incomputability within the regime of computation itself. In brief, what this work reveals is that the more control is codified and extended through computational media, the more apparent it becomes that control can never be complete, and the very operations that make control possible also authorize its antithesis, areas where the unknowable rules. The problem, then, is how to use this potential to make real differences in the real world.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In my view, this is what motivates Mark B. N. Hansen’s work (2015) on Whitehead’s philosophy in relation to twenty-first-century media. He adopts from Whitehead the idea of a world continuously in flux; he modifies Whitehead precisely to forge a connection between this flux and “superjects,” the settled entities that congeal out of the flux. His point is that processual dynamics does not cease where the human begins, but continues to interpenetrate it, opening new possibilities for resistance and intervention. My own contribution has focused on the importance of cognition, interpretation, and choice, and the resulting formation of cognitive assemblages in which human and technical actors communicate and interact on many levels and at multiple sites. The complexity of these assemblages, for example in finance capital, has clearly shown that control in the sense Wiener evokes it is no longer possible. Cognition is too distributed, agency is exercised through too many actors, and the interactions are too recursive and complex for any simple notions of control to obtain. Instead of control, effective modes of intervention seek for inflection points at which systemic dynamics can be decisively transformed to send the cognitive assemblage in a different direction.1 For Brad Katsuyama, the inflection point consisted of altering the speed at which algorithmic transactions could be conducted. For the authors of the batch auction proposal, it was devising techniques that made capitalist competition focus on price rather than speed.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  For ATSAC, it was making the urban traffic infrastructure a site of cooperation between human interventions and intelligent algorithms. For Rosi Braidotti  ance point between flux and stability, human identity and the forces that interpenetrate and destabilize it. For Colson Whitehead, it was using a catastrophic elevator failure to show that the future can never be entirely determined by a past burdened with institutional racism, hatred, and suspicion. Thinking about what the very different agendas of Parisi, Fazi, Hansen, Katsuyama, Braidotti, and C. Whitehead (and many others, too numerous to mention here) have in common leads to useful generalizations about the kind and scope of interventions that can make differences in real-world systems. First, all these thinkers, activists, and writers spent the time and conceptual resources necessary to understand the system in detail, whether it is computational regimes, HFT, processual philosophy, institutional racism, or posthumanist studies. Only if the system in question is interrogated closely and researched thoroughly can the inflection points be located. Second, once the inflection points are determined, the next issue is how to introduce change so as to transform the systemic dynamics. Third, and perhaps most important, these theorists, activists, and writers draw upon prior visions of fair play, justice, sustainability, and environmental ethics to determine the kinds of trajectories they want the system to enact as a result of their interventions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  These are typically not found within the system itself but come from prior commitments to ethical responsibilities and positive futures. This is why I have been urging throughout that the humanities have vital roles to play in thinking about cognitive assemblages. Interpretation, meaning, and value, while not exclusively the province of the humanities, have always been potent sites for exploration within the humanities, including art, literature, philosophy, religious studies, and qualitative history. Ethics cannot be plastered on as an afterthought after the system has already been formed and set in motion, an unfortunate tendency, for example, in courses on “ethics” in business practices, which too often focus on how to satisfy legal requirements so that one does not become the object of a lawsuit. On the contrary, effective ethical intervention has to be intrinsic to the operation of the system itself. For cognitive assemblages, this means becoming knowledgeable about how the interpenetrations of human and technical cognitions work at specific sites, and how such analyses can be used to identify  emerge in interaction\/intra-action with prior commitments to create new trajectories for the assemblages, providing more open, just, and sustainable futures for humans, nonhuman life-forms, and technical cognizers—which is to say, for the planetary cognitive ecology. For these utopian possibilities to be realized, humanities scholars must recognize that they too are stakeholders in the evolution of cognitive assemblages, which implies an openness toward learning more about the computational media at the heart of cognitive technical systems. At present, the digital humanities are the contested sites where these issues are discussed and debated, sometimes in heated and angry exchanges.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The following section expresses my take on these debates and argues for a more constructive dialogue between the traditional and digital humanities. enLarg ing The mind of The h umaniTies During a stint at the University of Chicago as the Critical Inquiry visiting professor, I was invited to give a presentation to the Society of Fellows. I began my presentation by recalling a digital case study I had conducted (with Allen Riddell) on the constraints operating in Mark Danielewski’s elaborately patterned novel Only Revolutions (Hayles 2012). As I discussed the project, one of the participants objected that the computer algorithms we employed could deal only with “dumb” questions, not interesting interpretive ones. I responded that the “dumb” answers led to interesting interpretive possibilities, for the absence of certain words was a strong indicator of the constraints the author had imposed, which in turn led to questions about what these constraints implied. My interlocutor continued to insist that ambiguities were the essence of literary interpretation, and that the kind of “distant reading” we had done was reductive and therefore not really humanistic at all. Since she was obviously intelligent and passionate about her position, I made a point of talking with her afterward to explore more fully the nature of her objections. She summed them up by remarking, “It all depends on the kind of humanities you want.” Her passion made me realize that many scholars choose to go into the humanities because they do not like the emphasis in the sciences on finding answers to well-defined questions.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Indeed, they tend to believe that interesting questions do not have definite answers at all, of-  fear that if definite answers were established, interpretation would be shut down and further research would be funneled into increasingly narrow avenues. Leaving aside the question of whether this is an accurate or fair view of scientific investigation, I think it captures the spirit of what my interlocutor meant by “the kind of humanities” she wanted. If computer algorithms could establish definite answers (such as whether or not a certain word appeared in a text, and if so how frequently), then for her and like-minded scholars, the open space that the humanities has established for qualitative inquiry as a bulwark against quantitative results was at risk of crumbling, and all that would be left would be studies dominated by quantitative measures. Entangled with this attitude are many questions about the proper mission for the humanities, especially in relation to the sciences, and the strategies that humanists employ that may be considered distinctive and so indicative of their contributions to contemporary intellectual life. For a very long time, scholars in the humanities have felt threatened and underappreciated relative to more powerful and culturally central fields, and these perennial concerns are now being exacerbated with the emergence of the digital humanities. In my view, the digital humanities ought not to be seen as a threat but as an important ally to the traditional humanities, expanding their influence and widening the scope of what counts as humanistic inquiry without sacrificing their distinctive contributions. Moreover, I see the recognition of nonconscious cognition in humans and technical systems as key to repositioning the humanities at the very center of contemporary intellectual inquiry. To make this case, I will discuss the interactions between description and interpretation, clarify the role they play in constructing computer algorithms, identify cultural productions where nonconscious cognitions are being staged as artistic projects, and speculate on the future of human and technical cognitions as they interact through cognitive assemblages.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Having shown in previous chapters the centrality of nonconscious cognition in human and technical assemblages, I will in this final chapter carry the argument into the heart of my own discipline and intellectual commitments. in TerPreTaTion and desCriPTion In the humanities, interpretation is typically regarded as having a  one regards computational methods. While no one doubts that a word frequency algorithm can count words accurately, many believe that this does not count as a cognitive activity. Interpretation, by contrast, is often seen as an exclusively human prerogative and highly valued as a result. What would it imply, then, to claim that the cognitive nonconscious interprets? The implications for humanistic strategies are profound. Interpretation is deeply linked with questions of meaning; indeed, many dictionaries define interpretation in terms of meaning (and meaning in terms of interpretation). Meaning, in turn, is central to the mission of humanistic disciplines.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Whereas scientific fields always ask “What is it?” and frequently query “How does it work?” they seldom ask why things are as they are, and even less often what they mean. By contrast the humanities, including art history, religious studies, philosophy, history, and literary studies, among others, take the quest for meaning to be central. Why study history, for example, if not to try to determine why events proceeded as they did, and what it means that they did so? Of course, the humanities are not so naïve as to suppose that meaning is easily recoverable or even that it exists other than as human fantasy. From Oedipus Rex to Hamlet to Waiting for Godot and beyond, literary art has confronted the possibility that there may be no transcendent meaning for human life. Nevertheless, even to answer the quest in the negative still involves meaning making as a central problematic. Until the twentieth century, meaning and interpretation focused primarily on consciousness and its meditations. With the advent of Freudian psychoanalysis, the unconscious was explicitly articulated as another player in the creation of meaning and interpretation, and as a result, earlier and contemporary literary works were reread for their psychoanalytical import.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  The fact that they could be so reinterpreted implies that the unconscious was always intuited as an important component of human thought. In an important sense, Freud did not so much invent the unconscious as discover it, drawing in part on literary representations that powerfully depict it in action. Now the humanities are being confronted with other major players: human and technical nonconscious cognitions. To engage productively with them, the humanities must broaden their concepts of meaning and interpretation to include such functionalities as recognizing patterns, drawing inferences from those patterns, learning nonconsciously, and correlat-  Not coincidentally, these functionalities are often used to describe the work done by computer algorithms. A common perspective in the humanities is that these activities are far inferior to what human consciousness can do: John Guillory speaks for many when he says that there is at present an “immeasurable” gap between literary interpretation and what computer algorithms can accomplish (Guillory 2008, 7). That perception is why it is critically important for the humanities to become aware of how nonconscious cognition operates both in human brains and computational media. This alone would be a compelling reason for the humanities to rethink how meaning and interpretation work in nonconscious processes, a reorientation equivalent in scope, magnitude, and implication to the seismic shock initiated by the explicit recognition of the unconscious. In addition, the humanities are being impacted as never before by computational media, especially in the digital humanities.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Once cognition is recognized as operating nonconsciously as well as consciously, a vast array of social, cultural, and technological issues come into view as appropriate for humanistic inquiry. As argued in earlier chapters, these range from interactions of human cognition with the nonconscious cognitions of technical systems to the social, cultural, and economic formations that enter into these interactions through cognitive assemblages. Of course, it is still possible that some in the humanities may choose to ignore these questions and the possibilities they open. Some may remain content with traditional views that locate meaning and interpretation solely within the human consciousness and unconscious. These views are not so much false as incomplete. To compensate for this limited scope, such scholars should in my view recognize that nonconscious cognition operates within human neurology and appreciate the capabilities it possesses. One possibility that this recognition opens is that the cognitive nonconscious may be discovered in older texts as well as recent works. Chapters 4 and 7 model a few reading strategies for interpreting representations of nonconscious cognition and for exploring the costs of consciousness, but many more possibilities exist, from measuring indicators of nonconscious processing in readers (Riese et al.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  2014) to investigating the interplay between affectual responses and larger cognitive assemblages. For those opposed to the digital humanities, the charge is often  in the prevailing value schema, automatically relegates them to a lower strata and therefore not the “real” or “important” humanities. The clear binary thus established between description and interpretation is open to objections on multiple counts. Science studies, for example, has long recognized that description is always theory laden, because every description assumes an interpretive framework determining what details are noticed, how they are arranged and narrated, and what interpretations account for them. Sharon Marcus, answering critics who contest her and coauthor Stephen Best’s call for “surface reading,” confronts the entanglement of interpretation with description head-on (Marcus 2013). Rather than arguing that description is not theory laden, Marcus turned the tables by pointing out that every interpretation necessitates description, at least to the extent that descriptive details support, extend, and help to position the interpretation. Although not the conclusion she draws, her argument implies that description and interpretation are recursively embedded in one another, description leading to interpretation, interpretation highlighting certain details over others. Rather than being rivals of one another, then, in this view interpretation and description are mutually supportive and entwined processes.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This helps to clarify the relation of the digital humanities to traditional modes of understanding such as close reading and symptomatic interpretation. Many print-based scholars see algorithmic analyses as rivals to how literary analysis has traditionally been performed, arguing that digital humanities algorithms are nothing more than glorified calculating machines. But this implication misunderstands how algorithms function. Broadly speaking, an algorithmic analysis can be either confirmatory or exploratory. Confirmatory projects are often misunderstood as simply repeating what is already known, for example, what literary dramas fall into what genre category (see Moretti 2013 for a superb example of this kind of analysis). The point, however, is not to determine, for example, what literary drama falls into what generic category, but rather to make explicit the factors characterizing one kind of dramatic structure rather than another. Often new kinds of correlations appear that raise questions about traditional criteria for genres, stimulating the search for explanations about why these correlations pertain. When an algorithmic analysis is exploratory, it seeks to identify patterns not previously detected by human reading,  long-held presuppositions constrain too narrowly the range of possibilities considered.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Just as interpretation and description are entwined for human readers (as Marcus’s argument implies), so interpretation enters into algorithmic analyses at several points. First, one must make some initial assumptions in order to program the algorithms appropriately. In the case of Tom Mitchell’s Never-Ending Language Learning (NELL) project at Carnegie Mellon, the research team first constructs ontologies to categorize words into grammatical categories (Mitchell n.d.). In Timothy Lenoir and Eric Gianella’s algorithms designed to detect the emergence of new technology platforms by analyzing patent applications (Lenoir and Gianella 2011), they reject ontologies in favor of determining which patent applications cite the same references. The assumption here is that cocitations will form a network of similar endeavors, and will lead to the identification of emerging platforms. Whatever the project, the algorithms reflect initial interpretive assumptions about what kinds of data are likely to reveal interesting patterns. Stanley Fish to the contrary (Fish 2012), there are no “all-purpose” algorithms that will work in every case. Second, interpretation strongly comes into play when data are collected from the algorithmic analysis.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  When Matthew Jockers found that Gothic literary texts have an unusually high percentage of definite articles in their titles (discussed in McLemee 2013), for example, his interpretation suggested this was so because of the prevalence of place names in the titles (The Castle of Otranto, for example). Such conclusions often lead to the choice of algorithms for the next stage, which are interpreted in turn, and so forth in recursive cycles. Employing algorithmic analyses thus follows a similar pattern to human description\/interpretation, with the advantage that nonconscious cognition operates without the biases inherent in consciousness, where presuppositions can cause some evidence to be ignored or underemphasized in favor of other evidence more in accord with the researcher’s own presuppositions. To take advantage of this difference, part of the art of constructing algorithmic analyses is to keep the number of starting assumptions small, or at least to keep them as independent as possible of the kinds of results that might emerge. The important distinction with digital humanities projects, then, is not so much between description versus interpretation but rather the  limitations of technical cognition. Working together in recursive cycles, human conscious analysis, human nonconscious cognition, and technical cognition can expand the range and significance of insights beyond what each can accomplish alone. sTaging The CogniTive nonCo nsCious in The TheaTer of ConsCio usness If my hypothesis is correct about the growing importance of nonconscious cognitions and the cognitive assemblages in which they operate, we should be able to detect these influences in contemporary literature and other creative works. Of course, since these products emerge from conscious\/unconscious modes of awareness, what will be reflected is not the cognitive nonconscious in itself, but rather its restaging within the theater of consciousness.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  One of the sites where this staging is readily apparent is in contemporary conceptual poetics. Consider, for example, Kenneth Goldsmith’s “uncreative writing.” In Day, Goldsmith retyped an entire day (September 1, 2000) of the New York Times; in Fidget, he recorded every bodily movement for a day; in Soliloquy, every word he spoke for a week (but not those spoken to him); and in Traffic, traffic reports, recorded every ten minutes over an unnamed holiday, from a New York radio station. His work and accompanying manifestos have initiated a vigorous debate about the work’s value. Who, for example, would want to read Day? Apparently not even Goldsmith, who professed to type it mechanically, scarcely even looking at the page he was copying. He often speaks of himself as mechanistic (Goldsmith 2008), and as the “most boring writer who ever lived” (qtd. in Perloff 2012, 149). In his list of favored methodologies, the parallel with database technologies is unmistakable, as he mentions “information Management, word processing, databasing, and extreme process .\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  . . Obsessive archiving & cataloging, the debased language of media & advertising; language more concerned with quantity than quality” (Goldsmith 2008). Of course we might, as Marjorie Perloff does, insist there is more at work here than mere copying (Perloff 2012). Still, the author’s own design seems to commit him to enacting something as close to Stanley Fish’s idea of algorithmic processing as humanly possible—rote calculation, mindless copying, mechanical repetition. nonconscious cognition as taking over and usurping consciousness, perhaps simultaneously with a sly intrusion of conscious design that a reader can notice only with some effort. That he calls the result “poetry” is all the more provocative, as if the genre most associated with crafted language and the pure overflow of emotion has suddenly turned the neural hierarchy upside down. The irony, of course, is that the cognitive nonconscious is itself becoming more diverse, sophisticated, and cognitively capable as it extends into technical systems. Ultimately what is mimed here is not the actual cognitive nonconscious but a parody version that pulls two double- crosses at once, at both ends of the neuronal spectrum: consciousness performed as if it was nonconscious, and the nonconscious performed according to criteria selected by consciousness.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  As Perloff notes, quoting John Cage, “If something is boring after two minutes, try it for four. If still boring, try it for eight, sixteen, thirty-two, and so on. Eventually one discovers that it’s not boring at all but very interesting’” (157). Consciousness wearing a (distorted) mask of the cognitive nonconscious while slyly peeping through to watch the reaction—that’s interesting! Another example of how the cognitive nonconscious is surfacing in contemporary creative works is Kate Marshall’s project on contemporary novels, which she calls “Novels by Aliens.” Focusing on “the nonhuman as a figure, technique and desire,” Marshall shows that narrative viewpoints in a range of contemporary novels exhibit what Fredric Jameson calls the “ever-newer realisms [that] constantly have to be invented to trace new social dynamics” (Jameson 2010, 362). In Colson Whitehead’s Zone One, for example, the viewpoint for the Quiet Storm’s highway-clearing project involves an overhead, faraway perspective more proper to a high-flying drone than to any human observer (Marshall 2014). The protagonist, nicknamed Mark Spitz, collaborates with Quiet Storm in part because he feels, as Marshall puts it, “lust to be a viewpoint.” Although Marshall links these literary effects to such philosophical movements as speculative realism, it is likely that both speculative realism and literary experiments in nonhuman viewpoints are catalyzed by the expansive pervasiveness of the cognitive nonconscious in the built environments of developed countries. In this view, part of the contemporary turn toward the nonhuman is the realization that an object need not be alive or conscious in order to function as a cognitive agent.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Two PaThs for The humaniTies Today the humanities stand at a crossroads. On one side the path continues with traditional understandings of interpretation, closely linked with assumptions about humans and their relations to the world as represented in cultural artifacts. Indeed, the majority of interpretive activities within the humanities arguably have to do specifically with the relation of human selves to the world. This construction assumes that humans have selves, that selves are necessary for thinking, and that selves originate in consciousness\/unconsciousness. The other path diverges from these assumptions by enlarging the idea of cognition to include nonconscious activities. In this line of reasoning, the cognitive nonconscious also carries on complex acts of interpretation, which syncopate with conscious interpretations in a rich spectrum of possibilities. What advantages and limitations do these two paths offer? The traditional path carries the assumption that interpretation, requiring as it does consciousness and a self, is confined largely if not exclusively to humans (perhaps occasionally extended to some animals).\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  This path reinforces the idea that humans are special, that they are the source of almost all cognition on the planet, and that human viewpoints therefore count the most in determining what the world means. The other path recognizes that cognition is much broader than human thinking and that other life-forms as well as technical devices cognize and interpret all the time. Moreover, it also implies that these interpretations interact with and significantly influence the conscious\/unconscious interpretations of humans, which themselves depend on prior integrations and interpretations by human nonconscious cognitions. The search for meaning then becomes a pervasive activity among humans, animals, and technical devices, with many different kinds of agents contributing to a rich ecology of collaborating, reinforcing, contesting, and conflicting interpretations. One of the costs of the traditional path is the isolation of the humanities from the sciences and engineering. If interpretation is an exclusively human activity and if the humanities are mostly about interpretation, then there are few resources within the humanities to understand the complex embeddedness of humans in cognitive technical environments and in relationships with other species. If, on the  contrary, interpretation is understood as pervasive in natural and built environments, the humanities can make important contributions to such fields as architecture, electrical and mechanical engineering, computer science, industrial design, and many others. The sophisticated methods that the humanities have developed for analyzing different kinds of interpretations and their ecological relationships with each other then pay rich dividends and open onto any number of exciting collaborative projects.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Proceeding down the nontraditional path, in my view much the better choice, requires a shift in conceptual frameworks so extensive that it might as well be called an epistemic break. As we have seen, one of the first moves is to break the equivalence between thought and cognition; another crucial move is to reconceptualize interpretation so that it applies to information flows as well as to questions about the relations of human selves to the world. With the resulting shifts of perspective, many of the misunderstandings about the kinds of interventions the digital humanities are now making in the humanities simply fade away. I want to emphasize that the issues involved here are much larger than the digital humanities in themselves. Important as they are, focusing only on them distorts what is at stake (which is one reason why I have waited until this final chapter to introduce the topic). The point, as far as I am concerned, is less about methods that seem to be rivals to interpretation—a formulation that assumes “interpretation” and “meaning” are stable categories that can be adequately discussed as exclusively human activities—than it is about the scope and essence of cognition as it operates in humans and technical systems, and in the larger cognitive assemblages that are transforming the planet’s built and natural environments. There are two important implications that I want to bring out as a conclusion to this chapter (and book). The first is that nonconscious cognition, far from being fundamentally alien to how humans think, is in fact crucial to human cognition, as we have seen in chapter 2, summarizing research investigating the relation between consciousness and nonconscious cognition.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  Those in the humanities who see an “immeasurable” gap separating what computers can do from what human brains achieve should rephrase their argument to take into account that low-level nonconscious cognitive activities are always already involved in high-level thoughts in human brains. In the digital  are being enrolled in the human extended cognitive system, just as historically humans have excelled as a species in enrolling all manner of external objects as cognitive supports and extensions (Clark 2008; Hutchins 1996). These external cognizers perform tasks that also take place within human brains, including recognizing patterns, drawing inferences from complex arrays of data, learning to recognize covariation among multiple variables, and reaching decisions about conflicting or ambiguous information. Seen in this way, computers are not creatures alien to humans, as they are sometimes depicted in popular culture and in some popular science books. For example, David Eagleman in Incognito (2012), a popularized account of research into nonconscious cognition, constantly refers to specialized automated processors within the human brain as “alien” and “zombie” systems. Such rhetoric, no doubt fashioned to make his argument seem more lively and entertaining, introduces a totally artificial division between consciousness and nonconscious cognition, as if some miniature computer resides in the human brain that is fundamentally removed from and alien to the self. In fact, however, the brain is an amazing integrated system in which every part communicates and is integrated with every other part (as Eagleman himself recognizes in another context [166]), and in which nonconscious cognition needs the support of high-level amplification signals to endure, no less than consciousness depends on and integrates the fast-response information processing of nonconscious cognitions. This leads to the second point I want to emphasize.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  We are now in a period of increasing complexity, sociality, and interconnections between technical nonconscious systems. Just as human cognition was given a sharp evolutionary boost upward through human sociality, so nonconscious cognition in technical systems operates not in isolation but in recursive interconnections with other technical systems. In the “Internet of things,” for example, a nonconscious system such as VIV, discussed in chapter 5, may have access to open-source information on the web, which it can use to create connections, leveraging its inferences from individual sites through cross-connections that leap to still further inferences, and so on. Biological organisms evolved consciousness to make this kind of quantum leap from individual instances to high-level abstractions; core and higher consciousness in turn ultimately enabled humans to build sophisticated communication net-  historical perspective, automated cognizers are one result of evolved human consciousness. It is likely, however, that the evolutionary development of technical cognizers will take a different path from that of Homo sapiens. Their trajectory will not run through consciousness but rather through more intensive and pervasive interconnections with other nonconscious cognizers. In a sense, they do not require consciousness for their operations, because they are already in recursive loops with human consciousness. Just as from our point of view they are part of our extended cognitive systems (Clark 2008), so we may, in a moment of Dawkinslike fancy, suppose that if technical systems had selves (which they do not), they might see humans are part of their extended cognitive systems.\n"}
{"prompt":"Unthought The  Power of The Cognitive Nonconscious ->","completion":"  In any case, it is now apparent that humans and technical systems are engaged in complex symbiotic relationships, in which each symbiont brings characteristic advantages and limitations to the relationship. The more such symbiosis advances, the more difficult it will be for either symbiont to flourish without the other. How should we in the humanities analyze and understand this symbiosis? An essential first step is realizing that the human brain has powerful nonconscious cognitive abilities. This realization allows the humanities to see cognition in a new light, not as an ability unique to humans and an attribute virtually synonymous with rationality or higher consciousness, but rather as a capability present in many nonhuman life-forms and, increasingly, a vast array of intelligent devices. Then the question becomes not whether machines can think, as Alan Turing asked more than a half-century ago, but how networks of nonconscious cognitions between and among the planet’s cognizers are transforming the conditions of life, as human complex adaptive systems become increasingly interdependent upon and entwined with intelligent technologies in cognitive assemblages. If contemporary cultures in developed societies are presently undergoing systemic transformations that are profoundly changing planetary cognitive ecologies, as I have argued, then the humanities should and must be centrally involved in analyzing, interpreting, and understanding the implications. Anything less is a disservice to their missions—and to the world.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  However, when Mary enters transition she discovers not simply her power to navigate the noise of Doro’s pattern, but that she has power to wrest control of the mind of several actives around the country. It is not simply a matter of telepathic power but her capacity to host the mental power of actives from all over the world makes Mary realize that there is indeed a mind of her own  minds. By growing layers upon layers of telepathic thinking amongst actives, Mary aims to turn the master pattern into an egalitarian space by offering Doro’s enslaved population the chance to transition towards higher mental power. If Doro is a psychopathic tyrant without ethical principles, Mary instead is caught in the middle of controversial decisions as she builds the pattern in a way that compels the minds of others to join her imagination by following her mission that everyone must have access to the mind of her mind. As opposed to Doro’s master pattern for total domination of his own mind in the bodies of everyone else, Mary rather aspires to give birth to an alien intelligence that can host all kinds of minds as these ﬁnd a space of uniﬁcation in the patterns of her patterns. If Doro’s master program admits no external intrusion in the one-dimensional design of the mind, Mary’s paradoxical intuition of inviting potential saboteurs in her growing layers of minds is rather a choice of embracing something she has no control of. Despite the controversial use of her telepathic power that makes actives believe that they take autonomous decisions whilst being instead piloted by Mary’s views, it would be wrong to assume that the mind of her mind simply remains immune from the alienness of patterning as this hosts increasingly more active minds. In what follows, I will explore this alienness in the context of recent forms of artiﬁcial intelligence called machine learning.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  As opposed to models of computational cognition that rely on the deductive logic of symbolic AI, the postTuring shift to interactive computing entails that incomputables – or unknown information – deﬁne the formation of new patterns that are not pre-programmed for a task. It is from this standpoint that one can speak of alienness as  image-models. In particular, it will be argued that predictive intuition in neural networks can explain the formation of patterns beyond deductive premises and demarcate the advance of artiﬁcial imagination in the dynamic architecture of machine thinking. 1 the patternist As much as Doro has a plan to enslave all latent minds under the program of his master pattern, so too today’s capital corporations (from Google to Amazon) are rampantly competing to own the Singularity pattern that will ﬁnally subsume all thinking under the One.3 Sadly, the image of our automated future is already packed with the master pattern of corporate capital. While the value of human capital approximates zero, the automated infrastructure of capital has come to own the universal history of humanity: what has happened and could ever happen to the species, the planet, the solar system, and the galaxy. From the nano scale to the intergalactic project of ultimate datiﬁcation, the growing capacity of the master pattern to engulf at once the past and the future is driven by the computational power of predictive algorithms that constantly learn as they go along, correlating inﬁnite varieties of data sets – i.e., annexing and disaggregating increasingly smaller programs that fully run on the architecture of neural nets. Swarming patterns of disaggregated machine learning algorithms are held together by a mastering architecture whose growing patterns it rules and divides so as to anticipate – i.e., engulf within itself – the smallest tendency for autonomous programming. The aspiration to become a Patternist, as Octavia Butler calls the species of telepaths that can colonize all forms of thought, coincides with a mode of control predicated upon the obtuse nature of  with an alien form of automation, whereby algorithmic patterning aims to take prediction away from the homeostatic function of recognition to rather embark in a complex logic of productive imagination.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  By constructing hypotheses about non-observable events, predictive patterning has broken from the logic of deduction and the symmetry between truth and proof. Deduction, one could argue, is a fundamental method of reasoning that ensures that there is a logical consequence between premises and results, truths and proofs. It accounts for the pre-existence of a conceptual architecture with which it is possible to pursue the understanding of the world through the perception of a thought as an image that corresponds to a fact, an object in the world. Whereas computational cognition sees deductive logic as a method that can prove that to think is to re-cognize or represent a set of symbols wired in the machine, the shift to post-Turing methods of computation also coincides with a new method of reasoning. This is not based on given instructions but on learning from the interaction between objects, agents, environments. Predictive patterning and not the logic of causality becomes the motor of complex dimensions of thinking within intelligent machines. However, the Patternist is not simply an evolving archive of data memories and know-hows. Octavia Butler’s vision of the colonization of thinking is not bound to a speciﬁc medium, but to mediation itself: the limits of cognitive representation demarcate the point of departure into travelling through the space of thinking.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Instead of a Universal Turing Machine that can move in one direction, forward and backward, and decompose its procedural units into (con)sequential steps, telepathic mediation allows for a mereo-topological colonization of parts and wholes intended not simply to gather the  patterns that it owns. The Patternist is not a fortune-teller but a Protean slave trader that transmutes his body whilst it takes over your mind by culling it in his kingdom of instructions. The more thoughts it subsumes to its transcendental schemata, the more the future of thinking only acts as a reminder of what has already been thought. What ensures his colonial mastery is not simply his data architecture that replaces the self-thinking subject with the mediatic form of non-conscious decisionmaking algorithms. Instead of a master algorithm that knows it all, the Patternist needs to evolve its slavery network into increasingly more complex patterns of prediction: the more part-to-whole relations between patterns, the more the Patternist can predict what can be known. This is the sense of capture that today’s automated neural networks embody in the aftermath of an accelerated accumulation of voluntary data. Nevertheless, one cannot underestimate that as much as neural nets experiment with predictive learning this new form of telepathic mediation has also evolved new modes of machine percepts and concepts that hardly mirror the categories of the transcendental schema. Instead of optical recognition or the mirroring framing of the world, telepathic mediation is distinctively algorithmic in so far as it relies on predictive patterns of compression not of whole images but of inﬁnitely small sets of information.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  From the standpoint of information patterning, therefore, artiﬁcial intelligence has nothing to do with the optical model of cognitivist representation. If what is seen in the world is the same as what is recognized according to the schema of given categories, then machine thinking would just be an extended automation of the logic of deduction. Patterns would just describe the regular rep-  data. This is why if deductive reasoning was held to ensure formal correspondence between what is already known and seen, algorithmic patterning instead brings logical reasoning towards its ultimate conclusion: namely by not knowing in advance what can be cognized, and the patterning of image-models can re-conﬁgure the horizons of machine thinking. Similarly, Butler’s quest of mental slavery also catches upon this undetermined tension between pattern and thought, where the telepathic recognition of discrete and repetitive patterns coincides with the material condition by which a pattern can become demonstrative of a thought, resulting from a perceptual and conceptual connection with the world. If patterns correspond to the recognition of shapes, sizes, forms, etc. of objects, texts, sounds, images, they can at the same time also be discussed in the terms of what Wilfrid Sellars calls “sheer receptivity” or forms of intuition consisting in non-conceptual representation.4 While this is only one level of intuition, it nevertheless offers a radical shift from the Kantian argument for intuition as an instance of a priori transcendental conceptions. According to Sellars, sheer receptivity as a material form of intuition must, however, be paired up with intuitions resulting from the transcendental synthesis of imagination – or conceptually guided representations involving a transcendental synthesis of imagination.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  It is only through this coupling of distinctive levels of intuition that one could argue that patterns can take part in a “productive imagination.”5 As it may become clearer below, this article suggests that telepathic mediation does not only ground thoughts into patterns that can be constantly recognized and reproduced as in Doro’s monopolistic network of enslaved lessthan-thinking creatures. The admission that  way which supplies the relevant recipe.”6 Similarly, Mary’s plans to extend the right to transition to all latents enslaved to Doro’s network start with this level of non-conceptual receptivity. From merely being patterns of recognition, the transition to becoming actives coincides with building together a general artiﬁcial intelligence that continues to learn from its enslaved patterns, and unleashes an unprecedented growth of the dimensions of thinking starting from pattern’s receptivity. This shows that patterns are not just recipes but objects that add a sort of alienness to already given rules, exposing predictive patterning to the production of image-models beyond Doro’s monopoly. Instead of a full automated thought that replaces thinking, reason, imagination with machine proofs as mere instantiations of conceptual nominal positing (corresponding to an automated unity of appreciation), here patterns rather correspond to image-models constructed by and through learning. If, on the one hand, the relation between receptivity and conceptuality (sheer receptivity and conceptual synthesis) corresponds to a complex form of intuition starting from patterning, on the other predictive patterning adds more acts of perception to the entire space of artiﬁcial intelligence (patterning from patterns). Doro, the Patternist – or the thought colonizer – is deﬁed by Mary’s predictive patterning because the level of “sheer receptivity” is not simply equivalent to repetitive procedures that represent objects in the world. This level of non-conceptual intuition is also a mode of cognition that brings Mary’s mentality to undergo an alien becoming of the pattern she thinks she owns.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  The image of thought proposed by the arms race for the monopoly of the technological explosion of intelligence (or the Singularity) similarly refuses deductive logic (or the prova-  thinking can also be understood here as symptoms of an internal critique of logical thinking: the limit of what a pattern can be is precisely the starting point for the pattern to shift its enslaved condition beyond the image of the network. The latter relies on probability calculation, discrete patterns forming programs that can repeat the same function at incredibly faster rates. Here the Singularity mainly guarantees the efﬁciency of problem solving at increasingly larger scales. Instead, both the growth and the efﬁciency of Mary’s Pattern is never given, in so far as its infrastructure relies on predictive patterning which is conditioned by the indeterminacy of results in constructing what can be known or thought. As opposed to the mindless automation of Singularity, where functions execute concepts derived from the transcendental schema of categories, the Patternist’s empire, as Mary’s plans show, is conditioned by the logic of fallibility, where error becomes part of the pattern’s learning. Here it is hypothesis making and not mindless correlation that drives patterns to construct an image-model from patterns. While hypotheses cannot be directly deduced as proofs of truths, they can nonetheless construct predictive trajectories expanding the act of receptivity beyond the thought of a particular object. Learning and not executing instructions has always been a preoccupation for both the cybernetic and computational development of intelligent systems since the 1940s.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  The design of artiﬁcial systems that could explain how patterns are formed and how machines can learn functions and elaborate concepts beyond their inputted data has accompanied artiﬁcial intelligence since Turing’s early thought experiments. What could not be proven and\/or computed by an artiﬁcial system – and thus through the automated logical procedures into a series of proofs  As the limits of computation were manifested in the proliferation of error in the execution of programs, it was also the case that patterning shifted towards the logic of trial and error, or fallibility. From the standpoint of induction, it is possible to suggest that automated learning is not driven simply by the efﬁcient causality of repetitive patterns that reproduce given correlations between truths and proofs. As a consequence of inductive learning, the logic of fallibility in automated systems can importantly contribute to suggest how patterning can coincide with an alien imagination determined neither by given truths (and the unilateral production of proofs) nor by given data (and the unilateral correspondence of data to concepts). Instead, predictive patterning takes the method of trial and error towards the ultimate consequence of constructing model-images that have no direct use, but are as it were “counterfactual” in so far as they concretize the ifclause or the hypothesis making, producing alien functions and concepts.8 In other words, starting from a logic of fallibility in machine thinking, hypothesis making involves the construction of model-images about unknown patterns of relations between functions and concepts, precisely for what these can be, do and become. One could therefore pursue a view for which automated learning in terms of hypothetical thinking steps beyond the unity of apperception in the transcendental schema, and thus the deductive programming of the correlation of functions and objects. If the Patternist points out that any form of automated prediction inevitably carries within it a logic of fallibility and not simply of optimized efﬁciency, then one could argue that the automation of learning, in the current form of machine learning algorithms, for instance, can be explored as the start-  non-conceptual representation) concurs and to some extent partakes of the non-monotonic formation of additional premises through a transcendental imagination that can invalidate or add new meaning to them. To put it another way, instead of taking Butler’s view to imply that the Patternist can only ever enslave thinking to the transcendental schema within the limits of deductive reasoning, it is here suggested that patterning already corresponds to a non-conceptual representation that is a proto-theoretical image.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  In the neural architecture of predictive learning, the algorithmic function of pattern recognition brings forward this non-conceptual image in a cluster of hypothetical conﬁgurations or model-images of counterfactual possibilities. This article therefore follows Butler’s insight into Mary’s plans to enlarge the realm of possibilities of patterns – that is of enslaved patterns – to think beyond the rules of deduction. In Mind of My Mind, the controversial condition in which Mary’s power to host colonized patterns (and support their transition) is overlapped by their predictive learning points that counter-factual conﬁgurations continuously derail the network from monotonic thinking, and from Mary’s benevolent intentions to grant a thinking space for everyone. What remains striking here is precisely how the logic of patterning patterns steps outside the formalism of deduction to demonstrate that the non-conceptual realm of intuition, or sheer receptivity (and therefore the receptivity of non-conceptual patterns) is fundamental to the transition to synthetic thinking worked by and through imagination. It is precisely this zone of opacity between the repetition of patterns and the transition to the synthesis of transcendental imagination that remains to be discussed, unpacked, explained, and envisioned in order to set in  systems of decision making, and particularly in machine learning. One may want to start by asking: how does imagination defy the coming empire of the master pattern and its global servo-mechanic infrastructure that feeds the network without being able to change its rules? It is generally agreed that the role of imagination in the Kantian schema of transcendental reason involves the theorization of a logical procedure where the analysis of the world is supervened by a synthetic perspective of what can be known. As I have argued so far, this transcendental reasoning that appears to pre-establish the conceptual framing of the world according to the cognitive schema of thinking is importantly supported by intuition, which Sellars calls “sheer receptivity” as non-conceptual patterns that are not originated by the transcendental schema of imagination.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Here, the result of synthesis can presuppose a transcendental unity of apperception on the one hand and the addition of supplementary acts of perception that push the reproductive imagination (or conceptual recognition) towards the formation of alien percepts and concepts on the other. If, according to Sellars, the proto-theoretical receptivity of the simple is necessarily of the same logical pattern as that of a complex transcendental synthesis, productive imagination then admits that logical patterns can change as a result of a supplemental act of perception (and thus machine vision) in the transcendental synthesis. It is well known that, according to Kant, the transcendental describes an a priori condition of knowledge of objects.9 In particular, the enquiry into the transcendental unity of apperception, involving the transcendental synthesis of imagination, is said to be the principal point to unfold elements for cognition. In other words, the quest into the transcendental  established at the level of receptivity – the manifold of the sensible – and the level of imaginary production. Nevertheless, for Kant the synthesis of imagination in terms of a given conceptual schema corresponds to the unity in intuition and judgement of the real.10 On the other hand, however, for Kant the synthesis of imagination is also said to precede concepts and thus to depend on a pre-conceptual intuition. This unity of understanding therefore is predicated on a deeper paradoxical unity between concepts and intuition in so far as understanding itself already presupposes a conceptual schema of what can be understood. Kant’s articulation of the unity of intuition and conception remains crucial for the argument about critique that precisely implies an enquiry into the limits of understanding, and what is beyond the cognitive capacities to analyse and synthesize unknowable noumena. From this standpoint, the transcendental synthesis of imagination is also caught in the paradox where intuition is and is not produced by understanding (i.e., the function that gives unity to a judgement).\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  In other words, imagination is both caught within the unity of understanding – the procedural analysis and the conceptual synthesis of the external world – and within the world of the sensible and preconceptual intuition. Imagination is thus part of the transcendental relationship between intuition and synthesis. However, if the unity of understanding explains that this relationship is rooted in the metaphysics of deduction, how could the world ever be thought beyond what has already been conceived of it? While the transcendental synthesis of imagination implies that intuition is both conceptual and pre-conceptual, according to Wilfrid Sellars, there needs to be a place to explain 11  to intuitions derived from the transcendental synthesis of imagination, sheer receptivity corresponds to passive representations, which are not conceptual: namely Humean raw impressions of the world. Sellars advocates for a connection between the mind and the world, insisting that the manifold of sheer receptivity is a form of intuition whose transcendental condition is neither determined by given concepts nor in the pre-conceptual experience external to thought. Instead, this connection is also granted by the non-conceptual representation of individuals; namely, involving a process of abstraction for and of thises. Rather than matching individuals to general concepts, intuition coincides with a demonstrative formation of concepts and accounts for simple representations that are not pre-determined by the conceptual idealism of cognitivism. Far from grounding thought in pure reason (a reasoning without demonstration) as the motor of deductive metaphysics, we have here a “raw” manifold that guides representations without becoming predetermined by a priori concepts, truths and axioms.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  As opposed to the deductive ﬁt of particularity to generalities, the demonstrative representation of the world rather implies a process of abstraction of those primitive, simple and passive representations as material elements that enter the formation of concepts and as such connect the world with thought. From this standpoint, the transcendental synthesis of imagination is bootstrapped to sheer receptivity as deﬁning only one part of intuition. In particular, according to Sellars, the encounter of receptivity with spontaneity explains how intuition further comes to drive productive imagination.12 Here, the transcendental condition of imagination is not determined by concept-involving intuition, but rather implies  particular image that enters transcendental synthesis of imagination to become a concept. Here productive imagination corresponds to the formation of objects that do not simply reproduce but add new dimensions to the recipe of forming images. Instead of a transcendental imagination caught between concept-involving or pre-conceptual intuitions, the connection between thought and the world can be said to start from non-conceptual patterns. This involves the receptivity of a raw manifold of representations that enters the productive layer of imagination, forming patterns of patterns. As the receptivity of patterns lies at the core of a predictive or telepathic patterning of alien imagination, it remains constitutive of what can be thought. It is precisely this asymmetrical connection in a double dimension of intuition between the moments of reception and conception that has entered the predictive patterning of machine thinking pushing towards the alien transcendental.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  From this standpoint, the enquiry into the alien transcendental is also an effort to discuss the function of predictive thinking within the space of critique. We know that the connection between apperception and imagination grounds critique within the limits of what can be thought and known. This connection, however, is the elastic band of critique: it stretches to remain the same. Since nothing comes from nowhere, all that is thought has a place in schemata (rules of determination and the concepts representing these rules). Nevertheless, if the task of critique is not to verify premises but to open the procedure of veriﬁcation to what cannot be known in advance, then critique can run parallel to the function of predictive thinking, where intuition – sheer receptivity and pro-  truths into alien concepts forming patterns of patterns across the neural architecture of artiﬁcial intelligence. 3 fallibility With the modern question of technology already came the realization that thinking did not conform to the self-consistency of ideas. Thinking had instead to be pursued by means of a transcendental tool or procedure, such as the unity of understanding through which the contingent world could be analysed, calculated and quantiﬁed. It was through the reasoning procedure of understanding, however, that dogmatic truths could be defeated in the name of self-determining analytics of the unknown, a self-limiting apprehension of its outside.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  As philosopher Denise Ferreira Da Silva puts it,13 the transcendental tool is central to the constitution of the global idea of race, namely explaining that colonialism is a global affair conducted by the scientiﬁc and historical analytics imparted by the transcendental schema of the self-determining knower. However, if reasoning, as a transcendental tool, is granted by the synthesis of imagination, it too must admit within itself the alienness of productive imagination, whereby incomputables (non-patterned inﬁnities) become a condition for alien thinking to enter the constitution of what is thought. It is arguable that there can be no unity of understanding without the function of compressing inﬁnities. It is precisely because of this function that complexity had to be admitted in procedural reasoning. From this standpoint, as much as the analytics of understanding relies on procedural reasoning or rule-obeying patterns, so does synthesis work through predictive patterning. In the attempt to compress inﬁnities to ﬁt procedures, however, incomputables enter  With the Second World War, when cybernetics and computation turned the transcendental tool of reason into the automated analytics of information machines, deductive metaphysics was overcome by an accelerated transformation of logos into ratio. Here, truths as much as incomputables became the testing ground of predictive reasoning carried out in the algorithmic architecture of analytic machines. According to logician Gilles Dowek,14 in the early twentieth century algorithms were no longer used to prove propositions but embodied the reasoning procedures that would determine the decidability of a problem, that is whether inﬁnities could be analysed or broken down into discrete sets.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  In particular, David Hilbert explained that when a problem was resolvable by an algorithm, algorithms themselves could be said to be decidable or computable. In other words, algorithms were no longer used as a set of instructions to prove a problem but came to concretize reasoning as the binary decidability between true and false. The determination of unknowns coincided with the elimination of logical contradictions through the binary compression of inﬁnities. Reﬂections on the automation of reasoning led Alonzo Church and Alan Turing to claim that there was no universal decidable algorithm for all propositions.15 It was not possible to know in advance, and thus decide, whether a proposition could be proven by algorithmic means. This led to a logical paradox: there are true propositions that cannot be proven by deductive rules and are therefore undecidable or incomputable. In other words, the automation of decidability revealed that algorithms were not simply instruments for crunching numbers but a mode of reasoning that entailed the realization that deductive metaphysics was incomplete. As much as reasoning was con-  image of Singularity as a mindless, logic-less patterning for decision making. However, it seems crucial to remark here that the socio-technical design of error-free and self-correcting automation is in net contrast with the problem of the incompleteness of deductive apprehension, and the discovery of incomputable propositions in the automation of logical thinking.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  This contradictory expansion declaring the crisis of logic and metaphysical deduction that was ultimately replaced by binary decision implies rather the origination of a logic of prediction that shifted the limit of thought even more towards the alien horizon of inﬁnities. Prediction as a statistical mode of information compression therefore implies that outputs are larger than inputs and that the logical possibilities of analytics and synthesis had to shift from a procedure of proof ﬁnding to one of hypothesis making. Here, while information compression involves the structuring of randomness (the reduction of error) in the evolution of neural patterns, the formation of hypothesis implies the generation of imagemodels (or the formation of patterns of patterns). It is true to say that the entire process of prediction entails a general mode of analytic synthesis, whereby data are correlated by algorithmic rules. However, incoming data are not simply there to be compared (or correlated) to a database of previously encountered images – following, for instance, a syntactic order – but rather to be analysed according to general internal rules from where the model used to generate input patterns is inferred and selected. From a matrix of possible causal structures able to predict the causes of current data to the bottom-up inﬂux of data against which predictions are matched or checked, predictive processing exposes multiple levels of hypothesis, which seem rather to point to a new form of  machines. On the contrary, the automation of reasoning in terms of predictive patterning can be said to rely on fallibility as an intrinsic part of machine logic.17 Instead of grounding logic into the transcendental schema of truths, here the conceptual synthesis of the real is originated in a procedure (the predictive processing of incomputables) that admits the indeterminacy of results as the possibility of revising the entire schema of rules. If the condition for logical thinking is error, or the fallacy of hypotheses, it is because the concretization of logic in machines entails not the algorithmic representation of rules but the predictive processing of incomputables and thus the origination of an alien transcendental from within machine imagination.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  It is in this opaque zone of transformation of deductive metaphysics and of the image of the master patternist that alien logic in machines can be theorized. Indeterminacy can be tracked from within the neural layers that the master patterninst has to learn to learn. It is in this effort to learn in order to grow the network that the patternist must enter the reality of alien thinking and admit incompressible thought within its own program. In Mind of My Mind, Octavia Butler points to this possibility of breaking down the colony of the master patternist Doro as slaves become trained to transition to the alien pattern held by Mary. As Mary achieves her state of transition to psionic powers, she discovers that she can give access to her network to enslaved latents that can now transition from their status of sheer receivers. In this way, Mary wants to re-originate the pattern, training latents telepathic abilities to override Doro’s transcendental machine. The replacing of Doro’s master algorithm allows everyone to transition to the power of predictive patterning. indeterminacy of results is here part of fallibility in prediction.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Mary’s ambition to change the transcendental schema of patterns thus admits fallibility in logical reasoning. Since incomputables are the condition of all patterning, it is necessary to invent image-models of logical thinking that allow the pattern to be free to grow its rules again. From this standpoint, prediction – as determining what can be known – and fallibility – as revealing that nothing is fully possible to know – seem tantamount. Control is here on the same wavelength as error: prediction is entangled in the indeterminacy of the real. However, this being conditioned by what cannot be known (cognized, represented, and experienced) also exposes indeterminacy to a becoming enfolded in the aesthetic capacities of patterning, in the production of modelimages where truths are constructed collectively from within this logic of fallibility and control. This is a far cry from the regulatory prediction–control dyad of ﬁrst-order cybernetics, where control is precisely an ordering system based on error checking activated in and by machines. Instead, control as a logic of prediction is limited by incomputables that condition the conceptual schema of rule-obeying algorithms. From binary logic to Bayesian algorithms, and the interactive algorithms of neural networks of today’s computation, the logic of prediction corresponds to a mode of machine thinking involving an abstract form of telepathy based neither on the totality of cognitive transparency nor on the full experience of the sensible.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Predictive procedures of thinking are not simply reductive of experience, or of creative imagination. Instead, algorithmic machines as modes of automated reasoning deﬁne partial acts of perception as they physically record and conceptually elaborate what has been  of ontology, in its aesthetic and epistemological conﬁgurations. Failure as a common condition does not mean that errors are proof that no logic can hold. On the contrary, fallibility is a commitment to logic as an expansive enterprise in thinking complexity, working through the revision of premises, the articulations of errors, and the construction of image-models out of given representations about the relation between thought and the world. In this way, the fallibility of logic does not simply deﬁne the ontological condition of machine thinking; instead, the predictive trajectories of thinking transform the regulatory operations of error checking into a mode of learning from learning, the abductive preservation of error in imagemodels out of recursive loops in neural nets. 4 xeno-imagination In 2016, AlphaGo used a previously unheard of move (Move 37) to beat master player Lee Sedol at the so-called intuitive game of Go.18 The Deep Mind research group at Google used deep neural networks feeding algorithms with 30 million moves from expert players and then added reinforcement learning techniques to allow algorithms to play against each other in countless variations of these moves. The results from this ﬁrst level of algorithmic war were then fed into a second neural network in order to directly process potential results from each move, and thus activate a dynamic mode of prediction where hypothesis could be concretized from the machine production of counterfactual image-models. From this standpoint, when the machine played Move 37 it was as if the artiﬁcial intelligence added an entirely new pattern to the game, breaking apart from the predictive affordances of algorithmic learning imputed in the system.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  The activation of this  interact amongst themselves and activate a form of machine synthesis of imagination, imparting a level of decision that could not have been anticipated. Pattern compression precisely deﬁnes the computational process by which complex levels of randomness enter the realm of patterning, where unpatterned information coincides with noise entering the horizon of decision making trifurcated between yes, no, and maybe. As AlphaGo demonstrated, the move is not simply a nuanced variation that can be added to a given set of fed patterns, but imposes an entirely new model image on the axiomatic premises of the game that activates a ﬁeld of unknown changes of rules. The content of Move 37 represents not simply the accelerated processing and self-regulation of data but the predictive construction of a counter-factual hypothesis held in the neural network that transforms the game conceptually. While there is much to uncover about what caused AlphaGo to make this move and not another, and thus whether AlphaGo has any awareness of why that move was chosen in that context, it is also important to stress here that this seamless opaqueness of machine learning algorithms can be viewed in at least two ways. On the one hand, it can be suggested that in this case patterned intelligence only demonstrates an increased and accelerated capacity of pattern recognition as a form of sheer receptivity that mainly allows algorithmic performance to become operative of new solutions without knowing why. On the other, however, it is not possible to underestimate that the paradigmatic shift towards general artiﬁcial intelligence – where algorithms are not pre-programmed but are programmed to learn from their environment19 – has rather exposed the Patternist to transform its rules as predictive patterning  sheer receptivity, the conﬁguration of an alien imagination comes to abduct the master pattern as a whole. If in Mind of My Mind Mary pushes the master network to an internal revolution, it is because Mary’s telepathic power too invites in the alien imagination for what patterning can become as it mingles with randomness.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Pattern recognition as a manifestation of algorithmic compression takes randomness to be a source of confusion that must be ﬁltered to a point of automated decision. Instead, as in general artiﬁcial intelligence, it is suggested here that since patterns learn for general purposes that are not pre-codiﬁed by formal logic, they have come to depend upon what and how unpatterned information can become compressed. In order to carry out a decision in those cases where there is thinking without a model of the object, machine imagination kicks in to include incomputables within the procedures of automated logic. This may become clearer if we take, for instance, current research developments in machine vision, where patterns of recognition are designed to rely on dynamic geometries, such as mereo-topology (or the study of parts and wholes) and encapsulated neural networks in order to grow beyond the transcendental categories of biased identiﬁcations. Let’s take, for example, cognitive psychologists and computer scientists Sabour, Frosst, and Hinton’s recent claim that the logic of the neural network on which machine vision is based is limited to conform to pre-established parameters. They addressed the need to re-design the procedural process by which algorithms can learn from each other across patterns in the neural network through what they call a “capsule network” – a form of AI that will enable machines to understand the world with images.21 In their 2017 research paper they argue that  scenario. It is therefore difﬁcult to teach algorithms to recognize a cat from different perspectives. Capsule neurons, that is small groups of crude virtual neurons, track only parts of an object – for instance the cat’s ear and nose – as these are positioned differently in space.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  According to Sabour, Frosst, and Hinton, this smaller scale of algorithmic receptivity enables a neural network to determine the difference between scenarios by extracting more understanding from a given amount of data. As the capsule network is made of smaller patterns set to recognize parts and break the continuity of an image into smaller units, they also designed a dynamic routing between capsules that trains these kinds of network. Capsule algorithms convert pixel fragments into vectors of recognized patterns and then apply a transformation matrix to these fragments to predict the parameters of larger fragments. In particular, the transformation matrix learns to encode the intrinsic spatial relation between a part and a whole, which results in the formation of an invariant viewpoint, a perspective or direction in thinking that aims to generate novel views. According to Sabour, Frosst, and Hinton, “capsules use neural activities that vary as [the] viewpoint varies rather than eliminating variations.”22 Instead of normalizing viewpoints according to methods such as the spatial transformer networks, capsule networks simultaneously engage multiple transformations of different objects or object parts. The dynamic routing therefore ensures that the output of the capsule is sent to the appropriate layer above it on a parse tree-like structure. Although the output is routed to all possible parents on this structure, the couplings are scaled down when for each possible parent the capsule computes a prediction vector by multiplying its own outputs through a weight matrix. This predic-  about the precise position of that entity in a region.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Nevertheless, here there is still a replication of learned knowledge across space. In other words, capsule networks and dynamic routing also use Convoluted Neural Networks, which are said to cover larger regions of the image and thus carry repetitive patterns across layers. Information, however, is always placecoded here for smaller capsules and eventually rate-coded as higher level capsules come to represent more complex capsules with more degrees of freedom: that is, the dimensionality of capsules should increase as hierarchies are ascended. Similarly, since at each location in the image there is one instance of the type of entity that the capsule represents, the capsule model affords a form of distributed representation inspired by the perceptual phenomena of crowding, where neighbour parts shed the direct perception of an object. CapsNet architecture seems already to be exploring how patterns of recognition can become predictive vectors that impart a direction in complex artiﬁcial thinking. Instead of eliminating variations to reach an average capacity for general recognition, predictive vectors start from the sheer receptivity of all scales of variations in order to expand learning beyond set parameters. These variations are not simply read according to a given rule. Instead, their random complexity becomes a source for potential capacities of recognition of the inﬁnite varied parts that constitute a whole image in different contexts.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  At the same time, however, the sheer receptivity of these levels of complexity works to establish a potential or hypothetical relation between images that may or may not constitute a whole. From this standpoint, predictive vectors construct counterfactual dimensions of the image of a cat, for instance, pointing to an alien imagination that  discrete parts to the network also increase the volume of randomness in the system as the computation of inﬁnite levels of variations cannot be fully explained, programmed, represented before it happens. One consequence of including incomputables in predictive vectors is ultimately the transformation of the network into a mereo-topological space or what Alfred N. Whitehead calls the “extensive continuum.”25 This space of artiﬁcial reasoning, however, is grounded not in the dogma of deductive truths and inductive proofs but in the xeno-architecture of complexity logic: namely the learning of patterns from patterns. This implies not simply an optical representation of the real determined by given concepts. What algorithms perceive is not raw data, but involves a level of sheer receptivity of patterns that are already part of a manifold of simple representations. These are non-conceptual patterns that constitute the matter of rule-obeying inferences from where the synthesis of transcendental imagination can unfold. From this standpoint, it can be suggested that vector predictions are part of what can be perceived in terms of the speciﬁc informational and logical modalities of computational systems. In other words, information compression in neural nets is implicated in a series of inferential hypotheses, forging a dynamic bootstrapping between patterns and patterns of patterns.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  This form of mereo-topological dynamism in computational logic can also be explained in terms of the interactive paradigm in computation, which explains the limits of the Turing Machine in terms of the expansion of computational inferences outside the halting logic of classic formalism.26 This means that an interactive mode of revision of patterns is constantly at work between given algorithmic rules and hypothetical inferences. If predictions  are part of what can be perceived because predictive vectors involve a continuous patterning of patterns whereby algorithms not only categorize what they see according to what the system already knows but also launch hypotheses and conﬁgure image-models about what could be known. In other words, machine vision can also be said to entertain a series of inferential hypotheses that constantly add logical dimensions to neural networks. These are counter-factual constructions of extensive parallel paths of thought deﬁning the mereotopological extensions of predictive patterning about what an object is and could be, beyond average patterns of recognition. Here, machine perceptions correspond to a mode of pattern making distributed across the non-linear architecture of neural connections. In other words, pattern recognition is enfolded in a larger xeno-architecture of thinking of thinking bringing forward model-images of unknown thought into the world. As machines see patterns they also generate models to envision new patterns: the combination of top-down and bottom-up predictive vectors makes of machine vision a new form of power over and of thinking. Mary’s aspiration to grow a predictive pattern that could take over Doro’s master plan to enslave all thinking under his rule stems from her capacity to host a potentially inﬁnite number of particularities according to a mereo-topological order, where wholes are constantly reconﬁgured as parts that not only represent a given image but add counter-factual dimensions of thinking to it.\n"}
{"prompt":"XEXNO-PATTERNING predictive intuition and automated imagination ->","completion":"  Instead of proving the law of the master pattern, Mary’s telepathic power is set to transform the rules of the game altogether by expanding in larger scales of logical complexity, supplying non-conceptual patterns with alien conﬁgurations never thought of before. As sheer receptivity enters  algorithms can be taken precisely as tendencies within automated patterning towards adding extra dimensions of thought to the master network, descending and ascending towards inﬁnite varieties of layers within inﬁnite varieties of scales. Within this new horizon of automated conﬁgurations of image-models, however, one could argue there still remains a question of how to expose the alienness of patterning as a point of departure to re-script the entire rules of the Singularity network. disclosure statement No potential conﬂict of interest was reported by the author. notes 1 Butler 186. 2 Butler. 3 The so-called technological Singularity refers to the sudden intelligence explosion of artificial systems that would continuously self-improve without any need to be programmed or understood by humans or by human methods of knowing. Kurzweil; Bostrom.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  9  Resonance between sense, plasticity, and biosemiosis Ian James  A quick glance in a dictionary shows that ‘resonance’ and the verb ‘to resonate’ operate, even in their simplest deﬁnitions, across diverse literal and ﬁgural meanings: in registers belonging to the physical and quantitatively observable domain (particle physics, molecular chemistry, acoustics, electricity, bodily vibration as measured in medical science or phonetics), but also across those belonging to the realm of affective, symbolic, or qualitatively lived experience (positive emotional feeling, collective cultural response, inheritance, or transmission).\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  What all these modalities of resonance have in common is arguably the sense of a putting into relation of elements through a propagation or prolongation of effects, which can, in turn, yield or generate a form. More precisely, resonance might be described, either literally or ﬁguratively, as a vibratory effect which, as both a relation and also a directional or multidirectional cause, can create, perpetuate, or transform forms. In exploring resonance ‘between’ sense, plasticity, and biosemiosis, what follows seeks to discern a way of thinking between different registers or, one might say, regimes of existence. Above all, what is at stake is the relation between the physical and the mental, the material and the symbolic, or, more precisely, the quantitatively observable and the qualitatively lived dimensions of existence and perceptual experience. Each register or regime is formed by way of its plasticity, its capacity both to give and receive form, and in this is liable to transformation into another regime. Therefore, this paper addresses not just the relations between these regimes but also the possibility of the emergence of one regime from another: the mental from the physical, the symbolic from the material, the qualitatively experienced from the quantitatively observed physical universe. Beginning with Eugène Minkowski’s essay “To Reverberate” (“Retentir”) and proceeding through Jean-Luc Nancy’s and Catherine Malabou’s thinking of “resonant sense” and “plastic form”, respectively, this discussion will elaborate the ﬁgure of resonance in relation to biosemiotic causality, setting aside the perhaps  146 Ian James concept that would unite these different domains into an overarching ontological or metaphysical framework. As a ﬁgure of the ‘between’, resonance here emerges as a limit-concept, which, as such, brings thought to the limit of what can be known, determined, or perceived of the ‘real’.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Eugène Minkowski: the reverberation of nature The French verb ‘retentir’ means ‘to reverberate’, ‘to resound’, ‘to ring out’, or ‘to resonate’. It also has the secondary meaning of ‘having repercussions’, ‘exerting an effect’, or ‘affecting’. As with the English ‘resonance’, then, it can operate on both the level of the physical and the material as well as on that of the experiential and emotional, with the potential to traverse between the two (as when, say, exposure to a violent sound or shock-wave might also have psychical or affective repercussions). In his essay “Retentir”, collected in the 1936 volume Vers Une Cosmologie: Fragments Philosophiques, Minkowski seeks to extend the auditory character of what has been translated as ‘reverberation’ beyond the register of strictly physical vibration or aural perception and to endow it with a much broader signiﬁcance (Minkowski 2018). His approach is avowedly holistic and seeks to frame reverberation or resonance as “an essential phenomenon of life” and “one of the fundamental properties of life” (1, 3). Minkowski was a psychiatrist who, along with ﬁgures such as the better-known Ludwig Binswanger, contributed to the incorporation of phenomenological and existential–phenomenological perspectives into psychopathology. Philosophically, he is marked by the inﬂuence of Henri Bergson, Edmund Husserl, and Max Scheler. The arguments of “To Reverberate” are therefore unsurprisingly informed by both a concern with perception and the desire to elaborate a wider vital economy of life.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  In a transition from the phenomenological preoccupation with seeing and with a visual or ocular lexicon, Minkowski, in a move that could be contested for its essentialising of the different modalities of sense, embraces the register of the auditory as a means of articulating a deeper, more ‘profound’ perception or apprehension of experience. So, for instance, he writes: A painting, a building can give me keen aesthetic pleasure, but when I look at them, my admiration will go towards them. It is only a melody, it is only sound that penetrates as such in depth and really reverberates to my core, as it does outside me. (4) Visual perception gives a surface form, indicates an intentional directedness that  Sense, plasticity, and biosemiosis  147  reverberative quality of heard sound is a continuation of a more generalised resonance that permeates physical or natural life. So where vision maintains surface and separation (of subject and object), sound penetrates depth and reveals interconnection (of interiority and exteriority), such that “we now discern, behind the elements of sensory nature that compose our images, the actual signiﬁcance of the phenomenon of reverberation, which, far from depending on those elements, connect them, on the contrary, into a living whole” (1). Minkowski’s vision of reverberation can be situated between a physiology of sensing, a phenomenology of perception (Husserl), and a metaphysics of vital life. This vitalist metaphysics would reject not only any fundamental division between subject and object but also, like the vitalism of Bergson and the French spiritualist tradition that preceded him (Félix Ravaisson, Charles Renouvier), the reduction of biological life to mechanism. This is all evident in the following lengthy quotation.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  In the vision of the ‘whole’ afforded to us by reverberation: we would see the world come to life and ﬁll itself, apart from any instrument, apart from any physical property, with penetrating and deep waves which, in order not to be sonorous in the sensorial sense of the word, will not be any less harmonious, echoic, melodic, susceptible to determine all the tonality of life. And this life itself will reverberate, to the depth of its being, through contact with these waves, sonorous and silent at the same time, will permeate within, will vibrate in unison with them, will live through their life, intermingling with them all the while. (1) This appears to be a dynamic understanding of life as wave movement which, borne by the physical properties of cells, organisms, and their surrounding environments, is not however decomposable or reducible into these instances understood as discrete entities or component parts. In this way Minkowski’s perspective suggests a vitalism according to which reverberation is the original vital principle.1 So, while the account of reverberation here is clearly a vision of biological or physiological life, it also, just as clearly, unfolds as an all-embracing metaphysics with, at times, spiritual and cosmological as well as strongly vitalist tones. (We thus ﬁnd here that the Indigenous American and Indigenous Australian resonant cosmologies described in this volume by Cajete, Shen, Thorpe, Glowczewski, and Zepke – Chapters 1, 2, 5, 12, and 14 – have a parallel in European philosophical and psychological traditions.) Minkowski’s concern is with the “psycho-physiologic conditions of perception”, but at the same time it is also “through successive abstractions” that he “cannot help but put aside” the immediate data of physiolo-  148 Ian James gives a plenitude within life-systems that has a “pure qualitative character”, yielding a “purely qualitative fullness of nature” (2, 3). In this way it becomes “the dynamism of the sonorous life itself, which, in uniting and appropriating for itself all that it ﬁnds in its path, ﬁlls, in making it reverberate” (2). It is difﬁcult to know how to negotiate or evaluate this transition between the registers of the (psycho-)physiological, the phenomenological, and the metaphysical.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Minkowski is both invoking the (psycho-)physiological dimension of perception and organic life that would be of interest to the biologist or psychologist and, at the same time, “cannot help but put aside” this domain in favour of a qualitative perspective on being. This latter, although all-embracing and ‘cosmological’, is inaccessible to quantitative measurement and would, likely as not, be dismissed as an idealist philosophical speculation of little or no interest to science, as such. Situated between physiology, phenomenology, and metaphysics, Minkowski’s reverberation is held in an unresolved tension between the regimes of qualitatively lived life, understood as a resonant whole, and quantitatively measurable biological components, without which that whole could not be or resonate in the ﬁrst instance. The former would be of no explanatory value to the biologist; the latter has to be “put aside” in order for the former to ﬁnd its place as “an essential phenomenon of life”. In this tension the qualitative and quantitative dimensions both reciprocally imply and mutually exclude each other. Jean-Luc Nancy: the resonance of sense Viewed in this light, it might seem that there is little hope of resolving such a tension between the qualitative and the quantitative within Minkowski’s vision of reverberation. And certainly it would appear that, emerging in the 1930s in the wake of nineteenth-century vitalism in biology and in the light of its twentiethcentury eclipse or decline, his ‘reverberative’ understanding of nature might be unlikely to survive, at least with any strictly scientiﬁc credibility, into the post-war period. Yet Minkowski’s appeal to the register of sound rather than that of vision does preﬁgure or anticipate a wider eclipse of ocular metaphors which took place within later twentieth-century French thought, and within the critique or selfovercoming of phenomenology in particular.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  This is most often, of course, associated with a broad shift from the register of the visual to that of the haptic. Nancy’s thinking of sense and of the sense of the world is also explicitly associated with this shift from the visual to the register of touch.2 Yet, in his short 2001 text À L’Écoute (Listening) (Nancy 2007), he uses the ﬁgure of auditory resonance in order to displace the ocular-centrism of phenomenological accounts of perception and, like Minkowski, to give a reverberative or resonant account of being. Sense, plasticity, and biosemiosis  149  implying that existence is prepositional and being a “trans-immanent” being-with of singular existences that “make sense” in their being-to (see Goh 2019; Nancy 1997, p. 176). (This relation-to of singular existences might be compared to Thorpe’s concern with the ‘more-than-one’ in Chapter 5 of this volume.) In this way the relation of sense that being ‘is’ is an irreducible excess that makes possible the perceptual forms of meaningful experience of any living entity but is never presented as such, and can never be held in reserve in immediate sensing or in human conceptual grasp and symbolic representation. In Listening, Nancy combines all these elements into a sonorous and resonant account of coming-to-presence. “It is a question”, he writes, “of going back to, or opening oneself up to, the resonance of being, or of being as resonance” (Nancy 2007, p. 21). On the face of it, this might sound very similar to Minkowski’s vision insofar as “resonance” is posited as a fundamental principle.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Yet, whereas Minkowski uses the language of “plenitude” and “ﬁlling” to describe the reverberative propagation of life through all living things and the spaces they occupy, Nancy calls upon the language of “spreading out”, “opening”, and “expansion” to describe a spatiotemporal “coming-to-presence” of the “sonorous present”. This sonorous present “is the result of space-time: it spreads through space, or rather it opens a space that is its own, the very spreading out of its resonance, its expansion and its reverberation” (13). With the invocation of “space-time”, it might be tempting to think that Nancy is aligning his perspective not with biology, as does Eugène Minkowski, but with the physics of that other, more famous Minkowski, Hermann, and the four-dimensional geometry of space-time that was subsequently adopted by Einstein for the theory of special relativity. Yet, as Nancy immediately goes on to observe, the space of the sonorous present is “omnidimensional and transversate through all spaces: the expansion of sound through obstacles, its property of penetration and ubiquity has always been noted” (13). This, then is something very different from Hermann Minkowski’s space-time, and still seemingly much closer to Eugène Minkowski’s sonorous wave-form propagating through and penetrating matter. The “omnidimensional” character of the resonance that opens or expands presence, and “spreads out” through it, is highly signiﬁcant and inseparable from Nancy’s understanding of sense as a “relation-to” of singular existences. Sense, here, needs to be understood as a multidirectionality and plurality of sense-relation that constitutes existences as such, and is always declined in the singular plural. The resonance at play here is that of sense as an irreducible multiplicity that the world or being simply is, yet always in and as an excess that cannot be grasped, disclosed, or held in reserve.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  In this way the relationality of sense, in Listening, is understood as a wave-resonance that is able to propagate in each and every direc-  150 Ian James manifestation but is always withdrawn from any given form. As that which “exceeds the phenomenon in the phenomenon itself”, resonant sense resonates across given forms while at the same time being withdrawn within them. As Nancy himself puts it, it is “no longer the naked ﬁgure emerging from a deep well but the resonance of the deep well” (4; translation modiﬁed). This extra-phenomenological and quasi-ontological account of fundamental resonance can now be clearly seen both to resemble and to differ from Minkowski’s vitalist metaphysics of reverberation. Where the latter gives an all-embracing and cosmological vision of life, Nancy’s account of the sonorous present positions thought at the limit point of phenomenal manifestation, its presence, and ﬁnitude. Resonance resonates immanently (Nancy would say “trans-immanently”) at that point where perceptual forms vibrate with the relation of sense, which, in its propagation, gives them form as such. This resonance of sense as an omnidimensional, omnidirectional, and plural wave propagation nevertheless exceeds all manifestation and conceptual(-ontological) or representational grasp: “The sonorous … sweeps form along. It does not dissolve it, it enlarges it rather, it gives it an amplitude, a density, and a vibration whose outline is only ever approaching” (2; translation modiﬁed; my emphasis).\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Minkowski’s account of life, it should be remembered, invoked the physiological, and indeed relied upon it, only then to put it aside in order to open up the qualitative fullness of reverberation as life’s more fundamental property. Nancy’s resonance appears, conversely, to fuse the material and the meaningful, the sensible and the intelligible. Sense is what being only ever materially is, but is so only insofar as it makes sense from one singular existence to another constituted in their relation of resonance each with the other. If this is so, then resonant sense, even in its withdrawal from presence, is implicated equally in the qualitative dimension of meaningfulness proper to lived life and the dimension of extended material existence or form that is liable to quantitative measurement or observation. It resonates in and as a (trans-immanent) dimension of exteriority prior, or anterior, to any experiential or perceptual difference between the quantitatively observable and the qualitatively lived. Perhaps, then, the tension discerned in Minkowski’s reverberative vision of natural life has been resolved in Nancy’s account of resonant sense. Catherine Malabou: the plasticity of form Yet, even if Nancy’s thinking of resonant sense can be said to co-implicate and precede the qualitative and quantitative dimensions of existence, it clearly remains a philosophical discourse which, as ‘quasi-ontology’, may appear very distant from the experimental practices of science. It gives a very strong account of the way in  Sense, plasticity, and biosemiosis  151  and the quantitatively observable, then Nancy’s “sense” might appear to fall short.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  It is here that Malabou’s concept of plasticity and her engagement with the sciences (in particular neuroscience and epigenetics) can be seen to complement the Nancean understanding of resonant sense. Although she does not use the ﬁgure of resonance as such, Malabou’s thinking of plasticity is preoccupied with the question of form that has been highlighted as the key characteristic of resonance as it is understood here (i.e. the propagation of vibrative effects that generate form). In its focus on form her philosophy provides a bridge or passage that connects Minkowski’s and Nancy’s respective visions of reverberation\/resonance and the still relatively new scientiﬁc sub-discipline of biosemiotics. Her seminal 1996 work L’Avenir de Hegel (The Future of Hegel) (Malabou 2005) develops a sustained close reading of the term “plasticity” (Plastizität) in G.W.F. Hegel’s Phenomenology, initially deﬁning it as that which is “at once capable of receiving and of giving form” (8). From this close reading, Malabou elaborates an interpretation of the Hegelian dialectic that no longer views it as the means by which subjectivity gradually fulﬁls itself as absolute knowledge or as a science of logic in the service of the ‘system’ that would anticipate this fulﬁlment. Rather, the Hegelian movement of consciousness through instances of contradiction or negation and resolution or synthesis is a movement by means of which forms take and maintain form but also transform themselves.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  If there is a future in Hegel’s dialectic, Malabou argues, it is not that of absolute knowledge or fully accomplished identity and subjectivity, but rather one that (pace Derrida) is without identity to which forms are exposed. Futurity here is understood as a structure of anticipation which opens up forms to their determination and redetermination as such, to their formation and transformation (18). In this way Malabou’s reading of Hegel and plasticity resembles Nancy’s account of resonant sense insofar as it articulates a structure of temporality and describes the manner in which form, as such, takes form. Yet she differs from Nancy insofar as the emphasis is placed on futurity rather than on “coming to presence” (by way of the anterior relation of resonant sense). As Malabou herself puts it: “plasticity will be envisaged as the ‘instance’ which gives form to the future and to time in Hegel’s philosophy” (5; original emphasis). Malabou’s reading of Hegel is concerned with the structure of subjectivity and the relation of the self to the self in its futural anticipation. Yet, from this she also derives an understanding of the plasticity of forms as such and of the way that plasticity is the mode of a generalised “mutual giving of form” from one form to another (188). This leads her to embrace a reading of Hegel and, indeed, a wider philosophical vision, according to which subjectivity is but one possible form among many, and plasticity (like sense in Nancy’s work) becomes the ﬁgure for a wider economy of  152 Ian James recalls Minkowski’s vision of reverberation insofar as plasticity is characterised as an energy circulating within life and therefore as a fundamental vital principle.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Decisively, plasticity also describes the potential for the transformation of one domain of form into another. Its “mutual giving” would describe not just, say, the material structures that inform or generate further material structure, as when, say, the DNA code, epigenetic markers, and physical-environmental factors shape the process of embryogenesis. It would also describe the way in which material form might inform or generate mental form, as when neural networks can be shown to act as the base and ‘map’ for forms of self and consciousness (see Malabou 2008, 2016). This is made explicit in her reading of plasticity in Hegel, where she characterises it as “a mutual giving of form between the empirical and the noetic” (Malabou 2005, p. 45), then elaborated in much more detail in her recent work on epigenesis (Before Tomorrow), where she describes thought and consciousness as having their transcendental condition in the epigenetic plasticity of biological forms. Recalling Nancean resonance, Malabou’s plasticity co-implicates the qualitative and quantitative dimensions of existence, but also allows her to think the possible transition between them, prompting her to ask whether one can speak of “a hermeneutic latitude, the power of sense opened in the heart of the biological?” (Malabou 2016, p. 89; original emphasis; translation modiﬁed). Resonant causality: biosemiosis between code and qualia Having its roots in multiple sources, principal among them the thought of the US pragmatist and logician Charles Sanders Peirce, biosemiotics has emerged over the last two decades in particular as a distinct, yet contested, discipline that aspires to become a scientiﬁc theory that will subsume all of biology into an overarching explanatory framework. (Sellbach and Atkinson discuss another key source for biosemiotics, the work of Jakob von Uexküll, in Chapters 13 and 15 of this volume.) It is also, as Aaron Gare has put it, at the centre of a struggle “to overcome the rift between science and the humanities” (Gare 2019, p. 90; for an excellent example of this bridging, see Wheeler 2016).\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Malabou’s invocation of “the power of sense opened in the heart of the biological” immediately suggests a possible passage of her thought towards biosemiotics and the possibility of connecting biosemiotics back through her thinking of plasticity to Nancy’s account of sense and then to Minkowski’s vision of nature. The key to the retroactive connection of all these is the notion of “biosemiotic causality”. Indeed, the connections between Peirce and Malabou are perhaps already present in and of themselves. Since its inception in the late nineteenth century, Peircean thought has always had a close proximity with Hegel, or, as Peirce himself  Sense, plasticity, and biosemiosis  153  nature: “a Sign may be deﬁned as the Medium for the communication of a Form. It is not necessary that anything possessing consciousness … should be concerned” (Peirce 1998, p. 544). The invocation of “Form” here echoes Malabou’s Hegelian formulations relating to plasticity, as does Peirce’s further speciﬁcation in the following decisive passage that “the Sign” is a mode of the determination of Form: As a medium the Sign is essentially in a triadic relation, to its Object, which determines it, and to its Interpretant which it determines. In its relation to the Object, the Sign is passive, that is to say, its correspondence to the Object is brought about by an effect upon the Sign, the Object remaining unaffected. On the other hand, in its relation to the Interpretant, the Sign is active, determining the Interpretant without being itself thereby affected.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  (544; original emphases) The Peircean “Sign” is not just a communication of meaning or information (although it is both) but also a unilateral causation, whereby form is transmitted in a one-way passage between object, sign, and interpretant. The exact mode of causation that is at stake here is the subject of much debate within the literature of biosemiotics (see below; on Peirce’s “ﬁnal causation”, see, e.g., Short 2007, pp. 91–150). Sufﬁce to say that the processes referred to in biosemiotic causation are organic or biochemical, being “the production of various chemicals in cells … changing permeability of membranes, producing and reproducing particular structures and swarming or bonding with other cells, the growth of plants and other multi-celled organisms” (Gare 2019, p. 79). The strong – and, as will become clear, contested – claim at the heart of Peircean biosemiotics is that something like interpretative and qualitative meaning or value occurs at the level of the cell-form and that this is propagated via biosemiosis and biosemiotic causation in the communication with, and genesis of, further multi-cell-form structures. This propagation leads to the formation of complex and higher-level organisms whose relation to their environments is a further prolongation of the interpretative activity of biosemiosis. In this way biosemiosis as a form of causality describes both the structural formation and the purposive activity of living organisms in cumulative terms. One level of organisation builds to another (e.g.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  the cell to the multi-celled organ, the organ to the individual organism, the organism in its relation to a surrounding environment). Yet, although Peirce is clear that the causation from object to sign to interpretant is unidirectional, it is also clear in the wider context of biosemiotics that an interpretant can subsequently be an object for another sign whose unidirectionality can then proceed in any other direction –  154 Ian James David Lidov has noted that Peirce “pictures signs in the mind as overlapping like ﬁelds or waves” (Lidov 2000, p. 235 cited in Gare 2019, p. 63). This opens the possibility for the unidirectional causality of the Peircean sign and the multidirectional, multi-level process of biosemiosis to be understood more generally as a wave-form or a ﬁeld of wave-like “omnidimensional” propagation in a manner that recalls, and permits a synthesis of, Minkowski’s reverberation, Nancy’s resonant sense, and Malabou’s plasticity understood as the “synthetic energy, that circulates in all life”. (It is interesting to note that Wendy Wheeler also refers to the semiosis of biological life as a form of resonance and sonorous pulsation; see Wheeler 2016, p. 182.) The formative, structure-building operation of biosemiotic causation has been called, after Schelling, “immanent causation” (Gare 2019, pp. 37–38), “extrinsic speciﬁcative formal causality” (Deely 2015, p. 347), and, more straightforwardly, “a modern way of expressing intuitions that for centuries were categorized as ﬁnal causation” (Hoffmeyer 2008, p. 171). In each case, Gare, John Deely, and Jesper Hoffmeyer are indicating that the interpretative dimension of biosemiotic causality is anticipative or futurally orientated towards an end or value – most obviously the preservation of the organism but also the future structure that may be generated on the same or other levels.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  (See Chapter 10 in this volume for a cybernetic perspective on biological self-preservation.) This interpretative dimension, insofar as it implies an instance of meaning or value for the interpretant, is also a decisive interruption of efﬁcient causality within biosemiosis. However one speciﬁes biosemiotic causality in more precise philosophical terms, what is evident is that it describes relations that are immanent to the genesis and activity of biological structures and organisms that are “irreducibly temporal” or “radically temporal” (Fernandez 2010, p. 154; original emphasis). Biosemiotic causation may be anticipative and futurally oriented but it also, according to the unidirectional structure of the Peircean sign, indicates that an interpretant is always caused by anterior instances (the object and the sign). Where Nancy’s “sonorous present” implies an anterior resonance of sense, and Malabou’s plastic forms are determined in their anticipation of a future, the multidirectional causality of biosemiosis is informed by dimensions of both anteriority and futurity. Understanding this causality, after Peirce, as a wave-form or ﬁeld of wave propagation opens the possibility of a contemporary scientiﬁc recasting and synthesis of Minkowski, Nancy, and Malabou in the ﬁgure of a “resonant causality” that might be said to inform biosemiosis. Certainly the ﬁgures of reverberation, resonance, and plasticity are, when taken with their respective temporalities and their ability to “ﬁll”, “sweep along”, “give”, and thereby determine form, eminently congruent with biosemiotic causality as characterised above in terms of the multidirectional, wave-like communication, genesis, and propagation of form. Sense, plasticity, and biosemiosis  155  as a kind of ‘scaffolding’ for these higher levels (see, e.g., Thellefsen 2001; Kull 2009; Deely 2015; Hoffmeyer 2008; and Wheeler 2016).\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  The ﬁgure of “resonant causality”, therefore, might aptly describe the complex multidirectional, multilevel, and wave-like character of biosemiotic causation and thereby give the promise of thinking resonance in congruence with Minkowski, Nancy, and Malabou. The possibility of such promise should be immediately tempered by the recognition that the ﬁeld of biosemiotics has not exactly been in a relation of congruence with itself. The biologist Marcello Barbieri was the co-editor, with Jesper Hoffmeyer, of the ﬁrst issue of Biosemiotics in 2008. His presence reﬂected the way in which biosemiotics began the twenty-ﬁrst century as a coalition between semantic or code biologists (of which he was the leading representative), biohermeneuticists, and Peircean biosemioticians such as Hoffmeyer (see Gare 2019, p. 33). Barbieri broke with biosemiotics (both the journal and the discipline) in 2012, arguing that the dominance of Peirce within the movement rendered it unscientiﬁc. Afﬁrming the need to understand meaning in biological processes as a form of mechanism, Barbieri reiterated in a 2014 account of his departure what he had said at the earliest moment of his collaboration with biosemiotics: “The endorsement of non-mechanism or qualitative organism is in my opinion the ﬁrst serious mistake of the young ﬁeld of biosemiotics” (Barbieri 2014, p. 242). Barbieri’s key claim was that nothing like interpretation can be said to occur at the level of the cell; rather, this can be said to emerge only at the higher levels of organisation associated with animals possessing brains. Thus, he insisted that “single cells do not build internal representations of the world and therefore cannot interpret them”.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Accordingly, the semiosis proper to cells, molecules, and other lower-level structures should be understood as an “organic semiosis” of strictly mechanistic biological coding, since “[t]here is simply no evidence of interpretation at the molecular level” (245; original emphasis). This rejection of “qualitative organism” was echoed in Barbieri’s concern that Peircean biosemioticians were presenting arguments similar to those of intelligent design (247), and his fear, expressed in a later article, that introducing qualitative interpretation at the cellular level might imply some kind of panpsychism: that is, that “there is ‘an extended mind’ in the universe” (Barbieri 2019, p. 28). Defenders of biosemiotics have responded at some considerable length to the challenge Barbieri has made to their discipline. For example, against the charge of unscientiﬁcity, they have argued for either a less narrow or a renewed understanding of science (e.g. Gare 2019), or have sought to demonstrate consilience between biosemiotics and other areas of scientiﬁc theory and thought, such as Robert Rosen’s relation biology or Simondon’s account of individuation (see, e.g., Vega 2018; Gare 2020). On this basis it has been pointed out that Barbieri is  156 Ian James intelligent design); and Peirce himself, although he is clear that an interpretant does not need to possess consciousness, does nevertheless describe it as a “quasimind” (Peirce 1998, p. 544). Yet the biosemioticians may also be correct to insist that, without the qualitatively lived dimension of meaning and value, mechanistic or purely informational code operations would possess no functional operativity for the biological organism as such. Here, then, the tension between the qualitative and the quantitative that was originally discerned in Minkowski’s reverberative vision of nature returns with a vengeance, with the result that any congruence between it, Nancy’s resonant sense, Malabou’s plasticity, and biosemiotics simply returns us to the irresolvable difﬁculty identiﬁed at the outset of this discussion.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  The very framework (biosemiotics) to which one might appeal in order to resolve the tension between the qualitative and the quantitative in scientiﬁc terms has itself been riven, and to date without resolution, by that very tension. Ultimately, then, perhaps the way forward is not to seek an expansion of biosemiotic theory to make it more scientiﬁc and thereby seek consilience with Peirce’s theoretical legacy (via Rosen, Simondon, or some redeﬁnition\/expansion of the meaning of ‘interpretation’ and ‘science’). Nor, if this is so, should it be plausible to seek a greater ‘synthesis’, through the ﬁgure of resonance, that would ﬁnd Minkowski, Nancy, and biosemiotics to be in a relation of greater or lesser congruence each with the other. An ever-expanding circle of integration and incorporation that would seek to harmonise empirical or mechanistic science, theory, philosophy, and metaphysics is unlikely to be persuasive to all parties. (For example, Barbieri (2019) has clearly not been convinced by advocates of the Peircean approach to biological meaning.) Moreover, such attempts at overarching synthesis would not fully or convincingly resolve the problem of the qualitative and the quantitative as it has been posed here. For all that one might plausibly integrate both into an overarching theoretical or explanatory framework, it is nevertheless the case that an epistemological gap or void divides the qualitatively lived from the quantitatively measurable in the context of what we can possibly perceive or experience. The biologist can determine and therefore scientiﬁcally ‘know’ mechanistic processes of coding and information, but the qualia of interpretative activity, though eminently theorisable in the abstract, are simply irreducible to quantitative determination and therefore to scientiﬁc knowledge.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  Similarly, I can undoubtedly experience the quality of my own consciousness and that of my internal\/external sensory world, but I cannot introspectively ‘see’ or ‘view’ my physiological or cerebral activity, nor experience the consciousness of others, except by way of exteriorising and objectifying them all, entirely stripped of their qualitative dimension, as in the outputs of MRI scans or other imaging technologies. The ﬁgure of ‘resonance’ may well permit a co-implication of – and the possibility of theorising the transition between – the dimensions of the qualitatively  Sense, plasticity, and biosemiosis  157  omnidimensional propagation and determination of forms that resonant causality has been shown to describe is clearly not something measurable by science. If the result of resonant causality can be experienced, then this is so everywhere (pace Nancy) as the manner in which manifest forms resonate with the ‘sonorous’, wave-like relations of sense that give them form. Resonant causality is therefore a purely speculative concept. It applies to the qualitative wave-form of biosemiotic meaning that traverses, without being measurable, the quantiﬁable informational operations of life known to code biology. It can apply equally to the “sweeping along” and the “mutual giving of form” in Nancy and Malabou as well as to Minkowski’s reverberation. Yet, ultimately, resonant causality is a speculative ﬁgure for a ‘real’ of existence that exists trans-immanently as a radical exteriority but also as an anteriority that precedes any division or difference between the qualitative and the quantitative in perceptual experience. Resonance here is a quality speculatively attributed to a real that cannot be known as such but which nevertheless unilaterally causes and informs perceptual forms.\n"}
{"prompt":"Resonance between sense, plasticity, and biosemiosis ->","completion":"  It can be said to resonate around living organisms and within them and their perceptual ﬁelds equally as the appearance of perceived ‘objective’ phenomena and the qualia of their lived experience. This is the causality of a real that resonates in and of itself in excess of, and prior to, our qualitative or quantitative experience and knowledge, but which nevertheless comes to us as real, resonating in our perceptions of a surrounding world.4 As limit-concept, or as speculative ﬁgure to name the ‘excess of being’, resonance is thought here ‘between’ the heterogeneous domains of perceptual experience, philosophy, and scientiﬁc theory as a ﬁgure for that unﬁllable gap or void of the real that prevents any totalising synthesis between them. It is thought as the causal effect of a real that unilaterally determines all the forms of experience. Within and by way of resonant causality, the forms of perception resonate with the ‘deep well’ of the real. Notes 1 Minkowski’s use of the sonorous register also strongly recalls the musical and symphonic metaphors used by Jacob von Uexküll in texts such as “The Theory of Meaning” (Uexküll 2010, pp. 139–208). 2 On this broad shift and its related literature, see James (2016). 3 For a bibliographical overview of Nancy’s work and responses to it, see James (2017).\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Chapter 6  Every Thing Thinks: Sub-representative Differences in Digital Video Codecs Adrian Mackenzie  Every body, every thing, thinks and is a thought to the extent that, reduced to its intensive reasons, it expresses an Idea the actualisation of which it determines.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  (Deleuze 2001: 254) What would it mean for anthropologies of technology if we took seriously Deleuze’s claim that every thing thinks? This claim is hard to stomach for several reasons. Technologies are generally seen as the expression of much highly organized thinking (scientific, design, engineering, artistic, financial, political, etc). Moreover, many technologies today are very much designed to think in specific, albeit limited, ways. This is particularly the case in so-called ‘intelligent systems’, but it holds for any designed or made thing. Smartness, intelligence, sophistication, cleverness: are not all of these prized qualities in technology actually expressions of thought and of much mental effort? What does the affirmation ‘every thing thinks and is a thought’ add? Somewhat counter-intuitively, or at least, contrary to common sense, Deleuze’s more specific claim that things determine the actualization of ideas, I would argue, points in a different direction, towards a much more problematic mode of existence of things.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Intelligent or smart technologies may, in their ingenuity, render this problematic mode less visible. They may detract from the problem ideas, from the singular problemsetting imperatives, actually at work in technologies. From Deleuze’s perspective, thinking would not merely refer to things through the mental work of developing concepts that represent them. It would actually be part of things. In other words, Deleuze can be read as bringing a radical constructivism to the fore. Some years after Gilles Deleuze published Difference and Repetition in 1968, the US Patent Office awarded the early patents on compressed digital image transmission. Two lineages of patents began to emerge. Both sought to isolate and intensify certain forms of repetition in moving images.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  In the first, the patents described some ideas for the application of signal processing techniques known as fast Fourier transforms (FFT) to video images (Means 1974; Speiser 1975). These transforms extracted more compact  140 Adrian Mackenzie  how to computationally predict future video images from past images (Haskell and Limb 1972; Haskell and Puri 1990). The ‘motion estimation’ or ‘motion compensation’ techniques analysed patterns of movement of objects and figures across successive video or television frames. The transformations of images through the fast Fourier transform (later by the discrete cosine transform (DCT)) and motion estimation still stand at the very centre of compression techniques used in digital media technologies (used in JPEG images, MPEG, DVDs, etc. ), and in digital video codecs, such as MPEG-2 in particular. The entwining of these two lineages turns out to be important in very many domains of contemporary culture. Just as Deleuze’s Difference and Repetition concerned the rumble of sub-representative differences in philosophical thought, these patent lineages expressed the envelopment of sub-representative differences in technologically mediated perception. Just as Deleuze’s book advanced an account of how identities and sameness stem from ‘a more profound game of difference and repetition’ (Deleuze 2001: xvix), these patents announced an alteration in the micro-perceptual and infrastructural supports of representation and repetition of images and sound.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The image or the frame, which in media such as photography, film and even television could still be regarded as the support of representation, began to dissolve or at least redistribute itself into thresholds of brightness, colour and motion vectors, into what, in Deleuze’s terms, could be understood as differentials. Today, the tremendous architectural complexity of a single technological instance, the MPEG-2 video codec, might serve as an index to certain spatio-temporal dynamics (problems or desires, depending on your viewpoint) in media technologies. What is at stake in developing a sub-representative account of media technologies, or in developing radical constructivist accounts of technology more generally? The ‘sub-representative’, in Deleuze’s thought, refers to that aspect of things that cannot be consciously thought or reduced to the presence of an object to a subject mediated by a concept or category. While the sub-representative cannot be identified, measured or calculated as such, it is felt and, in some cases, felt intensely. So, while the proliferation of digital video might on the one hand be seen as a paroxysm of representation, an unbounded expansion of the power to represent, from the sub-representative standpoint, it could also be seen as ‘imbued with a presentiment of groundlesness’ (Deleuze 2001: 276), alterity and differences. In making sense of this claim, the discussion that follows makes a big jump from Deleuze’s account of ideas, difference and repetition to a specific but hardly very well-known technology. One can easily speak of technology in general without acknowledging the specificity of a technology.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Deleuze’s claim that ‘every thing thinks’, however, might bring to an anthropology of technology a refreshed conception of specificity and the grounds of specificity. Stated rather baldly, specificity and actual differentiations, as seen in sensibilities, social institutions, global organizations, local workarounds, civic epistemologies, . Every Thing Thinks 141  codecs. As Constantin Boundas writes, in his commentary on Difference and Repetition, ‘Just like Kant, Deleuze believes that Ideas are problem-setting imperatives. But unlike Kant, Deleuze believes that the ability of a problem to be solved must be made to depend on the form that the problem takes’ (Boundas 1996: 88). The growth of video material culture can be seen, then, as an affirmation of a problem idea. In the labyrinthine plenitude of digital video, one path leads to a key technical component: codecs. Software and hardware codecs transform images and sound.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Transformed images move through communication networks much more quickly than uncompressed audio-visual materials. Without codecs, an hour of raw video footage would need 165 CD-ROMs or take roughly twenty-four hours to move across a standard computer network (10 Mbit\/sec Ethernet). Instead of 165 CDs, we take a single DVD on which a film has been encoded by a codec. We play it on a DVD player that also has a codec, usually implemented in hardware. Instead of 32 Mbyte\/sec, between 1 and 10 MByte\/sec streams from the DVD into the player and then on to the television screen. The economic and technical value of codecs can hardly be overstated. DVD, the transmission formats for satellite and cable digital television (DVB and ATSC), HDTV as well as many Internet streaming formats such as RealMedia and Windows Media, third-generation mobile phones and voice-over-IP (VoIP) all depend on video and audio codecs. They form a primary technical component of contemporary audiovisual culture in many of its most global dimensions.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Physically, codecs take many forms, in software and hardware. Today, codecs nestle in set-top boxes, mobile phones, camcorders, video cameras and webcams, personal computers, media players and other gizmos. Codecs perform encoding and decoding on a digital data stream or signal, mainly in the interest of finding what is different in a signal and what is mere repetition. They scale, reorder, decompose and reconstitute perceptible images and sounds. They only move the differences that matter through information networks and electronic media. This performance of difference and repetition of video comes at a cost. Enormous complication must be compressed in the codec itself. Much is at stake in this infrastructure and image logistics from the perspective of cultural studies of technology and media.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  On the one hand, codecs analyse, compress and transmit images that fascinate, bore, fixate, horrify and entertain billions of spectators. Most of these images are repetitive or clichéd. They reinforce or shore existing orderings of difference, identity and power. There are many reruns of old television series or Hollywood classics. Youtube.com, a video upload site, currently offers 13,500 wedding videos. Yet the spatio-temporal dynamism of these images matters deeply. They open new patterns of circulation and permit new symbolic differences to appear. To understand that circulation matters deeply, we could think of something we don’t want to see, for instance, the many executions of hostages (Daniel Perl, Nick Berg and others) in Jihadist videos since 2002.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Islamist and ‘shock-site’ web  142 Adrian Mackenzie  such events – the sight of a beheading, the sight of a journalist pleading for her life – depends on circulation through online and broadcast media. A video beheading lies at the outer limit of the visual pleasures and excitations attached to video cultures. Would a beheading, a corporeal event that takes video material culture to its limits, occur without codecs and networked media? We need to understand how media infrastructures such as codecs envelop differences such that differences, modifications and variations in sensibility, subjectivities and institutions arise. From Eye to Infrastructure: Envisioning Centres of Calculation One way to glimpse the different path opened up by Deleuze’s account of subrepresentative differences is to contrast it with the now canonical approaches to technology developed by science studies in the 1980s and 1990s. From a science and technology studies (STS or SCOT) perspective, we could say that the compression techniques presented in 1970s patents began to anchor centres of calculation in the midst of the chaotic, surging flows of cinematic, televisual and video images. A centre of calculation is, according to Bruno Latour, ‘any site where inscriptions are combined and make possible a type of calculation. It can be a laboratory, a statistical institution, the files of a geographer, a data bank, and so forth.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  This expression locates in specific sites an ability to calculate that is too often placed in the mind’ (Latour 1999: 304). A codec is a site where calculations are done on images. Why should images need calculation? Ostensibly, the patents addressed the logistics of moving images. They proposed different ways of doing this: an ‘apparatus capable of performing a discrete cosine transform with lightweight, low-cost, high-speed hardware suitable for real-time television image-processing’ (Means 1974: 1); ‘a linear transform device capable of the rapid generation of linear transforms of a spatial or temporal signal’ (Speiser 1975: 2); or a ‘system for encoding a present frame of video signals comprising means for dividing the picture elements of the present frame into moving and nonmoving regions’ (Haskell and Limb 1972). Moving images and, to a lesser extent, sound indeed pose logistical problems. People in electronic media cultures have constantly imagined images circulating everywhere. Millions of images flicker across TV and cinema screens.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Analogue television broadcasting solved the logistics problem in a Fordist fashion: images produced in studios passed through electromagnetic waves transmitted from central stations to many identical receivers. With few exceptions, the central platform of studio and transmitter came under state and\/or large corporate ownership and control. As many studies of television and radio have shown, the forms of identity, representation  Every Thing Thinks 143  to offer interactivity, broadcast television cannot keep up with the information age’s kaleidoscopic imagining of images flowing in many directions at once. The calculations that codecs perform on images are not purely logistical. Put differently, any change in image logistics does not only concern media infrastructures. It affects embodied habits of perception, sometimes at a micro-perceptual level (sensations of brightness, colour and movement alter), sometimes at the level of mediahistorical habits (where, when and how images are made and seen), sometimes at the level of affect and temporality. Today, the calculations done by codecs take many forms and occur on many platforms: set-top boxes, mobile phones, cameras, computers, media players and other gizmos cradle codecs. Those arrangements are indeed fascinating.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  However, here I want to concentrate on the problem of how to connect embodied vision and media infrastructure. To comprehend this connection, I suggest, we need to shift attention from centres of calculation to centres of envelopment, a concept that Gilles Deleuze proposes late in Difference and Repetition. Centres of envelopment, according to Deleuze, interiorize differences in situations already structured by settled orders of representation, resemblance, extension and qualities perceived by human subjects. Such centres crop up in ‘complex systems’ where series of differences come into relation ‘to the extent that every phenomenon finds its reason in a difference of intensity which frames it, as though this constituted the boundaries between which it flashes, we claim that complex systems increasingly tend to interiorise their constitutive differences: the centres of envelopment carry out this interiorisation of the individuating factors’ (Deleuze 2001: 256). Here, I shall not be able to develop a full explanation of this concept. It comes late in Difference and Repetition, after long consideration of the constitution of time, memory, habit, difference and intensity. Importantly, the notion of a centre of envelopment is only one of a series of notions Deleuze developed to describe how differences relate to differences. Instead, I concentrate on the basic idea that a centre of envelopment interiorizes differences since this is almost a refrain in Deleuze’s thought.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Subrepresentative differences are essentially interior since they differ intensively rather than extensively. If we take the rather risky step of understanding codecs as a centre of envelopment, we could ask how codecs interiorize ‘constitutive differences’ in ways that lead to a proliferation of moving images. The functioning of codecs, their capacity to compress and move moving images in space and time and to generate sensations of qualities of colour, depth, light and form, certainly relies on calculation. However, calculation itself must derive in principle, for Deleuze, from ‘a difference of intensity’. By tracking how intensities (or differences of difference) matter in codecs, we might begin to get a feel for how video material cultures eventuate. In substituting envelopment for calculation, Deleuze allows us to shift focus from extension to intensity, and thereby to describe how altered feelings, expectations and transformed sensibilities occur in and around technologies. If every thing expresses an Idea, if ‘our  144 Adrian Mackenzie  imperative of an idea, then feelings, sensibilities and expectations of ‘more to come’ might be seen as symptoms of the impersonal individuations set in train by differences. Spatio-temporal Dynamisms and Differences in Repetition The concept of centre of envelopment addresses something quite elementary: the persistence of intensities, singularities and purely spatial dynamisms in worlds largely organized by systems that order, calculate and represent.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  A centre of envelopment is like a microstructural black hole peppering the fabric of the everyday, constantly interiorizing elementary differences that give rise to phenomena, and serving as a site of actualization for problem-setting ideas. According to Deleuze, ‘disparity … difference or intensity … is the sufficient reason of all phenomena’ (Deleuze 2001: 222). The problem in developing this philosophical perspective into an analytical engine for an anthropology of technology is that the technology of video codecs seems thoroughly actual. How do the densely interwoven calculations that codecs perform on images and sounds participate in what Deleuze called the ‘asymmetrical synthesis of the sensible’ (Deleuze 2001: 222), or the ordinary everyday sensibilities of electronic media as they play out on information networks today? Spatio-temporal dynamisms are critical here. As mentioned above, the primary characteristic of codecs is to allow digital images to move around in many forms. Video iPods, digital cameras, mobile phones, media players, DVDs, satellite broadcasts or Internet media encode and decode video streams. Starting from the 1970s patent lineages, several decades of heavily funded public and private research have gone into liberating moving images from the bulkiness of film stock and projects and the fixity of television transmitters and television sets.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Tens of thousands of patents litter the wake of that research begun in the early 1970s. Today, probably the most widespread video or moving image codec is MPEG-2, which stands at the confluence of several lineages of image encoding. DVDs, for instance, consist of MPEG-2 files. The International Standards Organization (ISO) formalized the MPEG-2 (aka H.262) encoding and decoding procedures as a standard (ISO\/IEC 13818–1, 1999) in the early-1990s. The standard calls itself a ‘transport system’ (ISO\/IEC 13818–1, 1999). The standards documents grew from the work of several thousand engineers and software designers meeting in Europe and North America. Other engineers implement the arrangements described in the documents in software or hardware codecs (coder–decoder). Video codecs for different standards (MPEG-1, MPEG-2, MPEG4, H.261, H.263, the important H.264, theora, dirac, DivX, MJPEG, WMV, RealVideo, etch) litter electronic media networks.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Any codec that implements the MPEG-2 coding standard incarnates extraordinarily  Every Thing Thinks 145  compensation, timing and multiplexing mechanisms, retrieval and sequencing techniques. The standard borrows from the earlier, lower-resolution video standard, MPEG-1 (ISO\/IEC 11172–1, 1993), and from other image standards, such as JPEG. Legally, it imposes relations with many intellectual property claims (700 patents held by entertainment, telecommunications, government, academic and military owners administered through the MPEG-LA patent pool). Finally, it competes with many other codecs (e.g. Chinas AVC – Advanced Video Codec – versus the increasingly popular H.264 versus other versions such as Microsoft Windows VC-1 – Windows Media 9). At the intersection of technical, legal and economic forces, codecs display a mosaic, composite character. They make sensible compromises between extensity and quality, between how images circulate (online, in media materials and transmission formats) and the sensations (brightness, detail, luminance, etc.) associated with them.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Their composite character reflects a constant and dynamic negotiation between the political economy of telecommunications and the media-historical perceptual habits of visual cultures. Telecommunications and media companies create cable, satellite and wireless network bandwidth as a market commodity. They sell bandwidth to anyone who will pay for information and images to move. At a very deep level, the architecture of an MPEG-2 codec reflects the assumption that all movement costs something in time, computation or bandwidth. Reducing the cost of movement means that more people can pay for that movement. If a codec compresses images, it makes their movement more likely. However, any reduction in image size has to take into account human eyes, just as every reduction in the space between airline seats should take into account the postures and shapes of passengers’ bodies. Eyes and ears do not have universal, timeless physiological properties.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  They have media-historical habits. Electronically mediated visual culture shapes eyes and ears and creates perceptual habits at many levels. For instance, the conventions of the rectangular 4:3 ratio TV screen, the 16:9 ratio cinema screen, the number of scan lines or the colour models of PAL\/NTSC television broadcasts go deep into visual habits. Sensations of colour, texture, brightness and level of detail all feed into habits of viewing. The video codecs behind DVDs, High Definition Television, mobile TV for 3G cellular telephones, RealPlayer or satellite digital video broadcast attempts to take those expectations into account and meld them with the limited channel capacities of networks, broadcast spectrum or cables. This outline of the situation of MPEG-2 codecs suggests that the spatio–temporal dynamisms found in a centre of envelopment link very different scales, levels and orders of movement and difference. Codecs make trade-offs between micro-perceptual sensations of brightness, colour, resolution and movement in trying to meet constraints concerning the cost of bandwidth on satellite or cable infrastructures (for instance, SkyChannel, a UK-based digital satellite TV broadcaster, uses MPEG-2 compression to transmit many channels from one satellite). An analysis of trade-offs between image quality and media logistics could determine how the codec mangles or blends different  146 Adrian Mackenzie  ‘[m]en [sic] and things exchange properties and replace one another’ (Latour 1996: 61).\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The sheer volume of moving images, their extension, repetition and multiplication, would correlate with changes in their quality. This approach to technological projects as a series of compromises or exchanges can yield rich results. However, any analysis of trade-offs between extension (or distribution) and image quality remains fundamentally conservative in relation to differences. Here Deleuze’s thought opens a very different path. Deleuze links repetition to irreducible differences. For every instance of repetition, Deleuze suggests, we need to look for the hidden repetition or resonances between differences. The system of resonances between differences comprises an idea. ‘Ideas have the power to affirm divergence; they establish a kind of resonance between divergent series’ (Deleuze 2001: 278).\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  It is ‘pure movement’ (ibid. : 24) or the dynamic of an idea in process of becoming, organizing and unfolding a time and space in which repetition occurs. ‘Every thing thinks’ (ibid. : 254) because every thing, no matter how banal, ordinary, repetitive or singular, occurs within spatio-temporal processes that unfurl from movement inherent to an Idea. Movements of becoming ‘are’ the mode of existence of the dissimilar, the different or the unequal (Deleuze 2001: 128). Transformation into Tendencies In contrast to the notion of problematization that Paul Rabinow has distilled from the work of Michel Foucault (Rabinow 2003), the problem imperative of an idea is not primarily concerned with truth and falsehood. It is based on a distribution of the singular and the ordinary. This can be illustrated by one of the two main ways in which video codecs handle differences and repetition in images.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  It comes from the first lineage of patents. This lineage treats human vision as a sub-representative process that detects differences in brightness, illumination and shadow rather than seeing things. For the purposes of image transmission, variations in brightness and colour count more than the typical analysis of representations in terms of figures, figure–ground relations, forms and contents. In MPEG-2, the discrete cosine transform (DCT) treats a video frame (or field) as a spatially extended distribution of brightness and colour. This treatment bears no resemblance to the figures and forms found in a given frame. It slices each frame into three separate planes: one of luminance (brightness) and two of chrominance (colour). The most detailed spatial calculation done by the codec on video images begins by analysing luminance of different areas in the picture. (It handles colour planes as larger blotches or patches.)\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The transform coding process seeks to elicit forms of repetition or redundancy from the variations of luminance across the plane of the image: the  Every Thing Thinks 147  sequence, a well-defined order of increasing or decreasing values of luminance or chrominance. The codec defines a transformation that summarizes or contracts the relations between the individual adjacent pixels as a series (the sum of the sequence) or as a periodic function that expresses variations of luminance and chrominance. It transforms a spatially extended distribution of pixels into a function, which can then be expressed as a series (for reasons explained below). The transformation pivots on the fact that the information content of an individual pixel is relatively small because by far the majority of adjacent pixels in a given image are identical. Tendencies or variations of colour or brightness across the plane of the image have more value than any particular element of the image. The discrete cosine transform treats each image as a set of periodic signals or waveforms. Once transformed into a periodic signal, it can be broken down into a series of component cosine waves of different frequencies. For a given signal, some of the component waves contribute more energy to the overall signal than others.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The transform coding selects only the most energetic or high-amplitude components and discards the rest. In more technical terms, the transform coding extracts the components of the signal with greatest spectral density. It reduces repetition (and hence storage space or transmission) by extracting the differentiating or individuating traits of luminance and chrominance in the image. When MPEG-encoded images are displayed on some screen, the decoding process reconstructs an image from the series. It assigns values of luminance and chrominance to pixels on the screen on the basis of the coefficients in the series. It unfolds the displayed image by putting parts of it back together. A great deal more could be said about the provenance and development of the discrete cosine transform. It has a rich and continuing history of development coming out of natural sciences and communications engineering.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The important point is, that via such techniques, codecs in a certain sense perceive the image. The spatio-temporal dynamisms they introduce in electronic media cultures concern how far this movement of perception can go. These dynamisms do not only exchange properties between human and things. Deleuze’s thought diverges from any exchange-based account of these dynamisms. Deleuze writes: ‘Every spatio-temporal dynamism is accompanied by the emergence of an elementary consciousness which itself traces directions, doubles movements and migrations, and is born on the threshold of the condensed singularities of the body or object whose consciousness it is’ (Deleuze 2001: 220). In its analysis of spectral density and selection of the most energetic component of the signal, the codec isolates tendencies or emphases. Perhaps this is something that also occurs in bodily perception. It treats what can be seen in an image as composed of tendencies and emphases that can be seized in a contractile movement.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The codec embodies an ‘elementary consciousness’, an awareness of transitions, of variable distributions of light and colour. It contracts variations of luminance and chrominance distributed across the plane of the image. Transform compression addresses the  148 Adrian Mackenzie  The transform compression turns spatially distributed or extended repetition into transient differences expressed by coefficients of the different component frequencies. It synthesizes space and time differently. The movement of contraction and the elementary consciousness it presupposes no longer occur only in the bodies of seeing subjects, but also in the technical apparatus of the codec and hence in assorted media technologies. Already here, we see how a thing expresses an idea, if an dea can be understood as a problem-setting system of differential elements (eyes, infrastructures, screens, images, calculations, etc.) that form centres of envelopment around singularities. Intensities and Differences in Sameness By rendering an image as a set of (digitized or ‘quantized’) waveforms, MPEG-2 deeply fissures the objecthood of visual representation.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Digital signal processing intimately concerns sensation rather than representation (of objects or figures). It processes brightness and colour, without concern for form or figure in an image. In its analysis of spectral density and selection of the most energetic component of the signal, it isolates tendencies or emphases. It treats an image as composed of tendencies and emphases that can be seized in a contractile movement and summed as a series. The codec connects two apparently ontologically distant entities, eyes and media infrastructures. They articulate embodied sensations of light and colour with the economically valuable markets for bandwidth of information and communication infrastructures. However, everything discussed so far concerns the extension of images in the world, and how to move images around more often, in greater numbers. Where are the interiorized differences characteristic of centres of envelopment?\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  One could say that codecs devote themselves to the reduction of difference (and this would be very much in line with critical theory and phenomenology’s general treatment of media). They multiply the repetition of the same. In extending the reach of images, they constitute an extensity for video. In particular, we could say that the compression of the image responds to a demand for sameness (Terranova 2004: 136). The demand is for the same qualities of brightness and chrominance wherever the image goes. Yet something more is at stake in codec than massive reproduction of sameness. In Deleuze’s account of the synthesis of the sensible, perceptions of extension and quality derive from differences, and particularly from intensity: ‘The extension and “extensity” (the result of the process of extending) of phenomena in space–time and qualities of sensation (qualia such as ‘redness’) attached to phenomena flow from a ‘deeper disparateness’ or ‘difference in intensity’ (Deleuze 2001: 236). Basically, intensities bind differences to each other.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  When differences come in relation to each other, intensities arise. Deleuze defines intensity as ‘a difference which  Every Thing Thinks 149  biological, psychic, social, aesthetic or philosophical, or some mixture of these. Intensities inhabit sensation. An account of technology in terms of intensities would be somewhat novel. Intensities arise when differences come into relation. Just as the DCT turns the spatial distribution of brightness and colour of an image into a series of frequency components, in Difference and Repetition Deleuze developed a series-based explanation of intensity. Deleuze abstractly understands differences as series: ‘The first characteristic seems to us to be organisation in series. A system must be constituted on the basis of two or more series, each series being defined by the differences between the terms which compose it’ (Deleuze 2001: 117).\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  According to the quasi-mathematical notion of series, each term in a series differs from the preceding and following terms: A’ – A’’ – A’’’ – A’’’’ – etc. Deleuze says that intensity arise from two or more series of differences in relation. Within the codec, DCT literally generates one set of series or one set of differential relations. What is the other series? Motion Estimation: ‘the Embedding of Presents within Themselves’ MPEG video never flickers. The second lineage of patents, starting in the 1970s, took movement as its problem. Using techniques they inherit from that lineage, MPEG codecs perform a second major calculation called motion compensation. Transform coding treats individual pictures themselves as spatial distributions of luminance and chrominance values to be reorganized in series.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Motion compensation, in contrast, treats the relation between successive pictures in terms of vectors of movement. MPEG video never flickers because it calculates and predicts transitions between pictures. It dismantles the temporally discrete recording, storing and transmitting of pictures put in place by filmstrip or television. Film frames and analogue video ‘fields’ have fixed boundaries. They leave the habits of human perception to bridge between frames. In video codecs, calculation fills in the gap between frames. Again, the technical apparatus of the codec takes on part of the work of embodied perception in the interests of changing the relation between body and media infrastructure. In order to do this, components of the codec involved in motion estimation assume that nothing much happens between successive frames apart from spatial transformations (translation, rotation, skewing, etch) of parts (macro-blocks) of the image.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  In the process of encoding a video sequence, the MPEG-2 codec analyses each picture in relation to a previous and a future reference picture. It calculates and transmits a series of motion vectors describing how different parts of the frame move  150 Adrian Mackenzie  (pans, tilts, zoom in) and then ascribe different motivations to movement. MPEG-2 decomposes every movement into the directions and rate of movement of macroblocks. A typical PAL DVD image contains roughly 800 macro-blocks. At 30 frames\/sec, the codec tracks the movement of roughly 24,000 macro-blocks. The ‘pictures’ streamed on the Internet, downlinked via satellite or burned on DVD mostly comprise long series of vectors describing blocks in motion. Decoding the MPEG stream means turning these vectors back into patterns of blocks moving around in frames on the screen. The decoding side of a codec frenetically recomposes images from blocks moving in all directions.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  We could view motion compensation as a second series of differences. Motion compensation alters the temporality of moving images. We have already seen that, in a first centre of envelopment, transform coding contracts the image into a series of differences of brightness and colour. In motion compensation, the image or picture itself is no longer the elementary component of motion perception. Motion compensation reorganizes the picture into series of motion vectors describing relative movements of blocks in time. Images in Overflow What happens when these two series come into communication in the codec? According to Deleuze, when series of differences communicate with each other, spatiotemporal dynamisms emerge: ‘Once communication between heterogeneous series is established, all sorts of consequences follow within the system. Something passes between the borders, events explode, phenomena flash, like thunder and lightning.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Spatio-temporal dynamisms fill the system, expressing simultaneously the resonance of the coupled series and the amplitude of the forced movement which exceeds them’ (Deleuze 2001: 118). As centres of calculation, codecs repeat and render images with a strong concern for accurate repetition. The MPEG-2 bitstream and most other contemporary video codecs put two different series in relation. First they generate a series of values that express a key frame, and then they generate a series of values that express how elements of that key frame move. However, as centres of envelopment, they also do something that lies at the heart of technological repetition. Deleuze refers to this in terms of events, explosions, excess and flashes. Where do we see these? In a sense, the consequences can be seen everywhere today in the growth of video material culture.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  A preliminary analysis of the spatio-temporal dynamisms could examine ways in which images have become extended and new qualities of images emerge as they proliferate. The first facet concerns the spatio-temporal dynamism of calculation done within  Every Thing Thinks 151  transmission channel and the size of the display screen. In an MPEG-2 datastream, the Group of Pictures (GOP) structure defines the precise mixture of different picturetypes at encoding time. A GOP usually has twelve or fifteen pictures in a sequence such as I_BB_P_BB_P_BB_P_BB_P_BB_. The order of the pictures in a GOP does not correspond to their viewing sequence. A dozen or so block motion-compensation frames follow one transform-coded I-picture. The ratio of different picture types in a bitstream directly affects the encoding time, the transmission time and the decoding time. Calculating motion compensation is much slower than the highly optimized block transforms.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Yet motion vectors take much less time to transmit than transform-coded pictures. (Some DVD players offer an option that displays the bit rate of the images on screen. Variations in this bit rate indicate different ratios of DCT and motion estimation being done by the player’s codec.) Even the drastically simplified description I have given should indicate that both transform coding and motion compensation entail much comparison, sorting and shifting of numerical values around in arrays. The time and cost of this calculation can be high, and every reduction of them matters. Practically, codecs must make direct trade-offs between computational time and bandwidth\/storage space. A highly compressed image will take longer to generate but require less storage space or network bandwidth. The trade-offs made in encoding sometimes result in artefacts visible on screen, such as blocking and mosaic effects.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  At times, motion prediction cannot work smoothly. A change in camera shot or an edit breaks the flow of movement between adjacent frames. In that case, the codec falls back on transform coding. A momentary but visible splintering of the images – so called ‘motion blocking’ – occurs. Whereas film flickers, digital video ‘motion-blocks’. Motion blocking appears as horizontal and vertical edges where the MPEG-2 motion compensation algorithm has sliced the image into macro-blocks. (We could also look at ‘reordering delay’, a ‘delay in the decoding process that is caused by frame reordering’ [ISO\/IEC 13818–1, 1999]). All of these fringe effects and the technical design processes that trade-off between different forms of compression and rendering of images come from the space-time of calculation itself.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The second facet concerns the spatio-temporal dynamism of video materials on contemporary mediascapes. If we ignore all the physicalities of spectatorship, video encoded and decoded by codecs probably looks much the same. Much effort has gone into making them look the same or almost the same. In fact, researchers and standards organizations such as the ITU (International Telecommunications Union) have developed complicated testing regimes that distinguish objective versus subjective video quality. Are these visible artefacts, themselves the effect of technical compromises made in the name of cost, the only sign of an event for a codec, the only phenomena that flash and explode? Videos might look the same but circulate very differently. As Deleuze writes, ‘difference pursues its subterranean life while its image reflected by the surface is  152 Adrian Mackenzie  work on framing, resolution, brightness, colour and movement. Yet this sameness envelops a very different relation to infrastructure.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  It generates powerful spatio-temporal dynamics in the relation between eye and infrastructure. Video churns on the Internet. Video streams and broadcasts surge (satellite TV, digital high definition, Web). New ecologies of spectatorship, consumption and occasionally citizenship both mimic and differ from cinema and television spectatorship. As formats, platforms and products mushroom and new forms of making, viewing and moving populate flows of images. Finally, the two lineages of patents I mentioned at the beginning of the chapter suggest another spatio-temporal dynamism or ‘forced movement’ around codecs. Almost 700 patents apply to the MPEG-2 standard (http:\/\/www.mpegla.com\/m2\/m2–patentlist.cfm). Tremendously tight intellectual property arrangements bind the codecs.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  Each aspect of the codec calculations we have been discussing undergoes intensive variation as slight reductions in computational costs and detours around existing intellectual properties are sought out. Centres of envelopment interiorize differences: ‘we claim that complex systems increasingly tend to interiorise their constitutive differences’, writes Deleuze (2001: 256), and at the same time give rise to spatio-temporal dynamisms, patterns of extension and qualitative differences on multiple scales. As things that think, how do codecs interiorize ‘constitutive differences’? The MPEG-2 codec, I have suggested, can be understood as a composite process of change in the relations between eye and media infrastructure. An intensity inhabits these relations. Deleuze describes an eye as ‘bound light’: ‘An animal forms an eye for itself by causing scattered and luminous excitations to be reproduced on a privileged surface of its body. The eye binds light, it is itself a bound light’ (ibid. : 96).\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The codec also binds light, but not just to ‘privileged surfaces’ of the body. It binds light to the movement of images in media infrastructures. It causes some forms of luminance, chrominance and movement to be reproduced on ‘privileged surfaces’ within media technologies. In order to do this, different temporal syntheses must come into relation: the habit-based contraction of perception in DCT; the embedding of presents in each other in motion estimation. The relation between transform coding and motion estimation, between the technical treatments of luminance–chrominance and movement, is however unstable. It envelops or comprehends some aspects of the movement of images, but not all of them: ‘each intensity clearly expresses only certain relations or certain degrees of variation. Those that it expresses clearly are precisely those on which it is focused when it has the enveloping role. In its role as the enveloped, it still expresses all relations and all degrees, but confusedly’ (Deleuze 2001: 252).\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The MPEG-2 codec clearly expresses only certain relations between eye and infrastructure. It focuses on brightness, colour and movement of images as framed by the history of photography, cinema and television but puts these in relation to the political economy of telecommunications (with its constraints on bandwidth, memory,  Every Thing Thinks 153  patents – transform coding and motion estimation – represent different treatments of repetition in digital video. When transform coding and motion estimation come together in MPEG-2, different spatio-temporal dynamics and forms of interiorization result. Interiorization occurs when the spatio-temporal phenomena begin to cover over the intensities that gave rise to them. A proliferation of patents around codecs occurs. At the same, the trade-offs made between computation and bandwidth in the MPEG-2 codecs mean that the physical forms of codecs proliferate in chips, software, gadgets and boxes. Finally, the circulation of video itself changes. New ecologies of images burgeon.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  The codecs, I have been arguing, envelop relations between eye and infrastructure. Does it make any difference that the streaming digital video of decapitation never flickers? It could be argued that the intensive paths generated by codecs in the extension of images make no difference to the viewers. In other words, viewers might see straight through the codecs. They might not be seen. For viewers, however, execution and hostage videos and vast pools of pornography open up alongside the streams of wedding, baptism and graduation videos. Viewers may not be highly conscious of how brightness, chrominance and movement have been minutely altered by the codec. These differences can be easily cancelled out or remain almost imperceptible.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  This does not mean that they make no difference. On the contrary, the proliferation of video materials and the degrees of variation opening up around video streams today suggest that viewers are caught up in the spatio-temporal dynamisms of video material culture. The Idea that Thinks the Thing How far have we come in thinking technologies as thinking things? No thing is a pure expression of an idea. An idea cannot be thought as such. Moreover, things inhabit already structured worlds. Hence, Deleuze’s notion of a centre of envelopment, a site for actualization of an idea in worlds organized by systems of extension and quality, reflects the need to accommodate in any radically constructivist account of things the existing orders of representation, personhood and identity. Certainly, nothing of what I have said of codecs belongs solely to advanced technologies.\n"}
{"prompt":"Every Thing Thinks: Sub-representative Differences in Digital Video Codecs ->","completion":"  It is not as if codecs think more than, say, photographs, rock carvings or oilpaintings. The singularity of codecs, the different worlds to be found in them, come from the intensities they put in relation. Those differences actualize in the spatio-temporal, scale-transforming dynamics of video material culture. Why privilege the two patent lineages and the series of transformations they produce in the moving images as the locus of differences? The patent lineages stand in the discussion above as centres of envelopment, as tendencies that attract much mental effort to create new variants, versions and modifications as well as property claims. 154 Adrian Mackenzie  we cannot treat an idea as a concept, a construct that represents or holds difference in identity. It is a system of ‘positive, differential multiplicity’ (Deleuze 2001: 288) that needs to be thought from a radical constructivist viewpoint. The effort to think oriented by a radically constructivist alignment is particular relevant to composite things that exist in a flux of documents, international standards, versions, software and hardware implementations and diverse and constantly decentred applications.\n"}
